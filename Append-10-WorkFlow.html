
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>附录 K：贝叶斯工作流程 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="附录 J：贝叶斯优化" href="Append-09-BayesianOptimization.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  书籍正文
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第 3 章 线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较与模型平均
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter08-InterefenceEngine.html">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  文献阅读
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Append-01-MCMC_Tutorial.html">
   附录 A： MCMC 推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-02-VariationalInference_Tutorial.html">
   附录 B： 变分法推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-03-GaussianProcessTutorial_01.html">
   附录 C： 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-04-BayesianNN_Tutorial.html">
   附录 D：贝叶斯神经网络
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-05-BayesianDeepLearning_Tutorial.html">
   附录 E：贝叶斯深度学习
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-06-BayesianDeepLearningPymc3.html">
   附录 F：贝叶斯深度学习编程初步
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-07-ModelAveraging.html">
   附录 G：模型平均
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-08-ModelEnsembling.html">
   附录 H：模型集成
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-09-BayesianOptimization.html">
   附录 J：贝叶斯优化
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   附录 K：贝叶斯工作流程
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/Append-10-WorkFlow.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Append-10-WorkFlow.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd/issues/new?title=Issue%20on%20page%20%2FAppend-10-WorkFlow.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xishansnow/BayesianAnalysiswithPython2nd/master?urlpath=lab/tree/Append-10-WorkFlow.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/xishansnow/BayesianAnalysiswithPython2nd&urlpath=lab/tree/BayesianAnalysiswithPython2nd/Append-10-WorkFlow.md&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   1 概述
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     1.1. 从贝叶斯推断到贝叶斯工作流
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1.2 为什么需要贝叶斯工作流？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     1.3. 工作流及其与统计理论和实践的关系
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     1.4 组织贝叶斯工作流的诸多方面
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     1.5. 文章的目的和结构
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   2 在拟合模型之前
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     2.1 选择初始模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     2.2 模块化构建
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     2.3 缩放和转换参数
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     2.4 先验预测性检查
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     2.5 生成式和部分生成式模型
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   3 拟合一个模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     3.1 初值、适应和预热
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     3.2 运行迭代算法需要多长时间
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     3.3 近似算法和近似模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     3.4 快速拟合，快速失败
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id18">
   4 使用人为构造的伪数据发现和理解问题
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     4.1 伪数据模拟
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     4.2 基于模拟的较正
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     4.3 使用构造的数据进行实验
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id22">
   5 解决统计计算问题
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id23">
     5.1 统计计算的通俗理论
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id24">
     5.2 从简单和复杂的模型开始并在中间相遇
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id25">
     5.3 掌握需要很长时间才能拟合的模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id26">
     5.4 监控中间量
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id27">
     5.5 堆叠以重新加权混合不良的链
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id28">
     5.6 具有多峰和其他困难几何形状的后验分布
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id29">
     5.7 问题的重新参数化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id30">
     5.8 边缘化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id31">
     5.9 增加先验信息
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id32">
     5.10 增加数据
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id33">
   6 评估和使用拟合后的模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id34">
     6.1 后验预测性检查
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id35">
     6.2 单个数据点和数据子集的交叉验证和影响
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id36">
     6.3 先验信息的影响
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id37">
     6.4 对推断结果进行总结
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id38">
   7 修改模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id39">
     7.1 为数据构建模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id40">
     7.2 合并额外的数据
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id41">
     7.3 使用先验分布
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id42">
     7.4 模型拓扑
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id43">
   8. 理解和比较多个模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id44">
     8.1 可视化彼此相关的模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id45">
     8.2 交叉验证和模型平均
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id46">
     8.3 比较大量模型
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id47">
   9 把建模当做软件开发
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id48">
     9.1 版本控制使与他人和你过去自己的协作顺利进行
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id49">
     9.2 边运行边测试
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id50">
     9.3 使其基本上可重现
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id51">
     9.4 使其具有可读性和可维护性
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id52">
   10. 包含模型构建和模型扩展的工作流示例：高尔夫推杆
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id53">
     10.1 第一个模型：逻辑回归
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id54">
     10.2 从第一原则建模
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id55">
     10.3 在新数据上测试拟合后的模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id56">
     10.4 一种解释击球力度的新模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id57">
     10.5 通过加入一个模糊因子来扩展模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id58">
     10.6 高尔夫示例的一般教训
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id59">
   11 具有不可预期的多峰后验的工作流示例：行星运动
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id60">
     11.1 运动的机械模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id61">
     11.2 拟合一个简化模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id62">
     11.3 坏马尔可夫链，慢马尔可夫链？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id63">
     11.4 建立模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id64">
     11.5 行星运动示例的一般经验教训
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id65">
   12 讨论
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id66">
     12.1 统计建模和预测的不同视角
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id67">
     12.2 迭代式模型构建的必要性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id68">
     12.3 模型选择和过拟合
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id69">
     12.4 更大的数据集需要更大的模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id70">
     12.5 预测、泛化和后分层化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id71">
     12.6 继续往前走
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id72">
   参考文献
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id73">
   引文信息
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="k">
<h1>附录 K：贝叶斯工作流程<a class="headerlink" href="#k" title="Permalink to this headline">¶</a></h1>
<p>【摘要】贝叶斯数据分析方法为使用概率论处理观测、模型参数和模型结构中的所有不确定性提供了一种强大方法。概率编程语言使指定和拟合贝叶斯模型变得更加容易，但这仍然给我们留下了许多关于构建、评估和使用这些模型的选择，以及许多计算方面的挑战。使用贝叶斯推断解决实际问题不仅需要统计技能、学科知识和编程，还需要在数据分析过程中做出决策。所有这些方面都可以理解为应用贝叶斯统计的复杂工作流程的组成部分。除了推断以外，工作流还包括迭代模型构建、模型检查、计算问题验证及故障排除、模型理解和模型比较等。本文在几个示例背景下，回顾了工作流的各个方面。需要提醒读者：在实际工作中，应当为任何给定的问题拟合多个模型，即使最终可能只有非常有限的子集能够与结论相关。</p>
<p>【原文】Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and Burkner, Paul-Christian and Modrak, Martin; <strong>Bayesian workflow</strong>; arXiv:2011.01808}; 2020.</p>
<style>p{text-indent:2em;2}</style>
<div class="section" id="id1">
<h2>1 概述<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id2">
<h3>1.1. 从贝叶斯推断到贝叶斯工作流<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>如果数理统计是『关于如何应用统计学』的理论，那么任何对贝叶斯方法的认真讨论都需要明确其在实践中的使用方式。特别是，我们需要明确地<strong>将贝叶斯推断与贝叶斯数据分析的概念分开，特别是将其与完整的贝叶斯工作流程分开</strong>。</p>
<blockquote>
<div><p>注解： 作者强调<strong>贝叶斯推断</strong>、<strong>贝叶斯数据分析</strong>和<strong>贝叶斯工作流程</strong>的概念需要有非常明确的界定。</p>
</div></blockquote>
<ul class="simple">
<li><p><strong>贝叶斯推断</strong>：只是条件概率或概率密度 <span class="math notranslate nohighlight">\(p(\theta \mid y) ∝p(\theta)p(y \mid \theta)\)</span> 的形式化和计算，可视为一种计算工具。</p></li>
<li><p><strong>贝叶斯工作流</strong>：包括<strong>模型构建</strong>、<strong>统计推断</strong>和<strong>模型检查/改进</strong> 三个步骤，以及不同<strong>模型之间的比较</strong>（ 这种比较不仅仅是为了模型选择或模型平均，更是为了深入理解这些模型）。</p></li>
</ul>
<p>例如：为何某些模型无法预测数据的某些方面？ 或者一些重要参数的不确定性估计为什么会因模型而不同？ 即使我们有一个非常喜欢的模型，将其与更简单和更复杂模型推断进行比较，对于理解模型也是很有用的。</p>
<p>图 1 提供了一个贝叶斯工作流程的概要。扩展的贝叶斯工作流应当还包括（在收集数据和测量数据前的）试验设计以及推断完成后的决策制定，不过本文重点在于对数据进行建模。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211210110642-1649.webp" /></p>
<blockquote>
<div><p>图 1：在贝叶斯工作流中考虑的主要步骤。括号中的数字对应本文中讨论相应步骤的章节。该图旨在显示单个贝叶斯分析可能经历的步骤和路径，当然同时应该理解任何特定分析都不太可能涉及所有这些步骤。我们研究工作流程的目标之一是掌握这些想法是如何组合在一起的，以便更系统地使用它们。</p>
</div></blockquote>
<p>在典型贝叶斯工作流程中，我们最终会拟合出一组模型，其中某些模型可能是糟糕的选择（ 原因包括：数据拟合不佳、缺乏与实际理论或实际目标的联系、先验太弱/太强/不合适、编程错误等）；另外一些模型有用但可能存在缺陷（例如： 无依据地随意选择混杂因素或变量进行回归、只选择了捕获部分而非全部功能关系的参数形式等 ）；另外一些的最终结果可能值得采纳。</p>
<p>在实践中，必须认识到：错误模型、有缺陷模型都会是拟合有用模型无法避免的前驱步骤。理解这一点有助于帮助我们改变应用和配置统计方法的方式。</p>
</div>
<div class="section" id="id3">
<h3>1.2 为什么需要贝叶斯工作流？<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>我们需要贝叶斯工作流程的原因很多，不仅仅是贝叶斯推断。</p>
<ul class="simple">
<li><p><strong>贝叶斯方法本身就是不断试错的过程</strong>。计算可能是一项挑战，但是为了获得可信的推断，我们还是不得不经常完成各种步骤，包括：拟合更简单的或替代的模型、做不太准确但速度更快的近似计算、摸索拟合过程等。</p></li>
<li><p><strong>数据的动态性需要不断调整模型</strong>。在困难问题中，通常无法提前知道想要拟合什么样的模型。即便在极少数情况下提前选择了可接受的模型，也通常会在增加数据时或需要对数据进行更详细解释时调整它。</p></li>
<li><p><strong>模型对比和理解的需要</strong>。即使数据是静态的，并且我们知道要拟合的模型，拟合也没有问题，我们也仍然希望理解模型及其与数据的关系，而这种理解往往必须通过模型比较才能实现。</p></li>
<li><p><strong>模型自身不确定性的需要</strong>。有时不同的模型会得出不同的结论，但没有一个是明显有利的。在这种情况下，展示多个模型有助于说明模型选择的不确定性。</p></li>
</ul>
</div>
<div class="section" id="id4">
<h3>1.3. 工作流及其与统计理论和实践的关系<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>工作流在不同上下文中具有不同的含义。就本文而言，工作流比 『案例』 更通用一些，但又不如 『方法』 那样足够精确（ 见图 2 ）。实际上，我们受到了计算中有关工作流想法的影响。这些想法包括一些统计上的进展（例如 <code class="docutils literal notranslate"><span class="pre">tidyverse</span></code> ），有些进展可能不是特别贝叶斯，但具有类似的体验式学习的感觉（ <code class="docutils literal notranslate"><span class="pre">Wickham</span> <span class="pre">and</span> <span class="pre">Groelmund,</span> <span class="pre">2017</span></code> ）。机器学习的许多最新进展都具有类似即插即用的感觉：它们易于使用、易于试验，并且让用户有一种健康的感觉，即拟合模型是一种从数据中学习某些东西的方式，而该方式可能无需表达对某种概率模型或统计假设的承诺。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211210114936-bcfd.webp" /></p>
<blockquote>
<div><p>图 2：统计方法学的元工作流程，代表了新想法首先出现在案例中，然后被形式化为专项研究，编制成工作流程，被赋予一般通用实现方法，并最终形成理论的主题。</p>
</div></blockquote>
<p>图 2 显示了我们对统计方法学发展的看法，即 『 <strong>实例 –&gt; 专项研究 –&gt; 工作流 –&gt; 方法 –&gt; 理论</strong> 』 的编码过程。并非所有方法都能达到最终的数学抽象级别，但纵观统计学历史，我们已经看到很多在特定实例、风格化案例、新问题中的工作流等背景下开发的方法，其中很多在可能的情况下，都做了形式化、编码和理论研究。</p>
<p>理解图 2 的一种方法是沿着这条路径从左向右移动地理解统计史上的一些重要思想。有许多想法最初是作为黑客或与统计相关的工具开始的，最终被形式化为方法并进入统计学的核心。</p>
<p>例如：</p>
<ul class="simple">
<li><p><strong>分层建模</strong>扩展了模型以便将关于先验的推断纳入到完全贝叶斯框架中，并被形式化为对先验分布的经验贝叶斯估计。</p></li>
<li><p><strong>探索性数据分析</strong>可以理解为一种预测模型检查的形式（ <code class="docutils literal notranslate"><span class="pre">Gelman,</span> <span class="pre">2003</span></code> ）。</p></li>
<li><p>诸如 Lasso ( <code class="docutils literal notranslate"><span class="pre">Tibshirani,</span> <span class="pre">1996</span></code> ) and Horseshoe ( <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ) 等<strong>正则化方法</strong>已经取代了回归任务中的临时变量选择工具。</p></li>
<li><p>高斯过程（ <code class="docutils literal notranslate"><span class="pre">O’Hagan,</span> <span class="pre">1978</span></code>；<code class="docutils literal notranslate"><span class="pre">Rasumussen</span> <span class="pre">and</span> <span class="pre">Williams,</span> <span class="pre">2006</span></code> ）等<strong>非参数模型</strong>可以被认为是核平滑等程序的贝叶斯替代品。</p></li>
</ul>
<p>在上述案例还有许多其他案例中，统计方法论的框架已经通过使方法更加模块化和更有用的方式，被扩展到现有方法。</p>
<p>『工作流』 一词已逐渐在统计和数据科学中使用；参见例如 <code class="docutils literal notranslate"><span class="pre">Liu</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2005；Lins</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2008；Long,</span> <span class="pre">2009；Turner</span> <span class="pre">and</span> <span class="pre">Lambert,</span> <span class="pre">2015</span></code>。工作流的相关思想在软件开发和其他信息学领域中广为流传；最近针对从业者的讨论包括 <code class="docutils literal notranslate"><span class="pre">Wilson</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2014</span> <span class="pre">and</span> <span class="pre">2017</span></code>。</p>
<p>应用统计（不仅仅是贝叶斯统计）变得越来越计算化和算法化，这将工作流置于统计实践的中心（ 例如，参见 <code class="docutils literal notranslate"><span class="pre">Grolemund</span> <span class="pre">and</span> <span class="pre">Wickham,</span> <span class="pre">2017；Bryan,</span> <span class="pre">2017</span> <span class="pre">；</span> <span class="pre">Yu</span> <span class="pre">and</span> <span class="pre">Kumbier,</span> <span class="pre">2020</span></code> ），以及应用领域（ 例如，Lee 等 2019 年讨论了心理学研究中的建模工作流程）。</p>
<p>『贝叶斯工作流』 已被 <code class="docutils literal notranslate"><span class="pre">Savage</span> <span class="pre">,</span> <span class="pre">2016</span></code>、<code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">,</span> <span class="pre">2019</span></code> and <code class="docutils literal notranslate"><span class="pre">Betancourt</span>&#160; <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020a</span></code>表达为一个一般概念。 <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">,</span> <span class="pre">2011</span></code> 讨论了贝叶斯工作流的几个单独组件，但没有以连贯的方式进行讨论。此外，针对特定问题开发了贝叶斯工作流，如 <code class="docutils literal notranslate"><span class="pre">Shi</span> <span class="pre">and</span> <span class="pre">Stevens</span> <span class="pre">,</span> <span class="pre">2008</span></code> 以及 <code class="docutils literal notranslate"><span class="pre">Chiu</span> <span class="pre">et</span> <span class="pre">al.</span> <span class="pre">(2017)</span></code>。</p>
<p>在本文中，我们介绍了贝叶斯工作流的几个方面，希望这些方面最终能够进入日常实践和自动化软件。我们使用概率编程语言 Stan（ <code class="docutils literal notranslate"><span class="pre">Carpenter</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017;</span> </code>Stan<code class="docutils literal notranslate"> <span class="pre">Development</span> <span class="pre">Team,</span> <span class="pre">2020</span></code> ）建立了大部分工作流程，但类似的想法也适用于其他计算环境。</p>
</div>
<div class="section" id="id5">
<h3>1.4 组织贝叶斯工作流的诸多方面<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>统计工作流的教科书表达通常是线性的，不同的路径对应不同的问题情况。例如：</p>
<ul class="simple">
<li><p>医学临床试验通常从样本量的计算和分析计划开始，然后是数据收集、清理和统计分析，最后是报告 <span class="math notranslate nohighlight">\(p\)</span> 值和置信区间。</p></li>
<li><p>经济学中的观测性研究可能从探索性数据分析开始，然后为变量转换的选择提供信息，然后是一组回归分析，然后是一系列替代性声明和稳健性研究。</p></li>
</ul>
<p>本文中讨论的统计工作流程比教科书和研究文章中介绍的普通数据分析工作流程更加复杂。额外的复杂性来自以下几个地方，并且在更高级别的工作流中有许多子工作流：</p>
<p>（1）复杂模型的拟合计算本身就很困难，需要进行相当数量的实验来解决从后验分布的计算、逼近或预测模拟问题，同时检查计算算法是否按照预期执行。</p>
<p>（2）对于复杂的问题，我们通常会想到一个更复杂的通用模型（例如，包括相关性、层次结构和随时间变化的参数等特征），因此我们从已知缺少一些重要特征的模型开始，希望它在计算上更容易，并理解我们将逐渐添加特征。</p>
<p>（3）与此相关，我们经常考虑数据不固定的问题，要么是因为数据收集正在进行中，要么是因为我们能从相关数据集中抽取数据，例如民意分析中的新调查或药物试验中其他实验的数据。增加新的数据往往需要模型扩展，以允许参数变化或扩展函数形式，例如线性模型一开始可能很适合，但随着新条件下数据的增加而崩溃。</p>
<p>（4）除了拟合和扩展的所有挑战之外，通常可以通过与替代模型下的推断进行比较来最好地理解模型。因此，我们的工作流程包括用于理解和比较能够拟合相同数据的多个模型的工具。</p>
<p>统计是关于不确定性的。除了数据和模型参数中常见的不确定性之外，我们常常不确定是否正确地拟合了模型，不确定如何最好地建立和扩展模型，以及对它们的解释不确定。一旦我们超越了简单的预先分配的设计和分析，工作流程就会变得混乱，我们的重点在数据探索、实质性理论、计算和结果解释之间来回移动。因此，任何组织工作流程步骤的尝试都会过于简单，而且许多子工作流程非常复杂，足以证明它们自己的文章或书籍章节是合理的。</p>
<p>我们讨论了工作流的许多方面，但实际考虑因素（ 尤其是可用时间、计算资源和错误惩罚的严重程度 ）可能会迫使从业者走捷径。这样的捷径会使结果的解释变得更加困难，但我们必须意识到它们会被采用，并且根本不拟合模型可能比使用近似计算拟合它更糟糕（其中近似可以定义为不给出准确的总结）即使在无限计算时间的限制下的后验分布）。因此，我们描述统计工作流程的目的也是明确地将各种捷径理解为完整工作流程的近似值，让从业者就如何投资有限的时间和精力做出更明智的选择。</p>
</div>
<div class="section" id="id6">
<h3>1.5. 文章的目的和结构<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>应用统计学中有各种各样的隐性知识，并不总能将其纳入已发表的论文和教科书。本文旨在公开其中一些想法，以改进应用贝叶斯分析，同时为未来的理论、方法和软件研发提出建议。</p>
<p>我们的目标受众是：</p>
<p>(a) 应用贝叶斯统计的从业者，尤其是 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 等概率编程语言的用户。</p>
<p>(b) 面向上述用户的方法和软件研发人员。</p>
<p>(c) 贝叶斯理论和方法的研究人员，因为我们认为工作流的许多方面都没有得到充分研究。</p>
<p>在本文其余部分，我们将逐步介绍<strong>贝叶斯工作流程</strong>的各方面，如图 1 所示，从拟合模型之前要完成的步骤（ 第 2 节 ）开始，通过拟合、调试和评估模型（ 第 3-6 节 )，然后修改模型（ 第 7 节 ），并理解和比较一系列模型（ 第 8 节）。</p>
<p>第 10 节和第 11 节通过两个例子来示范这些步骤，一个例子将特征逐步添加到<strong>高尔夫推杆模型</strong>中，另一个例子通过一系列调查来解决拟合行星运动的简单模型。前者展示了新数据如何推动模型改进，还说明了扩展模型时出现的一些意外挑战。后者展示了计算中存在的挑战会造成建模的困难。两个例子都没有使用贝叶斯工作流的全部要素，但至少表明，将贝叶斯模型开发的许多方面系统化可能会有好处。</p>
<p>我们在第 12 节中梳理了一些一般性讨论，并对工作流可能存在的批评做出了回应。</p>
</div>
</div>
<div class="section" id="id7">
<h2>2 在拟合模型之前<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id8">
<h3>2.1 选择初始模型<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>几乎所有分析的起点都是从适应先前所做的工作开始的，这些先前的工作包括教科书、案例研究、已应用于类似问题的论文（有些类似软件工程中设计模式的概念）等。使用之前的一些模型并对其进行更新，是进行有效数据分析的捷径。通过对模型模板的结果分析，可以知道模型向哪个方向丰化或简化更有空间。模型模板可以节省模型构建和计算的时间，同时我们也要考虑到那些需要理解结果的人可能存在认知负担。快捷方式对人类和计算机都很重要，快捷方式有助于解释 『为什么典型的工作流程是迭代的』（更多信息请参见第 12.2 节）。类似地，如果要尝试对计算机进行编程以自动执行数据分析，则必须通过某种算法来构建模型，而这种算法的构建块就代表着某种模板。尽管 『菜谱式分析』 有很强的负面含义，但我们认为模板可以用作更精细分析的起点和比较点。</p>
<p>我们应该认识到理论的动态性，『科学理论的发展过程』与『统计模型的发展过程』并不相同（ <code class="docutils literal notranslate"><span class="pre">Navarro,</span> <span class="pre">2020</span></code> ）。</p>
<p>有些时候，我们的工作流程从一个简单模型开始，其目的就是为了稍后逐步添加特征（ 以便对不同的参数进行建模，包括测量误差、相关性等 ）。另外一些时候，我们可能会从一个大模型开始，并打算在接下来的步骤中逐步剥离一些特征，以努力找到一些简单易懂、但仍能捕获数据关键特征的东西。有时我们甚至会考虑对相同的数据采用『多种完全不同的方法』来建模，因此会存在多个可供选择的起点。</p>
<blockquote>
<div><p>注解： 这也许解释了大量阅读文献、掌握发展状态的必要性。</p>
</div></blockquote>
</div>
<div class="section" id="id9">
<h3>2.2 模块化构建<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>一个贝叶斯模型是由若干模块构建而成的，这些模块通常可被视为在必要时能够被替换的占位符。例如，我们先用<em>正态分布</em>对数据建模，然后用<em>长尾分布</em>或<em>混合分布</em>替换它；我们将回归函数建模为<em>线性函数</em>，然后将其替换为<em>非线性样条</em>或<em>高斯过程</em>；我们可以将一组观测值视为精确的，然后添加一个测量误差模型；我们可以从弱先验开始，然后当发现后验推断包含不切实际的参数值时，再增强先验。将模块视为占位符可以减轻模型构建过程的一些压力，因为你可以随时返回并根据需要概括或添加信息。</p>
<p>模块化构造的想法与统计文献中的长期传统背道而驰。在传统中，整个模型被统一命名，每次对现有模型进行微调时都会给出一个新名称。而给模型的各个模块命名，可以更容易地看到不同模型之间的联系，并使其适应给定项目的特定要求。</p>
</div>
<div class="section" id="id10">
<h3>2.3 缩放和转换参数<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>我们希望模型参数都能够被给出实际和道德原因的解释。这导致需要其尽量在自然尺度上描述，并将其建模为相互独立的（ 如果可能的话 ），或者需要这些模型参数具有可解释的依赖结构，因为这有助于使用信息性先验（ <code class="docutils literal notranslate"><span class="pre">Gelman,</span> <span class="pre">2004</span></code> ）。</p>
<p>不过分离出尺度以便未知参数变得尺度无关，也是很有帮助的。例如，在药理学中的问题中（ <code class="docutils literal notranslate"><span class="pre">Weber</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2018</span></code> ），预计有一个参数的测量尺度约为 <span class="math notranslate nohighlight">\(50\)</span> ；遵循缩放原则，我们可能会在 <span class="math notranslate nohighlight">\(\log (\theta/50)\)</span> 上建立一个模型，从而在对数尺度上的 <span class="math notranslate nohighlight">\(0\)</span> 对应了一个可解释的值（ 原始尺度上的 50 ），而 <span class="math notranslate nohighlight">\(0.1\)</span> 的差异，在对数尺度上对应于增加或减少约 <span class="math notranslate nohighlight">\(10 \%\)</span> 。这种转换不仅为了便于解释；它还为分层建模做好了准备。当我们构建更大的模型（ 例如：通过合并来自其他患者组的数据或其他药物的数据 ）时，允许参数因组而异是有意义的，并且部分池化在尺度无关的参数上更为有效。</p>
<p>例如，毒理学模型需要研究每个人的肝脏体积。我们没有直接将分层模型拟合到这些体积上，而是将每个人的肝脏建模为相对于体重的比例（ 即做了尺度缩放 ）；我们预计这些尺度无关的因子在不同人之间的差异较小，因此与直接对绝对体积建模的相比，拟合的模型可以进行更多的部分池化。缩放变换是一种能够促进有效分层建模的方法。</p>
<p>在许多情况下，我们可以通过对数变换、 <span class="math notranslate nohighlight">\(\text{\text{logit} }\)</span> 变换、标准化或者归一化来粗略地将参数置于单位尺度上。如果中心和尺度本身是根据数据计算出来的，就像在 <code class="docutils literal notranslate"><span class="pre">rstanarm</span></code> 中为回归系数的默认先验所设置的那样（ <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020a</span></code>），则我们可以将其视为分层模型的近似，其中中心和尺度是从数据中估计的超参数。</p>
<p>更复杂的转换也可以使参数更易于解释，从而促进先验信息的使用；<code class="docutils literal notranslate"><span class="pre">Riebler</span> <span class="pre">et</span> <span class="pre">al.</span> <span class="pre">(2016)</span></code> 给出了一类空间相关模型的例子，<code class="docutils literal notranslate"><span class="pre">Simpson</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">(2017)</span></code> 更普遍地考虑这个想法。</p>
</div>
<div class="section" id="id11">
<h3>2.4 先验预测性检查<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>先验预测性检查是在生成模型背景下理解先验分布含义的有用工具（ <code class="docutils literal notranslate"><span class="pre">Box,</span> <span class="pre">1980</span></code> ；<code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>；有关如何使用先验分布的详细信息，参见第 7.3 节 ）。特别是，由于先验预测性检查使用来自模型的模拟而不是观测数据，因此能够提供了一种『无需多次使用数据即可优化模型』的方法。</p>
<p>图 3 显示了逻辑回归模型的简单先验预测性检查。模拟数据表明，随着模型中预测变量数量的增加，即使各个系数的独立先验也具有不同的含义。这是回归模型中的普遍现象，随着预测变量数量的增加，如果想让模型远离极端预测，我们需要模型系数具有更强的先验（ 或足够的数据 ）。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211210202053-9d7d.webp" /></p>
<blockquote>
<div><p>图 3：演示使用先验预测性检查来了解模型的非明显特征。上图对应于具有 <span class="math notranslate nohighlight">\(100\)</span> 个数据点和 <span class="math notranslate nohighlight">\(2\)</span>、<span class="math notranslate nohighlight">\(4\)</span> 或 <span class="math notranslate nohighlight">\(15\)</span> 个二元预测变量的逻辑回归模型。在每种情况下，回归系数都被赋予独立的 <span class="math notranslate nohighlight">\(\text{Normal}(0,1)\)</span> 先验分布。对于每个模型，我们执行了先验预测性检查，<span class="math notranslate nohighlight">\(1000\)</span> 次模拟来自先验的系数向量 <span class="math notranslate nohighlight">\(\theta\)</span>，然后模拟来自逻辑回归模型的数据集 <span class="math notranslate nohighlight">\(y\)</span>，然后通过模拟数据的均值 <span class="math notranslate nohighlight">\(\bar y\)</span> 对其进行汇总。每个图都显示了此汇总统计量的先验预测性分布，即 <span class="math notranslate nohighlight">\(\bar y\)</span> 的 <span class="math notranslate nohighlight">\(1000\)</span> 次模拟。当模型中的预测变量数量很少时，这种先验预测性分布会展开，表明该模型与范围广泛的数据体系兼容。但是随着预测变量数量的增加，后验预测性分布变得集中在 <span class="math notranslate nohighlight">\(\bar y = 0\)</span> 或 <span class="math notranslate nohighlight">\(1\)</span> 附近，这表明模型各个系数的弱先验意味着这个特定预测量的强先验。如果我们想要 <span class="math notranslate nohighlight">\(\bar y\)</span> 上更温和的先验预测性分布，则系数的先验需要强烈集中在零附近。</p>
</div></blockquote>
<p>一种有用的方法是考虑结果变量的先验，然后推导出相应的参数联合先验（ <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">and</span> <span class="pre">Vehtari,</span> <span class="pre">2017</span></code> ； <code class="docutils literal notranslate"><span class="pre">Zhang</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。更一般地说，联合先验允许我们控制较大参数集的整体复杂性，这有助于生成更合理的先验预测，而独立先验很难或不可能实现这些预测。</p>
<p>图 4 显示了对高斯过程模型的三个先验分布选择进行先验预测性检查的示例（ <code class="docutils literal notranslate"><span class="pre">Rasmussen</span> <span class="pre">and</span> <span class="pre">Willams,</span> <span class="pre">2006</span></code> ）。这种模拟和图形比较在处理任何模型时都很有用，在设置不熟悉或复杂的模型时必不可少。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211210201950-f271.webp" /></p>
<blockquote>
<div><p>图 4：先验预测性分布从具有平方指数协方差函数和不同幅度参数 <span class="math notranslate nohighlight">\(τ\)</span> 和长度尺度参数 <span class="math notranslate nohighlight">\(l\)</span> 的高斯过程模型得出。（ <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2013</span></code>）。</p>
</div></blockquote>
<p>先验预测性模拟的另一个好处是，它们可用于引出有关可测量的感兴趣量的专家先验知识，这通常比征求专家对不可观测模型参数的意见更容易（ <code class="docutils literal notranslate"><span class="pre">O'Hagan</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2006</span></code> ）。</p>
<p>最后，即使跳过计算先验预测性检查这一步骤，考虑我们选择的先验将如何影响假设的模拟数据集可能也会非常有用。</p>
</div>
<div class="section" id="id12">
<h3>2.5 生成式和部分生成式模型<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p><strong>（1）完全生成式模型</strong></p>
<p>完全的贝叶斯数据分析需要一个生成模型，即所有可观测数据和参数的联合概率分布。这一点与贝叶斯推断有着极其微妙的不同：</p>
<ul class="simple">
<li><p><strong>贝叶斯推断</strong>： 其目的是推断得到后验分布，而根据贝叶斯定理，这只需要指定先验和数据的似然函数即可，不必指定生成模型，不同的生成模型可能具有相同的似然。</p></li>
<li><p><strong>贝叶斯数据分析</strong>：其要求有生成模型，并且能够进行预测性模拟和模型检查（ 见第 2.4、4.1、4.2、6.1 and 6.2 节 ）</p></li>
<li><p><strong>贝叶斯工作流</strong>：其会考虑一组可能的生成模型，以进行评估、对比和选择等。</p></li>
</ul>
<p>举一个简单的例子，假设有数据 <span class="math notranslate nohighlight">\(y \mid \text{Binomial}(n,\theta)\)</span>，其中 <span class="math notranslate nohighlight">\(n\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 是观测到的，我们希望对 <span class="math notranslate nohighlight">\(\theta\)</span> 进行推断。</p>
<ul class="simple">
<li><p>如果仅仅做贝叶斯推断，则数据是用通过什么方式生成的无关紧要。相对于估计 <span class="math notranslate nohighlight">\(\theta\)</span> 的目的而言，『固定 <span class="math notranslate nohighlight">\(n\)</span> 次采样（二项式采样）』或者『采样直到出现指定次数成功（负二项式采样）』所对应的似然是等效的，因为两者之间的不同仅由一个 <span class="math notranslate nohighlight">\(y\)</span> 和 <span class="math notranslate nohighlight">\(n\)</span> 决定的乘性因子决定，和 <span class="math notranslate nohighlight">\(\theta\)</span> 无关。</p></li>
<li><p>如果我们想模拟来自预测模型的新数据，则这两个模型是不同的。因为二项式模型产生具有固定值 <span class="math notranslate nohighlight">\(n\)</span> 的重复项，而负二项式模型产生具有固定 <span class="math notranslate nohighlight">\(y\)</span> 值的重复项。这两种不同的生成模型下，先验和后验预测性检查（第 2.4 and 6.1 节）看起来会有所不同。</p></li>
</ul>
<p>上式例子并不是说贝叶斯数据分析方法一定更好；生成模型的假设可以提高推断效率，但也可能出错，而这推动了大部分工作流程。</p>
<p><strong>（2）部分生成式模型</strong></p>
<p>在贝叶斯分析中使用不完全生成的模型也很常见。例如，在回归中，通常会对给定预测变量 <span class="math notranslate nohighlight">\(x\)</span> 的结果 <span class="math notranslate nohighlight">\(y\)</span> 建模，而没有 <span class="math notranslate nohighlight">\(x\)</span> 的生成模型。另一个例子是带有删失的生存数据，其中删失过程通常不建模。在对此类模型执行预测性检查时，要么需要以观测到的预测变量为条件，要么扩展模型以允许对预测变量的新值进行采样。当然，模型的某些部分也可能没有随机生成过程，例如： <span class="math notranslate nohighlight">\(x\)</span> 是通过确定性的实验设计选择而得。</p>
<p>从生成模型角度思考，可以帮助阐明从观测中学到的东西的局限性。例如，我们可能想对具有复杂自相关结构的时间过程建模，但如果实际数据在时间上相距很远，可能无法将该模型与具有几乎独立误差的更简单过程区分开来。</p>
<p>此外，使用不正确先验的贝叶斯模型不是完全生成模型，因为它们没有数据和参数的联合分布，并且不可能从先验预测性分布中采样。当我们确实使用不正确的先验时，将其视为占位符或沿着路径的步骤，以建立完整的贝叶斯模型，并在参数和数据上进行适当的联合分布。</p>
<p>在应用工作中，复杂性通常来自于合并不同的数据源。例如，使用州和全国民意调查为 <span class="math notranslate nohighlight">\(2020\)</span> 年总统选举拟合贝叶斯模型，部分汇总基于政治和经济 “基本面” 的预测（ <code class="docutils literal notranslate"><span class="pre">Morris、Gelman</span> <span class="pre">and</span> <span class="pre">Heidemanns,</span> <span class="pre">2020</span></code> ）。该模型包括一个针对州和国家舆论中潜在时间趋势的随机过程。使用 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 拟合模型会产生后验模拟，用于计算选举结果的概率。基于贝叶斯模型的方法表面上类似于 <code class="docutils literal notranslate"><span class="pre">Katz</span> <span class="pre">,</span> <span class="pre">2016</span></code> 描述的投票聚合，后者也通过随机模拟总结不确定性。不同之处在于贝叶斯模型可以向前运行以生成投票数据；它不仅是一个数据分析程序，而且还为国家和州级的舆论提供了一个概率模型。</p>
<p>更一般地思考，我们可以考虑一个从最少到最多生成模型的过程。其中一个极端是完全的非生成式方法，它们被简单地定义为数据摘要，根本没有数据模型；接下来可以考虑经典统计模型，其特征在于给定参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的数据 <span class="math notranslate nohighlight">\(y\)</span> 的概率分布 <span class="math notranslate nohighlight">\(p(y; \theta)\)</span> ，但没有 <span class="math notranslate nohighlight">\(\theta\)</span> 的概率分布；下一步可以考虑通常拟合的贝叶斯模型，其在 <span class="math notranslate nohighlight">\(y\)</span> 和 <span class="math notranslate nohighlight">\(\theta\)</span> 上生成，但包括额外的未建模数据 <span class="math notranslate nohighlight">\(x\)</span> ，以及样本大小、设计设置和超参数等，我们将此类模型写成 <span class="math notranslate nohighlight">\(p(y,\theta \mid x)\)</span> ；最后一步是一个完全的生成式模型 <span class="math notranslate nohighlight">\(p(y,\theta,x)\)</span> ，该模型没有 “遗漏” 数据 <span class="math notranslate nohighlight">\(x\)</span> 的生成模型。</p>
<p>在统计工作流程中，我们可以在上述阶梯中上下移动，例如从未建模的数据缩略算法开始，然后将其形式化为概率模型；或者从概率模型推断开始，将其视为基于数据的估计，并以某种方式对其进行调整以提高性能。在贝叶斯工作流中，我们可以将数据移入和移出模型，例如采用未建模的预测变量 <span class="math notranslate nohighlight">\(x\)</span> 并允许其具有测量误差，以便模型包含新级别的隐数据（ <code class="docutils literal notranslate"><span class="pre">Clayton,</span> <span class="pre">1992</span></code>; <code class="docutils literal notranslate"><span class="pre">Richardson</span> <span class="pre">and</span> <span class="pre">Gilks,</span> <span class="pre">1993</span></code> ）。</p>
</div>
</div>
<div class="section" id="id13">
<h2>3 拟合一个模型<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>历史传统中，贝叶斯计算是使用解析方式和正态近似的组合来执行的。在 1990 年代，使用 <code class="docutils literal notranslate"><span class="pre">Gibbs</span></code> and <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 算法对各种模型执行贝叶斯推断成为可能（ <code class="docutils literal notranslate"><span class="pre">Robert</span> <span class="pre">and</span>&#160; <span class="pre">Casella,</span> <span class="pre">2011</span></code> ）。当前用于拟合开放式贝叶斯模型的最先进算法包括变分推断（ <code class="docutils literal notranslate"><span class="pre">Blei</span> <span class="pre">and</span> <span class="pre">Kucukelbir,</span> <span class="pre">2017</span></code>）、序贯蒙特卡罗（ <code class="docutils literal notranslate"><span class="pre">Smith,</span> <span class="pre">2013</span></code>）和 <code class="docutils literal notranslate"><span class="pre">Hamiltonian</span> <span class="pre">Monte</span> <span class="pre">Carlo</span> <span class="pre">(</span> <span class="pre">HMC</span> <span class="pre">)</span></code>（ <code class="docutils literal notranslate"><span class="pre">Neal,</span> <span class="pre">2011</span></code>; <code class="docutils literal notranslate"><span class="pre">Betancourt,</span> <span class="pre">2017a</span></code>）。变分推断是对<code class="docutils literal notranslate"><span class="pre">期望最大化</span> <span class="pre">(EM)</span></code> 算法的推广，在贝叶斯上下文中，可以被视为提供了对后验分布的快速但可能不准确的近似。变分推断是计算密集型模型（ 例如深度神经网络 ）的当前标准。 序贯蒙特卡洛方法是 <code class="docutils literal notranslate"><span class="pre">Metropolis</span> <span class="pre">算法</span></code>的推广，可以应用于任何贝叶斯计算，而 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 是 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 的另外一种推广，它使用梯度计算在连续概率空间中进行高效移动。</p>
<p>在本文中，我们专注于使用 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 及其变体来拟合贝叶斯模型，如在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 和其他概率编程语言中实现的。虽然类似原则也适用于其他软件和其他算法，但细节上会有差异。</p>
<p>要在贝叶斯工作流中安全地使用推断算法，算法必须提供强大的诊断功能来确定计算何时不可靠。在本文中，我们讨论了 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 的此类诊断工具。</p>
<div class="section" id="id14">
<h3>3.1 初值、适应和预热<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>除了最简单的情况外，马尔可夫链模拟算法在多个阶段运行。</p>
<p>首先是预热阶段，旨在将模拟从可能不具代表性的初始值移动到更接近参数空间的区域，在该区域中，对数后验密度接近其期望值，这与信息论中的<strong>典型集</strong>有关（ <code class="docutils literal notranslate"><span class="pre">Carpenter,</span> <span class="pre">2017</span></code> ）。初始值在渐近极限中并不重要，但在实践中很重要，因为错误的初值选择可能会威胁到结果的有效性和收敛的时效性。</p>
<p>第二个阶段同样发生在预热期间，需要一些过程来设置算法的调整参数；这可以通过从预热运行中收集的信息来实现。</p>
<p>第三个阶段是采样，理想情况下一直运行到多个链混合为止（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。</p>
<p>在拟合已正确指定的模型时，预热有两个目的：(a) 运行瞬态阶段以减少由于依赖初始值而导致的偏差； (b) 在设置调谐参数时，提供有关要使用的目标分布的信息。在模型探索过程中，预热还有第三个作用，即快速标记计算上有问题的模型。</p>
</div>
<div class="section" id="id15">
<h3>3.2 运行迭代算法需要多长时间<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>我们同样希望在更大的工作流程中考虑迭代算法操作中的决策。推荐的标准做法是至少运行直到所有感兴趣的参数和量的 <span class="math notranslate nohighlight">\(\hat R\)</span> ( 链混合程度的度量 ）都小于 <span class="math notranslate nohighlight">\(1.01\)</span>（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ），并且还监测多变量混合统计 <span class="math notranslate nohighlight">\(R^*\)</span>（ <code class="docutils literal notranslate"><span class="pre">Lambert</span> <span class="pre">and</span> <span class="pre">Vehtari,</span> <span class="pre">2020</span></code> ）。有时，在建模早期阶段提前停止是有意义的。例如，运行 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 直到有效样本大小达到数千似乎是一个安全而保守的选择，或者与参数解释所需的精度相比，蒙特卡罗标准误差很小，但这会需要很长时间，限制了探索阶段可拟合的模型数量。</p>
<p>通常情况下，我们的模型也存在一些较大的问题（ 尤其是程序代码错误 ），这些问题在仅运行几次迭代后就会变得明显，从而浪费了剩余的计算。在这方面，为新编写的模型运行多次迭代类似于软件工程中的过早优化。对于最终模型，所需的迭代次数取决于感兴趣量所需的蒙特卡罗精度。</p>
<p>计算中的另一个选择是如何最好地利用并行性，而不是在多个内核上运行 <span class="math notranslate nohighlight">\(4\)</span> 或 <span class="math notranslate nohighlight">\(8\)</span> 个独立链的默认设置。除了增加迭代次数，还可以通过增加并行链的数量来获得有效的<code class="docutils literal notranslate"><span class="pre">方差减少</span></code>（参见 <code class="docutils literal notranslate"><span class="pre">Hoffman</span> <span class="pre">and</span> <span class="pre">Ma,</span> <span class="pre">2020</span></code> ）。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229093821-8590.webp" /></p>
<blockquote>
<div><p>图 5：贝叶斯计算中近似算法和 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 之间权衡的理想草图。如果目标获得目标分布的最佳拟合，那么 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 最终应该胜出。但如果考虑的是拟合一组模型，那么使用近似算法以便能够在模型空间中快速移动非常有意义。这些算法中哪一个表现更好取决于用户的时间预算以及两条曲线的交点。</p>
</div></blockquote>
</div>
<div class="section" id="id16">
<h3>3.3 近似算法和近似模型<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>贝叶斯推断通常涉及难以处理的积分，因此需要近似。马尔可夫链模拟是一种近似形式，随着模拟次数增加，理论误差接近于零。如果链是混合的，我们可以很好地估计蒙特卡罗标准差（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code>），并且出于实际目的经常将这些计算视为准确的。</p>
<p>不幸的是，随着数据和模型变大，运行 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 至收敛并不总是一个具备可扩展性的解决方案，因此需要更快的近似值。图 5 显示了速度和准确性之间的权衡。此图只是概念性的；在实际问题中，线的位置是未知的。在某些实际问题中，即使在较短的时间尺度上，近似算法的性能也有可能比 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 差。</p>
<p>根据在工作流程中所处的位置不同，我们对计算的后验有不同的要求。在工作流程接近尾声时，我们正在检查精细尺度和精细特征，因此需要准确探索后验分布。这通常需要 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 。另一方面，在工作流程开始时，我们可以经常根据后验的大规模特征做出建模决策，这些特征可以使用相对简单的方法进行准确估计，例如经验贝叶斯、线性化或拉普拉斯近似、嵌套近似（如 INLA，<code class="docutils literal notranslate"><span class="pre">Rue</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2009</span></code>）等。甚至有时可以采用如期望传播的数据拆分近似方法（ <code class="docutils literal notranslate"><span class="pre">Vehtari、Gelman、Siivola</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）、如变分推断的峰值寻找近似方法（ <code class="docutils literal notranslate"><span class="pre">Kucukelbir</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> ），或惩罚最大似然。关键是要使用合适的工具来完成这项工作，而不是试图用雕刻家的凿子敲掉挡土墙。</p>
<p>所有这些近似方法背后都有至少十年的实践经验、理论和诊断。没有一刀切的近似推断算法，但是当工作流包含相对容易理解的组件（例如广义线性模型、分层回归、自回归时间序列模型或高斯过程）时，通常可以构造适当的近似算法。此外，根据所使用的特定近似值，<code class="docutils literal notranslate"><span class="pre">Yao</span> <span class="pre">et</span> <span class="pre">al.(2018a)</span> </code> and <code class="docutils literal notranslate"><span class="pre">Talts</span> <span class="pre">et</span> <span class="pre">al.</span> <span class="pre">(2020)</span></code> 描述了通用诊断工具，可用于验证特定近似算法是否重现了特定模型的后验特性。</p>
<p>另一种观点是将近似算法理解为近似模型的精确算法。从这个意义上说，工作流是抽象计算方案中的一系列步骤，旨在推断出一些最终的、未陈述的模型。更有用的是，我们可以将经验贝叶斯近似之类的东西视为用特定数据相关点质量先验替换模型的先验分布。类似地，拉普拉斯近似可以被视为所需模型的数据相关线性化，而嵌套拉普拉斯近似（ <code class="docutils literal notranslate"><span class="pre">Rue</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2009</span></code> ; <code class="docutils literal notranslate"><span class="pre">Margossian</span> <span class="pre">et</span> <span class="pre">al.,2020a</span></code> ）使用线性化条件后验代替假定的条件后验。</p>
</div>
<div class="section" id="id17">
<h3>3.4 快速拟合，快速失败<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<p>另外一个重要的中间目标是在拟合“坏”模型时能够快速失败。这可以被认为是一种捷径，可以避免浪费大量时间对一个“坏”模型进行接近完美的推断。有大量关于近似算法以快速拟合所需模型的文献，但很少涉及旨在将尽可能少的时间浪费在最终将放弃的模型上的算法。我们认为根据此标准评估方法很重要，特别是“坏”模型通常更难以拟合，从而有可能浪费更多的时间。</p>
<p>对于一个简单的理想化示例，假设你是几个世纪前的天文学家，根据 <span class="math notranslate nohighlight">\(10\)</span> 个带误差的测量数据点来拟合行星轨道椭圆。图 6a 显示了可能出现的数据类型，几乎任何算法都可以很好地拟合。例如，你可以采用不同的 <span class="math notranslate nohighlight">\(5\)</span> 个点集并为每个点拟合精确的椭圆，然后取这些拟合的平均值。或者你可以将一个椭圆拟合到前五个点，稍微扰动它以拟合第六个点，然后稍微扰动它以拟合第七个点，依此类推。或者你可以实现某种最小二乘算法。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229094209-4943.webp" /></p>
<blockquote>
<div><p>图 6：“快速拟合，快速失败”的需求说明：（a）理想化代表行星轨道测量值的数据，可以拟合为具有测量误差的椭圆，(b) 被死星扰动的假设轨道的测量值。在第二个示例中，将单个椭圆拟合到数据中将具有挑战性，但在任何情况下，我们都对椭圆拟合没有特别的兴趣。我们希望任何将椭圆拟合到第二个数据集的尝试都会快速失败。</p>
</div></blockquote>
<p>现在假设一些死星出现并改变了轨道，在这种情况下，我们故意选择一个不切实际的例子来创建模型和数据之间的严重差异，因此你的 <span class="math notranslate nohighlight">\(10\)</span> 个数据点看起来像图 6b 。在这种情况下，收敛将更难实现。如果你从拟合前五个点的椭圆开始，则很难采用任何一组小扰动来使曲线拟合系列中后面的点。但更重要的是，即使可以获得最小二乘解，其对应的任何椭圆都与数据拟合的非常糟糕。这是一个不合适的模型，如果将椭圆拟合到这些数据，你应该希望拟合快速失败，以便快速转向更合理的方法。</p>
<p>这个例子具有一种困难统计计算的通用模式，即拟合数据的不同子集会产生非常不同的参数估计。</p>
</div>
</div>
<div class="section" id="id18">
<h2>4 使用人为构造的伪数据发现和理解问题<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h2>
<p>验证计算的第一步是检查模型是否在可接受的时间范围内切实地完成了拟合过程，并且收敛诊断是合理的。在 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 上下文中，主要的诊断手段有：不存在发散的转移、<span class="math notranslate nohighlight">\(\hat R\)</span> 诊断指标接近 <span class="math notranslate nohighlight">\(1\)</span> 、聚集趋势的充分有效样本量、尾分位数和能量（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。不过，上述诊断方法无法防止能够正确计算的、但代码对应的模型与用户预期不符的概率程序。</p>
<p>我们用于确保统计计算完成得相当好的主要工具是：『将模型拟合到某些实际数据，并检查拟合是否良好』。为此目的，真实数据可能很尴尬，因为建模问题早期可能会与计算问题发生冲突，并且很难判断到底是计算问题还是模型问题。为解决这个问题，可以先将模型拟合到模拟数据来探索模型。</p>
<div class="section" id="id19">
<h3>4.1 伪数据模拟<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>在已知真实参数的受控环境中工作，可以帮助我们理解“数据模型和先验”、“可以从实验中学到什么”以及“推断方法的有效性”。基本思想是检查程序在拟合伪数据时，是否恢复了正确的参数值。</p>
<p>通常，我们选择在先验上看起来合理的参数值，然后模拟与原始数据具有相同大小、形状和结构的伪数据集。接下来我们将模型拟合到伪数据上来检查几件事。</p>
<p><strong>（1） 检查数据设计</strong></p>
<p>我们检查的第一件事不是计算，而是数据设计的一个方面。对于所有参数，检查观测数据是否能够提供超出之前的额外信息。该过程使用固定的已知参数从模型中模拟一些伪数据，然后查看我们的方法是否接近重现已知事实。我们可以查看<code class="docutils literal notranslate"><span class="pre">点估计</span></code>以及<code class="docutils literal notranslate"><span class="pre">后验区间覆盖范围</span></code>。</p>
<p>如果伪数据检查失败，在某种意义上，推断与假设的参数值不接近，或者似乎有模型的某些组件没有根据数据获得任何信息（ <code class="docutils literal notranslate"><span class="pre">Lindley,1956</span></code> ；<code class="docutils literal notranslate"><span class="pre">Goel</span> <span class="pre">and</span> <span class="pre">DeGroot,</span> <span class="pre">1981</span></code>），我们建议分解模型，让其变得越来越简单，直到让模型工作为止。然后，在那里尝试识别问题，如第 5.2 节所示。</p>
<p><strong>（2）检查是否可以将真实参数大致恢复到拟合后验分布所隐含的不确定性范围内。</strong></p>
<p>如果数据不能为参数提供信息，这将是不可能的，但通常应该发生其他情况。不可能运行单个伪数据模拟、计算相关的后验分布并声明一切正常。我们将在下一节看到需要更精细的设置。但是，单个模拟运行通常会发现明显的错误。例如，如果代码中有错误并且拟合了错误的模型，这通常会从参数恢复的灾难性失败中明确。</p>
<p><strong>（3）使用伪数据模拟来了解模型的行为如何在参数空间的不同部分发生变化。</strong></p>
<p>从这个意义上说，统计模型可以包含许多关于数据如何生成的故事。如第 5.9 节所示，当指数分离得很好时，数据可以提供有关下降指数总和的参数的信息，但当两个分量彼此接近时，数据就不那么重要了。这种取决于参数值的不稳定也是微分方程模型中的常见现象，如第 11 节所示。 再举一个例子，层次模型的后验分布在漏斗的颈部和嘴部看起来大不相同分层先验隐含的几何。类似的问题出现在高斯过程模型中，这取决于过程的长度尺度和数据的分辨率。</p>
<p>所有这些都意味着伪数据模拟在可预测数据的参数空间区域中可能特别相关。这反过来又提出了一个两步的程序，在该程序中，首先将模型拟合到真实数据中，然后从得到的后验分布中提取参数以用于伪数据检查。这种程序的统计特性尚不清楚，但在实践中，我们发现这种检查是有帮助的，既可以揭示计算或模型的问题，也可以在基于伪数据的推断确实再现假定的参数值时提供一些保证。</p>
<p>为了进一步实现这个想法，我们可能会通过提供一些伪数据来破坏我们的方法，从而导致程序给出错误的答案。这种模拟和探索可能是深入理解推断方法的第一步，即使对于计划将这种方法仅用于一个应用问题的从业者来说，这也很有价值。它也可用于构建一组更复杂的模型以供稍后探索。</p>
<p>伪数据模拟是贝叶斯工作流程的关键组成部分，因为可以说，这是我们可以直接检查对隐变量的推断的唯一点是可靠的。在将模型拟合到真实数据时，根据定义，我们不会观测到隐变量。因此，只能评估模型如何拟合观测数据。如果我们的目标不仅仅是预测而是估计隐变量，那么检查预测只会对我们有很大帮助。对于过度参数化的模型尤其如此，其中非常不同的参数值可以产生可比较的预测（例如第 5.9 节和  <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">1996</span></code> ）。</p>
<p>一般来说，即使模型拟合良好，我们也应该谨慎地对估计的隐变量得出结论。将模型与模拟数据拟合有助于我们更好地了解模型在我们知道基本事实的受控环境中可以了解和不了解潜在过程的哪些方面。如果一个模型能够对从该模型生成的伪数据做出很好的推断，这并不能保证它对真实数据的推断是合理的。但是，如果模型无法对此类虚伪数据进行良好的推断，那么期望该模型对真实数据进行合理的推断就无望了。虚伪数据模拟提供了可以了解潜在过程的上限。</p>
</div>
<div class="section" id="id20">
<h3>4.2 基于模拟的较正<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>如图 7 所示，将贝叶斯推断的结果（后验分布）与单个（真实）点进行比较时，存在一个正式的、有时甚至是实际的问题。</p>
<p>使用单个伪数据模拟来测试模型不一定“工作”，即使计算算法工作正常。这里出现的问题不仅是因为在一次模拟中任何事情都可能发生（随机抽取有 <span class="math notranslate nohighlight">\(5\%\)</span> 的机会在 <span class="math notranslate nohighlight">\(95\%\)</span> 的不确定性区间之外），而且还因为贝叶斯推断通常只会在对先验求平均时进行校准，不适用于任何单个参数值。此外，参数恢复可能失败不是因为算法失败，而是因为观测数据没有提供可以更新特定参数先验量化的不确定性的信息。如果先验和后验近似单峰并且选择的参数值来自先验的中心，我们可以预期后验间隔的过度覆盖。</p>
<p>比我们在第 4.1 节中介绍的方法更全面的是<code class="docutils literal notranslate"><span class="pre">基于模拟的校准（</span> <span class="pre">SBC</span> <span class="pre">)</span></code>； <code class="docutils literal notranslate"><span class="pre">Cook</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2006</span></code>  ; <code class="docutils literal notranslate"><span class="pre">Talts</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。在该方案中，模型参数取自先验；然后根据这些参数值模拟数据；然后模型拟合数据；最后将获得的后验值与用于生成数据的模拟参数值进行比较。通过多次重复此过程，可以检查推断算法的一致性。这个想法是通过在使用从先验中提取的参数模拟的一系列数据集执行贝叶斯推断，我们应该恢复先验。基于模拟的校准对于评估近似算法与理论后验的匹配程度非常有用，即使在后验不可处理的情况下。</p>
<p>虽然在许多方面优于针对真实点进行基准测试，但基于模拟的校准需要多次拟合模型，这会产生大量的计算成本，特别是如果我们不使用广泛的并行化。在我们看来，基于模拟的校准和真值基准测试是光谱的两端。粗略地说，一个单一的真值基准可能会标记严重的问题，但它并不能保证任何事情。随着我们做更多的实验，有可能在计算中看到越来越精细的问题。通过少量抽奖来理解  <code class="docutils literal notranslate"><span class="pre">SBC</span></code>  是一个开放的研究问题。我们期望放弃随机抽取以对先验进行更有设计的探索将使该方法更有效，尤其是在参数数量相对较少的模型中。</p>
<p><code class="docutils literal notranslate"><span class="pre">SBC</span></code> 的一个严重问题是它与大多数建模者指定他们的比他们认为必要的更广泛的先验。弱信息先验的稍微保守的性质可能导致  <code class="docutils literal notranslate"><span class="pre">SBC</span></code>  期间模拟的数据集偶尔会变得极端。<code class="docutils literal notranslate"><span class="pre">加布里</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> 举了一个例子，其中模拟了假空气污染数据集，其中污染比黑洞更密集。这些极端数据集可能导致在现实数据上运行良好的算法严重失败。但这并不是计算的问题，而是先前的问题。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229095234-971c.webp" /></p>
<blockquote>
<div><p>图 7：后验分布与假设的真实参数值的比较。在将模型拟合到模拟数据时，我们可以检查后验样本（蓝色直方图）是否与真实参数值（红线）相符。在场景 1 中，后验以真值为中心，这表明拟合是合理的。在场景 2 中，真实参数现在位于后验分布的尾部。目前尚不清楚这是否表明我们的推断存在错误。在场景 3 中，后验是多峰的，很明显，将后验与单个点进行比较无法验证推断算法。更全面的方法，比如基于模拟的校准，可以教会我们更多。</p>
</div></blockquote>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229095333-b_167.webp" /></p>
<blockquote>
<div><p>图 8：来自对教育干预效果的假设研究的 500 名学生的模拟数据。</p>
</div></blockquote>
<p>解决此问题的一种可能方法是确保先验非常紧密。然而，一个务实的想法是保留先验并使用真实数据计算合理的参数值。这可以通过粗略估计或通过计算实际后验来完成。然后，我们建议稍微扩大估计范围，并将其用作  <code class="docutils literal notranslate"><span class="pre">SBC</span></code>  的先验。这将确保所有模拟数据在模型允许的情况下尽可能真实。</p>
</div>
<div class="section" id="id21">
<h3>4.3 使用构造的数据进行实验<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>理解模型的一个好方法是将其拟合到从不同场景模拟的数据中。</p>
<p>对于一个简单的例子，假设我们对线性回归的统计特性对拟合来自替代分布形式的数据感兴趣。首先，我们可以指定数据 <span class="math notranslate nohighlight">\(x_i, i = 1,...,n\)</span> ，绘制系数 <span class="math notranslate nohighlight">\(a\)</span> 和 <span class="math notranslate nohighlight">\(b\)</span> 以及来自我们先验分布的残差标准偏差 <span class="math notranslate nohighlight">\(\sigma\)</span>，模拟来自 <span class="math notranslate nohighlight">\(y_i \sim \text{Normal}(a + bx_i ,\sigma)\)</span> 的数据，并将模型拟合到模拟数据。重复这个 <span class="math notranslate nohighlight">\(1000\)</span> 次，我们可以检查区间估计的覆盖范围：这是基于模拟的校准版本。然后我们可以拟合相同的模型，但使用不同的假设模拟数据，例如从 <span class="math notranslate nohighlight">\(t_4\)</span> 分布而不是正态分布中抽取独立的 <span class="math notranslate nohighlight">\(y_i\)</span> 数据点。这将使基于仿真的校准失败——正在拟合错误的模型——但这里有趣的问题是，这些推断会有多糟糕？例如，可以使用  <code class="docutils literal notranslate"><span class="pre">SBC</span></code>  模拟来检查系数的后验 <span class="math notranslate nohighlight">\(50\%\)</span> 和 <span class="math notranslate nohighlight">\(95\%\)</span> 区间的覆盖率。</p>
<p>对于更详细的示例，我们执行一系列模拟以了解观测性研究中的假设和偏差校正。我们从一个场景开始，其中一个班级价值 <span class="math notranslate nohighlight">\(500\)</span> 个学生参加期中和期末考试。我们通过首先从 <span class="math notranslate nohighlight">\(\text{Normal}(50,20)\)</span> 分布中绘制学生的真实能力 <span class="math notranslate nohighlight">\(η_i\)</span> 来模拟数据，然后将两个考试分数 <span class="math notranslate nohighlight">\(x_i,y_i\)</span> 绘制为独立的 <span class="math notranslate nohighlight">\(\text{Normal}( η_i,10)\)</span> 分布。这导致两个分数的相关性为 <span class="math notranslate nohighlight">\(\frac{20^2}{20^2+5^2} = 0.94\)</span>; 我们设计了具有如此高值的模拟，以使图形中的模式更加明显。图 8a 显示了结果以及基础回归线 <span class="math notranslate nohighlight">\(E(y \mid x)\)</span> 。然后，我们构建了一个假设的随机实验，在期中之后进行的处理会为任何学生的期末考试成绩增加 10 分。我们为每个学生提供接受治疗或控制的平等机会。图 8b 显示了模拟数据和基础回归线。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229095836-9a42.webp" /></p>
<blockquote>
<div><p>图 9：替代模拟，其中治疗分配不平衡，表现较差的学生被更有可能接受治疗。</p>
</div></blockquote>
<p>在这个例子中，我们可以通过简单地取两组之间的差异来估计治疗效果，对于这些模拟数据，估计值为 <span class="math notranslate nohighlight">\(10.7\)</span>，标准误差为 <span class="math notranslate nohighlight">\(1.8\)</span> 。或者我们可以对期中分数进行回归调整，得出 <span class="math notranslate nohighlight">\(9.7 ±0.6\)</span> 的估计值。</p>
<p>接下来我们考虑一种不平衡分配机制，其中接受治疗的概率取决于期中分数：<span class="math notranslate nohighlight">\(\text{Pr}(z = 1) = \text{\text{logit} }^{−1}((x −50)/10)\)</span>。图 9a 显示了 <span class="math notranslate nohighlight">\(200\)</span> 个学生的模拟治疗分配，图 9a 显示了模拟考试分数。基础回归线与之前相同，因为此模拟更改了 <span class="math notranslate nohighlight">\(z\)</span> 的分布，但未更改 <span class="math notranslate nohighlight">\(y \mid x,z\)</span> 的模型。在这种设计下，优先对待表现较差的学生，因此对期末考试成绩的简单比较将给出较差的估计。对于这个特定的模拟，比较两组的平均成绩差异为 <span class="math notranslate nohighlight">\(−13.8 ±1.5 \)</span>，这是一个可怕的推论，因为真正的效果是，通过构造，<span class="math notranslate nohighlight">\( 10 \)</span>。不过，在这种情况下，线性回归调整 <span class="math notranslate nohighlight">\( x\)</span> 恢复了治疗效果，产生了 <span class="math notranslate nohighlight">\(9.7 ±0.8\)</span> 的估计值。</p>
<p>但是这个新的估计值对 <span class="math notranslate nohighlight">\(x\)</span> 调整的函数形式很敏感。我们可以通过模拟来自替代模型的数据来看到这一点，其中真实的治疗效果为 <span class="math notranslate nohighlight">\(10\)</span>，但函数 <span class="math notranslate nohighlight">\(E(y \mid x,z)\)</span> 不再是线性的。在这种情况下，我们通过像以前一样从 <span class="math notranslate nohighlight">\(\text{Normal}(η_i,10)\)</span> 中绘制给定真实能力的期中考试分数来构建这样一个模型，但是转换期末考试分数，如图 10 所示。我们再次考虑两个假设实验：图 10a 显示了完全随机分配的数据，图 10b 显示了使用图 9a 中的不平衡处理分配规则的结果。两个图也显示了潜在的回归曲线。</p>
<p>当我们现在拟合线性回归来估计治疗效果时会发生什么？图 10a 中设计的估计是合理的：即使线性模型是错误的，因此产生的估计在统计上并不完全有效，但设计中的平衡确保平均规格误差将被抵消，估计为 <span class="math notranslate nohighlight">\(10.5±0.8\)</span>。但不平衡设计存在问题：即使在线性回归中调整 <span class="math notranslate nohighlight">\(x\)</span> 后，估计值仍为 <span class="math notranslate nohighlight">\(7.3 ±0.9\)</span>。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211229100248-bc60.webp" /></p>
<blockquote>
<div><p>图 10：再次比较两种不同的治疗分配，这次是在期末和期中考试分数之间的关系为非线性。在本文的上下文中，此示例的重点是展示在不同条件下模拟统计系统如何让我们深入了解计算问题，而且更广泛地了解数据和推断。在这个特定的例子中，人们可以通过考虑不同的治疗效果、对不可观测项的选择和其他并发症来更进一步，而且通常情况下，可以无限期地考虑此类理论探索以解决可能出现的任何问题。</p>
</div></blockquote>
</div>
</div>
<div class="section" id="id22">
<h2>5 解决统计计算问题<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id23">
<h3>5.1 统计计算的通俗理论<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<p>当你遇到计算问题时，通常是模型出现了问题（<code class="docutils literal notranslate"><span class="pre">Yao、Vehtari</span> <span class="pre">and</span> <span class="pre">Gelman,</span> <span class="pre">2020</span></code>）。许多收敛不佳的情况对应于参数空间中没有实质性意义的区域，甚至对应于一个毫无意义的模型。图 6 给出了参数空间不相关区域中的病理示例。 另外一个基础的问题模型案例是在代码中存在错误、或者是对高斯或逻辑回归中的每个观测量分别使用不同的高斯分布截距，在这些情况下，它们不能从数据中获取任何有用信息。面对问题模型时，第一直觉不应该是在模型上投入更多的计算资源（ 例如，通过运行采样器进行更多迭代或减少 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 算法的步长 ），而是检查模型是否包含实质性的病理。</p>
</div>
<div class="section" id="id24">
<h3>5.2 从简单和复杂的模型开始并在中间相遇<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h3>
<p>图 11 说明了一种常用的调试方法。起点时模型表现不佳，可能无法收敛或无法在伪数据模拟中重现真实参数值，或无法很好地拟合数据，或产生不合理的推断。诊断问题的途径是向两个方向移动：一是逐渐简化性能极差的模型，剥离不必要的特征直到其能够工作；二是从一个简单易懂的模型开始，逐渐添加特征直到问题出现。类似地，如果模型有多个组件（ 例如，一个微分方程和该方程参数的一个线性预测器 ），先使用模拟数据确保每个组件可以单独拟合并完成单元测试，通常是明智的选择。</p>
<p>我们可能永远无法成功拟合最初打算拟合的复杂模型，要么是因为当前可用计算算法拟合太困难，要么是因为现有数据和先验信息不足，无法从模型中进行有用的推断，或者仅仅是因为模型探索的过程将我们引向了与原先计划不同的方向。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211230095520-7e8a.webp" /></p>
<blockquote>
<div><p>图 11：建议的调试图。右下方的星号代表在尝试拟合所需的复杂模型时出现问题的场景。左上角的点代表在拟合各种简单版本时成功，右下角的点代表在拟合完整模型的各种简化时失败。虚线表示可以在适合的简单模型和不适合的复杂模型之间的某处识别问题的想法。来自 <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">and</span> <span class="pre">Hill,</span> <span class="pre">2007</span></code> 。</p>
</div></blockquote>
</div>
<div class="section" id="id25">
<h3>5.3 掌握需要很长时间才能拟合的模型<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h3>
<p>我们通常使用 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 来拟合模型，但它可能由于各种原因运行缓慢，其中包括：昂贵的微分方程梯度评估、高维参数空间、在后验中部分区域有效的 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 在其他区域却不合适等。计算缓慢通常是其他问题的先兆，它不仅表明 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 的性能不佳，也同时意味着模型更难调试。</p>
<p>例如，最近在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 用户组中收到一个关于分层逻辑回归的问询，其中包含 <span class="math notranslate nohighlight">\(35,000\)</span> 个数据点、<span class="math notranslate nohighlight">\(14\)</span> 个预测变量和 <span class="math notranslate nohighlight">\(9\)</span> 个不同截距的批次，使用 <code class="docutils literal notranslate"><span class="pre">rstanarm</span></code> 的默认设置在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 中运行几个小时后仍然未能完成运行。</p>
<p>我们给出了以下建议，没有特定的顺序：</p>
<p><strong>（ 1 ）利用伪数据尽早发现问题。</strong></p>
<p>从模型中生成模拟伪数据，并尝试将模型拟合到伪数据（ 第 4.1 节 ），错误指定的模型此时通常会很慢，而模拟的伪数据让我们不用考虑是否是缺乏拟合的原因。</p>
<p><strong>（ 2 ）从小模型开始性价比更高一些。</strong></p>
<p>大模型计算会很慢，所以你应该从较小的模型开始入手开始构建。首先拟合没有变化截距的模型，然后添加一批不同的截距，然后是下一批，依此类推。</p>
<p><strong>（ 3 ）早期少一些迭代次数。</strong></p>
<p>运行 <span class="math notranslate nohighlight">\(200\)</span> 次迭代，而不是使用 <span class="math notranslate nohighlight">\(2000\)</span> 次的默认值。你当然也可以运行 <span class="math notranslate nohighlight">\(2000\)</span> 次迭代，但是当你仍在试图弄清楚发生了什么问题时，迭代次数太多没有意义。如果在 <span class="math notranslate nohighlight">\(200\)</span> 次迭代后，<span class="math notranslate nohighlight">\(\hat R\)</span> 仍然很大，那么你可以尝试运行更长的时间，但完全没有必要一开始就使用 <span class="math notranslate nohighlight">\(2000\)</span> 次迭代。</p>
<p><strong>（ 4 ）尝试设置信息性先验。</strong></p>
<p>在回归系数和组级方差参数（ 第 7.3 节 ）上放置适度的信息性先验。</p>
<p><strong>（ 5 ）考虑预测变量之间可能的交互作用。</strong></p>
<p>有 <span class="math notranslate nohighlight">\(14\)</span> 个预测变量但其间毫无交互作用的加法模型似乎很奇怪。这个建议似乎与用户关心的性能问题无关（ 事实上，添加交互只会增加运行时间 ），但要清楚，我们的最终的目标是做出预测或了解底层过程，而不仅是获得一组很随意的预测变量，我们应当选择能够收敛的模型。</p>
<p><strong>（ 6 ）先在在数据子集上拟合模型。</strong></p>
<p>这是在将模型投入到所有数据之前，了解拟合过程并使其正常工作的一般性建议之一。</p>
<p>所有上述技巧的共同主题是将任何特定的模型选择视为一种临时考虑，并且一定要认识到：<strong>数据分析需要拟合许多模型而不是一个</strong>，以便对特定应用问题的计算和推断过程进行控制。</p>
</div>
<div class="section" id="id26">
<h3>5.4 监控中间量<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h3>
<p>诊断模型问题的另一种有用方法，是在计算过程中保存中间量，并将该中间量与其他 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code>的 输出一起绘制可视化图件，例如使用 <code class="docutils literal notranslate"><span class="pre">bayesplot</span></code>（ <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020a</span></code> ）或 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code>（ <code class="docutils literal notranslate"><span class="pre">Kumar</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ）。这些可视化方法是在代码中插入打印语句的替代方法，而且我们通常能够从可视化中学到更多的内容。</p>
<p>有时会出现的一个问题是马尔科夫链会卡在参数空间中的某个后验密度比较低的偏僻区域、或 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 算法中无法回到<code class="docutils literal notranslate"><span class="pre">对数后验密度</span></code>接近期望的区域、或大部分后验质量所在的区域。正如我们将在第 11 节中说明的那样，在给定这些参数值的情况下，查看模型的预测以了解出了什么问题会很有帮助。但最直接的方法是绘制 “以这些链中的参数值为条件” 的预期数据，然后将参数的梯度转换为期望数据的梯度。这应该可以让我们深入了解，参数如何映射到后验分布相关区域中的期望数据。</p>
</div>
<div class="section" id="id27">
<h3>5.5 堆叠以重新加权混合不良的链<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h3>
<p>在实践中，通常我们的 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 算法混合得很好。其他时候，模拟会快速移动到参数空间的不合理区域，表明可能存在模型的错误指定、无信息或弱信息的观测数据，或者只是仅仅因为复杂的后验几何。</p>
<p>但多个链混合起来很慢，但又在合理范围内的中间情况也比较常见。此时可以使用堆叠来组合模拟，并使用交叉验证为不同的链分配权重（ <code class="docutils literal notranslate"><span class="pre">Yao、Vehtari</span> <span class="pre">and</span> <span class="pre">Gelman,</span> <span class="pre">2020</span></code> ）。这将具有丢弃卡住的链的近似效果。 堆叠的结果不一定等价（ 甚至是渐近地等价）于完全贝叶斯推断，但它服务于许多相同的目标，特别适合在模型探索阶段，让我们向前迈进，花更多时间和精力在其他贝叶斯工作流步骤上，而不会被拟合一个特定模型所困扰。</p>
<p>此外，当与跟踪图和其他诊断工具一起使用时，非均匀堆叠权重能够以迭代方式了解应当将精力集中在哪里。</p>
</div>
<div class="section" id="id28">
<h3>5.6 具有多峰和其他困难几何形状的后验分布<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h3>
<p>我们可以粗略地区分四类与困难的后验几何相关的 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 问题：</p>
<p><strong>（ 1 ） 类型一： 可以显著区分的多峰后验形态</strong></p>
<p><strong>特点</strong>： 多个峰中只有一个峰的质量比较大，其他峰的质量都接近于零。一个例子出现在第 11 节。</p>
<p><strong>处理方法</strong>：通过选择模拟初始值、添加先验信息、对参数设置硬约束来避免次要峰，或者通过近似估计每个峰的质量来修剪它们。</p>
<p><strong>（ 2 ） 类型二：可以显著区分的微对称多峰后验形态</strong></p>
<p><strong>特点</strong>：多个峰之间分割地比较清楚，各峰的概率质量相似，例如混合模型中的标签。</p>
<p><strong>处理方法</strong>：标准做法是以某种方式限制模型以识别感兴趣的峰；参见 <code class="docutils literal notranslate"><span class="pre">Bafumi</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2005</span></code>  和 <code class="docutils literal notranslate"><span class="pre">Betancourt,</span> <span class="pre">2017b</span></code> 。</p>
<p><strong>（ 3 ）类型三：可以显著区分但质量不同的多峰后验形态。</strong></p>
<p><strong>特点</strong>：多个峰之间分割地比较清楚，但各峰的概率质量不同。例如，在基因调控模型 ( <code class="docutils literal notranslate"><span class="pre">Modrák,</span> <span class="pre">2018</span></code>) 中，一些数据承认两种不同的调控机制具有相反的效应符号，而接近于零的效应具有低得多的后验密度。这个问题更具挑战性。</p>
<p><strong>处理方法</strong>：在某些情况下，可以使用<strong>堆叠（ 预测模型平均</strong> ）作为近似解决方案，但这并不完全通用，因为它需要定义感兴趣的预测量；一种更完整的贝叶斯替代方法是通过引入强混合先验将模型分成几部分，然后在给定先验每个组件的情况下分别拟合模型；其他时候，可以使用具有排除某些可能峰效果的强先验来解决问题。</p>
<p><strong>（ 4 ） 类型四：具有算术不稳定尾部的高概率质量单一后验形态</strong>。</p>
<p><strong>特点</strong>：概率质量比较集中的单一峰，但在尾部存在不稳定的低矮峰。</p>
<p><strong>处理方法</strong>：如果分布的质量附近初始化，则大多数推断应该不会出现问题。如果对极其罕见的事件特别感兴趣，那么应该对问题进行重新参数化，因为从通常默认的几百到几千的有效样本量中能够学到的东西非常有限。</p>
</div>
<div class="section" id="id29">
<h3>5.7 问题的重新参数化<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h3>
<p>通常，基于 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 的采样器在如下情况下效果是最好的：<strong>概率质量矩阵经过适当调整，并且联合后验分布的几何形状比较平滑，不存在犄角、尖头等不规则之处</strong>。这对于许多经典模型来说很容易满足，其中 <code class="docutils literal notranslate"><span class="pre">Bernstein-von</span> <span class="pre">Mises</span> <span class="pre">定理</span></code>等表明：<strong>当有足够数据时，后验将变得相当简单</strong>。</p>
<p>不幸的是，一旦模型变得稍微复杂一点，我们就不能再保证有足够数据来达到这个渐近乌托邦。对于这些模型，通过选择使后验几何更简单的参数化方案，可以极大地改善 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 的行为。</p>
<p>例如，当组级方差参数接近零时，分层模型可能会在极限范围内具有困难的漏斗病理（ <code class="docutils literal notranslate"><span class="pre">Neal,</span> <span class="pre">2011</span></code>） ，但在许多此类问题中，这些计算困难可以使用重新参数化来解决，遵循 <code class="docutils literal notranslate"><span class="pre">Meng</span> <span class="pre">and</span> <span class="pre">van</span> <span class="pre">Dyk,</span> <span class="pre">2001</span> </code>讨论的原则；另见 <code class="docutils literal notranslate"><span class="pre">Betancourt</span> <span class="pre">and</span> <span class="pre">Girolami,</span> <span class="pre">2015</span></code>。</p>
</div>
<div class="section" id="id30">
<h3>5.8 边缘化<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h3>
<p>后验分布中具有挑战性的几何形状通常是来自于参数之间的相互作用。一个例子是上面提到的漏斗形状，我们可以在绘制组级尺度参数 <span class="math notranslate nohighlight">\(\phi\)</span> 和个体级均值 <span class="math notranslate nohighlight">\(\theta\)</span> 的联合密度时观测到。相比之下， <span class="math notranslate nohighlight">\(\phi\)</span> 的边缘密度表现良好。因此，可以有效地从边缘后验中提取 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 样本，
$<span class="math notranslate nohighlight">\(
p(\phi \mid y) = \int_\Theta p(\phi,\theta \mid y) \ \ \rm{d}\theta
\)</span>$</p>
<p>要绘制使用 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 采样的后验图，贝叶斯规则告诉我们只需要边缘似然 <span class="math notranslate nohighlight">\(p(y \mid \phi)\)</span> 。然后，可以通过从条件分布 <span class="math notranslate nohighlight">\(p(\theta \mid \phi,y)\)</span> 中以较小的计算成本进行精确采样来恢复 <span class="math notranslate nohighlight">\(\theta\)</span> 的后验采样。这种边缘化策略特别适用于具有正态似然的高斯过程（例如 <code class="docutils literal notranslate"><span class="pre">Rasmussen</span> <span class="pre">and</span> <span class="pre">Williams,</span> <span class="pre">2006</span></code> ；<code class="docutils literal notranslate"><span class="pre">Betancourt,</span> <span class="pre">2020b</span></code>）。</p>
<p>一般而言，密度 <span class="math notranslate nohighlight">\(p(y \mid \phi)\)</span> 和 <span class="math notranslate nohighlight">\(p(\theta \mid \phi,y)\)</span> 不可用。利用问题的结构，我们可以使用<code class="docutils literal notranslate"><span class="pre">拉普拉斯近似</span></code>来逼近这些分布，特别是对于<code class="docutils literal notranslate"><span class="pre">隐高斯模型</span></code>（例如，<code class="docutils literal notranslate"><span class="pre">Tierney</span> <span class="pre">and</span> <span class="pre">Kadane,</span> <span class="pre">1986</span></code> ；<code class="docutils literal notranslate"><span class="pre">Rasmussen</span> <span class="pre">and</span> <span class="pre">Williams,</span> <span class="pre">2006</span></code> ；<code class="docutils literal notranslate"><span class="pre">Rue</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2009</span></code> ； <code class="docutils literal notranslate"><span class="pre">Margossian</span> <span class="pre">等，2020b</span></code> ）。当与 <code class="docutils literal notranslate"><span class="pre">HMC</span></code> 结合使用时，如果允许以偏差为代价，这种边缘化方案可以根据情况比重新参数化更有效；有关该主题的讨论，请参阅 <code class="docutils literal notranslate"><span class="pre">Margossian</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020a</span></code>。</p>
</div>
<div class="section" id="id31">
<h3>5.9 增加先验信息<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h3>
<p>通常，计算中的问题可以通过包含已经可用但尚未包含在模型中的先验信息来解决，例如，因为领域专家的先验获取成本很高（<code class="docutils literal notranslate"><span class="pre">O'Hagan</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2006</span></code> ；  <code class="docutils literal notranslate"><span class="pre">Sarma</span> <span class="pre">and</span> <span class="pre">Kay,</span> <span class="pre">2020</span></code> ），我们从一些模板模型和先验模型开始（第 2.1 节）。在某些情况下，运行更多的迭代也有帮助。但是当添加合理的先验信息时，许多拟合问题就会消失，这并不是说先验的主要用途是解决拟合问题。</p>
<p>我们可能已经假设（或希望）数据对模型的所有部分都足够有用，但仔细检查或作为计算诊断的副产品，我们可能会发现情况并非如此。在经典统计中，模型有时被归类为可识别或不可识别，但这可能会产生误导（即使在添加了部分或弱可识别性等中间类别之后），因为可以从观测中学到的信息量还取决于具体的实现实际获得的数据。此外，“识别”在统计学中被正式定义为渐近属性，但在贝叶斯推断中，我们关心对有限数据的推断，特别是考虑到我们的模型通常会随着更多数据被包含在分析中而增加大小和复杂性。渐近结果可以提供对有限样本性能的一些见解，但我们通常更愿意考虑摆在我们面前的后验分布。  <code class="docutils literal notranslate"><span class="pre">Lindley</span> <span class="pre">,</span> <span class="pre">1956</span></code>  以及  <code class="docutils literal notranslate"><span class="pre">Goel</span> <span class="pre">and</span> <span class="pre">DeGroot</span> <span class="pre">,</span> <span class="pre">1981</span></code>  讨论了如何衡量实验提供的信息，即后验与先验的不同。如果数据对模型的某些方面没有提供信息，我们可以通过先验提供更多信息来改善情况。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084016-9cdf.webp" /></p>
<blockquote>
<div><p>图 12：来自模型的模拟数据，<span class="math notranslate nohighlight">\(y = (a_1e^{−b_1x} + a_2e^{−b_2x}) ∗\mathrm{error}\)</span>:  (a) 设置 <span class="math notranslate nohighlight">\((b_1,b_2) = (0.1,2.0)\)</span>，和 (b) 设置 <span class="math notranslate nohighlight">\((b_1,b_2) = (0.1,0.2)\)</span>。此外，第二个图中的虚线显示了曲线 <span class="math notranslate nohighlight">\(y = 1.8e^{-0.135x}\)</span>，它几乎与这些数据范围内的真实曲线完全一致。很容易将模型拟合到左图中的数据并恢复真实的参数值。然而，对于右图中的数据，观测并没有提供充分降低不确定性的信息，并且模型只能使用提供需要缺失信息的先验分布来稳定拟合。</p>
</div></blockquote>
<p>此外，我们通常更喜欢一个参数能够被数据中的信息更新的模型，而不是一个更接近事实但数据无法提供足够信息的模型。在第 6.2-6.3 节中，我们讨论了用于评估单个数据点或超参数信息量的工具。</p>
<p>我们用估计“衰减率未知的下降指数总和”的任务来说明。这项任务是数值分析中众所周知的病态问题之一，也出现在药理学等应用中 ( <code class="docutils literal notranslate"><span class="pre">Jacquez,</span> <span class="pre">1972</span></code> )。我们假设数据</p>
<div class="math notranslate nohighlight">
\[
y_i = (a_1e^{−b_1x_i} + a_2e^{−b_2x_i} ) \times e^{\epsilon_i} ，\mathrm{for} \ i = 1,...,n,
\]</div>
<p>其中，独立误差 <span class="math notranslate nohighlight">\(\epsilon_i  \sim  	\text{Normal}(0,\sigma)\)</span> ；系数 <span class="math notranslate nohighlight">\(a_1\)</span>、<span class="math notranslate nohighlight">\(a_2\)</span> 和残差标准偏差 <span class="math notranslate nohighlight">\(\sigma\)</span> 被限制为正数；参数 <span class="math notranslate nohighlight">\(b_1\)</span> 和 <span class="math notranslate nohighlight">\(b_2\)</span> 也是正的（假设呈指数下降而不是指数增长），并且被约束为有序，即 <span class="math notranslate nohighlight">\(b_1 &lt; b_2\)</span> ，以便唯一地定义两个模型组件。</p>
<p>我们从一个模型的模拟伪数据开始，该模型的两条曲线应该清楚地区分，设置 <span class="math notranslate nohighlight">\(b_1 = 0.1\)</span> 和 <span class="math notranslate nohighlight">\(b_2 = 2.0\)</span>，两者比例因子为 <span class="math notranslate nohighlight">\(20\)</span>。我们模拟了 <span class="math notranslate nohighlight">\(1000\)</span> 个数据点，其中预测值 <span class="math notranslate nohighlight">\(x\)</span> 在 <span class="math notranslate nohighlight">\(0\)</span> 到 <span class="math notranslate nohighlight">\(10\)</span> 之间均匀分布，并且有些随意地设置 <span class="math notranslate nohighlight">\(a_1 = 1.0, a_2 = 0.8, \sigma = 0.2\)</span> 。图 12a 显示了真实曲线和模拟数据。然后我们使用 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 从数据中拟合模型。模拟运行平稳，后验推断恢复了模型的五个参数，鉴于数据是从模型中模拟出来的，这并不奇怪。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084048-7d55.webp" /></p>
<blockquote>
<div><p>图 13：添加的数据如何改变后验分布几何形状的示例。(A) 正态似然作为平均值 <span class="math notranslate nohighlight">\(\mu\)</span> 和标准差 <span class="math notranslate nohighlight">\(\sigma\)</span> 的函数，随着从标准正态分布中抽取的可用观测值数量 <span class="math notranslate nohighlight">\(N\)</span> 增加而不断增加。对于 <span class="math notranslate nohighlight">\(N = 1\)</span>，似然的增加无边界，对于 <span class="math notranslate nohighlight">\(N = 2\)</span>，几何形状仍然是漏斗状，这可能会导致计算问题。对于 <span class="math notranslate nohighlight">\(N = 8\)</span>，漏斗状形态被抑制。 (B) 使用 <code class="docutils literal notranslate"><span class="pre">Lotka-Volterra</span></code> 人口动态模型（总共 <span class="math notranslate nohighlight">\(8\)</span> 个参数）的实际示例，如  <code class="docutils literal notranslate"><span class="pre">Carpenter</span> <span class="pre">,</span> <span class="pre">2018</span></code>  所述，显示了从在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 中拟合模型得出的两个参数的后验样本散点图。具有 <span class="math notranslate nohighlight">\(6\)</span> 个数据点的拟合显示出漏斗形状。红点表示发散的转移，表明采样器遇到了困难的几何形状并且结果不可信。当使用 <span class="math notranslate nohighlight">\(9\)</span> 个数据点时 ，<code class="docutils literal notranslate"><span class="pre">Stan</span></code>  能够拟合模型，尽管几何形状略有不均匀。当拟合到 <span class="math notranslate nohighlight">\(21\)</span> 个数据点时，该模型表现良好。</p>
</div></blockquote>
<p>但现在我们使问题变得稍微困难​​一些。该模型在构造上仍然是正确的，但是我们没有将 <span class="math notranslate nohighlight">\((b_1,b_2)\)</span> 设置为 <span class="math notranslate nohighlight">\((0.1,2.0)\)</span>，而是将它们设为 <span class="math notranslate nohighlight">\((0.1,0.2)\)</span>，因此现在只有 <span class="math notranslate nohighlight">\(2\)</span> 的因子将两个下降指数的尺度分开。模拟数据如图 12b 所示。现在当我们尝试在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 中拟合模型时，我们得到了可怕的收敛。两个下降的指数变得非常难以区分，正如在图中通过还包括曲线 <span class="math notranslate nohighlight">\(y = 1.8e^{−0.135x}\)</span> 所表明的那样，在给定这些数据的情况下，基本上不可能与真实模型区分开来。</p>
<p>我们可以使通过添加先验信息使计算更加稳定。例如，将所有参数的先验都默认为 <span class="math notranslate nohighlight">\(\text{Normal}(0,1)\)</span> 就可以做充分正则化。但如果模型已经建立，且参数大致在单位尺度上，那么先验信息仍然很弱，如第 2.3 节所述。在这种情况下，我们还可以检查后验推断对先验选择的敏感性，通过与 <span class="math notranslate nohighlight">\(\text{Normal}(0,0.5)\)</span> 和 <span class="math notranslate nohighlight">\(\text{Normal}(0,2)\)</span> 等替代方案进行比较，或者通过区分关于先验尺度的推断，如所讨论的在第 6.3 节中。</p>
<p>使用先验的信息性正态分布增加了后验密度的<code class="docutils literal notranslate"><span class="pre">对数凹尾（</span> <span class="pre">tail-log-concavity</span> <span class="pre">）</span></code>，这导致更快的 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 混合时间。但是信息性先验并不代表模型偏差与计算效率的权衡；相反，在这种情况下，随着计算负担的减轻，模型拟合得到了改进，这是第 5.1 节中讨论的通俗定理的一个实例。更一般地，可以有厚尾的强先验，因此尾行为不能保证更多对数凹。另一方面，先验在似然的上下文中可能很弱，同时仍然保证<code class="docutils literal notranslate"><span class="pre">对数凹尾</span></code>。这与模型的信息量取决于提出的问题有关。</p>
<p>在抽象层次上，将阶梯考虑为四个步骤：</p>
<ol class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 混合不良；</p></li>
<li><p>困难的几何学作为对上述的数学解释；</p></li>
<li><p>模型某些部分的弱信息数据作为对上述的统计解释；</p></li>
<li><p>实质性先验信息作为上述问题的解决方案。</p></li>
</ol>
<p>从这个阶梯的开始，我们有计算故障排除；从最后开始，计算工作流程。</p>
<p>作为另一个例子，当组级方差参数接近零时，试图在极限范围内避免分层模型的漏斗病理，可以使用避零先验（例如，<code class="docutils literal notranslate"><span class="pre">对数正态分布</span></code>或<code class="docutils literal notranslate"><span class="pre">逆伽马分布</span></code> ） 避开似然的高曲率区域； <code class="docutils literal notranslate"><span class="pre">Chung</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2013,</span> <span class="pre">2014</span></code> 讨论了惩罚边缘似然估计的相关想法。当此类先验信息可用时，避零先验是有意义的 —— 例如对于高斯过程的长度尺度参数（ <code class="docutils literal notranslate"><span class="pre">Fuglstad</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ）—— 但我们在此使用此类限制只是为了使算法运行速度更快。最终，如果使用限制性先验来加速计算，我们应该清楚这是在向模型添加信息。</p>
<p>更一般地说，我们发现，统计拟合算法的混合不良通常可以通过更强的正则化来解决。然而，这并不是免费的：为了在不模糊待估计模型的各方面情况下，有效地进行正则化，我们需要一些主题知识（ 真实的先验信息、经验信息 ）。随意调整模型直到计算问题消失是危险的，并且可能会威胁推断的有效性，不过现在还没有一种好的方法来诊断这个问题。</p>
</div>
<div class="section" id="id32">
<h3>5.10 增加数据<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h3>
<p>与添加先验信息类似，可以通过添加在模型内处理的新数据源来约束模型。例如，一次校准实验可以得到响应的标准差信息。</p>
<p>在其他情况下，对于较大数据集表现良好的模型在小数据范围内可能存在计算问题；图 13 显示了一个示例。虽然在这种情况下，后验的漏斗形状看起来与分层模型中的漏斗相似，但这种病态更难避免，通常只能承认：数据未能提供支撑完整模型的信息，需要使用更简单的模型。  <code class="docutils literal notranslate"><span class="pre">Betancourt</span> <span class="pre">,</span> <span class="pre">2018</span></code>  进一步讨论了这个问题。</p>
</div>
</div>
<div class="section" id="id33">
<h2>6 评估和使用拟合后的模型<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h2>
<p>模型拟合好后，评估拟合的工作流程会更加复杂，因为可以检查许多不同的东西，而这些检查中的每一个都可以指向许多方向。统计模型可以针对多个目标进行拟合，并针对不同的用户群体开发统计方法。需要检查的模型要素取决于应用。</p>
<div class="section" id="id34">
<h3>6.1 后验预测性检查<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h3>
<p>后验预测性检查类似于先验预测性检查（第 2.4 节），只不过使用的参数实例抽取自后验分布而不是先验分布。<strong>先验预测性检查是一种理解模型和指定先验含义的方法，而后验预测性检查允许人们检查模型对真实数据的拟合情况</strong>（ <code class="docutils literal notranslate"><span class="pre">Box,</span> <span class="pre">1980</span></code> ， <code class="docutils literal notranslate"><span class="pre">Rubin,</span> <span class="pre">1984</span></code> ， <code class="docutils literal notranslate"><span class="pre">Gelman、Meng</span> <span class="pre">and</span> <span class="pre">Stern,</span> <span class="pre">1996</span></code> ）。</p>
<p>将来自后验预测性分布的模拟数据集与实际数据集进行比较时，如果正在分析的数据集不能代表后验预测性分布，则表明模型无法描述数据的某些方面。最直接的检查就是“<strong>对比预测性分布模拟与数据完整分布</strong>”，或“比较两者之间在数据（或子集）上计算的汇总统计量”，特别是对于模型中未包含的分组（ 参见图 14 ）。</p>
<p>没有通用的方法来选择应该对模型执行哪些检查，但运行一些上述的直接检查可以防止比较明显的严重错误指定。同时，也没有通用的方法来决定何时这种检查会失败，需要调整模型。</p>
<p>根据分析目标以及特定情况的成本和收益，我们可能会容忍模型未能捕获数据的某些方面，或者可能必须投资于改进模型。总的来说，我们试图找到 “严格的测试”（ <code class="docutils literal notranslate"><span class="pre">Mayo,</span> <span class="pre">2018</span></code> ）：如果模型对我们最关心的问题给出误导性的答案，这些检查可能会失败。</p>
<p>图 15 显示了来自应用的更复杂的后验预测性检查项目。这个例子展示了预测模拟与图形显示相结合的方式，它也说明了预测性检查的实际挑战，因为通常需要针对特定问题提出独特的可视化。</p>
</div>
<div class="section" id="id35">
<h3>6.2 单个数据点和数据子集的交叉验证和影响<a class="headerlink" href="#id35" title="Permalink to this headline">¶</a></h3>
<p>后验预测性检查通常足以揭示模型失配，但由于它同时使用数据进行模型拟合和失配评估，因此可能过于乐观。在交叉验证中，部分数据被遗漏，模型拟合剩余数据，并在遗漏数据上检查预测性能。这改进了预测性检查诊断，尤其是对于灵活模型（例如，参数多于观测值的超参数化模型）。我们发现对进一步评估模型有用的三种使用交叉验证的诊断方法是</p>
<ol class="simple">
<li><p>使用交叉验证预测的校准检查分布，</p></li>
<li><p>确定哪些观测或观测组最难预测，</p></li>
<li><p>确定特定观测的影响力，即它们在其他观测之上提供了多少信息。</p></li>
</ol>
<p>在所有三种情况下，有效的近似值都留给了——使用重要性采样的一次性交叉验证可以通过在每个数据点被遗漏时消除重新拟合模型的需要来促进实际使用（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Paananen</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084117-346f.webp" /></p>
<blockquote>
<div><p>图 14：使用 <code class="docutils literal notranslate"><span class="pre">bayesplot</span></code> R 包中实施的简单后验预测性检查诊断模型失配的示例。在所有图中，<span class="math notranslate nohighlight">\(y\)</span> 是基于输入数据绘制的，而 <span class="math notranslate nohighlight">\(y_{rep}\)</span> 是基于后验模拟的分布绘制的。 (A) 正态分布的“密度”检查是否适合从对数正态分布模拟的数据：<span class="math notranslate nohighlight">\(y_{rep}\)</span> 的尾部表现与 <span class="math notranslate nohighlight">\(y\)</span> 非常不同。 (B) 二项式分布的“统计”检查是否适合从 <span class="math notranslate nohighlight">\(\beta-\)</span> 二项式分布模拟的数据。将 <span class="math notranslate nohighlight">\(y_{rep}\)</span> 数据集的标准偏差 (sd) 直方图与 <span class="math notranslate nohighlight">\(y\)</span> 的 sd 进行比较。检查显示数据具有比模型可以处理的更大的 sd。 (C) 离散数据的“条形”检查（注意 <span class="math notranslate nohighlight">\(y\)</span> 和 <span class="math notranslate nohighlight">\(y_{rep}\)</span> 之间的颜色切换）。这个检查看起来不错：<span class="math notranslate nohighlight">\(y\)</span> 中个体计数的频率分布完全落在 <span class="math notranslate nohighlight">\(y_{rep}\)</span> 中。 (D) 相同的模型和数据，但检查按预测变量分组，该预测变量未包含在模型中但实际上影响了响应。高子组系统地偏离了 <span class="math notranslate nohighlight">\(y_{rep}\)</span> 的范围，表明存在模型未能捕获的额外变异源。</p>
</div></blockquote>
<p>尽管预测性分布的完美校准不是贝叶斯推断的最终目标，但查看校准的留一法交叉验证 (<code class="docutils literal notranslate"><span class="pre">LOO-CV</span></code>) 预测性分布的程度，可以揭示改进模型的机会。虽然后验预测性检查通常将预测的边缘分布与数据分布进行比较，但留一法交叉验证预测性检查着眼于条件预测性分布的校准。</p>
<p>在良好校准下，给定遗漏观测值的预测性分布（也称为<code class="docutils literal notranslate"><span class="pre">概率积分变换，PIT</span></code>）的条件累积概率分布是均匀的。例如，与均匀性的偏差可以揭示预测性分布的分散不足或过度分散。图 16 显示了 <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>  的一个例子。 其中留一法交叉验证概率积分变换 (<code class="docutils literal notranslate"><span class="pre">LOO-PIT</span></code>) 值过于集中在中间附近，表明与实际条件观测相比，预测性分布过于分散。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084206-1013.webp" /></p>
<blockquote>
<div><p>图 15：后验预测示例查看。左列显示从心理学实验中观测数据，显示为 15×23 数组，由 6 个参与者中的每一个的二元响应组成，按行、列和人排序。右列显示来自拟合模型的后验预测性分布的 7 个复制数据集。每个复制的数据集都已排序，因为这是显示的一部分。检查揭示了观测中的一些峰，这些峰没有出现在复制中，表明模型与数据缺乏拟合的一个方面。从格尔曼 et al.。 (2013)。</p>
</div></blockquote>
<p>除了查看条件预测性分布的校准之外，我们还可以查看哪些观测值难以预测，并查看是否存在模式或解释说明为什么有些观测值比其他观测值更难预测。这种方法可以揭示数据或数据处理中的潜在问题，或者指出模型改进的方向（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> ； <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ）。我们通过对孟加拉国一个小地区居民的调查进行分析来说明，该地区受到饮用水中砷的影响。井中砷含量升高的受访者被问及他们是否有兴趣从邻居的井中换水，并且一系列模型适用于在给定家庭信息的情况下预测这种二元响应（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> ）。</p>
<p>图 17 比较两个模型的逐点对数分数。图 17a 左侧和图 17b 右下方的分散蓝点对应于其中一个模型拟合特别差的数据点，即对预期对数预测密度的负贡献较大。我们可以对所有逐点差异求和，以产生 <span class="math notranslate nohighlight">\(16.4\)</span> 的预期对数预测密度 <span class="math notranslate nohighlight">\(\rm elpd_{loo}\)</span> 的估计差异，标准误差仅为 <span class="math notranslate nohighlight">\(4.4\)</span> ，但除此之外，我们可以使用此图来找出哪些数据点给模型带来了问题，在此案例 <span class="math notranslate nohighlight">\(10-15\)</span> 现有砷水平非常高的非转换者。</p>
<p>建议在孟加拉国采取的行动。<code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> 提供了一个例子，其中 <code class="docutils literal notranslate"><span class="pre">LOO-CV</span></code> 表明问题促使人们努力改进统计模型。</p>
<p>上述两种方法侧重于预测，但我们也可以看看当每个数据点被遗漏时参数推断如何变化，这提供了对每次观测的影响的感觉。与更普遍的交叉验证一样，如果数据被聚类或以其他方式结构化，因此需要删除多个点才能产生效果，这种方法有局限性，但它仍然可以作为一般贝叶斯工作流程的一部分，因为它的计算成本很低并且在许多应用环境中都很有价值。遵循这种交叉验证的想法，可以根据逼近 <code class="docutils literal notranslate"><span class="pre">LOO-CV</span></code> 时计算的重要性权重分布的属性来总结单个数据点 <span class="math notranslate nohighlight">\(y_i\)</span> 的影响（有关逼近和相应实现的详细信息，请参见  <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> ）在 <code class="docutils literal notranslate"><span class="pre">loo</span></code> 的 <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">包</span></code>中 (<code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code>)。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084810-b_17a.webp" /></p>
<blockquote>
<div><p>图 16：留一法交叉验证概率积分变换 (<code class="docutils literal notranslate"><span class="pre">LOO-PIT</span></code>) 图评估拟合模型的预测校准。在完美校准下，<code class="docutils literal notranslate"><span class="pre">LOO-PIT</span> <span class="pre">值</span></code> 将是一致的。在这种情况下，值集中在中间附近，表明预测性分布太宽( <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> )。</p>
</div></blockquote>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084251-e4a3.webp" /></p>
<blockquote>
<div><p>图 17：逻辑回归示例，比较两个模型的逐点贡献以遗漏一个（<code class="docutils literal notranslate"><span class="pre">LOO</span></code>）交叉验证错误：（a）直接比较 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 的贡献； (b) 绘制 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 差异作为关键预测因子（现有砷水平）的函数。为了帮助洞察，我们根据（二进制）输出对数据进行了着色，红色对应于 <span class="math notranslate nohighlight">\(y = 1\)</span>，蓝色代表 <span class="math notranslate nohighlight">\(y = 0\)</span>。对于任何给定的数据点，一个模型将比另一个更适合，但对于本示例，图表显示，模型之间的 <code class="docutils literal notranslate"><span class="pre">LOO</span></code> 差异源于线性模型对 <span class="math notranslate nohighlight">\(10-15\)</span> 个特定数据点的预测不佳。来自 <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code>.</p>
</div></blockquote>
<p>重要性加权的另一种方法是将数据点的删除作为更大模型空间中的梯度。假设我们有一个简单的独立似然，<span class="math notranslate nohighlight">\(\prod^n_{i=1} p(y_i \mid \theta)\)</span> ，我们使用更一般的形式，<span class="math notranslate nohighlight">\(\prod^n_{i=1} p(y_i \mid \theta)^{\alpha_i}\)</span> ，当对于所有 <span class="math notranslate nohighlight">\(i\)</span> ，<span class="math notranslate nohighlight">\(\alpha_i = 1\)</span> 。留一法交叉验证对应于一次为一个观测设置 <span class="math notranslate nohighlight">\(\alpha_i = 0\)</span> 。但是另一种选择，由 <code class="docutils literal notranslate"><span class="pre">Giordano</span> <span class="pre">et</span> <span class="pre">al.</span> <span class="pre">,</span> <span class="pre">2018</span></code>讨论并由 <code class="docutils literal notranslate"><span class="pre">Giordano</span> <span class="pre">,</span> <span class="pre">2018</span></code> 实施，是计算作为 <span class="math notranslate nohighlight">\(\alpha\)</span> 函数的增广对数似然的梯度：这可以解释为一种差分交叉验证或影响函数。</p>
<p>多级（分层）模型的交叉验证需要更多的思考。留一法仍然是可能的，但它并不总是符合我们的推断目标。例如，在执行多级回归以调整政治调查时，我们通常对估计州级的意见感兴趣。模型可以在州级显示真正的改进，而这在个人观测的交叉验证级是无法检测到的（ <code class="docutils literal notranslate"><span class="pre">Wang</span> <span class="pre">and</span> <span class="pre">Gelman,</span> <span class="pre">2016</span></code> ）。 <code class="docutils literal notranslate"><span class="pre">Millar</span> <span class="pre">,</span> <span class="pre">2018</span></code>、<code class="docutils literal notranslate"><span class="pre">Merkle、Furr</span> <span class="pre">and</span> <span class="pre">Rabe-Hesketh,</span> <span class="pre">2019</span></code> and <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">,</span> <span class="pre">2019</span></code> 在分层模型中展示了不同的交叉验证变体及其近似值，包括留一单元输出和留一组输出。在应用问题中，我们进行了混合，保留一些个体观测和一些群体，然后评估两个级别的预测（ <code class="docutils literal notranslate"><span class="pre">Price</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">1996</span></code> ）。</p>
<p>不幸的是，使用重要性抽样来近似这种交叉验证程序往往比在留一法。这是因为一次忽略了更多的观测，这意味着从完整模型到子集模型的后验分布发生了更强的变化。因此，我们可能不得不依赖更昂贵的模型改装来获得留一单元和留一组出交叉验证结果。</p>
</div>
<div class="section" id="id36">
<h3>6.3 先验信息的影响<a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h3>
<p>复杂模型可能难以理解，因此需要探索性模型分析（  <code class="docutils literal notranslate"><span class="pre">Unwin</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2003</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Wickham,</span> <span class="pre">2006</span></code> ）和可解释的人工智能（ <code class="docutils literal notranslate"><span class="pre">Chen</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2018</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Gunning,</span> <span class="pre">2017</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Rudin,</span> <span class="pre">2018</span></code> ），它们对方法进行了补充用于使用一系列相互关联的方法评估、比较和平均模型，包括交叉验证、堆叠、提升和贝叶斯评估。</p>
<p>在本节中，我们将讨论了解拟合模型下的后验推断如何依赖于数据和先验的方法。</p>
<p>统计模型可以通过两种方式来理解：生成式和推断式。从生成的角度来看，我们想了解参数如何映射到数据。我们可以执行先验预测性模拟来可视化模型中可能的数据（如图 4 所示）。从推断的角度来看，我们想了解从输入（数据和先验分布）到输出（估计和不确定性）的路径。</p>
<p>了解先验影响的最直接方法是通过用多个先验重新拟合模型来运行敏感性分析，然而，如果模型需要很长时间才能拟合，这可能会非常昂贵。但是，有一些捷径。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084835-822c.webp" /></p>
<blockquote>
<div><p>图 18：针对毒理学问题的统计模型的静态敏感性分析示例。每个图都显示了在两种条件下代谢百分比的后验模拟图（因此每个图顶部和底部的点簇），绘制与模型中的两个参数的关系。这些图显示，在一种条件下对代谢百分比的推断对任一参数几乎没有敏感性，但对另一种情况具有很强的敏感性。这种图表可用于评估对替代先验分布的敏感性，而无需重新拟合模型。来自 <code class="docutils literal notranslate"><span class="pre">Gelman、</span> <span class="pre">Bois</span> <span class="pre">and</span> <span class="pre">Jiang,</span> <span class="pre">1996</span></code>。</p>
</div></blockquote>
<p>一种方法是计算先验和后验之间的收缩，例如，通过比较每个参数的先验标准偏差或通过比较先验和后验分位数。如果相对于先验的数据对特定参数提供信息，则该参数的收缩应该更强。这种类型的检查在文献中得到了广泛的发展。例如，参见  <code class="docutils literal notranslate"><span class="pre">Nott</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> 。</p>
<p>另一种方法是使用重要性采样来使用旧模型的后验来近似新模型的后验，前提是两个后验足够相似以便重要性采样桥接（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>  ； Paananen et al.。 , 2020)。如果不是，这本身也是有价值的信息（参见第 6.2 节）。</p>
<p>另一种方法是执行静态敏感性分析，这是一种研究后验推断对先验扰动的敏感性的方法，而不需要模型使用替代先验分布重新拟合（ <code class="docutils literal notranslate"><span class="pre">Gelman、Bois</span> <span class="pre">and</span> <span class="pre">Jiang,</span> <span class="pre">1996</span></code> ；示例见图 18）。图 18 中的每个图都显示了后验模拟，揭示了作为模型中参数的函数的感兴趣量（在本例中，是身体代谢的毒素的百分比）的后验依赖性。</p>
<p>将图 18 视为四个散点图，因为这两个图表中的每一个实际上都是叠加的两个图，一个用于低暴露于毒素的条件，另一个用于高暴露。这四个图的每一个都可以用两种方式解释。首先，直接解释显示了感兴趣的预测量（体内代谢的百分比）与特定参数（例如，毒素代谢的比例系数）之间的后验相关性。其次，可以间接读取每个散点图，以揭示绘制在 <span class="math notranslate nohighlight">\(y\)</span> 轴上的数量对绘制在 <span class="math notranslate nohighlight">\(x\)</span> 轴上的参数的先验的敏感性。解释如下：绘制在 <span class="math notranslate nohighlight">\(x\)</span> 轴上的参数的 35 先验分布的变化可以通过根据新的先验与分析中使用的比率重新加权图表上的点来执行。使用这些图，重要性权重可以隐式地可视化：可以根据散点图中的依赖性看到先验分布变化的影响。</p>
<p>也可以更正式地研究先验和数据到后验的映射，如第 1 节所述 6.2.</p>
</div>
<div class="section" id="id37">
<h3>6.4 对推断结果进行总结<a class="headerlink" href="#id37" title="Permalink to this headline">¶</a></h3>
<p>贝叶斯推断非常适用于具有隐变量和其他不确定性无法解决的设置的问题。此外，我们经常使用分层模型，其中包括表示变化的成批参数。例如，在报告我们的选举预测模型的结果时，我们对预测投票的不确定性以及各州之间的变化感兴趣。</p>
<p>不幸的是，显示贝叶斯推断的常用方法并没有完全捕捉到我们的多层次变化和不确定性。推论。参数估计、不确定性和标准误差的表格甚至图表仅显示一维边缘，而边缘后验分布图对于具有许多参数的模型来说是笨拙的，并且也无法捕捉层次结构中不确定性和变化之间的相互作用模型。</p>
<p>首先，我们应该遵循良好的统计实践和图形数据和拟合模型的一般原则，既为了“探索性数据分析”的目的，即发现数据中的意外模式，也更直接地了解模型与模型的关系。用于拟合它的数据。</p>
<p>我们从  <code class="docutils literal notranslate"><span class="pre">Ghitza</span> <span class="pre">and</span> <span class="pre">Gelman</span> <span class="pre">,</span> <span class="pre">2020</span></code>  对 2016 年美国总统大选投票偏好的分析中说明了图形模型探索和总结的一些用途。图 19 显示了支持两位候选人的估计性别差距，首先显示为地图，然后显示为散点图。该地图是可视化这些估计的自然第一步，它揭示了一些有趣的地理模式，然后在散点图中以更集中的方式进行探索。图 20 通过与更简单的县级估计进行比较来评估模型。此示例演示了探索性图形中的一般工作流程，其中推断总结的结果激发了未来的探索。</p>
<p><code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>  提出了我们关于贝叶斯工作流图形的一些想法，其中一些已经在 R 包 bayesplot 中实现（  <code class="docutils literal notranslate"><span class="pre">Gabry</span> <span class="pre">et</span> <span class="pre">al.,2020b</span></code> ，另见  <code class="docutils literal notranslate"><span class="pre">Kay,2020ab</span></code>  ； <code class="docutils literal notranslate"><span class="pre">Kumar,2019</span></code> ）。概率编程最终有可能允许像任何其他数据对象一样操纵随机变量，所有绘图和计算中都隐含着不确定性（ <code class="docutils literal notranslate"><span class="pre">Kerman</span> <span class="pre">and</span> <span class="pre">Gelman,</span> <span class="pre">2004,</span> <span class="pre">2007</span></code> ），但需要做更多的工作来将这种似然转化为现实，超越点估计和区间估计，以便我们可以充分利用我们拟合的模型。</p>
</div>
</div>
<div class="section" id="id38">
<h2>7 修改模型<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h2>
<p>模型构建是一项类似于语言的任务，其中建模者将现有组件（线性、逻辑和指数函数；加法和乘法模型；二项式、泊松和正态分布；变系数等）组合在一起，以包含新的数据和现有数据的附加特征，以及与感兴趣的底层过程的链接。</p>
<p>如第 2.2 节所述，模型的大部分部分可以被视为允许替换或扩展的占位符。或者，我们可能会发现需要使用近似模型或近似算法，如第 3.3 节所述。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084921-98de.webp" /></p>
<blockquote>
<div><p>图 19：从模型拟合到 <span class="math notranslate nohighlight">\(2016\)</span> 年美国总统竞选期间的调查数据：(a) 估计之间的性别差距白人选民，(b) 绘制的估计性别差距与奥巴马 <span class="math notranslate nohighlight">\(2012\)</span> 年白人选票中估计的县级选票份额。每个圆圈的面积与该县的选民人数成正比，地图上的颜色代表从深紫色（比较白人男性和白人女性的投票模式没有差异）到浅灰色（支持克林顿的白人女性）的范围比白人男性多 <span class="math notranslate nohighlight">\(7.5\)</span> 个百分点）到深绿色（白人性别差距为 <span class="math notranslate nohighlight">\(15\)</span> 个百分点）。显着的地理模式——南部大部分地区的白人性别差距较低，西部以及东北部和中西部的大部分地区较高——激发了散点图，这表明白人性别差距往往在白人人口较多的县中最高。投票接近平分。来自  <code class="docutils literal notranslate"><span class="pre">Ghitza</span> <span class="pre">and</span> <span class="pre">Gelman</span> <span class="pre">,</span> <span class="pre">2020</span></code> 。</p>
</div></blockquote>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231084951-d327.webp" /></p>
<blockquote>
<div><p>图 20：对图 19 所示模型的一个方面的评估，比较了根据两个不同模型估计的县级对克林顿的支持。我们将其包含在这里是为了说明可以使用图形方法来总结、理解、评估和比较拟合模型的方式。来自  <code class="docutils literal notranslate"><span class="pre">Ghitza</span> <span class="pre">and</span> <span class="pre">Gelman</span> <span class="pre">,</span> <span class="pre">2020</span></code> 。</p>
</div></blockquote>
<p>模型扩展能够响应新数据、模型对已有数据拟合失败、现有拟合过程计算困难等一系列问题。对于 <code class="docutils literal notranslate"><span class="pre">Gelman、Hullman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> 中描述的选举预测。我们从 <code class="docutils literal notranslate"><span class="pre">Linzer,</span> <span class="pre">2013</span></code> 的民意调查聚合模型开始，我们在 <span class="math notranslate nohighlight">\(2016\)</span> 年对其进行了调整，但在某些摇摆州的预测明显失败，我们将其归因于州之间投票摇摆的相关性建模不佳，以及民意调查中存在非抽样错误（ <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">and</span> <span class="pre">Azari,</span> <span class="pre">2017</span></code> ）。在我们的修订中，扩展了模型以包含这两个功能。第 10 节和第 11 节给出了迭代模型构建和评估的扩展示例。</p>
<div class="section" id="id39">
<h3>7.1 为数据构建模型<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h3>
<p>在统计学的教科书中，给定参数的数据分布通常只是给定的。 但在应用中，我们希望基于对数据拟合情况和领域专业知识的组合，来建立数据模型。如果模型是从一个有限菜单中做选择，那我们至少希望它是开放的。通常，数据模型最重要的方面不是其概率分布形式，而是数据如何与感兴趣的基础参数相关联。例如，在选举预测中，民意调查模型包括个人民意调查和民意调查平均值的非抽样误差项（ <code class="docutils literal notranslate"><span class="pre">Shirani-Mehr</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2018</span></code> ）。</p>
<p>此时一个相关挑战出现了，因为数据在到达我们之前通常会经过预处理，因此任何生成式模型都必然是一个近似值。这可能出现在元分析中、或者使用机器学习算法和降维技术将大量预测变量组合成一个或两个汇总变量的场景中。与往常一样，我们需要关注数据质量，数据模型最重要的方面可能是偏差，而不是传统上被认为是测量误差的那个部分。理解这一点会影响贝叶斯工作流程，因为扩展模型以允许系统误差非常有价值，我们将在 10.5 节给出一个例子。</p>
</div>
<div class="section" id="id40">
<h3>7.2 合并额外的数据<a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h3>
<p>有时统计方法最重要的方面不是它对数据做了什么，而是使用了什么数据。贝叶斯工作流的一个关键部分是扩展模型以利用更多数据。这可以像添加回归预测变量一样简单，但当添加更多参数时，可能有必要假设并非所有参数都能同时对模型产生重大影响。<strong>看到这一点的一种方法是将参数的添加视为先前集中在零的先验分布的松弛</strong>。例如，通过在回归中添加交互项来扩展选举模型以解释政治两极分化，从而允许近年来国民经济预测因子的系数较低。有时我们有两种类似数据的测量形式，因此需要为两个数据源创建一个生成模型。</p>
<p>有时这会带来技术挑战，例如当将样本的直接测量与总体汇总统计相结合，或整合不同质量的测量时（例如， <code class="docutils literal notranslate"><span class="pre">Lin</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">1999</span></code> ），或当信息可用于表格的部分边缘时（ <code class="docutils literal notranslate"><span class="pre">Deming</span> <span class="pre">and</span> <span class="pre">Stephan,</span> <span class="pre">1940</span></code> ）。在 <code class="docutils literal notranslate"><span class="pre">Weber</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2018</span></code> 中，我们拟合了一个药理学模型，该模型具有一组服用某药物的患者的直接数据，但只有一组接受过竞争对手产品的患者的平均数据。为了避免将所有平均患者的结果建模为潜在数据的计算成本，我们设计了一种分析方法来近似相关积分，以便可以将平均数据包含在似然函数中。</p>
</div>
<div class="section" id="id41">
<h3>7.3 使用先验分布<a class="headerlink" href="#id41" title="Permalink to this headline">¶</a></h3>
<p>在贝叶斯统计中，我们经常谈论非信息性或完全信息性先验，但这两种先验通常都不存在：均匀先验包含了一些信息，因为它取决于模型的参数化方案；参考先验取决于用于收集新数据的假设渐近机制（<code class="docutils literal notranslate"><span class="pre">Berger</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2009</span></code>）；一个信息丰富的先验也很少能够包含所有的可用知识。</p>
<p>相反，我们更愿意考虑似然的阶梯：</p>
<p>-&gt;（不适当的）平坦先验；</p>
<p>—-&gt; 模糊但适当的先验；</p>
<p>——-&gt; 信息非常弱的先验；</p>
<p>———-&gt; 通用的弱信息先验；</p>
<p>————-&gt; 特定的信息性先验。</p>
<p>例如，我们的选举模型包括随机游走条款，以允许州和国家层面的态度变化。这些随机游走中的每一个都有标准差参数，对应于一天内无法解释的变化（ 在 <span class="math notranslate nohighlight">\(\text{logit}\)</span>  尺度上 ）。</p>
<p>这个新创的标准差可以被赋予：</p>
<ul class="simple">
<li><p>一个均匀先验</p></li>
<li><p>一个模糊但适当的先验， 例如，<span class="math notranslate nohighlight">\(\text{Normal}^+(0 ,1000)\)</span>，其中使用符号 <span class="math notranslate nohighlight">\(\text{Normal}^+\)</span> 来表示被截断为正的正态分布</p></li>
<li><p>一个弱先验，例如，百分比尺度上的 <span class="math notranslate nohighlight">\(\text{Normal}^+(0,1)\)</span> ，这将允许不切实际的大日常支持候选人的概率会发生 <span class="math notranslate nohighlight">\(0.25\)</span> 个百分点的变化，但仍会使分布远离极端参数值</p></li>
<li><p>或者更多信息的先验，例如 <span class="math notranslate nohighlight">\(\text{Normal}^+(0,0.1)\)</span> ，它不包含我们所有的先验知识，但确实将此参数软限制在合理范围内。</p></li>
</ul>
<p>我们的观点是：<strong>选择先验的同时，也在选择要包含在分析任务中的主题相关信息的量</strong>。</p>
<p>理解先验分布的另一种视角是将其作为约束。例如，如果我们拟合线性模型加上样条或高斯过程，<span class="math notranslate nohighlight">\(y = b_0 + b_1x+ g(x) + \text{error}\)</span> ，其中非线性函数 <span class="math notranslate nohighlight">\(g\)</span> 有界，然后在 <span class="math notranslate nohighlight">\(g\)</span> 上具有足够强的先验，我们正在拟合一条接近线性的曲线。在此示例中，先验分布可以表示先验信息，也可以被其视为近似线性曲线模型的声明的一部分。<code class="docutils literal notranslate"><span class="pre">Simpson</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> 进一步讨论了使用先验分布向更简单的模型收缩。这也导致了更普遍的观点，即先验就像统计模型的任何其他部分一样，可以用于不同的目的。模型和先验之间的任何明确区别在很大程度上是任意的，并且通常主要取决于创建者的概念背景区别。</p>
<p>获得合理推断所需的先验信息量很大程度上取决于参数在模型中的作用以及参数在层次结构中的深度（ <code class="docutils literal notranslate"><span class="pre">Goel</span> <span class="pre">and</span> <span class="pre">DeGroot,</span> <span class="pre">1981</span></code> ）。例如，主要控制中心量（ 例如均值或中位数 ）的参数通常比尺度参数更能容忍模糊先验，这比控制尾部量的参数更能容忍模糊先验，例如广义极值分布的形状参数。当模型具有层次结构时，与数据更接近的参数通常比层次结构更下方的参数更愿意容忍模糊的先验。</p>
<p>在贝叶斯工作流中，一系列模型需要先验。通常，随着模型变得更加复杂，所有先验都需要变得更紧密。以下多级数据的简单示例（ 例如，参见  <code class="docutils literal notranslate"><span class="pre">Raudenbush</span> <span class="pre">and</span> <span class="pre">Bryk,</span> <span class="pre">2002</span></code> ）说明了为什么这可能是必要的。</p>
<p>考虑数据为 <span class="math notranslate nohighlight">\(y_{ij}, i = 1,...,n_j, j = 1, ..,J\)</span> 的工作流。 这里 <span class="math notranslate nohighlight">\(i\)</span> 索引了观测，<span class="math notranslate nohighlight">\(j\)</span> 索引了组。想象一下，对于工作流中的第一个模型，我们选择忽略组结构并使用简单的正态分布来表示与均值的偏差。在这种情况下，一些信息预算将用于估计总体均值，而其中一些是花在观测标准差上。如果我们有适量的数据，无论先验有多弱，均值将近似为 <span class="math notranslate nohighlight">\(\bar y= \sum^n_{i=1} y_i/n\)</span> 。此外，新观测的预测性分布将近似为正态 <span class="math notranslate nohighlight">\((\bar y,s)\)</span>，其中 <span class="math notranslate nohighlight">\(s\)</span> 是样本标准偏差。同样，这对于观测标准差的大多数合理先验都是正确的，无论它们有多模糊。</p>
<p>如果工作流程的下一步是使用多级模型以允许平均值随组变化，那么信息预算仍然需要在标准差和均值之间进行划分。但是，该模型现在有 <span class="math notranslate nohighlight">\(J + 1\)</span> 个额外参数（每个组一个，组间标准差一个），因此需要进一步划分均值的预算以对组均值建模，而标准差的预算需要在组内偏差和组间偏差之间分配。但是我们仍然拥有相同数量的数据，因此需要小心确保这种模型扩展不会破坏估计。这意味着除了在新参数上放置适当的先验之外，可能还需要收紧总体均值和观测标准差的先验，以免信息缺乏导致无意义的估计。</p>
<p>一个相关的问题是在高维空间中测量的汇集。例如，在预测变量的数量增加的回归中，如果希望将大部分先验质量保持在峰附近（因为远离峰的体积增加得更快），则系数向量的先验需要在峰附近具有更高的密度，参见  <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">and</span> <span class="pre">Vehtari,</span> <span class="pre">2017</span></code> 。考虑线性或逻辑回归，以及如果权重的边缘先验是固定的， <span class="math notranslate nohighlight">\(R^2\)</span> 上的先验会发生什么。如果我们希望 <span class="math notranslate nohighlight">\(R^2\)</span> 上的先验保持不变，则权重的先验需要变得更紧。图 21 使用先验预测性检查（参见第 2.4 节）来显示线性回归中 <span class="math notranslate nohighlight">\(26\)</span> 个权重的通常弱先验如何对应于强烈支持更高 <span class="math notranslate nohighlight">\(R^2\)</span> 值的先验，也影响后验。从这个角度来看，如果它们大量出现，弱信息但独立的先验可能共同具有强信息。</p>
<p>必须为工作流程中的每个模型指定先验。扩展模型可能需要额外考虑参数化。例如，当从 <span class="math notranslate nohighlight">\(\text{Normal}( \mu ,\sigma)\)</span> 到具有 <span class="math notranslate nohighlight">\(ν\)</span> 自由度的 <span class="math notranslate nohighlight">\(t\)</span> 分布 <span class="math notranslate nohighlight">\(t_ν( \mu ,\sigma)\)</span> 时，我们必须注意 <span class="math notranslate nohighlight">\(\sigma\)</span> 上的先验。尺度参数 <span class="math notranslate nohighlight">\(\sigma\)</span> 对于两者看起来相同模型，但 <span class="math notranslate nohighlight">\(t\)</span> 分布的方差实际上是 <span class="math notranslate nohighlight">\(\frac{ν}{ν−2} \sigma^2\)</span> 而不是 <span class="math notranslate nohighlight">\(\sigma^2\)</span> 。因此，如果 <span class="math notranslate nohighlight">\(ν\)</span> 很小，则 <span class="math notranslate nohighlight">\(\sigma\)</span> 不再接近残差标准偏差。</p>
<p>一般来说，我们需要考虑模型中所有参数的联合先验，这个可以在生成式模型的上下文中评估，以免不幸的取消或共振导致比建模者实际想要的更不稳定或信息量更多的先验（ <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code> ； <code class="docutils literal notranslate"><span class="pre">Kennedy</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ）。正如第 2.4 节所讨论的，先验预测性检查是在特定数据模型的上下文中探索和理解先验分布的一种很好的通用方法。</p>
<p>上述示例包含关于先验的特定信息，但也包含关于我们如何看待工作流的元信息在构建统计模型时。诸如“信息预算仍然需要划分”之类的短语代表了我们做出的关于我们为包含先验信息付出了多少努力的重要但有些非正式的决定。在不承认已经做出的权衡和选择的情况下，在按原样呈现最终模型的文章或教科书中，这种担忧并不总是很清楚。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085024-b2a5.webp" /></p>
<blockquote>
<div><p>图 21：贝叶斯 <span class="math notranslate nohighlight">\(R^2\)</span> 的先验和后验分布用于回归预测学生成绩的 <span class="math notranslate nohighlight">\(26\)</span> 个预测变量，使用三个不同的先验系数：(a) 默认弱先验，(b) 正常先验与预测变量的数量成比例，以及（ c) 规范化的马蹄形先验。来自  <code class="docutils literal notranslate"><span class="pre">Gelman、Hill</span> <span class="pre">and</span> <span class="pre">Vehtari</span> <span class="pre">,</span> <span class="pre">2020</span></code>  的第 12.7 节。</p>
</div></blockquote>
</div>
<div class="section" id="id42">
<h3>7.4 模型拓扑<a class="headerlink" href="#id42" title="Permalink to this headline">¶</a></h3>
<p>考虑一类模型，为了简单起见在某些特定的受限域中，例如自回归移动平均 (ARMA) 模型、二元分类树或具有一些固定输入变量集的线性回归。任何这些框架中的模型都可以构造为偏序：例如，<span class="math notranslate nohighlight">\(\text{AR(1)}\)</span> 比 <span class="math notranslate nohighlight">\(\text{AR(2)}\)</span> 简单，<span class="math notranslate nohighlight">\(\text{AR(2)}\)</span>  比 <span class="math notranslate nohighlight">\(\text{ARMA(2,1)}\)</span>  简单， <span class="math notranslate nohighlight">\(\text{MA(1)}\)</span> 也比 <span class="math notranslate nohighlight">\(\text{ARMA(2,1)}\)</span> 简单，但 <span class="math notranslate nohighlight">\(\text{AR(1)}\)</span> 和 <span class="math notranslate nohighlight">\(\text{MA(1)}\)</span> 本身不是有序的。类似地，树分裂形成偏序，线性回归中包含或排除的 <span class="math notranslate nohighlight">\(2^k\)</span> 种似然可以构造为立方体的角。正如这些例子所示，这些模型框架中的每一个都有自己的拓扑或网络结构，由类中的模型及其偏序决定。</p>
<p>我们称之为模型的拓扑而不是概率空间，因为我们不一定感兴趣为各个模型分配概率。我们在这里的兴趣不是对模型求平均，而是在模型之间导航，拓扑是指模型之间以及网络中相邻模型中参数之间的连接。</p>
<p>这个想法的一个示例实现是 Automatic Statistician ( <code class="docutils literal notranslate"><span class="pre">Hwang</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2016</span></code>  ； <code class="docutils literal notranslate"><span class="pre">Gharamani</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> )，它在特定但开放的类别（例如，时间序列模型和线性回归模型）中搜索模型，使用推断和模型批评来探索模型和数据空间。我们相信，通过对统计建模语言诱导的模型拓扑结构的更正式理解，可以更好地理解并最终改进此类算法。另一个方向是基于菜单的软件包，例如 Prophet（ <code class="docutils literal notranslate"><span class="pre">Taylor</span> <span class="pre">and</span> <span class="pre">Lethem,</span> <span class="pre">2018</span></code> ），它允许用户从一组构建块中组合模型（在这种情况下，用于时间序列预测）。在此类包中，重要的是不仅要能够构建和拟合这些模型，而且要了解每个模型与适合相同数据的更简单或更复杂的变体相比。</p>
<p>自动加法模型就足够了，这里每个模型本身都是一个高维对象。不同模型的输出，作为概率随机变量，可以相加、相乘、线性混合、对数线性混合、逐点混合等，这在我们需要指定的模型拓扑选择范围内。</p>
<p>此外，每个模型在一个框架内有它自己的内部结构，涉及可以从数据中估计的参数。而且，重要的是，网络中不同模型中的参数可以“相互交谈”，因为在模型本身的范围之外具有共享的、可观测的意义。在机器学习和应用统计学中，预测和因果推断是两个熟悉的模型共享推断量示例。在预测中，一组越来越复杂的程序可用于特定的预测目标。在因果推断中，可以使用一系列回归来估计治疗效果，从简单的差异开始，然后转向复杂的交互模型，调整观测到的治疗组和对照组之间的差异。回想一下，因果推断是涉及反事实的预测的一种特殊情况；例如，参见  <code class="docutils literal notranslate"><span class="pre">Morgan</span> <span class="pre">and</span> <span class="pre">Winship</span> <span class="pre">,</span> <span class="pre">2014</span></code> 。</p>
<p>因此，统计或机器学习模型的拓扑结构包括模型的偏序，以及更大框架内跨不同模型的参数或参数函数之间的连接。另一个扭曲是先验分布为结构添加了一个连续的维度，在模型之间架起了桥梁。</p>
</div>
</div>
<div class="section" id="id43">
<h2>8. 理解和比较多个模型<a class="headerlink" href="#id43" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id44">
<h3>8.1 可视化彼此相关的模型<a class="headerlink" href="#id44" title="Permalink to this headline">¶</a></h3>
<p>贝叶斯工作流的关键方面超越了贝叶斯数据分析，是我们在处理单个问题的同时拟合多个模型。我们在这里谈论的不是模型选择或模型平均，而是使用一系列拟合模型来更好地理解每个模型。用  <code class="docutils literal notranslate"><span class="pre">Wickham、Cook</span> <span class="pre">and</span> <span class="pre">Hofmann</span> <span class="pre">,</span> <span class="pre">2015</span></code>  的话来说，我们寻求“探索模型拟合的过程，而不仅仅是最终结果”。我们拟合多个模型有几个原因，包括：</p>
<ul class="simple">
<li><p>拟合和理解一个大模型可能很困难，所以我们将从简单的模型构建它。</p></li>
<li><p>在构建我们的模型时，我们犯了很多错误：拼写错误、编码错误、概念错误（例如，没有意识到观测值不包含模型某些部分的有用信息）等。</p></li>
<li><p>随着我们获得更多数据，我们通常会相应地扩展我们的模型。例如，如果我们在做药理学研究并获得一组新患者的数据，我们可能会让某些参数因组而异。</p></li>
<li><p>通常我们拟合一个在数学上明确指定的模型，但是一旦我们将其拟合到数据中，我们就会意识到我们可以做更多的事情，所以我们扩展它。</p></li>
<li><p>与此相关的是，当我们第一次拟合模型时，我们经常将它与各种占位符放在一起。我们经常从弱先验开始并增强它们，或者从强先验开始并放松它们。</p></li>
<li><p>我们将检查模型，发现问题，然后扩展或替换它。这是“贝叶斯数据分析”的一部分；额外的“工作流程”部分是我们仍然保留旧模型，不是为了求平均值，而是为了理解我们在做什么。</p></li>
<li><p>有时我们拟合简单模型作为比较。例如，如果你要进行因果推断的大回归，你还需要进行简单的未调整比较，然后查看调整后的结果。</p></li>
<li><p>上述想法被列为出于统计考虑，但有时由于计算问题，我们被迫采取行动。</p></li>
</ul>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085053-e5e0.webp" /></p>
<blockquote>
<div><p>图 22：比较多个模型中感兴趣的数量的推断的假设图。这里的目标不是执行模型选择或模型平均，而是了解当我们从简单的比较（在图的左侧）到最终模型（在图的右侧）时，对感兴趣量的推断如何变化图），经过各种中间选择。</p>
</div></blockquote>
<p>鉴于我们正在拟合多个模型，我们还必须关注研究人员的自由度（ <code class="docutils literal notranslate"><span class="pre">Simmons</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2011</span></code> ），如果选择了单个最佳模型，则最直接来自过度拟合，或者更巧妙的是，如果我们不小心，我们可以考虑从一组拟合模型中得出的推论来包含一些总的不确定性，而无需认识到还有其他模型我们可以拟合。这种担忧出现在我们的选举预测模型中，最终我们只有少数过去的总统选举用于校准我们的预测。</p>
<p>图 22 说明了基本思想：该图可以表示，例如，用一系列越来越复杂的模型估计的因果效应，从简单的治疗控制比较开始，然后进行一系列调整。即使最终的兴趣只在最终模型中，了解随着调整的增加推断如何变化也很有用。</p>
<p>遵循建议的工作流程并探索模型的拓扑结构通常可以引导我们找到通过所有检查的多个模型。我们可以执行多元宇宙分析并使用所有模型，而不是仅选择一个模型，并查看模型之间的结论如何变化（ <code class="docutils literal notranslate"><span class="pre">Steegen</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2016</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Dragicevic</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Kale、Kay</span> <span class="pre">and</span> <span class="pre">Hullman,</span> <span class="pre">2019</span></code> ）。使用多元宇宙分析还可以减轻验证模型和先验的工作量：如果结论没有改变，那么决定哪个模型“最好”就不太重要了。图 23 显示了一个可能的输出示例。其他分析选择（数据预处理、响应分布、评估指标等）也可以进行多元宇宙分析。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085118-f0c5.webp" /></p>
<blockquote>
<div><p>图 23：来自 Niederlová et al. 的补充材料的多元宇宙分析结果。 (2019)。热图显示了关于表型（PD、CI、REN、HEART、LIV）与 BBSome 各种基因突变（BBS01 - BBS8、cLOF - 功能完全丧失）之间关系的选定结论的统计评估，使用一组贝叶斯分层逻辑回归模型和成对频率论测试。基于后验预测性检查，贝叶斯模型被分类为“主要”（通过所有检查）、“次要”（某些检查中的小问题）和“有问题的拟合”，尽管我们看到大多数结论适用于所有可能的模型。模型在包含的预测变量和先验变量（默认/宽/窄/非常窄）方面有所不同。</p>
</div></blockquote>
</div>
<div class="section" id="id45">
<h3>8.2 交叉验证和模型平均<a class="headerlink" href="#id45" title="Permalink to this headline">¶</a></h3>
<p>我们可以使用交叉验证来比较适合相同数据的模型（ <code class="docutils literal notranslate"><span class="pre">Vehtari</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code>）。在进行模型比较时，如果比较中存在不可忽略的不确定性（ <code class="docutils literal notranslate"><span class="pre">Sivula</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ），我们不应简单地选择具有最佳交叉验证结果的单一模型，因为这会丢弃交叉验证中的所有不确定性过程。相反，我们可以维护此信息并使用堆叠来组合推断，使用权重设置以最小化交叉验证错误（ <code class="docutils literal notranslate"><span class="pre">Yao</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2018b</span></code> ）。我们认为堆叠比传统的贝叶斯模型平均更有意义，因为后者可以强烈依赖于对预测影响最小的模型方面。例如，对于数据充分了解并且其参数在单位尺度上的模型，将参数先验从 <span class="math notranslate nohighlight">\(\text{Normal}(0,10)\)</span> 更改为 <span class="math notranslate nohighlight">\(\text{Normal}(0,100)\)</span> 会将边缘似然除以大约 <span class="math notranslate nohighlight">\(10^k\)</span>（具有 <span class="math notranslate nohighlight">\(k\)</span> 个参数的模型），同时保持所有预测基本相同。此外，堆叠考虑了联合预测，当候选模型列表中有大量相似但弱的模型时效果很好。</p>
<p>在概念上，堆叠有时可以被视为逐点的模型选择。当有两个模型并且第一个模型在 <span class="math notranslate nohighlight">\(20%\)</span> 的时间内优于第二个模型时，堆叠权重将接近 <span class="math notranslate nohighlight">\((0.2,0.8)\)</span> 。有鉴于此，堆叠填补了面向独立错误的机器学习验证与现代大数据的分组结构之间的空白。因此，模型堆叠也是模型拟合异质性的一个指标，这表明我们可以通过分层模型进一步改进聚合模型，因此堆叠是模型改进的一个步骤，而不是其本身。在极端情况下，还可以进行模型平均，以便不同的模型可以应用于不同的数据点（ <code class="docutils literal notranslate"><span class="pre">Kamary</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code>  ； <code class="docutils literal notranslate"><span class="pre">Pirš</span> <span class="pre">and</span> <span class="pre">Štrumbelj,</span> <span class="pre">2019</span></code> ）。</p>
<p>在贝叶斯工作流中，我们将拟合许多不感兴趣的模型包括在任何平均值中；这种 “脚手架” 包括那些故意过于简单的模型（ 包括只是为了与感兴趣的模型进行比较 ）和纯粹出于实验目的构建的模型，以及存在重大缺陷甚至编码错误的模型。但即使在消除了这些错误或故意的过度简化之后，在进行预测时也可能有几个模型可以对其进行平均。在我们自己的应用工作中，通常没有很多机会执行这种模型平均，因为我们更喜欢持续地模型扩展，但是在某些场景中，用户会合理地希望对竞争的贝叶斯模型进行平均预测，例如 <code class="docutils literal notranslate"><span class="pre">Montgomery</span> <span class="pre">and</span> <span class="pre">Nyhan,</span> <span class="pre">2010</span></code>。</p>
</div>
<div class="section" id="id46">
<h3>8.3 比较大量模型<a class="headerlink" href="#id46" title="Permalink to this headline">¶</a></h3>
<p>有很多问题，例如在具有多个潜在相关预测变量的线性回归中，有许多候选模型可用，所有这些都可以描述为单个扩展模型的特殊情况。如果候选模型的数量很大，我们通常有兴趣找到一个相对较小的模型，该模型与我们的扩展模型具有相同的预测性能。</p>
<p>这导致了预测器（变量）选择的问题。如果我们有许多模型做出类似的预测，那么根据最小化交叉验证误差来选择其中一个模型会导致过度拟合和次优模型选择（ <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">and</span>&#160; <span class="pre">Vehtari,</span> <span class="pre">2017</span></code> ）。相比之下，投影预测变量选择在寻找具有良好预测性能的较小模型方面已被证明是稳定可靠的（ <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">and</span> <span class="pre">Vehtari,</span> <span class="pre">2017</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Piironen</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Pavone</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。虽然搜索大模型空间通常与过度拟合的危险相关，但投影预测方法通过仅检查基于扩展模型的预测的投影子模型而不是将每个模型独立地拟合到数据来避免这种情况。</p>
<p>除了变量选择，投影预测模型选择可用于广义加性多级模型中的结构选择（ <code class="docutils literal notranslate"><span class="pre">Catalina</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）以及为复杂的非参数模型创建更简单的解释（ <code class="docutils literal notranslate"><span class="pre">Afrabandpey</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。</p>
</div>
</div>
<div class="section" id="id47">
<h2>9 把建模当做软件开发<a class="headerlink" href="#id47" title="Permalink to this headline">¶</a></h2>
<p>用概率编程语言开发统计模型意味着编写代码，因此是一种软件开发形式，有几个阶段：编写和调试模型本身；将数据转化为合适的建模形式所必需的预处理；以及随后的理解、交流和使用由此产生的推论的步骤。开发软件很难。很多事情都可能出错，因为有很多活动部件需要仔细同步。</p>
<p>软件开发实践旨在减轻由编写计算机程序的固有复杂性引起的问题。不幸的是，许多方法转向教条、豆数或两者兼而有之。我们可以推荐的一些参考文献是 <code class="docutils literal notranslate"><span class="pre">Hunt</span> <span class="pre">and</span> <span class="pre">Thomas,</span> <span class="pre">1999</span></code> 以及  <code class="docutils literal notranslate"><span class="pre">McConnell</span> <span class="pre">,</span> <span class="pre">2004</span></code> ，它们为开发人员提供了可靠、实用的建议。</p>
<div class="section" id="id48">
<h3>9.1 版本控制使与他人和你过去自己的协作顺利进行<a class="headerlink" href="#id48" title="Permalink to this headline">¶</a></h3>
<p>版本控制软件，例如 Git，应该是项目的第一个基础设施。学习版本控制似乎是一项巨大的投资，但能够键入单个命令以恢复到以前的工作版本或获取当前版本和旧版本之间的差异是非常值得的。当你需要与他人共享工作时甚至是在纸上共享工作时效果更好 - 工作可以独立完成然后自动合并。虽然版本控制会跟踪一个模型中较小的更改，但将明显不同的模型保存在不同的文件中以方便比较模型是很有用的。版本控制还有助于记录迭代模型构建中的发现和决策，从而提高过程的透明度。版本控制不仅仅针对代码。它也适用于报告、图表和数据。</p>
<p>版本控制不仅仅针对代码。它也适用于报告、图表和数据。版本控制是确保所有这些组件同步的关键部分，更重要的是，可以将项目回滚到以前的状态。版本控制特别有用，因为它能够打包和标记与里程碑报告和出版物相对应的模型和数据的“候选发布”版本，并将它们存储在同一目录中，而无需求助于可怕的 <code class="docutils literal notranslate"><span class="pre">_final_final_161020.pdf</span></code> 样式命名约定。</p>
<p>在处理用于指导政策决策制定的模型时，公共版本控制存储库提高了特定报告使用了哪些模型、数据、推断参数和脚本的透明度。一个很好的例子是帝国理工学院的模型和脚本存储库，用于估计 COVID-19 的死亡和病例数（ <code class="docutils literal notranslate"><span class="pre">Flaxman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。</p>
</div>
<div class="section" id="id49">
<h3>9.2 边运行边测试<a class="headerlink" href="#id49" title="Permalink to this headline">¶</a></h3>
<p>理想情况下，软件设计从最终用户的目标到实现它所需的技术机制自上而下地进行。对于贝叶斯统计模型，自上而下的设计至少涉及数据输入格式、数据的概率模型和先验，但也可能涉及模拟器和模型测试，如基于模拟的校准或后验预测性检查。理想情况下，软件开发从经过良好测试的基础功能到更大的功能模块自下而上地工作。这样，开发将通过一系列经过充分测试的步骤进行，在每个阶段都只在经过测试的部分上进行构建。与构建大型程序然后调试它相比，以这种方式工作的优势与增量模型开发相同——更容易跟踪开发出错的地方，并且你在使用经过良好测试的基础工作的每一步都更有信心。</p>
<p>无论是初始开发还是修改代码，计算开发的关键是模块化。大杂乱的功能难以记录、难以阅读、异常难以调试，并且几乎不可能维护或修改。模块化意味着从较小的可信部分构建更大的部分，例如低级功能。每当代码片段重复时，都应该将它们封装为函数。这导致代码更易于阅读和维护。</p>
<p>作为低级函数的示例，可以通过实施标准化 <span class="math notranslate nohighlight">\(z(v) = (v −\text{mean}(v))/\text{sd}(v)\)</span> 为广义线性模型重新调整预测变量。虽然这个函数看起来很简单，但从 <span class="math notranslate nohighlight">\(\text{sd}\)</span> 函数开始，它有时被定义为 <span class="math notranslate nohighlight">\(\text{sd}(v) =\sqrt{\sum^n_{i=1}(v_i −\text{mean}(v))^2/n}\)</span> ，有时被定义为 <span class="math notranslate nohighlight">\(\text{sd}(v) = \sqrt{\sum^n_{i=1}(v_i - \text{mean}(v))^2/(n -1)}\)</span> 。如果在标准化函数层面不解决这个问题，在推断过程中会产生神秘的偏差。不依赖于 <span class="math notranslate nohighlight">\(\text{sd}()\)</span> 函数的简单测试将在函数开发过程中解决这个问题。如果选择是除以 <span class="math notranslate nohighlight">\(n -1\)</span> 的估计值，则需要决定当 <span class="math notranslate nohighlight">\(v\)</span> 是长度为 <span class="math notranslate nohighlight">\(1\)</span> 的向量时要做什么。在存在非法输入的情况下，在输入-输出例程中进行检查会有所帮助让用户知道什么时候出现问题，而不是让错误渗透到以后神秘的除以零错误。</p>
<p>微分方程的三次样条或欧拉求解器的实现是高级函数的一个示例，应在使用前对其进行测试。随着函数变得越来越复杂，由于边界条件组合学的问题、更一般的输入（例如要积分的函数）、数值不稳定性或不精确性，其域的区域可能会或可能不会接受，因此它们变得更难测试，这取决于应用，需要稳定的衍生品等。</p>
</div>
<div class="section" id="id50">
<h3>9.3 使其基本上可重现<a class="headerlink" href="#id50" title="Permalink to this headline">¶</a></h3>
<p>任何项目的一个崇高目标是使其完全可重现，因为另一台机器上的另一个人可以重新创建最终报告。这不是科学领域考虑的可重复性类型，科学领域希望确保影响得到未来新数据的证实（现在通常称为“可重复性”，以便更好地区分不同概念）。相反，这是确保始终如一地完成一项特定分析的更有限（但仍然至关重要）的目标。特别是，我们希望能够生成与原始文档基本相同的分析和图表。位级可再现性可能是不可能的，但我们仍然会在实际水平上将等效性进行比较。如果这种类型的复制改变了论文的结果，我们会争辩说原始结果不是特别可靠。</p>
<p>与其在运行模型时在命令行上输入命令（或直接将命令输入到 R 或 Python 等交互式编程语言中），不如编写脚本来通过模型运行数据并生成你需要的任何后验分析。可以为 shell、R、Python 或任何其他编程语言编写脚本。</p>
<p>脚本应该是独立的，因为它应该在一个完全干净的环境中运行，或者最好在不同的计算机上运行。这意味着脚本不得依赖于已设置的全局变量、正在读入的其他数据或脚本中没有的任何其他内容。脚本是很好的文档。如果运行项目只是一行代码，这似乎有点过分，但脚本不仅提供了一种运行代码的方法，而且还提供了一种关于正在运行的内容的具体文档的形式。对于复杂的项目，我们经常发现构建良好的一系列脚本比一个大的 R Markdown 文档或 Jupyter notebook 更实用。</p>
<p>根据长期的再现性需求，为手头的工作选择合适的工具很重要。为了保证位级的可重复性，有时甚至只是为了让程序运行，从硬件到操作系统，再到每一个软件和设置，都必须用它们的版本号来指定。随着脚本的初始编写和复制尝试之间的时间流逝，即使环境随脚本一起提供，也几乎不可能实现位级可复制性，就像在 Docker 容器中一样。</p>
</div>
<div class="section" id="id51">
<h3>9.4 使其具有可读性和可维护性<a class="headerlink" href="#id51" title="Permalink to this headline">¶</a></h3>
<p>像对待其他形式的写作一样对待程序和脚本为观众提供了如何使用代码的重要视角。不仅其他人可能想要阅读和理解一个程序或模型，开发人员自己以后也会想要阅读和理解它。 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 设计的动机之一是让模型在变量使用（例如，数据或参数）、类型（例如，协方差矩阵或无约束矩阵）和大小方面进行自我记录。这使我们能够理解 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 代码（或其他静态类型概率编程语言的代码），以便在没有应用它的数据上下文的情况下也能被理解。</p>
<p>可读性的很大一部分是一致性，特别是在命名和布局方面，不仅是程序本身，还有存储它们的目录和文件。编码的另一个关键原则是避免重复，而是将共享代码提取到可以重用的函数中。</p>
<p>代码的可读性不仅仅与注释有关——它还与可读性的命名和组织有关。事实上，注释会使代码的可读性降低。最好的方法是编写可读的代码，而不是带有注释的不透明代码。例如，我们不想这样写：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>real x17; // 氧气水平，应该是正的
</pre></div>
</div>
<p>当我们可以这样写时：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">real</span><span class="o">&lt;</span><span class="n">lower</span> <span class="o">=</span> <span class="mi">0</span><span class="o">&gt;</span><span class="n">oxygen_level</span><span class="p">;</span>
</pre></div>
</div>
<p>同样，我们也不想这样做：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">+=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">^</span><span class="mi">2</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">^</span><span class="mi">2</span><span class="p">;</span> <span class="o">//</span> <span class="n">y</span> <span class="n">分布</span> <span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> 
</pre></div>
</div>
<p>当我们可以写：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">+=</span> <span class="n">normal_lpdf</span><span class="p">(</span><span class="n">y</span>  \<span class="n">mid</span>  <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">);</span>
</pre></div>
</div>
<p>好的做法是尽量减少内联代码注释，而是编写可读代码。如上述示例所示，编程语言为用户提供了他们需要使用的工具，从而促进了干净的代码。</p>
<p>面向用户的函数应该在函数级别记录其参数类型、返回类型、错误条件和行为——这是用户看到的应用程序编程接口 (API)，而不是代码内部。针对开发人员的内联代码注释的问题在于，它们在开发过程中很快就会变得陈旧，最终弊大于利。相反，与其在内联记录实际代码，不如将函数减少到可管理的大小，并应选择名称以便代码可读。较长的变量名并不总是更好，因为它们会使代码结构更难以扫描。编写代码文档时应该假设读者很好地理解编程语言；因此，只有在代码偏离了语言的惯用用法或涉及复杂算法时才需要文档。当试图对长表达式或代码块进行注释时，请考虑将其替换为一个命名良好的函数。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085150-cd7a.webp" /></p>
<blockquote>
<div><p>图 24：职业高尔夫球手推杆成功率，来自 <code class="docutils literal notranslate"><span class="pre">Berry,</span> <span class="pre">1995</span></code> 中出现的小数据集。图中与每个点 j 相关的误差线是简单的经典标准偏差，<span class="math notranslate nohighlight">\(\sqrt{\hat p_j(1 − \hat p_j)/n_j}\)</span>，其中 <span class="math notranslate nohighlight">\(\hat p_j = y_j/n_j\)</span> 是在距离 <span class="math notranslate nohighlight">\(x_j\)</span> 处推杆的成功率。</p>
</div></blockquote>
<p>与可读性相关的是工作流代码的可维护性。在拟合一系列相似的模型时，它们之间会共享很多模块（参见第 2.2 节），因此也会共享相应的代码。如果我们每次编写新模型时都复制所有模型代码，然后发现共享模块中的一个错误，我们将不得不在所有模型中手动修复它。这又是一个容易出错的过程。相反，不仅以模块化方式构建模型而且保持相应的代码模块化并根据需要将其加载到模型中是明智的。这样，修复模块中的错误只需要在一处而不是多处更改代码。当我们在整个工作流程中移动时，将不可避免地发生错误和其他对以后更改的要求，如果我们相应地准备我们的建模代码，它将为我们节省大量时间</p>
</div>
</div>
<div class="section" id="id52">
<h2>10. 包含模型构建和模型扩展的工作流示例：高尔夫推杆<a class="headerlink" href="#id52" title="Permalink to this headline">¶</a></h2>
<p>我们使用一组适合高尔夫推杆数据的模型示例演示了贝叶斯建模的基本工作流程 ( <code class="docutils literal notranslate"><span class="pre">Gelman,</span> <span class="pre">2019</span></code> )。</p>
<p>图 24 显示了职业高尔夫球手关于成功推杆的比例作为距离球洞（圆形）距离的函数的数据。不出所料，投篮的概率随着距离的增加而下降。</p>
<p>`
<img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085215-704a.webp" /></p>
<blockquote>
<div><p>图 25：图 24 中的高尔夫数据以及拟合逻辑回归和拟合曲线绘制，<span class="math notranslate nohighlight">\(y = \text{logit} −1(a + bx_j)\)</span>，给定 <span class="math notranslate nohighlight">\((a,b)\)</span> 的后验绘制。</p>
</div></blockquote>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085235-a85c.webp" /></p>
<blockquote>
<div><p>图 26：简单几何模型高尔夫推杆，显示可以击球的角度范围，并且仍然具有完全进入球洞的轨迹。不按比例。</p>
</div></blockquote>
<div class="section" id="id53">
<h3>10.1 第一个模型：逻辑回归<a class="headerlink" href="#id53" title="Permalink to this headline">¶</a></h3>
<p>我们能否将高尔夫推杆成功的概率建模为与球洞距离的函数？鉴于通常的统计实践，自然的起点是逻辑回归：</p>
<div class="math notranslate nohighlight">
\[
y_j  \sim \text{Binomial}  (n_j,\text{logit}^{−1}(a + bx_j)), \text{for} \ \ j = 1,...,J.
\]</div>
<p>图 25 显示了逻辑回归拟合回归和抽签形成后验分布。</p>
<p>这里我们在 <span class="math notranslate nohighlight">\((a,b)\)</span> 上使用均匀先验进行拟合，考虑到大样本量，这不会导致任何问题。</p>
</div>
<div class="section" id="id54">
<h3>10.2 从第一原则建模<a class="headerlink" href="#id54" title="Permalink to this headline">¶</a></h3>
<p>接下来，我们使用高尔夫推杆过程的简单数学模型拟合数据。图 26 显示了高尔夫击球的简化草图。虚线表示半径为 <span class="math notranslate nohighlight">\(r\)</span> 的球必须被击中以使其落入半径为 <span class="math notranslate nohighlight">\(R\)</span> 的洞内的角度。该阈值角度是 <span class="math notranslate nohighlight">\(\sin^{-1}((R-r)/x)\)</span>。该图旨在说明需要进入球洞的球的几何形状。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085253-c5eb.webp" /></p>
<blockquote>
<div><p>图 27：适合高尔夫数据的两个模型。即使使用更少的参数，基于几何的模型也比逻辑回归拟合得更好。</p>
</div></blockquote>
<p>下一步是对人为错误进行建模。我们假设高尔夫球手试图将球完全打直，但许多小因素会干扰这个目标，因此实际角度遵循正态分布，以 <span class="math notranslate nohighlight">\(0\)</span> 为中心，具有一些标准偏差 <span class="math notranslate nohighlight">\(\sigma\)</span> 。球进入球洞的概率为那么角度小于阈值的概率；即</p>
<div class="math notranslate nohighlight">
\[
\mathrm{Pr( \left \vert angle \right \vert} &lt; \sin^{−1}((R −r)/x)) = 2\Phi \left( \frac{sin^{−1}((R −r)/x)} {\sigma} \right) - 1, 
\]</div>
<p>其中 <span class="math notranslate nohighlight">\(\Phi\)</span> 是累积正态分布函数。该模型中唯一未知的参数是 <span class="math notranslate nohighlight">\(\sigma\)</span> ，即射击角分布的标准偏差。</p>
<p>将这个模型与上述数据拟合，在 <span class="math notranslate nohighlight">\(\sigma\)</span> 上具有平坦的先验，产生后验估计 <span class="math notranslate nohighlight">\(\hat \sigma = 1.53°\)</span>，标准误差为 <span class="math notranslate nohighlight">\(0.02\)</span>。图 27 显示了拟合模型以及之前的逻辑回归拟合。自定义非线性模型更适合数据。这并不是说这个模型是完美的——任何高尔夫经验都会表明角度不是决定球是否进洞的唯一因素——但这似乎是一个有用的开始，它展示了积累的优势直接使用模型而不是简单地使用传统形式。</p>
</div>
<div class="section" id="id55">
<h3>10.3 在新数据上测试拟合后的模型<a class="headerlink" href="#id55" title="Permalink to this headline">¶</a></h3>
<p>在拟合上述模型几年后，我们看到了一个更新、更全面的职业高尔夫推杆数据集（ <code class="docutils literal notranslate"><span class="pre">Broadie,</span> <span class="pre">2018</span></code> ）。为简单起见，我们只在此处查看汇总数据，即距离球洞 <span class="math notranslate nohighlight">\(75\)</span> 英尺以内的球进入球洞的概率。图 28 这些新数据，连同我们之前的数据集和之前已经拟合的基于几何的模型，扩展到新数据的范围。</p>
<p>比较 <span class="math notranslate nohighlight">\(0-20\)</span> 英尺范围内的两个数据集，成功率相似更长的推杆，但比以前的短推杆要高得多。这可能是一个测量问题，如果到球洞的距离只是旧数据的近似值，也可能是高尔夫球手比以前更好。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085333-dd23.webp" /></p>
<blockquote>
<div><p>图 28：检查已经适合新高尔夫球推杆的模型数据。在同等距离下，新数据的成功率更高，这可能代表随着时间的推移有所改进或只是数据集的差异。此外，新数据显示在更远的距离出现系统模型失败，促使模型改进。</p>
</div></blockquote>
<p>超过 <span class="math notranslate nohighlight">\(20\)</span> 英尺，经验成功率变得低于旧模型预测的成功率。这些尝试要困难得多，即使考虑到随着距离的增加所需的角度精度也越来越高。另外，新数据看起来更流畅，这或许是数据收集更全面的体现。</p>
</div>
<div class="section" id="id56">
<h3>10.4 一种解释击球力度的新模型<a class="headerlink" href="#id56" title="Permalink to this headline">¶</a></h3>
<p>要想把球打进洞里，角度不是你唯一需要控制的；你还需要击球足够用力。</p>
<p><code class="docutils literal notranslate"><span class="pre">Broadie,</span> <span class="pre">2018</span></code> 通过引入另一个与高尔夫球手对距离的控制相对应的参数，将其添加到几何模型中。假设 <span class="math notranslate nohighlight">\(u\)</span> 是在没有球洞的情况下高尔夫球手的击球距离，布罗德假设推杆将进入，如果 (a) 角度允许球越过球洞，并且 (b) <span class="math notranslate nohighlight">\(u\)</span> 在范围 <span class="math notranslate nohighlight">\([x ,x + 3]\)</span>。也就是说，球必须足够用力才能到达球洞，但不能走得太远。因素（a）是我们之前考虑过的；我们现在必须添加因子 (b)。</p>
<p>图 29 说明了距离和击球角度在某个范围内的必要性，在这种情况下，灰色区域代表球将到达球洞的轨迹和留在其中。</p>
<p>Broadie 假设高尔夫球手的目标是将球击出球洞一英尺，但击球的潜在距离存在乘法误差，因此 <span class="math notranslate nohighlight">\(u = (x + 1) ·(1 + \epsilon)\)</span>，其中误差 <span class="math notranslate nohighlight">\(\epsilon\)</span> 具有均值为 <span class="math notranslate nohighlight">\(0\)</span> 且标准差为 <span class="math notranslate nohighlight">\(\sigma_{distance}\)</span> 的正态分布。在统计符号中，这个模型是，<span class="math notranslate nohighlight">\(u \sim \text{Normal}(x+1,(x+1)\sigma_{distance})\)</span>，如果 <span class="math notranslate nohighlight">\(u \in [x,x+3]\)</span>，一个具有概率</p>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}
\Phi \left( \frac{2}{ (x +1)\sigma_{distance}} \right) −\Phi \left( \frac{−1}{(x+1) \sigma_{distance}} \right)
$$ 。\\将这些放在一起，射入的概率变为：\end{aligned}\end{align} \]</div>
<p>\left( 2\Phi \left(\frac{sin^{−1}((R−r)/x)}{\sigma_{angle}} \right) −1 \right)  \left( \Phi \left( \frac{2}{ (x+1)\sigma_{distance}}\right) − \Phi \left( \frac {−1} {(x +1)\sigma_{distance}} \right)\right)
$$</p>
<p>我们将早期模型中的参数 <span class="math notranslate nohighlight">\(\sigma\)</span> 重命名为 <span class="math notranslate nohighlight">\(\sigma_{angle}\)</span> 以区别于新的 <span class="math notranslate nohighlight">\(\sigma_{distance}\)</span> 参数。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085403-c5db.webp" /></p>
<blockquote>
<div><p>图 29：高尔夫推杆的几何模型，还包括击球必须足够用力才能到达球洞但又不能太用力以至于它跳过去的约束。不按比例。</p>
</div></blockquote>
<p>结果是一个具有两个参数 <span class="math notranslate nohighlight">\(\sigma_{angle}\)</span> 和 <span class="math notranslate nohighlight">\(\sigma_{distance}\)</span> 的模型。即使是这种改进的基于几何的模型也是对推杆的粗略过度简化，并且分箱数据中的平均距离不是每次击球的准确距离。但它应该是较早前的单参数模型的进步；下一步是看它如何拟合数据。</p>
<p>我们首先尝试用平坦的先验拟合这个模型，但结果在计算上不稳定，因此我们分配信息量较弱的 <span class="math notranslate nohighlight">\(\text{Half\_Normal} \ (0,1)\)</span> 先验。即使在此之后，我们的收敛性也很差。</p>
<p>运行 <span class="math notranslate nohighlight">\(4\)</span> 个链，每个链都进行 <span class="math notranslate nohighlight">\(2000\)</span> 次迭代，会产生很高的 <span class="math notranslate nohighlight">\(\hat R\)</span> 值，表明混合不佳并使我们关注模型，遵循民间定理（参见第 5.1 节）。</p>
<p>在这种情况下，而不是与检查迹线图和研究马尔可夫链模拟的病理相比，我们只是直接检查模型的拟合，如使用通过对混合不良链的模拟进行平均获得的参数的粗略估计来估计的那样。</p>
<p>图 30a 显示了结果。整体拟合并不糟糕，但曲线中间存在问题，经过一番思考后，我们意识到该模型正在挣扎，因为二项式似然在曲线的左上角对它的约束太强了，这里的计数是更高。查看拟合曲线在 <span class="math notranslate nohighlight">\(x\)</span> 的最低值处与数据的紧密程度。</p>
<p>图 30b 显示了以分档形式提供给我们的数据，用于距离最短的推杆。由于不同的大样本量，二项式模型非常努力地尽可能精确地拟合这些概率。到目前为止，似然函数对前几个数据点给出了最大的权重。如果我们确定模型是正确的，这将是正确的做法，但考虑到不可避免的模型错误，结果是对整个曲线的拟合有问题。此外， <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 收敛性差是可以理解的：没有适合所有数据的参数值，并且链很难在适合大量数据的值和适合前几个数据点的值之间平滑移动。</p>
</div>
<div class="section" id="id57">
<h3>10.5 通过加入一个模糊因子来扩展模型<a class="headerlink" href="#id57" title="Permalink to this headline">¶</a></h3>
<p>由于数据被分箱，各个推杆距离已四舍五入到分箱中心值，这在非常短的距离中具有最大的影响。我们可以为推杆距离加入舍入误差模型，但我们选择更简单的误差模型。为了让模型能够很好地拟合所有数据，而无需对最短距离处的数据进行超精确拟合，我们采用了数据模型 <span class="math notranslate nohighlight">\(y_j  \sim \text{Binomial} (n_j,p_j)\)</span> ，并添加了一个每个观测值的独立误差项。没有简单的方法可以将误差直接添加到二项式分布中——我们可以用它的过度分散的泛化来代替它，<span class="math notranslate nohighlight">\(β-\)</span> 二项式，但这在这里不合适，因为每个数据点 <span class="math notranslate nohighlight">\(j\)</span> 的方差仍然大致与样本大小为 <span class="math notranslate nohighlight">\(n_j\)</span>，我们在这里的重点是摆脱该假设并允许模型错误指定 - 因此我们首先通过正态近似二项式数据分布，然后添加独立方差；因此：</p>
<div class="math notranslate nohighlight">
\[
y_j/n_j  \sim \text{Normal} \ ( p_j, \sqrt{p_j(1 −p_j)/n_j + \sigma^2_y} ) .
\]</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085643-9749.webp" /></p>
<blockquote>
<div><p>图 30：了解收敛性差的扩展高尔夫推杆模型的收敛性差。 (a) 数据图和拟合模型揭示了曲线中间附近的拟合问题，我们意识到马尔可夫模拟的不良行为源于模型过于努力地拟合曲线左上角的数据曲线。 (b) 最短距离推杆的数据，<span class="math notranslate nohighlight">\(x\)</span> 是每个区间中推杆的平均距离（大概是 <span class="math notranslate nohighlight">\(0-0.5\)</span> 英尺、<span class="math notranslate nohighlight">\(0.5-1.5\)</span> 英尺、<span class="math notranslate nohighlight">\(1.5-2.5\)</span> 英尺等）。初始 bin 中的样本量非常大，因此二项式模型试图几乎精确地拟合这些点。</p>
</div></blockquote>
<p>这个模型有它自己的问题，如果任何单元格中的计数足够小就会崩溃，但它是透明的并且易于设置和编码，因此我们尝试了它，并了解我们稍后可以清理它如有必要。</p>
<p>在为这个新模型的所有三个参数分配独立的半正态 <span class="math notranslate nohighlight">\((0,1)\)</span> 先验后，它在 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 中没有问题，产生后验均值估计 <span class="math notranslate nohighlight">\(\sigma_{angle} = 1.02°\)</span>，<span class="math notranslate nohighlight">\(\sigma_{distance} = 0.08\)</span>（暗示镜头可以距离的不确定性约为 <span class="math notranslate nohighlight">\(8%\)</span> ），并且 <span class="math notranslate nohighlight">\(\sigma_y = 0.003\)</span>（意味着图 29 中勾画的几何模型将总成功率拟合为距离的函数，精度为 <span class="math notranslate nohighlight">\(0.3\)</span> 个百分点）。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085708-9729.webp" /></p>
<blockquote>
<div><p>图 31：(a) 添加额外的误差项后，图 29 中描绘的模型非常适合扩展的高尔夫推杆数据。 (b) 拟合模型的残差很小并且没有显示任何模式，因此我们在这一点上看不到明显的改进方向。</p>
</div></blockquote>
<p>图 31 显示了拟合模型和作为距离函数的残差 <span class="math notranslate nohighlight">\(y_j/n_j −\hat p_j\)</span>。拟合好，残差不明显，绝对值也低——模型预测的成功率在大多数距离都在半个百分点以内，这表明模型不是完美的，而是没有明确的仅根据当前数据进行进一步开发的方法。</p>
<p>可以通过多种方式改进模型，最明显的方法是分解数据并允许两个参数因高尔夫球手、球洞和天气条件而异。如前所述，模型扩展的一个关键动机是允许包含更多数据，在这种情况下，可以对拍摄者和地点进行分类。</p>
</div>
<div class="section" id="id58">
<h3>10.6 高尔夫示例的一般教训<a class="headerlink" href="#id58" title="Permalink to this headline">¶</a></h3>
<p>这是一个很吸引人的例子，因为一个简单的单参数模型拟合了初始数据集，然后通过再添加一个参数来拟合新数据，以捕捉距离和镜头角度的不确定性。模型扩展的一个显着特点是二项式似然性太强，新模型很难一次拟合所有数据。这种粘性问题——出现在计算和推断中——在任何贝叶斯模型中都是隐含的，但随着样本量的增加，它们会变得更加突出。</p>
<p>这是大数据需要更大模型的一般原则的一个例子。在这种情况下，我们通过添加一个没有基础高尔夫解释的误差项来扩展我们的第二个模型，但允许模型灵活地拟合数据。这类似于在多中心试验中，我们可能允许治疗效果因区域而异，即使我们对这种变化并不特别感兴趣，只是因为这可以捕获数据的其他无法解释的方面，并且也类似于经典方差分析中的思想，包括一个完全饱和的交互项来表示残差。</p>
<p>高尔夫示例还说明了可以比较来自一系列模型的推论的方式，既可以通过将预测与数据一起绘制图形，也可以通过研究参数估计随着模型的扩展而变化的方式。例如，当我们在镜头距离中添加不确定性时，我们对角度不确定性的估计会降低。最后，我们认识到即使是最终的拟合模型也在进行中，因此我们希望在概率编程环境中工作，在那里我们可以通过允许参数因球员和球场条件而变化来扩展它。</p>
</div>
</div>
<div class="section" id="id59">
<h2>11 具有不可预期的多峰后验的工作流示例：行星运动<a class="headerlink" href="#id59" title="Permalink to this headline">¶</a></h2>
<p>前面的例子相对简单，我们建立了一个模型并逐步改进它。接下来我们考虑一个案例研究，其中我们从一个复杂的模型开始，在我们的推断中遇到问题，并且必须弄清楚发生了什么。</p>
<p>第 3.4 节暗示了行星运动的测量。现在让我们从稍微不同的角度来研究这个例子。虽然看起来很简单，但这个问题说明了我们讨论过的许多概念，并强调了工作流利用了统计和现场专业知识。它还提醒我们工作流不是一个自动化的过程；每一步都需要仔细推断。对于我们遇到的许多问题，找到合适的可视化工具通常是理解我们的模型、其局限性以及如何改进它的关键。这个例子也不例外。我们按照第 5.4 节的规定监控各种中间量，并广泛使用预测性检查（第 2.4 and 6.1 节）。</p>
<div class="section" id="id60">
<h3>11.1 运动的机械模型<a class="headerlink" href="#id60" title="Permalink to this headline">¶</a></h3>
<p>我们使用基于经典力学基本概念的力学模型，而不是拟合椭圆。这使我们能够估计物理感兴趣的数量，例如恒星质量，更容易应用领域知识，以及跟踪行星在空间和时间上的轨迹。</p>
<p>我们可以使用牛顿定律来描述行星的运动，这是二阶微分方程或等效的两个一阶微分方程系统，它产生 Hamilton 公式：</p>
<div class="math notranslate nohighlight">
\[
\frac{\mathrm{d}q}{\mathrm{d}t} = \frac p m
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\mathrm{d}p} {\mathrm{d}t} = − \frac{k}{r^3}(q −q∗),
\]</div>
<p>其中</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(q(t)\)</span> 是行星的位置随时间变化的向量，</p></li>
<li><p><span class="math notranslate nohighlight">\(p(t)\)</span> 是行星随时间的动量向量，</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> 是行星的质量（在某些单位中假设为 <span class="math notranslate nohighlight">\(1\)</span> ），</p></li>
<li><p><span class="math notranslate nohighlight">\(k = GmM\)</span> ，其中 <span class="math notranslate nohighlight">\(G = 10^{−3}\)</span>，重力常数适当的单位，<span class="math notranslate nohighlight">\(M\)</span> 是恒星质量；因此 <span class="math notranslate nohighlight">\(k = 10^{−3}M\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(r = \sqrt{(q −q_∗)^T (q −q_∗)}\)</span> 是行星和恒星之间的距离，<span class="math notranslate nohighlight">\(q_∗\)</span> 表示恒星的位置（假设是固定的）。</p></li>
</ul>
<p>行星在平面上运动，因此 <span class="math notranslate nohighlight">\(p\)</span> 和 <span class="math notranslate nohighlight">\(q\)</span> 都是长度为 <span class="math notranslate nohighlight">\(2\)</span> 的向量。微分方程告诉我们，位置的变化是由行星的动量决定的，动量的变化本身是由重力驱动的。</p>
<p>我们想推断恒星和行星之间的引力，特别是隐变量 <span class="math notranslate nohighlight">\(k\)</span> 。其他隐变量包括行星的初始位置和动量，分别为 <span class="math notranslate nohighlight">\(q_0\)</span> 和 <span class="math notranslate nohighlight">\(p_0\)</span>，行星的后续位置 <span class="math notranslate nohighlight">\(q(t)\)</span> 和恒星的位置 <span class="math notranslate nohighlight">\(q_*\)</span> 。实际上，天文学家会使用圆柱坐标，但为简单起见，我们坚持使用笛卡尔坐标。我们在规则的时间间隔内记录行星的位置，并假设在时间 <span class="math notranslate nohighlight">\(t_1,...,t_n\)</span> 测量 <span class="math notranslate nohighlight">\(q_{obs,1},...,q_{obs,n}\)</span>，其中每个观测 <span class="math notranslate nohighlight">\(q_{obs,i}\)</span> 是二维的，具有独立的正态分布误差，</p>
<div class="math notranslate nohighlight">
\[
q_{obs,i} \sim N_2(q(t_i),\sigma^2I).
\]</div>
<p>我们遵循我们的一般工作流程并使用伪数据拟合模型，看看我们是否可以恢复假设的参数值。我们使用 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 为该模型运行 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 采样器，它支持数值常微分方程 (ODE) 求解器。第一次尝试失败了：链不收敛并且需要很长时间才能运行。这是一个从更简单的模型开始的邀请，再次在模拟数据提供的受控设置中工作，在那里我们知道每个参数的真实值。</p>
</div>
<div class="section" id="id61">
<h3>11.2 拟合一个简化模型<a class="headerlink" href="#id61" title="Permalink to this headline">¶</a></h3>
<p>理想情况下，我们会找到一种更易于管理但仍能证明我们的算法遇到的问题的简化。我们的第一个简化模型仅估计 <span class="math notranslate nohighlight">\(k\)</span> ，先验 <span class="math notranslate nohighlight">\(k  \sim  \text{Normal}+(0,1)\)</span> ，假设真实值为 <span class="math notranslate nohighlight">\(k = 1\)</span> 。我们将模型的其他参数设置为 <span class="math notranslate nohighlight">\(m = 1\)</span>，<span class="math notranslate nohighlight">\(q_* = (0,0)\)</span> , <span class="math notranslate nohighlight">\(q_0 = (1,0)\)</span> 和 <span class="math notranslate nohighlight">\(p_0 = (0,1)\)</span> 。由于参数空间是一维的，我们可以使用正交计算后验分布；尽管如此，我们还是使用 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> ，因为我们的目标是了解阻碍我们采样算法的挑战。</p>
<p>我们运行 <span class="math notranslate nohighlight">\(8\)</span> 个链，每个链在预热阶段进行 <span class="math notranslate nohighlight">\(500\)</span> 次迭代，在采样阶段进行 <span class="math notranslate nohighlight">\(500\)</span> 次迭代，我们看到：</p>
<ul class="simple">
<li><p>运行时间差异很大链之间，范围从 <span class="math notranslate nohighlight">\(~ 2\)</span> 秒到 <span class="math notranslate nohighlight">\(~ 2000\)</span> 秒。虽然这本身不一定是一个问题，但这表明链的行为方式大不相同。</p></li>
<li><p>某些参数的 <span class="math notranslate nohighlight">\(\hat R\)</span> 很大，这意味着链没有混合。通常，我们对 <span class="math notranslate nohighlight">\(\hat R &lt; 1.01\)</span> 感到满意。当 <span class="math notranslate nohighlight">\(\hat R &gt; 2\)</span> 时，这表明链没有很好地混合。</p></li>
</ul>
<p>面对这些问题，我们检查跟踪图（图 32）。这些链似乎被困在局部峰中，并且没有凝聚力地探索后空间。一些链的对数后验密度比其他链低得多。当专门对这些链进行后验预测性检查时，我们发现模拟数据与观测结果不一致。由于我们将发现的原因，具有最低对数后验和最高 <span class="math notranslate nohighlight">\(k\)</span> 的链也被证明是运行时间最长的链。与 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 的默认设置不同，我们还在预热阶段绘制了迭代图。该图现在清楚地表明每个链收敛到哪个峰由其初始值决定，表明这些峰对马尔可夫链具有很强的吸引力。这是一个重要的实用点：正确的绘图几乎可以立即帮助我们诊断问题，但不幸的是，尽管我们尽了最大努力，默认绘图不一定是正确的绘图。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231085751-06c8.webp" /></p>
<blockquote>
<div><p>图 32：我们简化的行星运动模型的轨迹图。链无法混合，它们会收敛到几个不同的局部峰，这取决于它们的初始值。变化的对数后验表明某些峰比其他峰与数据更一致。阴影区域代表预热阶段的样本。</p>
</div></blockquote>
<p>重要的是要弄清楚这些峰是否描述了我们在分析中必须考虑的潜在的感兴趣的现象，或者它们是否是由数学人工制品引起的。</p>
<p>因为我们可以拟合一个简化的模型，所以我们可以准确地计算出什么正在进行中，并将获得的洞察力用于更精细的模型。图 33 绘制了通过正交方案计算的似然，并确认了局部峰的存在。为了理解这些峰是如何产生的，我们可以将对数似然作为惩罚 <span class="math notranslate nohighlight">\(q_{obs}\)</span> 与 <span class="math notranslate nohighlight">\(q(k)\)</span> 之间距离的函数进行推断， <span class="math notranslate nohighlight">\(q_{obs}\)</span> 与 <span class="math notranslate nohighlight">\(q(k)\)</span> 之间的距离是针对特定 <span class="math notranslate nohighlight">\(k\)</span> 值模拟的行星位置。事实上，</p>
<div class="math notranslate nohighlight">
\[
\log p(q_{obs} \mid k) = C − \frac{1}{2\sigma} \parallel q_{obs} −q(k)\parallel^2_2, 
\]</div>
<p>其中 <span class="math notranslate nohighlight">\(C\)</span> 是一个不依赖于 <span class="math notranslate nohighlight">\(k\)</span> 的常数。图 34 显示了给定不同 <span class="math notranslate nohighlight">\(k\)</span> 值的行星模拟运动。回想一下，<span class="math notranslate nohighlight">\(k\)</span> 控制着引力相互作用的强度：更高的值意味着更近和更短的轨道。假定值为 <span class="math notranslate nohighlight">\(k = 1\)</span> 。<span class="math notranslate nohighlight">\(k\)</span> 的其他值无法生成与观测数据一致的数据。对于 <span class="math notranslate nohighlight">\(k &lt; 1\)</span> ，轨迹可以任意漂移远离观测到的椭圆。但是对于 <span class="math notranslate nohighlight">\(k &gt; 1\)</span> ，模拟椭圆必须包含在观测椭圆内，这限制了 <span class="math notranslate nohighlight">\(q_{obs}\)</span> 与 <span class="math notranslate nohighlight">\(q\)</span> 之间的距离。最后，当我们改变 <span class="math notranslate nohighlight">\(k\)</span> 并旋转椭圆时，一些观测到的和模拟的位置碰巧变得相对接近，这会导致局部峰出现在似然尾部的摆动。峰下的参数值不会引起与数据非常一致的模拟；但它们比相邻的参数值做得更好，这足以在似然性中产生一个颠簸。</p>
<p>尾部模​​式是数据周期性结构的数学产物，并不表征感兴趣的潜在现象。此外，它们仅贡献可忽略不计的概率质量。因此，任何不关注主导峰的链都会浪费我们宝贵的计算资源。所以，我们能做些什么？</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231090023-bf2f.webp" /></p>
<blockquote>
<div><p>图 33：对于我们简化的行星运动模型， <span class="math notranslate nohighlight">\(k\)</span> 的各种值的对数似然。在 <span class="math notranslate nohighlight">\(k = 1\)</span> 附近有一个主导峰，随着 <span class="math notranslate nohighlight">\(k\)</span> 的增加，局部峰紧随其后。这些峰是由于循环轨迹，它允许近似混叠的似然。</p>
</div></blockquote>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231090106-fe99.webp" /></p>
<blockquote>
<div><p>图 34：行星运动模型中不同 <span class="math notranslate nohighlight">\(k\)</span> 值的模拟轨道。<span class="math notranslate nohighlight">\(k\)</span> 没有很强的简并性，但是随着这个参数的变化，一些模拟点偶然地接近它们观测到的对应点，导致对数似然尾部的摆动并产生局部峰。例如，第 35 次观测（实心点，在 <span class="math notranslate nohighlight">\(k = 1\)</span> 轨道上）比 <span class="math notranslate nohighlight">\(k = 1.6\)</span>（绿线交叉）更接近 <span class="math notranslate nohighlight">\(k = 2.2\)</span>（蓝线交叉）模拟的相应位置。</p>
</div></blockquote>
<p>建立更强大的先验。一种选择是建立一个更丰富的先验，以反映我们认为高 <span class="math notranslate nohighlight">\(k\)</span> 值是不可信的；或者任何数据生成过程表明这颗行星在观测时间内经历了几个轨道是不可能的。当这些信息可用时，更强的先验确实​​可以改进计算。不幸的是，这里的情况并非如此。更强的先验会降低峰处的密度，但关节尾部的摆动会持续存在。矛盾的是，随着数据的增多，这些摆动变得更加强烈：该模型基本上是多峰值的。还要注意，我们当前的先验 <span class="math notranslate nohighlight">\(k  \sim  \text{Normal}+(0,1)\)</span> 已经与 <span class="math notranslate nohighlight">\(k\)</span> 在次要峰下的值不一致。原则上，我们可以更进一步，添加对轨道时间或速度的硬约束以去除峰。</p>
<p>重新加权从每个链中提取。一个问题是马尔可夫链无法从一种峰转换到另一种峰，这意味着一些链在一个低概率质量的区域上采样。我们可以使用重新加权方案（例如堆叠）来校正我们的蒙特卡罗估计。这种策略可能给了我们合理的 Monte Carlo 估计，但是：（i）我们不会全面探索具有 <span class="math notranslate nohighlight">\(8\)</span> 个链的所有峰，因此堆叠应该真正被视为丢弃卡在局部峰的链，并且（ii）我们仍然付出沉重的代价计算成本，因为处于次要峰的链需要长达 <span class="math notranslate nohighlight">\(1000\)</span> 倍的时间来运行。</p>
<p>调整起点。我们没有指定马尔可夫链的起点，而是依赖于 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 的默认值，它从无约束空间上的一致 <span class="math notranslate nohighlight">\((−2,2)\)</span> 中采样初始点，即起点是从 <span class="math notranslate nohighlight">\(\log k(0)  \sim  \text{Uniform}(-2,2)\)</span>。这个默认值是为单位尺度上的无约束参数而设计的，它放纵了与我们的先验知识和领域专业知识广泛不一致的 <span class="math notranslate nohighlight">\(k\)</span> 值。在非渐近机制中，马尔可夫链并不总是“忘记”它的起点，即使我们将链运行更多次迭代，也不太可能在这里这样做。因此我们不能忽略我们算法的这个调整参数。默认值的替代方法是从我们的先验中采样 <span class="math notranslate nohighlight">\(k(0)\)</span> ，从而强加链从一个被认为合理的值范围开始。在这种设置中，链快速收敛，我们的计算集中在相关区域。</p>
<p>无论是堆叠、调整起点，还是其他方式，我们都需要帮助 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 避免局部峰。一般来说，忽略非收敛链是不好的做法，所以我们想强调这里介绍的过程与此有何不同。首先，我们使用后验预测性检查检查所有链，并准确计算出局部峰是如何产生的。我们果断地证明它们没有描述感兴趣的数据生成过程，它们贡献的概率质量也可以忽略不计。只有这样，我们才能重新定向我们的计算资源，以专注于所有概率质量集中的峰。</p>
</div>
<div class="section" id="id62">
<h3>11.3 坏马尔可夫链，慢马尔可夫链？<a class="headerlink" href="#id62" title="Permalink to this headline">¶</a></h3>
<p>回想一下，产生最低对数后验的链也是最慢的链——统计计算的民间定理的一个例子（见第 5.1 节）。事实上，我们可以证明随着 <span class="math notranslate nohighlight">\(k\)</span> 的增加，哈密顿方程变得更难求解。直觉如下：如果引力相互作用很强，那么行星的运动速度就会快得多。从数值的角度来看，这意味着每个时间步长 <span class="math notranslate nohighlight">\(\mathrm{d}t\)</span> 都会导致 <span class="math notranslate nohighlight">\(q(t)\)</span> 发生更大的变化，并且必须相应地调整积分器的步长。</p>
<p>这则轶事是有智慧的：在贝叶斯分析中，一个简单的确定性问题可能会变得困难。事实上，贝叶斯推断要求我们解决一系列参数值的问题，这意味着我们有时必须面对所述问题的未预料到的版本。根据我们的经验，尤其是在药理学和流行病学中基于微分方程的模型中，我们有时需要计算成本更高的刚性求解器来解决预热阶段生成的困难 ODE。</p>
<p>其他时候缓慢的计算会提醒我们我们的推断允许荒谬的参数值并且我们需要更好的先验或更合理的初始点。</p>
<p>不幸的是，这违背了第 3.4 节中概述的“快速失败”原则。当拟合不好时，我们当前的工具往往会慢得多，因此贝叶斯计算工作流程中的一个重要研究课题是快速标记潜在问题以避免在死胡同上浪费太多时间。</p>
</div>
<div class="section" id="id63">
<h3>11.4 建立模型<a class="headerlink" href="#id63" title="Permalink to this headline">¶</a></h3>
<p>从简化的模型开始，我们现在逐步构建回到原始模型的方法。事实证明这不是很简单，但我们可以很好地利用我们从简化模型中学到的东西。我们在拟合的模型中遇到的大多数推断问题都可以追溯到似然和循环观测之间的相互作用——这是一个基本概念，一旦掌握，但在比我们使用的环境更简单的环境中很难发现。</p>
<p>这是一个例子。在完整的模型中，我们估计星的位置 <span class="math notranslate nohighlight">\(q_*\)</span> ，并发现链收敛到许多不同的值，产生的模拟取决于链，同意或不同意观测。然而，根据跟踪图，起点和收敛邻域之间没有明显的联系。很难检查这种类型的连接，因为该模型现在有 7 个参数，其中一些具有很强的后验相关性。幸运的是，我们可以对问题的物理原理进行推断，并意识到调整恒星的位置 <span class="math notranslate nohighlight">\(q_*\)</span> 以及隐含的星-行星距离 <span class="math notranslate nohighlight">\(r\)</span> 与修改 <span class="math notranslate nohighlight">\(k\)</span> 没有什么不同。回想一下</p>
<div class="math notranslate nohighlight">
\[
\frac{\mathrm{d}p}{\mathrm{d}t} = − \frac{k} {r^3} (q − q_∗), 
\]</div>
<p>其中 <span class="math notranslate nohighlight">\(k\)</span> 和 <span class="math notranslate nohighlight">\(r\)</span> 都控制引力相互作用。</p>
<p>我们无法对模型的所有 7 个参数进行求交。相反，我们查看条件似然，其中我们保持所有参数（ <span class="math notranslate nohighlight">\(k\)</span>、<span class="math notranslate nohighlight">\(q_0\)</span> 和 <span class="math notranslate nohighlight">\(p_0\)</span> ）固定，除了 <span class="math notranslate nohighlight">\(q_*\)</span> 。从某种意义上说，这相当于调查我们模型的另一种简化。图 35 显示了可疑模式，从而支持了我们的猜想。在这一点上，在一定程度的信心下，我们构建起点来引导我们的马尔可夫链走向支配模式并获得完整模型的良好拟合。</p>
</div>
<div class="section" id="id64">
<h3>11.5 行星运动示例的一般经验教训<a class="headerlink" href="#id64" title="Permalink to this headline">¶</a></h3>
<p>当我们无法拟合模型时，检查简化模型可以帮助我们了解阻碍推断算法的挑战。在实践中，很难找到一种易于管理且仍然表现出我们希望理解的病理的简化。正如第 7.4 节中提到的，对围绕我们模型的拓扑进行推断可以帮助我们完成这个过程。一种直接的简化方法是修复一些模型参数。</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/stats-20211231090143-f5b_1.webp" /></p>
<blockquote>
<div><p>图 35：对于行星运动示例，当改变恒星的位置 <span class="math notranslate nohighlight">\(q^*\)</span> 时记录条件似然。左：所有参数保持固定，除了 <span class="math notranslate nohighlight">\(q^*\)</span> 的 <span class="math notranslate nohighlight">\(x\)</span> 坐标。右图：这次 <span class="math notranslate nohighlight">\(q^*\)</span> 的两个坐标都允许变化。正交计算使我们能够暴露问题的多峰性。</p>
</div></blockquote>
<p>在行星运动示例中，我们面临着多峰值后验分布。这种几何形状阻止了我们的链内聚地探索参数空间并导致蒙特卡罗估计有偏差。了解这些局部峰如何产生以及它们对后验概率质量的贡献是很重要的。我们使用后验预测性检查来做到这一点。对于具有可忽略的概率质量的次要峰，“捕获”马尔可夫链的情况并不少见。这种不合适峰的似然意味着我们应该始终运行多个链，可能比我们当前的默认值 4 多。</p>
<p>这个案例研究还提出了起点可能扮演什么角色的问题。理想情况下，马尔可夫链会忘记其初始值，但在非渐近机制中，情况可能并非如此。这不是一个广泛讨论的话题，但仍然是从业者和贝叶斯工作流的核心重要性之一。正如没有普遍的默认先验一样，也没有普遍的默认初始点。建模者通常需要偏离默认值，以确保联合密度的数值稳定评估并改进 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 计算。同时，我们想要分散的初始点，以便进行可靠的收敛诊断并潜在地探索所有相关模式。与推断算法的其他调整参数一样，选择起点可以是一个迭代过程，在第一次尝试拟合模型后进行调整。</p>
<p>我们不主张盲目丢弃行为不当的链。重要的是要分析这种不良行为的来源，以及它是否暗示我们的模型和推断中存在严重缺陷。我们调整初始估计值的选择基于：</p>
<p>(a) 认识到默认值与我们的专业知识广泛不一致，</p>
<p>(b) 如我们的详细分析所示，对局部模式不描述感兴趣的潜在现象的理解周期性数据如何与正常似然相互作用。</p>
</div>
</div>
<div class="section" id="id65">
<h2>12 讨论<a class="headerlink" href="#id65" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id66">
<h3>12.1 统计建模和预测的不同视角<a class="headerlink" href="#id66" title="Permalink to this headline">¶</a></h3>
<p>考虑考虑建模和预测的三种不同方式：</p>
<ul class="simple">
<li><p>传统的统计观点。在教科书中，统计推断通常被设置为提前选择模型的问题，而在贝叶斯上下文中，目标是准确总结后验分布。只要有必要，就应该进行计算以达到近似收敛。</p></li>
<li><p>机器学习观点。在机器学习中，通常的目标是预测，而不是参数估计，当交叉验证预测精度趋于稳定时，计算可以停止。</p></li>
<li><p>模型探索视角。在应用统计工作中，我们的大部分建模工作都花在探索上，尝试了一系列模型，其中许多模型对数据的拟合很差，预测性能很差，收敛速度也很慢（另见第 5.1 节）。</p></li>
</ul>
<p>这三种情况意味着不同的推断目标。在传统的统计建模问题中，长时间运行计算是有意义的，仅在绝对必要时才使用近似值。另一种说法是，在传统统计中，近似可能在于模型的选择而不是计算。在机器学习中，我们希望选择一种在预测准确性、泛化性和可扩展性之间进行权衡的算法，以便在固定的计算预算和预测目标内使用尽可能多的数据。在模型探索中，我们希望循环遍历许多模型，这使得近似具有吸引力。但是这里有一个警告：如果我们要高效准确地探索模型空间而不是算法空间，我们需要任何近似值都足够忠实以重现后验的显着特征。</p>
<p>这里的区别不是推断与。预测，或探索性与验证性分析。事实上，推断中的所有参数都可以被视为一些要预测的数量，我们所有的建模都可以被视为具有探索性目标（ <code class="docutils literal notranslate"><span class="pre">Gelman,</span> <span class="pre">2003</span></code> ）。相反，区别在于我们在多大程度上信任给定模型并允许计算近似。</p>
<p>正如第 10 节和第 11 节中的示例所示，事后统计模型的问题通常看起来很明显，但我们需要工作流程来识别它们并理解显而易见。这些例子的另一个重要特征，经常出现在应用问题中，是建模中的特殊挑战出现在手头数据的背景下：如果数据不同，我们可能永远不会遇到这些特殊问题，但其他人很可能已经出现。这是应用统计中的子领域从应用到应用不断发展的原因之一，因为现有模型中新的皱纹变得明显。本文的一个核心动机是使我们可以发现并解决这些建模问题的步骤更加透明。</p>
</div>
<div class="section" id="id67">
<h3>12.2 迭代式模型构建的必要性<a class="headerlink" href="#id67" title="Permalink to this headline">¶</a></h3>
<p>我们将模型导航过程视为数据科学的下一个变革步骤。数据科学的第一个大步骤，直到 1900 年左右，是数据汇总，以收集相关数据为中心，并通过平均值、相关性、最小二乘拟合等进行汇总。从高斯和拉普拉斯开始并一直持续到今天的下一个重要步骤是建模：认识到具有科学内容的概率模型可以极大地提高任何给定数据集的价值，并且使组合不同来源的数据变得更加可行数据。我们目前正处于另一个重要的步骤中，计算：通过现代贝叶斯和机器学习方法，算法和计算效率的提高已经对我们进行预测和因果推断的能力产生了质的提高。我们希望超越特定案例研究中的良好实践和工作流程，制定模型导航过程，“促进模型空间的探索”（ <code class="docutils literal notranslate"><span class="pre">Devezer</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ）。</p>
<p>在理想的世界中，我们将构建一个完美的模型并解决数学问题。在现实世界中，我们需要考虑人类和计算机的局限性，这应该包括在科学模型和统计模型中（ <code class="docutils literal notranslate"><span class="pre">Navarro,</span> <span class="pre">2019</span></code>  ； <code class="docutils literal notranslate"><span class="pre">Devezer</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）。</p>
<p>从人类的角度来看，我们有限的认知能力让逐步学习变得更容易。从简单模型开始的迭代模型构建是逐步学习，帮助我们更好地理解建模的现象。此外，构建丰富的模型需要付出努力，从更简单的模型开始并在模型看起来足够好时停止，这在人类时间上是有效的。我们在第 10 节中给出了一个例子。工作流的一个目标是使人类的过程更容易，即使在可以自动执行精确计算的理想化设置中。</p>
<p>从计算的角度来看，迭代一组模型也是有用的。给定一个适当的后验，贝叶斯推断中的计算在理论上是可以解决的。在实践中，我们必须应对有限的计算资源。存在渐近保证的算法在运行有限时间时可能会失败。没有完全自动化的计算可以产生完美的结果，至少不会跨越从业者关心的大量模型。工作流的另一个目标是避免一些计算问题并能够有效地诊断剩余的问题。在这里，将模型解构为更简单的版本也很有帮助：当移动部件较少时，更容易理解计算挑战。因此，即使给出了模型的数学描述，正确实现模型往往需要迭代。</p>
<p>迭代模型构建不仅从认知和计算的角度来看是有益的，而且复杂计算模型的复杂性使人类用户很难解开计算问题、建模问题、数据质量问题和代码中的错误。通过迭代地构建模型，我们可以在建模过程中使用软件工程技术。在添加更复杂的组件之前，可以检查简单的模型组件以确保它们以预期的方式运行。</p>
</div>
<div class="section" id="id68">
<h3>12.3 模型选择和过拟合<a class="headerlink" href="#id68" title="Permalink to this headline">¶</a></h3>
<p>所提议的迭代工作流的一个潜在问题是模型改进取决于当前考虑的模型与数据之间的差异，因此至少数据的某些方面被多次使用。这种“双重倾斜”原则上会威胁到我们推断的频率特性，重要的是要意识到模型选择引起的过度拟合的似然，例如 <code class="docutils literal notranslate"><span class="pre">Fithian</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2015</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Loftus,</span> <span class="pre">2015</span></code> 所考虑的。一个相关的问题是分叉路径的花园，如果数据不同，不同模型将适用的想法（ <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">and</span> <span class="pre">Loken,</span> <span class="pre">2013</span></code> ）。我们不提倡在一些这样的模型集中选择最合适的。相反，我们描述了一个构建更复杂模型的过程，需要花时间来理解和证明每个决定的合理性。</p>
<p>概括地说：假设我们拟合模型 M1，然后后验预测性检查揭示了它与数据的拟合问题，所以我们转向改进的 M2，我们希望它包含更多先验信息，并且对所研究的数据和应用问题更有意义。但如果数据不同，我们会对 M1 感到满意。模型检查和改进的步骤虽然绝对必要，但代表了拟合数据的一个方面，该方面未在似然或先验中捕获。</p>
<p>这是选择后推断问题的一个示例（ <code class="docutils literal notranslate"><span class="pre">Berk</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2013</span></code>  ；   <code class="docutils literal notranslate"><span class="pre">Efron,</span> <span class="pre">2013</span></code> ）。该领域的大部分研究都是关于如何调整 p 值和置信区间以在整个拟合过程中获得适当的频率属性，但贝叶斯推断也受此问题的影响。例如，这是我们在选举预测中做出的一项调整的故事（ <code class="docutils literal notranslate"><span class="pre">Gelman、Hullman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2020</span></code> ）：</p>
<blockquote>
<div><p>在我们为《经济学人》发布第一个选举周期模型几周后，我们感到不安在其某些国家预测的狭隘性。特别是，在某一时刻，该模型让拜登有 99% 的机会赢得全国投票。拜登显然处于领先地位，但鉴于当时可用的信息，99% 的似然似乎太高了。看到这个难以置信的预测区间促使我们重构我们的模型，我们发现了我们的代码中的一些错误以及模型可以改进的其他一些地方——包括状态间相关性的增加，这增加了国家聚合的不确定性。我们模型的变化并没有产生巨大的影响——考虑到我们在 2008 年、2012 年和 2016 年测试了我们早期的模型，这并不奇怪——但修订确实将拜登赢得普选的估计概率降低到 98%。这仍然是一个高值，但它与民意调查以及我们在竞选期间看到的民意调查变化一致。</p>
</div></blockquote>
<p>我们发现的错误是真实的，但如果我们没有意识到这些特别有问题的预测，我们可能永远不会回去检查。我们分析的这种数据依赖性意味着基于我们确定的最终模型的概率陈述的完全贝叶斯解释存在问题。而且，在这种情况下，模型平均不会解决这个问题：我们不想将我们的最终模型与其有缺陷的前身进行平均。我们可能想将其预测与某些改进的未来模型的预测进行平均，但我们也不能这样做，因为这个未来模型尚不存在！</p>
<p>也就是说，我们认为这里描述的贝叶斯工作流程将避免过度拟合的最严重问题。 Taylor and Tibshirani（2015）警告了以“搜索最强关联”为条件的推断问题。但是我们的工作流程不涉及搜索最佳拟合模型或在不确定性下进行硬模型选择。相反，我们使用拟合模型的问题来重新评估我们的建模选择，并在可能的情况下包括附加信息。</p>
<p>就我们的目的而言，我们从对选择后推断的关注中得到的主要信息是我们的最终模型应考虑尽可能多的信息可能，并且当我们可能要在大量可能的模型中进行选择时，我们会将它们嵌入到更大的模型中，执行预测模型平均，或同时使用所有模型（参见第 8 节）。正如 <code class="docutils literal notranslate"><span class="pre">Gelman、Hill</span> <span class="pre">and</span> <span class="pre">Yajima,</span> <span class="pre">2012</span></code> 所讨论的那样，我们预计这会比尝试对模型检查和扩展过程进行正式建模更有效。</p>
<p>我们还相信我们的工作流程使从业者能够对许多假设进行严格的测试是正在检查的模型的基础（ <code class="docutils literal notranslate"><span class="pre">Mayo,</span> <span class="pre">2018</span></code> ）。我们的主张是，尽管是依赖于数据的迭代工作流程的结果，但其假设经受了如此严格测试的模型通常比根本没有经过测试的预注册模型更值得信赖。</p>
<p>稍微不同的方法，迭代模型构建是完全有理由作为理解固定的复杂模型的一种方式。这是工作流的一个重要部分，因为众所周知，复杂模型中的组件可以以复杂的方式进行交互。例如， <code class="docutils literal notranslate"><span class="pre">Hodges</span> <span class="pre">and</span> <span class="pre">Reich,</span> <span class="pre">2010</span></code>  描述了结构化模型组件（如空间效应）如何与线性预测变量效应产生复杂的相互作用。</p>
</div>
<div class="section" id="id69">
<h3>12.4 更大的数据集需要更大的模型<a class="headerlink" href="#id69" title="Permalink to this headline">¶</a></h3>
<p>近几十年来，在使用统计学、机器学习以及从心理测量学到药理学等应用领域开发的方法从数据中学习方面取得了巨大进步。分层贝叶斯建模、深度学习和其他基于正则化的方法使研究人员能够将更大、更复杂的模型拟合到现实世界的数据中，从而实现信息聚合和来自不同数据源的推断的部分汇集。</p>
<p>虽然所提出的工作流程提供了优势，但在数据集的大小中，大数据的案例值得特别一提。 “大数据”有时被定义为太大而无法放入你机器的内存中，但在这里我们更广泛地使用该术语还包括大到我们通常的算法无法在合理时间内运行的数据集。在任何一种情况下，定义都与你当前的计算能力和推断目标相关。</p>
<p>人们经常假设大数据可以减轻对仔细建模的需求。我们认为情况并非如此。数量并不总能代替质量。大数据是杂乱的数据。大数据优先考虑可用性而不是随机化，这意味着大数据几乎总是观测性的，而不是来自设计的实验。大数据经常使用可用的代理，而不是对感兴趣的底层结构的直接测量。为了从大数据中做出相关推论，我们需要从样本到总体、从对照组到治疗组、从测量值到隐变量进行外推。所有这些步骤都需要某种统计假设和调整，在贝叶斯框架中，这是使用概率建模和推断目标的数学联系来完成的。例如，我们可能会根据受访者的人口统计和地理特征为数据拟合一个多级模型，然后进行后分层以将来自该模型的预测与关于一般人群的推断目标联系起来。</p>
<p>我们针对更多因素进行调整——即包含更多信息——但我们很快就会遇到技术障碍。针对许多因素进行调整的模型可能变得难以估计，而有效的建模需要 (a) 正则化以获得更稳定的估计（进而允许我们针对更多因素进行调整），以及 (b) 对隐变量建模（对于纵向数据建模时因人而异的示例参数）、缺失和测量误差。</p>
<p>贝叶斯工作流的一个关键部分是使模型拟合手头的数据和感兴趣的问题。模型不是孤立存在的，也不是从外部指定的；它来自与应用和可用数据的接触。</p>
</div>
<div class="section" id="id70">
<h3>12.5 预测、泛化和后分层化<a class="headerlink" href="#id70" title="Permalink to this headline">¶</a></h3>
<p>统计学的三个核心任务是从样本泛化到总体，从控制组泛化到治疗组，以及从观测数据泛化到感兴趣的潜在结构。在机器学习和因果推断中，术语“领域适应”和“可移植性”已被用来表示从特定数据集进行推断并将其应用于新问题的挑战（ <code class="docutils literal notranslate"><span class="pre">Blitzer、Dredze</span> <span class="pre">and</span> <span class="pre">Pereira,</span> <span class="pre">2007</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Pearl</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2011</span></code> ）。多年来，已经开发了许多统计工具来解决泛化问题，例如样本调查中的加权和后分层、因果推断中的匹配和回归，以及心理测量学和计量经济学等领域中存在间接或偏见问题的隐变量建模观测。</p>
<p>贝叶斯方法以各种方式进入，包括分层建模或部分池化的思想，以适当地概括相似但不相同的设置，这已在许多领域重新发现（例如， <code class="docutils literal notranslate"><span class="pre">Henderson,</span> <span class="pre">1950</span></code> ， <code class="docutils literal notranslate"><span class="pre">Novick</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">1972</span></code>  ,  <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">and</span> <span class="pre">Hill,</span> <span class="pre">2007</span></code>  ； <code class="docutils literal notranslate"><span class="pre">Finkel</span> <span class="pre">and</span> <span class="pre">Manning,</span> <span class="pre">2009</span></code> ； <code class="docutils literal notranslate"><span class="pre">Daumé,</span> <span class="pre">2009</span></code>)，正则化以促进大型非参数模型的使用（ <code class="docutils literal notranslate"><span class="pre">Hill,</span> <span class="pre">2011</span></code> ），以及隐变量的多级建模（<code class="docutils literal notranslate"><span class="pre">Skrondal</span> <span class="pre">and</span> <span class="pre">Rabe-Hesketh,</span> <span class="pre">2004</span></code>） ，并且在可移植性和贝叶斯图模型之间存在联系（ <code class="docutils literal notranslate"><span class="pre">Pearl</span> <span class="pre">and</span> <span class="pre">Bareinboim,</span> <span class="pre">2014</span></code> ）。</p>
<p>贝叶斯工作流程不会因为拟合的推断而停止 模型。我们还对新现实世界情况的推论感兴趣，这意味着通常的先验和数据模型被嵌入到一个更大的框架中，包括对新环境的预测和推论，包括可能不同的测量模式和治疗分配。统计模型也可以投入生产，这为未来的反馈和改进提供了机会。</p>
<p>正如先验通常只能在似然的背景下理解一样（ <code class="docutils literal notranslate"><span class="pre">Gelman</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2017</span></code>  ；  <code class="docutils literal notranslate"><span class="pre">Kennedy</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">2019</span></code> ），因此也应该根据将如何使用该模型来理解该模型。例如，<code class="docutils literal notranslate"><span class="pre">辛格</span> <span class="pre">et</span> <span class="pre">al.,</span> <span class="pre">1999</span></code> and <code class="docutils literal notranslate"><span class="pre">Gelman、Stevens</span> <span class="pre">and</span> <span class="pre">Chan,</span> <span class="pre">2003</span></code> 拟合了一系列模型来估计经济激励对调查响应率的影响。这些模型中与预测邮件调查中小激励的影响相关的方面不同于电话调查中与大激励预测相关的方面。这与第 6.3 节和第 8.1 节中对敏感性分析的讨论有关。对于这一点的另一个说明，<code class="docutils literal notranslate"><span class="pre">Rubin,</span> <span class="pre">1983</span></code> 给出了一个例子，其中变换的选择对分布中位数的推断影响较小，而对均值的推断影响很大。</p>
</div>
<div class="section" id="id71">
<h3>12.6 继续往前走<a class="headerlink" href="#id71" title="Permalink to this headline">¶</a></h3>
<p>所有的工作流程都有漏洞，我们不能希望穷尽应用数据分析的所有潜在缺陷。在先验和后验预测性检查中，错误的模型会默默地通过检查，因为在观测值处过度拟合所有输出。在基于模拟的校准中，如果后验停留在先验中，则不正确的计算程序可以满足诊断。在交叉验证中，一致性依赖于预测变量的条件独立性和平稳性。在因果推断中，无论我们拟合了多少模型，总会存在无法检验的因果假设。更一般地说，统计数据依赖于一些外推，为此总是需要一些假设。为了最终检查模型并推动工作流程向前推进，我们通常需要收集更多数据，并在扩展模型的过程中，适当的实验设计将成为这个更大工作流程的一部分。</p>
<p>本文重点介绍数据分析：引导步骤从数据和假设到科学推论和预测。此处未讨论的贝叶斯统计的其他重要方面包括设计、测量和数据收集（在数据分析之前）以及决策和沟通（在数据分析之后）。我们也没有深入讨论计算环境或协作的社会和经济方面、67 个数据和代码的共享等的细节。</p>
<p>我们提供的工作流步骤列表太长，无法作为有用的实践指南。可以做什么？与其给用户一份 25 项的清单，我们希望我们可以澄清这些流程，以便它们可以应用于结构化甚至自动化的框架中。我们的粗略计划如下：</p>
<ul class="simple">
<li><p>从我们目前对最佳实践的理解中抽象出这些原则，从而产生本文。</p></li>
<li><p>将此工作流程应用于一些应用问题，并将其写为案例研究。</p></li>
<li><p>尽可能多地实施工作流程在用于一般应用的软件工具中。</p></li>
</ul>
<p>自动化可以自动化的内容应该使统计学家或应用研究人员能够超越按钮操作并将数据与领域专业知识相结合。该项目的最终目标是使我们自己和其他数据分析师能够更有效地使用统计建模，并使我们对得出的推论和决策建立信心。</p>
<p>这篇文章是一篇评论，一份对领土的调查，提醒我们使用过的方法，我们遵循的程序，以及我们想要追求的想法。为了对从业者有用，我们需要带有代码的工作示例。我们还想提供更多结构：如果不是清单，至少有一些贝叶斯分析要遵循的路径。 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 用户指南（Stan 开发团队，2020）中提供了一些指导，我们正在编写一本关于使用 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 的贝叶斯工作流的书，以便为新手和有经验的统计学家提供这样的资源。也就是说，我们认为本文具有价值，作为将贝叶斯工作流的许多不同活动置于同一屋檐下的第一步。</p>
</div>
</div>
<div class="section" id="id72">
<h2>参考文献<a class="headerlink" href="#id72" title="Permalink to this headline">¶</a></h2>
<p>Afrabandpey, H., Peltola, T., Piironen, J., Vehtari, A., and Kaski, S. (2020). Making Bayesian predictive models interpretable: A decision theoretic approach. Machine Learning 109, 1855–1876.</p>
<p>Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. In Proceedings of the Second International Symposium on Information Theory, ed. B. N. Petrov and F. Csaki, 267–281. Budapest: Akademiai Kiado. Reprinted in Breakthroughs in Statistics, ed. S. Kotz, 610–624. New York: Springer (1992).</p>
<p>Berger, J. O., Bernardo, J. M., and Sun, D. (2009). The formal definition of reference priors. Annals of Statistics 37, 905–938.</p>
<p>Berk, R., Brown, L., Buja, A., Zhang, K., and Zhao, L. (2013). Valid post-selection inference. Annals of Statistics 41, 802–837.</p>
<p>Berry, D. (1995). Statistics: A Bayesian Perspective. Duxbury Press.</p>
<p>Betancourt, M. (2017a). A conceptual introduction to Hamiltonian Monte Carlo. <a class="reference external" href="http://arxiv.org/abs/1701.02434">arxiv.org/abs/1701.02434</a></p>
<p>Betancourt, M. (2017b). Identifying Bayesian mixture models. <code class="docutils literal notranslate"><span class="pre">Stan</span></code> Case Studies 4. <a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html">mc-stan.org/users/documentation/case-studies/identifying_mixture_models.html</a></p>
<p>Betancourt, M. (2018). Underdetermined linear regression. <a class="reference external" href="http://betanalpha.github.io/assets/case_studies/underdetermined_linear_regression.html">betanalpha.github.io/assets/case_studies/underdetermined_linear_regression.html</a></p>
<p>Betancourt, M. (2020a). Towards a principled Bayesian workflow. <a class="reference external" href="http://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html">betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html</a></p>
<p>Betancourt, M. (2020b). Robust Gaussian Process Modeling. <a class="reference external" href="http://github.com/betanalpha/knitr_case_studies/tree/master/gaussian_processes">github.com/betanalpha/knitr_case_studies/tree/master/gaussian_processes</a></p>
<p>Betancourt, M., and Girolami, M. (2015). Hamiltonian Monte Carlo for hierarchical models. In Current Trends in Bayesian Methodology with Applications, ed. S. K. Upadhyay, U. Singh, D. K. Dey, and A. Loganathan, 79–102.</p>
<p>Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. (2017). Variational inference: A review for statisticians. Journal of the American Statistical Association 112, 859–877.</p>
<p>Blitzer, J., Dredze, M., and Pereira, F. (2007). Biographies, Bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, 440–447.</p>
<p>Box, G. E. P. (1980). Sampling and Bayes inference in scientific modelling and robustness. Journal of the Royal Statistical Society A 143, 383–430.</p>
<p>Broadie, M. (2018). Two simple putting models in golf. <a class="reference external" href="http://statmodeling.stat.columbia.edu/wp-content/uploads/2019/03/putt_models_20181017.pdf">statmodeling.stat.columbia.edu/wp-content/uploads/2019/03/putt_models_20181017.pdf</a></p>
<p>Bryan, J. (2017). Project-oriented workflow. <a class="reference external" href="http://www.tidyverse.org/blog/2017/12/workflow-vs-script">www.tidyverse.org/blog/2017/12/workflow-vs-script</a></p>
<p>Bürkner, P.-C. (2017). brms: An R Package for Bayesian multilevel models using Stan. Journal of Statistical Software 80, 1–28.</p>
<p>Carpenter, B. (2017). Typical sets and the curse of dimensionality. <code class="docutils literal notranslate"><span class="pre">Stan</span></code> Case Studies 4. <a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/curse-dims.html">mc-stan.org/users/documentation/case-studies/curse-dims.html</a></p>
<p>Carpenter, B. (2018). Predator-prey population dynamics: The Lotka-Volterra model in Stan. <code class="docutils literal notranslate"><span class="pre">Stan</span></code> Case Studies 5. <a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html">mc-stan.org/users/documentation/case-studies/lotka-volterra-predator-prey.html</a></p>
<p>Carpenter, B., Gelman, A., Hoffman, M., Lee, D., Goodrich, B., Betancourt, M., Brubaker, M., Guo, J., Li, P., and Riddell, A. (2017). Stan: A probabilistic programming language. Journal of Statistical Software 76 (1).</p>
<p>Chen, C., Li, O., Barnett, A., Su, J., and Rudin, C. (2019). This looks like that: Deep learning for interpretable image recognition. 33rd Conference on Neural Information Processing Systems. <a class="reference external" href="http://papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf">papers.nips.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf</a></p>
<p>Chiu, W. A., Wright, F. A., and Rusyn, I. (2017). A tiered, Bayesian approach to estimating of population variability for regulatory decision-making. ALTEX 34, 377–388.</p>
<p>Chung, Y., Rabe-Hesketh, S., Gelman, A., Liu, J. C., and Dorie, A. (2013). A non-degenerate penalized likelihood estimator for hierarchical variance parameters in multilevel models. Psychometrika 78, 685–709.</p>
<p>Chung, Y., Rabe-Hesketh, S., Gelman, A., Liu, J. C., and Dorie, A. (2014). Nonsingular covariance estimation in linear mixed models through weakly informative priors. Journal of Educational and Behavioral Statistics 40, 136–157.</p>
<p>Clayton, D. G. (1992). Models for the analysis of cohort and case-control studies with inaccurately measured exposures. In Statistical Models for Longitudinal Studies of Exposure and Health, ed.
J. H. Dwyer, M. Feinleib, P. Lippert, and H. Hoffmeister, 301–331. Oxford University Press.</p>
<p>Cook, S., Gelman, A., and Rubin, D. B. (2006). Validation of software for Bayesian models using posterior quantiles. Journal of Computational and Graphical Statistics 15, 675–692.</p>
<p>Daumé, H. (2009). Frustratingly easy domain adaptation. <a class="reference external" href="http://arxiv.org/abs/0907.1815">arxiv.org/abs/0907.1815</a></p>
<p>Deming, W. E., and Stephan, F. F. (1940). On a least squares adjustment of a sampled frequency table when the expected marginal totals are known. Annals of Mathematical Statistics 11, 427–444.</p>
<p>Devezer, B., Nardin, L. G., Baumgaertner, B., and Buzbas, E. O. (2019). Scientific discovery in a model-centric framework: Reproducibility, innovation, and epistemic diversity. PLoS One 14,e0216125.</p>
<p>Devezer, B., Navarro, D. J., Vanderkerckhove, J., and Buzbas, E. O. (2020). The case for formal methodology in scientific reform. <a class="reference external" href="http://doi.org/10.1101/2020.04.26.048306">doi.org/10.1101/2020.04.26.048306</a></p>
<p>Dragicevic, P., Jansen, Y., Sarma, A., Kay, M., and Chevalier, F. (2019). Increasing the transparency of research papers with explorable multiverse analyses. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, paper no. 65.</p>
<p>Efron, B. (2013). Estimation and accuracy after model selection. Journal of the American Statistical Association 109, 991–1007.</p>
<p>Finkel, J. R., and Manning, C. D. (2009). Hierarchical Bayesian domain adaptation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, 602–610.</p>
<p>Fithian, W., Taylor, J., Tibshirani, R., and Tibshirani, R. J. (2015). Selective sequential model selection. <a class="reference external" href="http://arxiv.org/pdf/1512.02565.pdf">arxiv.org/pdf/1512.02565.pdf</a></p>
<p>Flaxman, S., Mishra, S., Gandy, A., et al. (2020). Estimating the effects of non-pharmaceutical interventions on COVID-19 in Europe. Nature 584, 257–261. Data and code at <a class="reference external" href="http://github.com/ImperialCollegeLondon/covid19model">github.com/ImperialCollegeLondon/covid19model</a></p>
<p>Fuglstad, G. A., Simpson, D., Lindgren, F., and Rue, H. (2019). Constructing priors that penalize the complexity of Gaussian random fields. Journal of the American Statistical Association 114,445–452.</p>
<p>Gabry, J., et al. (2020a). rstanarm: Bayesian applied regression modeling via Stan, version 2.19.3. <a class="reference external" href="http://cran.r-project.org/package=rstanarm">cran.r-project.org/package=rstanarm</a></p>
<p>Gabry, J., et al. (2020b). bayesplot: Plotting for Bayesian models, version 1.7.2. <a class="reference external" href="http://cran.r-project.org/package=bayesplot">cran.r-project.org/package=bayesplot</a></p>
<p>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., and Gelman, A. (2019). Visualization in Bayesian workflow (with discussion and rejoinder). Journal of the Royal Statistical Society A 182, 389–441.</p>
<p>Gelman, A. (2003). A Bayesian formulation of exploratory data analysis and goodness-of-fit testing. International Statistical Review 71, 369–382.</p>
<p>Gelman, A. (2004). Parameterization and Bayesian modeling. Journal of the American Statistical Association 99, 537–545.</p>
<p>Gelman, A. (2011). Expanded graphical models: Inference, model comparison, model checking, fake-data debugging, and model understanding. <a class="reference external" href="http://www.stat.columbia.edu/~gelman/70">www.stat.columbia.edu/~gelman/70</a>
presentations/ggr2handout.pdf</p>
<p>Gelman, A. (2014). How do we choose our default methods? In Past, Present, and Future of Statistical Science, ed. X. Lin, C. Genest, D. L. Banks, G. Molenberghs, D. W. Scott, and J. L. Wang. London: CRC Press.</p>
<p>Gelman, A. (2019). Model building and expansion for golf putting. <code class="docutils literal notranslate"><span class="pre">Stan</span></code> Case Studies 6. <a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/golf.html">mc-stan.org/users/documentation/case-studies/golf.html</a></p>
<p>Gelman, A., et al. (2020). Prior choice recommendations. <a class="reference external" href="http://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations</a></p>
<p>Gelman, A., and Azari, J. (2017). 19 things we learned from the 2016 election (with discussion). Statistics and Public Policy 4, 1–10.</p>
<p>Gelman, A., Bois, F. Y., and Jiang, J. (1996). Physiological pharmacokinetic analysis using population modeling and informative prior distributions. Journal of the American Statistical Association 91, 1400–1412.</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., and Rubin, D. B. (2013). Bayesian Data Analysis, third edition. London: CRC Press.</p>
<p>Gelman, A., and Hill, J. (2007). Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press.</p>
<p>Gelman, A., Hill, J., and Vehtari, A. (2020). Regression and Other Stories. Cambridge University Press.</p>
<p>Gelman, A., Hill, J., and Yajima, M. (2012). Why we (usually) don’t have to worry about multiple comparisons. Journal of Research on Educational Effectiveness 5, 189–211.</p>
<p>Gelman, A., Hullman, J., Wlezien, C., and Morris, G. E. (2020). Information, incentives, and goals in election forecasts. Judgment and Decision Making 15, 863–880.</p>
<p>Gelman, A., and Loken, E. (2013). The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time. <a class="reference external" href="http://www.stat.columbia.edu/~gelman/research/unpublished/forking.pdf">www.stat.columbia.edu/~gelman/research/unpublished/forking.pdf</a></p>
<p>Gelman, A., Meng, X. L., and Stern, H. S. (1996). Posterior predictive assessment of model fitness via realized discrepancies (with discussion). Statistica Sinica 6, 733–807.</p>
<p>Gelman, A., Simpson, D., and Betancourt, M. (2017). The prior can often only be understood in the context of the likelihood. Entropy 19, 555.</p>
<p>Gelman, A., Stevens, M., and Chan, V. (2003). Regression modeling and meta-analysis for decision making: A cost-benefit analysis of a incentives in telephone surveys. Journal of Business and Economic Statistics 21, 213–225.</p>
<p>Gharamani, Z., Steinruecken, C., Smith, E., Janz, E., and Peharz, R. (2019). The Automatic Statistician: An artificial intelligence for data science. <a class="reference external" href="http://www.automaticstatistician.com/index">www.automaticstatistician.com/index</a></p>
<p>Ghitza, Y., and Gelman, A. (2020). Voter registration databases and MRP: Toward the use of large scale databases in public opinion research. Political Analysis 28, 507–531.</p>
<p>Giordano, R. (2018). StanSensitivity. <a class="reference external" href="http://github.com/rgiordan/StanSensitivity">github.com/rgiordan/StanSensitivity</a></p>
<p>Giordano, R., Broderick, T., and Jordan, M. I. (2018). Covariances, robustness, and variational Bayes. Journal of Machine Learning Research 19, 1981–2029.</p>
<p>Goel, P. K., and DeGroot, M. H. (1981). Information about hyperparameters in hierarchical models.Journal of the American Statistical Association 76, 140–147.</p>
<p>Grinsztajn, L., Semenova, E., Margossian, C. C., and Riou, J. (2020). Bayesian workflow for disease transmission modeling in Stan. <a class="reference external" href="http://mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html">mc-stan.org/users/documentation/case-studies/boarding_school_case_study.html</a></p>
<p>Grolemund, G., and Wickham, H. (2017). R for Data Science. Sebastopol, Calif.: O’Reilly Media.</p>
<p>Gunning, D. (2017). Explainable artificial intelligence (xai). U.S. Defense Advanced Research Projects Agency (DARPA) Program.</p>
<p>Henderson, C. R. (1950). Estimation of genetic parameters (abstract). Annals of Mathematical Statistics 21, 309–310.</p>
<p>Hill, J. L. (2011). Bayesian nonparametric modeling for causal inference. Journal of Computational and Graphical Statistics 20, 217–240.</p>
<p>Hodges, J. S., and Reich, B. J. (2010). Adding spatially-correlated errors can mess up the fixed effect you love. American Statistician 64, 325–334.</p>
<p>Hoffman, M., and Ma, Y. (2020). Black-box variational inference as a parametric approximation to Langevin dynamics. Proceedings of Machine Learning and Systems, in press.</p>
<p>Hunt, A., and Thomas, D. (1999). The Pragmatic Programmer. Addison-Wesley.</p>
<p>Hwang, Y., Tong, A. and Choi, J. (2016). The Automatic Statistician: A relational perspective. ICML 2016: Proceedings of the 33rd International Conference on Machine Learning.</p>
<p>Jacquez, J. A. (1972). Compartmental Analysis in Biology and Medicine. Elsevier.</p>
<p>Kale, A., Kay, M., and Hullman, J. (2019). Decision-making under uncertainty in research synthesis: Designing for the garden of forking paths. Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, paper no. 202.</p>
<p>Kamary, K., Mengersen, K., Robert, C. P., and Rousseau, J. (2019). Testing hypotheses via a mixture estimation model. <a class="reference external" href="http://arxiv.org/abs/1412.2044">arxiv.org/abs/1412.2044</a></p>
<p>Katz, J. (2016). Who will be president? <a class="reference external" href="http://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html">www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html</a></p>
<p>Kay, M. (2020a). ggdist: Visualizations of distributions and uncertainty. R package version 2.2.0. <a class="reference external" href="http://mjskay.github.io/ggdist">mjskay.github.io/ggdist</a>. doi:10.5281/zenodo.3879620.</p>
<p>Kay, M. (2020b). tidybayes: Tidy data and geoms for Bayesian models. R package version 2.1.1. <a class="reference external" href="http://mjskay.github.io/tidybayes">mjskay.github.io/tidybayes</a>. doi:10.5281/zenodo.1308151.</p>
<p>Kennedy, L., Simpson, D., and Gelman, A. (2019). The experiment is just as important as the likelihood in understanding the prior: A cautionary note on robust cognitive modeling. Computational Brain and Behavior 2, 210–217.</p>
<p>Kerman, J., and Gelman, A. (2004). Fully Bayesian computing. <a class="reference external" href="http://www.stat.columbia.edu/~gelman/research/unpublished/fullybayesiancomputing-nonblinded.pdf">www.stat.columbia.edu/~gelman/research/unpublished/fullybayesiancomputing-nonblinded.pdf</a></p>
<p>Kerman, J., and Gelman, A. (2007). Manipulating and summarizing posterior simulations using random variable objects. Statistics and Computing 17, 235–244.</p>
<p>Kucukelbir, A., Tran, D., Ranganath, R., Gelman, A., and Blei, D. M. (2017). Automatic differentiation variational inference. Journal of Machine Learning Research 18, 1–45.</p>
<p>Kumar, R., Carroll, C., Hartikainen, A., and Martin, O. A. (2019). ArviZ a unified library for exploratory analysis of Bayesian models in Python. Journal of Open Source Software, doi:10.21105/joss.01143.</p>
<p>Lambert, B., and Vehtari, A. (2020). R∗: A robust MCMC convergence diagnostic with uncertainty using gradient-boosted machines. <a class="reference external" href="http://arxiv.org/abs/2003.07900">arxiv.org/abs/2003.07900</a></p>
<p>Lee, M. D., Criss, A. H., Devezer, B., Donkin, C., Etz, A., Leite, F. P., Matzke, D., Rouder, J. N.,Trueblood, J. S., White, C. N., and Vandekerckhove, J. (2019). Robust modeling in cognitive science. Computational Brain and Behavior 2, 141–153.</p>
<p>Lin, C. Y., Gelman, A., Price, P. N., and Krantz, D. H. (1999). Analysis of local decisions using hierarchical modeling, applied to home radon measurement and remediation (with discussion).
Statistical Science 14, 305–337.</p>
<p>Lindley, D. V. (1956). On a measure of the information provided by an experiment. Annals of Mathematical Statistics 27, 986–1005.</p>
<p>Lins, L., Koop, D., Anderson, E. W., Callahan, S. P., Santos, E., Scheidegger, C. E., Freire, J., and Silva, C. T. (2008). Examining statistics of workflow evolution provenance: A first study. In Scientific and Statistical Database Management, SSDBM 2008, ed. B. Ludäscher and N. Mamoulis, 573–579. Berlin: Springer.</p>
<p>Linzer, D. A. (2013). Dynamic Bayesian forecasting of presidential elections in the states. Journal of the American Statistical Association 108, 124–134.</p>
<p>Liu, Y., Harding, A., Gilbert, R., and Journel, A. G. (2005). A workflow for multiple-point geostatistical simulation. In Geostatistics Banff 2004, ed. O. Leuangthong and C. V. Deutsch. Dordrecht: Springer.</p>
<p>Loftus, J. (2015). Selective inference after cross-validation. <a class="reference external" href="http://arxiv.org/pdf/1511.08866.pdf">arxiv.org/pdf/1511.08866.pdf</a></p>
<p>Long, J. S. (2009). The Workflow of Data Analysis Using Stata. London: CRC Press.</p>
<p>Mallows, C. L. (1973). Some comments on Cp. Technometrics 15, 661–675.</p>
<p>Margossian, C. C., and Gelman, A. (2020). Bayesian model of planetary motion: Exploring ideas for a modeling workflow when dealing with ordinary differential equations and multimodality. <a class="reference external" href="http://github.com/stan-dev/example-models/tree/case-study/planet/knitr/planetary_motion">github.com/stan-dev/example-models/tree/case-study/planet/knitr/planetary_motion</a></p>
<p>Margossian, C. C., Vehtari, A., Simpson, D., and Agrawal, R. (2020a). Hamiltonian Monte Carlo using an adjoint-differentiated Laplace approximation: Bayesian inference for latent Gaussian models and beyond. Advances in Neural Information Processing Systems 34. arXiv:2004.12550</p>
<p>Margossian, C. C., Vehtari, A., Simpson, D., and Agrawal, R. (2020b). Approximate Bayesian inference for latent Gaussian models in Stan. Presented at StanCon2020. <a class="reference external" href="http://researchgate.net/publication/343690329_Approximate_Bayesian_inference_for_latent_">researchgate.net/publication/343690329_Approximate_Bayesian_inference_for_latent_</a>
Gaussian_models_in_Stan</p>
<p>Mayo, D. (2018). Statistical Inference as Severe Testing: How to Get Beyond the Statistics Wars. Cambridge University Press.</p>
<p>McConnell, S. (2004). Code Complete, second edition. Microsoft Press.</p>
<p>Meng, X. L., and van Dyk, D. A. (2001). The art of data augmentation. Journal of Computational and Graphical Statistics 10, 1–50.</p>
<p>Merkle, E. C., Furr, D., and Rabe-Hesketh, S. (2019). Bayesian comparison of latent variable models: Conditional versus marginal likelihoods. Psychometrika 84, 802–829.</p>
<p>Millar, R. B. (2018). Conditional vs marginal estimation of the predictive loss of hierarchical models using WAIC and cross-validation. Statistics and Computing 28, 375–385.</p>
<p>Modrák, M. (2018). Reparameterizing the sigmoid model of gene regulation for Bayesian inference.</p>
<p>Computational Methods in Systems Biology. CMSB 2018. Lecture Notes in Computer Science, vol. 11095, 309–312.</p>
<p>Montgomery, J. M., and Nyhan, B. (2010). Bayesian model averaging: Theoretical developments and practical applications. Political Analysis 18, 245–270.</p>
<p>Morgan, S. L., and Winship, C. (2014). Counterfactuals and Causal Inference: Methods and Principles for Social Research, second edition. Cambridge University Press.</p>
<p>Morris, G. E., Gelman, A., and Heidemanns, M. (2020). How the Economist presidential forecast works. <a class="reference external" href="http://projects.economist.com/us-2020-forecast/president/how-this-works">projects.economist.com/us-2020-forecast/president/how-this-works</a></p>
<p>Navarro, D. J. (2019). Between the devil and the deep blue sea: Tensions between scientific judgement and statistical model selection. Computational Brain and Behavior 2, 28–34.</p>
<p>Navarro, D. J. (2020). If mathematical psychology did not exist we might need to invent it: A comment on theory building in psychology. Perspectives on Psychological Science. <a class="reference external" href="http://psyarxiv.com/ygbjp">psyarxiv.com/ygbjp</a></p>
<p>Neal, R. M. (1993). Probabilistic inference using Markov chain Monte Carlo methods. Technical Report CRG-TR-93-1, Department of Computer Science, University of Toronto.</p>
<p>Neal, R. M. (2011). MCMC using Hamiltonian dynamics. In Handbook of Markov Chain Monte Carlo, ed. S. Brooks, A. Gelman, G. L. Jones, and X. L. Meng, 113–162. London: CRC Press.</p>
<p>Niederlová, V., Modrák, M., Tsyklauri, O., Huranová, M., and Štěpánek, O. (2019). Meta-analysis of genotype-phenotype associations in Bardet-Biedl Syndrome uncovers differences among causative genes. Human Mutation 40, 2068–2087.</p>
<p>Nott, D. J., Wang, X., Evans, M., and Englert, B. G. (2020). Checking for prior-data conflict using prior-to-posterior divergences. Statistical Science 35, 234–253.</p>
<p>Novick, M. R., Jackson, P. H., Thayer, D. T., and Cole, N. S. (1972). Estimating multiple regressions in m-groups: a cross validation study. British Journal of Mathematical and Statistical Psychology 25, 33–50.</p>
<p>O’Hagan, A., Buck, C. E., Daneshkhah, A., Eiser, J. R., Garthwaite, P. H., Jenkinson, D. J., Oakely, J. E., and Rakow, T. (2006). Uncertain Judgements: Eliciting Experts’ Probabilities. Wiley.</p>
<p>Paananen, T., Piironen, J., Bürkner, P.-C., and Vehtari, A. (2020). Implicitly adaptive importance sampling. Statistics and Computing, in press.</p>
<p>Pearl, J., and Bareinboim, E. (2011). Transportability of causal and statistical relations: A formal approach. In Data Mining Workshops (ICDMW), 2011 IEEE 11th International Conference, 540–547.</p>
<p>Pearl, J., and Bareinboim, E. (2014). External validity: From do-calculus to transportability across populations. Statistical Science 29, 579–595.</p>
<p>Piironen, J., and Vehtari, A. (2017). Sparsity information and regularization in the horseshoe and other shrinkage priors. Electronic Journal of Statistics 11, 5018–5051.</p>
<p>Pirš, G., and Štrumbelj, E. (2009). Bayesian combination of probabilistic classifiers using multivariate normal mixtures. Journal of Machine Learning Research 20, 1–18.</p>
<p>Price, P. N., Nero, A. V., and Gelman, A. (1996). Bayesian prediction of mean indoor radon concentrations for Minnesota counties. Health Physics 71, 922–936.</p>
<p>Rasmussen, C. E., and Williams, C. K. I. (2006). Gaussian Processes for Machine Learning. MIT Press.</p>
<p>Raudenbush, S. W., and Bryk, A. S. (2002). Hierarchical Linear Models, second edition. Sage Publications.</p>
<p>Richardson, S., and Gilks, W. R. (1993). A Bayesian approach to measurement error problems in epidemiology using conditional independence models. American Journal of Epidemiology 138, 430–442.</p>
<p>Riebler, A., Sørbye, S. H., Simpson, D., and Rue, H. (2018). An intuitive Bayesian spatial model for disease mapping that accounts for scaling. Statistical Methods in Medical Research 25,1145–1165.</p>
<p>Robert, C., and Casella, G. (2011). A short history of Markov chain Monte Carlo: Subjective recollections from incomplete data. Statistical Science 26, 102–115.</p>
<p>Rubin, D. B. (1984). Bayesianly justifiable and relevant frequency calculations for the applied statistician. Annals of Statistics 12, 1151–1172.</p>
<p>Rudin, C. (2018). Please stop explaining black box models for high stakes decisions. NeurIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning. <a class="reference external" href="http://arxiv.org/abs/1811.10154">arxiv.org/abs/1811.10154</a></p>
<p>Rue, H., Martino, S., and Chopin, N. (2009). Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations. Journal of the Royal Statistical Society B 71, 319–392.</p>
<p>Sarma, A., and Kay, M. (2020). Prior setting in practice: Strategies and rationales used in choosing prior distributions for Bayesian analysis. Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems.</p>
<p>Savage, J. (2016). What is modern statistical workflow? <a class="reference external" href="http://khakieconomics.github.io/2016/08/29/What-is-a-modern-statistical-workflow.html">khakieconomics.github.io/2016/08/29/What-is-a-modern-statistical-workflow.html</a></p>
<p>Shi, X., and Stevens, R. (2008). SWARM: a scientific workflow for supporting bayesian approaches to improve metabolic models. CLADE ’08: Proceedings of the 6th International Workshop on Challenges of Large Applications in Distributed Environments, 25–34.</p>
<p>Shirani-Mehr, H., Rothschild, D., Goel, S., and Gelman, A. (2018). Disentangling bias and variance in election polls. Journal of the American Statistical Association 118, 607–614.</p>
<p>Simmons, J., Nelson, L., and Simonsohn, U. (2011). False-positive psychology: Undisclosed flexibility in data collection and analysis allow presenting anything as significant. Psychological Science 22, 1359–1366.</p>
<p>Simpson, D., Rue, H., Riebler, A., Martins, T. G., and Sørbye, S. H. (2017). Penalising model component complexity: A principled, practical approach to constructing priors. Statistical Science 32, 1–28.</p>
<p>Singer, E., Van Hoewyk, J., Gebler, N., Raghunathan, T., and McGonagle, K. (1999). The effects of incentives on response rates in interviewer-mediated surveys. Journal of Official Statistics
15, 217–230.</p>
<p>Sivula, T., Magnusson, M, and Vehtari, A. (2020). Uncertainty in Bayesian leave-one-out cross-validation based model comparison. <a class="reference external" href="http://arxiv.org">arxiv.org</a>./abs/2008.10296</p>
<p>Skrondal, A. and Rabe-Hesketh, S. (2004). Generalized Latent Variable Modeling: Multilevel, Longitudinal and Structural Equation Models. London: CRC Press.</p>
<p>Smith, A. (2013). Sequential Monte Carlo Methods in Practice. New York: Springer.</p>
<p>Stan Development Team (2020). <code class="docutils literal notranslate"><span class="pre">Stan</span></code> User’s Guide. <a class="reference external" href="http://mc-stan.org">mc-stan.org</a></p>
<p>Steegen, S., Tuerlinckx, F., Gelman, A., and Vanpaemel, W. (2016). Increasing transparency through a multiverse analysis. Perspectives on Psychological Science 11, 702–712.</p>
<p>Stone, M. (1974). Cross-validatory choice and assessment of statistical predictions (with discussion). Journal of the Royal Statistical Society B 36, 111–147.</p>
<p>Stone, M. (1977). An asymptotic equivalence of choice of model cross-validation and Akaike’s criterion. Journal of the Royal Statistical Society B 36, 44–47.</p>
<p>Talts, S., Betancourt, M., Simpson, D., Vehtari, A., and Gelman, A. (2020). Validating Bayesian inference algorithms with simulation-based calibration. <a class="reference external" href="http://www.stat.columbia.edu/~gelman/">www.stat.columbia.edu/~gelman/</a>
research/unpublished/sbc.pdf</p>
<p>Taylor, J., and Tibshirani, R. J. (2015). Statistical learning and selective inference. Proceedings of the National Academy of Sciences 112, 7629–7634.</p>
<p>Taylor, S. J., and Lethem, B. (2018). Forecasting at scale. American Statistician 72, 37–45.</p>
<p>Tierney, L., and Kadane, J. B. (1986). Accurate approximations for posterior moments and marginal densities. Journal of the American Statistical Association 81, 82–86.</p>
<p>Turner, K. J., and Lambert, P. S. (2015). Workflows for quantitative data analysis in the social sciences. International Journal on Software Tools for Technology Transfer 17, 321–338.</p>
<p>Unwin, A., Volinsky, C., and Winkler, S. (2003). Parallel coordinates for exploratory modelling analysis. Computational Statistics and Data Analysis 43, 553–564.</p>
<p>Vehtari, A. (2019). Cross-validation for hierarchical models. <a class="reference external" href="http://avehtari.github.io/modelselection/rats_kcv.html">avehtari.github.io/modelselection/rats_kcv.html</a></p>
<p>Vehtari A., Gabry J., Magnusson M., Yao Y., Bürkner P., Paananen T., Gelman A. (2020). loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models. R package version 2.3.1, <a class="reference external" href="http://mc-stan.org/loo">mc-stan.org/loo</a>.</p>
<p>Vehtari, A., and Gabry, J. (2020). Bayesian 堆叠and pseudo-BMA weights using the loo package. <a class="reference external" href="http://mc-stan.org/loo/articles/loo2-weights.html">mc-stan.org/loo/articles/loo2-weights.html</a></p>
<p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing 27, 1413–1432.</p>
<p>Vehtari, A., Gelman, A., Simpson, D., Carpenter, D., and Bürkner, P.-C. (2020). Rank-normalization, folding, and localization: An improved R-hat for assessing convergence of MCMC. Bayesian Analysis.</p>
<p>Vehtari, A., Gelman, A., Sivula, T., Jylanki, P., Tran, D., Sahai, S., Blomstedt, P., Cunningham,J. P., Schiminovich, D., and Robert, C. P. (2020). Expectation propagation as a way of life: A framework for Bayesian inference on partitioned data. Journal of Machine Learning Research 21, 1–53.</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2015). Pareto smoothed importance sampling. <a class="reference external" href="http://arxiv.org/abs/1507.02646">arxiv.org/abs/1507.02646</a></p>
<p>Wang, W., and Gelman, A. (2015). Difficulty of selecting among multilevel models using predictive accuracy. Statistics and Its Interface 8 (2), 153–160.</p>
<p>Weber, S., Gelman, A., Lee, D., Betancourt, M., Vehtari, A., and Racine-Poon, A. (2018). Bayesian aggregation of average data: An application in drug development. Annals of Applied Statistics 12, 1583–1604.</p>
<p>Wickham, H. (2006). Exploratory model analysis with R and GGobi. <a class="reference external" href="http://had.co.nz/model-vis/2007-jsm.pdf">had.co.nz/model-vis/2007-jsm.pdf</a></p>
<p>Wickham, H., Cook, D., and Hofmann, H. (2015). Visualizing statistical models: Removing the  blindfold. Statistical Analysis and Data Mining: The ASA Data Science Journal 8, 203–225.</p>
<p>Wickham, H., and Groelmund, G. (2017). R for Data Science. Sebastopol, Calif.: O’Reilly.</p>
<p>Wilson, G., Aruliah, D. A., Brown, C. T., Hong, N. P. C., Davis, M., Guy, R. T., Haddock, S. H. D.,Huff, K. D., Mitchell, I. M., Plumbley, M. D., Waugh, B., White, E. P., and Wilson, P. (2014).Best practices for scientific computing. PLoS Biology 12, e1001745.</p>
<p>Wilson, G., Bryan, J., Cranston, K., Kitzes, J. Nederbragt, L., and Teal, T. K. (2017). Good enough practices in scientific computing. PLoS Computational Biololgy 13, e1005510.</p>
<p>Yao, Y., Cademartori, C., Vehtari, A., and Gelman, A. (2020). Adaptive path sampling in metastable posterior distributions. <a class="reference external" href="http://arxiv.org/abs/2009.00471">arxiv.org/abs/2009.00471</a></p>
<p>Yao, Y., Vehtari, A., and Gelman, A. (2020). Stacking for non-mixing Bayesian computations: The curse and blessing of multimodal posteriors. <a class="reference external" href="http://arxiv.org/abs/2006.12335">arxiv.org/abs/2006.12335</a></p>
<p>Yao, Y., Vehtari, A., Simpson, D., and Gelman, A. (2018a). Yes, but did it work?: Evaluating variational inference. In Proceedings of International Conference on Machine Learning, 5581–5590.</p>
<p>Yao, Y., Vehtari, A., Simpson, D., and Gelman, A. (2018b). Using 堆叠to average Bayesian predictive distributions (with discussion). Bayesian Analysis 13, 917–1003.</p>
<p>Yu, B., and Kumbier, K. (2020). Veridical data science. Proceedings of the National Academy of Sciences 117, 3920–3929.</p>
<p>Zhang, Y. D., Naughton, B. P., Bondell, H. D., and Reich, B. J. (2020). Bayesian regression using a prior on the model fit: The R2-D2 shrinkage prior. Journal of the American Statistical Association, doi:10.1080/01621459.2020.1825449</p>
</div>
<div class="section" id="id73">
<h2>引文信息<a class="headerlink" href="#id73" title="Permalink to this headline">¶</a></h2>
<p>&#64;Article{gelman2020bayesian,
author  = {Gelman, Andrew and Vehtari, Aki and Simpson, Daniel and Margossian, Charles C and Carpenter, Bob and Yao, Yuling and Kennedy, Lauren and Gabry, Jonah and B{“u}rkner, Paul-Christian and Modr{‘a}k, Martin},
journal = {arXiv preprint arXiv:2011.01808},
title   = {Bayesian workflow},
year    = {2020}
}</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Append-09-BayesianOptimization.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">附录 J：贝叶斯优化</p>
        </div>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>