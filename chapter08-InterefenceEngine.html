
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>第 8 章 推断引擎 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第 9 章 下一步去哪儿？" href="chapter09-WheretoGoNext.html" />
    <link rel="prev" title="第 7 章 高斯过程" href="chapter07-GaussianProcesses.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  书籍正文
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第 3 章 线性回归模型的贝叶斯视角
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  附录阅读
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Append-01-MCMC_Tutorial.html">
   附录 A： MCMC 随机性推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-02-VariationalInference_Tutorial.html">
   附录 B： 变分法确定性推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-03-GaussianProcessTutorial.html">
   附录 C：高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-04-BayesianNN_Tutorial.html">
   附录 D：贝叶斯神经网络概述
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-05-BayesianDeepLearning_Tutorial.html">
   附录 E：贝叶斯深度学习综述
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-06-BayesianDeepLearningPymc3.html">
   附录 F：贝叶斯深度学习编程初步
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-07-CausalInference.html">
   附录 G：因果推断问题
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/chapter08-InterefenceEngine.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter08-InterefenceEngine.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd/issues/new?title=Issue%20on%20page%20%2Fchapter08-InterefenceEngine.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xishansnow/BayesianAnalysiswithPython2nd/master?urlpath=lab/tree/chapter08-InterefenceEngine.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/xishansnow/BayesianAnalysiswithPython2nd&urlpath=lab/tree/BayesianAnalysiswithPython2nd/chapter08-InterefenceEngine.md&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   8.1 几类推断引擎
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   8.2 非马尔可夫方法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     8.2.1 网格计算法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     8.2.2 平方近似法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     8.2.3 变分方法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#advi">
     8.2.4  一种通用的自动变分方法 – ADVI
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   8.3 马尔科夫方法
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     8.3.1 蒙特卡洛
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     8.3.2 马尔科夫链
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metropolis-hastings">
     8.3.3 Metropolis-Hastings 算法
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     8.3.4 汉密尔顿蒙特卡洛方法/不掉向采样
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     8.3.5 序贯蒙特卡洛
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   8.4 诊断样本
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     8.4.1 收敛性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     8.4.2 蒙特卡洛误差
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     8.4.3 自相关
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     8.4.4 有效样本量
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     8.4.5 发散性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     8.4.6 非居中参数化
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id19">
   8.5 小结
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id20">
   练习
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>第 8 章 推断引擎<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>到目前为止，我们的重点是建立模型、解释结果和评估模型，依靠 <code class="docutils literal notranslate"><span class="pre">pm.sample</span></code> 函数的魔力计算后验分布。本章将重点学习此函数背后的推断引擎。概率编程工具（如 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> ）使用户不用关心如何进行采样，但了解其原理对全面理解推断过程很重要，同时还能帮助我们了解这些方法何时会失败、为何失败、如何处理等。如果您对后验推断的方法原理不感兴趣，可以跳过本章大部分内容，但强烈建议至少阅读 **8.4 『样本诊断』**节，这一节提供了一些帮助您检查后验样本是否可靠的指导原则。</p>
<p>计算后验分布的方法很多。本章将讨论一些基本思想，并将重点介绍在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中实现的最重要的方法。</p>
<p>在本章中，我们将学习：</p>
<ul class="simple">
<li><p>变分方法</p></li>
<li><p>Metropolis-Hastings</p></li>
<li><p>汉密尔顿蒙特卡洛</p></li>
<li><p>序贯蒙特卡洛</p></li>
<li><p>样本诊断</p></li>
</ul>
<hr class="docutils" />
<div class="section" id="id2">
<h2>8.1 几类推断引擎<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>虽然概念上很简单，但贝叶斯方法在数学和数值上都极具挑战性。主要原因是：贝叶斯定理中的分母（即边缘似然）是一个难以处理或计算昂贵的积分形式。因此，后验估计通常使用马尔可夫链蒙特卡洛 (MCMC) 家族的随机采样算法或变分算法进行数值估计。这些方法能够近似几乎任何概率模型的后验分布，因此被称为推断引擎。虽然实践中推断引擎并不总是起作用，但也推动了概率编程语言（如 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>) 的发展。</p>
<p>概率编程语言实现了建模过程与推断过程的隔离，进而促进了模型构建、评估、修改或扩展的迭代过程。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 等概率编程语言将推断过程视为黑匣子，用户可以将注意力放在具体问题和模型上，而让 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 去处理计算细节。本书之前的章节一直在这么做，所以可能让你感觉推断是简单的事情。但事实上，在概率编程语言出现之前，推断工作都是由设计概率模型的人自己实现的，通常会根据其模型量身定做，或简化模型，使其适合某些数学近似。并且这种工作现在在学术界仍然在进行。这种量身定制的方法也许更优雅、更有效，但也更容易出错和耗时，即便对专家来说也是如此。</p>
<p>上述定制方法不适合大多数用概率模型解决问题的从业者。像 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 这样的软件欢迎各种背景的人使用概率模型，从而降低了数学和计算的入门门槛。前面的章节主要侧重于贝叶斯建模的基础知识，而本章将在概念层面学习如何实现自动推断，并讨论何时以及为何失败、以及失败时的解决办法。</p>
<p>目前有两大类计算后验分布的数值方法：</p>
<p><strong>非马尔可夫方法</strong></p>
<ul class="simple">
<li><p>网格计算法</p></li>
<li><p>二次逼近法或拉普拉斯近似法</p></li>
<li><p>变分方法</p></li>
<li><p>集成嵌入拉普拉斯近似（INLA）方法</p></li>
</ul>
<p><strong>马尔可夫方法</strong></p>
<ul class="simple">
<li><p>Metropolis-Hastings法</p></li>
<li><p>哈密顿蒙特卡洛法</p></li>
<li><p>序贯蒙特卡洛法</p></li>
</ul>
</div>
<div class="section" id="id3">
<h2>8.2 非马尔可夫方法<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>对于某些问题，非马尔科夫方法的推断非常有效，但有时此类方法只能提供真实后验的粗略近似。</p>
<div class="section" id="id4">
<h3>8.2.1 网格计算法<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>网格计算法是一种暴力穷举的方法。其基本思想是既然完整计算出后验很困难，那么退而求其次，只要能够通过先验、似然和边缘似然计算得到点的后验，就至少能够通过均匀间隔获得不那么精细的近似后验。</p>
<p>假设要计算某个单参数模型的后验，网格近似法可以按照如下方式进行：</p>
<ul class="simple">
<li><p>确定参数的一个合理区间（先验会给你点提示）；</p></li>
<li><p>在以上区间确定一些网格点（通常是等距的）；</p></li>
<li><p>对于网格中的每个点计算先验、似然和后验。</p></li>
</ul>
<p>视情况可能会对计算结果进行归一化（把每个点的计算结果除以所有点的计算结果之和）。很容易看出，选的点越多（网格越密）近似的就越好。事实上，如果使用无限多点，可以得到准确的后验。</p>
<p>网格计算法对于多参数场景不太适用，因为随着参数增加，采样空间相比后验空间会急剧增加，换言之，我们需要花费更多时间去计算后验值，但由于维度太大，采样空间呈指数级增长，造成所花费的时间并没有有效提升后验估计的效果，而且计算后验的时间比用后验做预测的时间还长，因而该方法对于大多数统计学和数据科学问题并不太实用。</p>
<p>下面的代码用网格计算法解决了第一章中的抛硬币问题：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;arviz-darkgrid&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">posterior_grid</span><span class="p">(</span><span class="n">grid_points</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">tails</span><span class="o">=</span><span class="mi">9</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A grid implementation for the coin-flipping problem</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">grid_points</span><span class="p">)</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">grid_points</span><span class="p">,</span> <span class="n">grid_points</span><span class="p">)</span>  <span class="c1"># uniform prior</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">heads</span><span class="p">,</span> <span class="n">heads</span><span class="o">+</span><span class="n">tails</span><span class="p">,</span> <span class="n">grid</span><span class="p">)</span>
    <span class="n">posterior</span> <span class="o">=</span> <span class="n">likelihood</span> <span class="o">*</span> <span class="n">prior</span>
    <span class="n">posterior</span> <span class="o">/=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">grid</span><span class="p">,</span> <span class="n">posterior</span>
</pre></div>
</div>
</div>
</div>
<p>假设我们抛硬币 13 次，观察到 3 个头：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">points</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">t</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">h</span>
<span class="n">grid</span><span class="p">,</span> <span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior_grid</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">posterior</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;heads = </span><span class="si">{</span><span class="n">h</span><span class="si">}</span><span class="s1">, tails = </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/chapter08-InterefenceEngine_4_0.png" src="_images/chapter08-InterefenceEngine_4_0.png" />
</div>
</div>
<div class="figure align-center" id="fig8-1">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716063392.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716063392.webp" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">13 次抛硬币实验结果示意图</span><a class="headerlink" href="#fig8-1" title="Permalink to this image">¶</a></p>
</div>
<p>很容易发现：点数量越多（或者网格越小），结果的近似越好。事实上，当趋向于无限个点时，该方法会以增加计算资源为代价，得到精确的后验。</p>
<p>网格法最大的问题是：<strong>此方法不能很好地随参数数量（也称维度）进行调整，而且精度越高，计算要求越大。</strong></p>
<p>例如：假设想要使用四个等距点采样一个单位区间（参见图 8.2)，则分辨率为 0.25 个单位，需要 4 个采样点；现假设有一个 2D 问题（图 8.2 中的正方形），使用相同分辨率的网格，则将需要 16 个点；当面向 3D 问题时，将需要 64 个采样点（图 8.2 中的立方体）。也就是说，从 1 维到 3维，采样点增长了16倍。换一个角度，如果希望结果能够更精确些，将分辨率从本例中的 0.25 调整为 0.1 个单位，则每个维度需要 10 个点，整个单位立方体需要 1000 个采样点，又增加了一个很大的量级：</p>
<div class="figure align-center" id="fig8-2">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607160809ce.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607160809ce.webp" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">一维、二维和三维网格法示意图</span><a class="headerlink" href="#fig8-2" title="Permalink to this image">¶</a></p>
</div>
<p>除了上面比较直观的点数大幅增加问题，还存在另一种高维空间中存在的特殊现象：<u>相对于整个参数空间而言，随着<code class="docutils literal notranslate"><span class="pre">参数数量（维度）</span></code>增加，后验反而越来越聚集在更小的区域</u>。这在统计学和机器学习中被称为<code class="docutils literal notranslate"><span class="pre">维度诅咒</span></code>，而数学家更喜欢将其称为 <code class="docutils literal notranslate"><span class="pre">量度集中</span></code>。</p>
<p>可以利用<code class="docutils literal notranslate"><span class="pre">维度诅咒</span></code>来讨论各种相关现象，有些现象在低维空间中可能不存在，但在高维空间中存在。例如：</p>
<ul class="simple">
<li><p>随着维数增加，任意一对样本之间的欧式距离变得越来越近。即高维空间中的大多数点，彼此之间的距离基本相同。</p></li>
<li><p>对于超立方体，大部分体积在其角落，而不是在中间。对于超球体，大部分体积在其表面，而不在中间。</p></li>
<li><p>在高维空间中，多变量高斯分布的大部分质量并非聚集在平均值或众数，而是在其周围的壳层中；并且随着维数增加，壳层距离高斯分布的平均值越来越远。</p></li>
</ul>
<p>有关其中一些事实的代码示例，请查看 <a class="reference external" href="https://github.com/aloctavodia/BAP">链接</a></p>
<p>所有这些事实表明，如果没有提前考虑和优化在哪些区域做后验评估，那很有可能会花费大部分时间用于计算对后验评估过几乎没有贡献的值。网格法不是一种选择在哪里评估后验分布的明智方法，特别是对于高维问题。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>此处意指随着维数的增改，维度诅咒现象越来越明显，数据在高维空间中越来越聚集。如果按照均匀网格的做法，就会花费大量时间用于计算数据聚集范围以外的值，而这些值对估计真实后验分布几乎毫无意义，因为真实数据几乎不会位于那些非聚集区域。</p>
</div>
</div>
<div class="section" id="id5">
<h3>8.2.2 平方近似法<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>平方近似法（也称为 <code class="docutils literal notranslate"><span class="pre">拉普拉斯方法</span></code> 、 <code class="docutils literal notranslate"><span class="pre">正态近似法</span></code>）用高斯分布 <span class="math notranslate nohighlight">\(q(x)\)</span> 来近似后验分布 <span class="math notranslate nohighlight">\(p(x)\)</span>。</p>
<p>此方法由两个步骤组成：</p>
<ul class="simple">
<li><p>找出真实后验分布的众数，并将其作为 <span class="math notranslate nohighlight">\(q(x)\)</span> 的均值。</p></li>
<li><p>计算 Hessian 矩阵。由此可以计算出的 <span class="math notranslate nohighlight">\(q(x)\)</span> 的标准差。</p></li>
</ul>
<p>第一步可以使用最优化方法进行数值计算，也就是找出函数的最大值或最小值，有许多现成的方法。对于高斯分布，众数和均值相等，所以可以使用众数作为近似分布 <span class="math notranslate nohighlight">\(q(x)\)</span> 的平均值。</p>
<p>第二步稍微复杂些，通过计算众数/平均值处的曲率来近似计算 <span class="math notranslate nohighlight">\(q(x)\)</span> 的标准差。这可以通过计算海森矩阵的平方根的倒数来实现。海森矩阵是函数二阶导数的矩阵，其逆矩阵为协方差矩阵。</p>
<p>使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>，可以执行以下操作：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">normal_approximation</span><span class="p">:</span>
     <span class="c1"># Beta先验</span>
     <span class="n">p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
     <span class="c1"># 二项似然</span>
     <span class="n">w</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
     <span class="c1"># 最大后验点作为近似高斯分布的均值点，该点处的曲率用于近似计算标准差</span>
     <span class="n">mean_q</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">()</span>
     <span class="n">std_q</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="n">pm</span><span class="o">.</span><span class="n">find_hessian</span><span class="p">(</span><span class="n">mean_q</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="p">]))</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> 
     
     <span class="c1">#输出近似高斯分布 q 的均值和标准差</span>
     <span class="n">mean_q</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span> <span class="n">std_q</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_3774</span><span class="o">/</span><span class="mf">2956847994.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>      <span class="n">w</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s1">&#39;w&#39;</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>      <span class="c1"># 最大后验点作为近似高斯分布的均值点，该点处的曲率用于近似计算标准差</span>
<span class="ne">----&gt; </span><span class="mi">7</span>      <span class="n">mean_q</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>      <span class="n">std_q</span> <span class="o">=</span> <span class="p">((</span><span class="mi">1</span><span class="o">/</span><span class="n">pm</span><span class="o">.</span><span class="n">find_hessian</span><span class="p">(</span><span class="n">mean_q</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="p">]))</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/tuning/starting.py</span> in <span class="ni">find_MAP</span><span class="nt">(start, vars, method, return_raw, include_transformed, progressbar, maxeval, model, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span> 
<span class="g g-Whitespace">    </span><span class="mi">113</span>     <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>         <span class="n">dlogp_func</span> <span class="o">=</span> <span class="n">bij</span><span class="o">.</span><span class="n">mapf</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fastdlogp_nojac</span><span class="p">(</span><span class="nb">vars</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span>         <span class="n">compute_gradient</span> <span class="o">=</span> <span class="kc">True</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="k">except</span> <span class="p">(</span><span class="ne">AttributeError</span><span class="p">,</span> <span class="ne">NotImplementedError</span><span class="p">,</span> <span class="n">tg</span><span class="o">.</span><span class="n">NullTypeGradError</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/model.py</span> in <span class="ni">fastdlogp_nojac</span><span class="nt">(self, vars)</span>
<span class="g g-Whitespace">    </span><span class="mi">460</span>     <span class="k">def</span> <span class="nf">fastdlogp_nojac</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">461</span>         <span class="sd">&quot;&quot;&quot;Compiled log density gradient function, without jacobian terms.&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">462</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">fastfn</span><span class="p">(</span><span class="n">gradient</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logp_nojact</span><span class="p">,</span> <span class="nb">vars</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">463</span> 
<span class="g g-Whitespace">    </span><span class="mi">464</span>     <span class="k">def</span> <span class="nf">fastd2logp_nojac</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/theanof.py</span> in <span class="ni">gradient</span><span class="nt">(f, vars)</span>
<span class="g g-Whitespace">    </span><span class="mi">132</span> 
<span class="g g-Whitespace">    </span><span class="mi">133</span>     <span class="k">if</span> <span class="nb">vars</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">134</span>         <span class="k">return</span> <span class="n">tt</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">gradient1</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">135</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">136</span>         <span class="k">return</span> <span class="n">empty_gradient</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/theanof.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">132</span> 
<span class="g g-Whitespace">    </span><span class="mi">133</span>     <span class="k">if</span> <span class="nb">vars</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">134</span>         <span class="k">return</span> <span class="n">tt</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">gradient1</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">135</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">136</span>         <span class="k">return</span> <span class="n">empty_gradient</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/theanof.py</span> in <span class="ni">gradient1</span><span class="nt">(f, v)</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span> <span class="k">def</span> <span class="nf">gradient1</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span>     <span class="sd">&quot;&quot;&quot;flat gradient of f wrt v&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">123</span>     <span class="k">return</span> <span class="n">tt</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">disconnected_inputs</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> 
<span class="g g-Whitespace">    </span><span class="mi">125</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">grad</span><span class="nt">(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)</span>
<span class="g g-Whitespace">    </span><span class="mi">637</span>             <span class="k">assert</span> <span class="n">g</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">float_dtypes</span>
<span class="g g-Whitespace">    </span><span class="mi">638</span> 
<span class="ne">--&gt; </span><span class="mi">639</span>     <span class="n">rval</span> <span class="o">=</span> <span class="n">_populate_grad_dict</span><span class="p">(</span><span class="n">var_to_app_to_idx</span><span class="p">,</span> <span class="n">grad_dict</span><span class="p">,</span> <span class="n">wrt</span><span class="p">,</span> <span class="n">cost_name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">640</span> 
<span class="g g-Whitespace">    </span><span class="mi">641</span>     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rval</span><span class="p">)):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">_populate_grad_dict</span><span class="nt">(var_to_app_to_idx, grad_dict, wrt, cost_name)</span>
<span class="g g-Whitespace">   </span><span class="mi">1438</span>         <span class="k">return</span> <span class="n">grad_dict</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1439</span> 
<span class="ne">-&gt; </span><span class="mi">1440</span>     <span class="n">rval</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">wrt</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1441</span> 
<span class="g g-Whitespace">   </span><span class="mi">1442</span>     <span class="k">return</span> <span class="n">rval</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1438</span>         <span class="k">return</span> <span class="n">grad_dict</span><span class="p">[</span><span class="n">var</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1439</span> 
<span class="ne">-&gt; </span><span class="mi">1440</span>     <span class="n">rval</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">elem</span><span class="p">)</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">wrt</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1441</span> 
<span class="g g-Whitespace">   </span><span class="mi">1442</span>     <span class="k">return</span> <span class="n">rval</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">   </span><span class="mi">1059</span>             <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span>
<span class="g g-Whitespace">   </span><span class="mi">1060</span> 
<span class="ne">-&gt; </span><span class="mi">1061</span>             <span class="n">output_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">access_grad_cache</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1062</span> 
<span class="g g-Whitespace">   </span><span class="mi">1063</span>             <span class="c1"># list of bools indicating if each output is connected to the cost</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_grad_cache</span><span class="nt">(var)</span>
<span class="g g-Whitespace">   </span><span class="mi">1391</span>                     <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">node_to_idx</span><span class="p">[</span><span class="n">node</span><span class="p">]:</span>
<span class="g g-Whitespace">   </span><span class="mi">1392</span> 
<span class="ne">-&gt; </span><span class="mi">1393</span>                         <span class="n">term</span> <span class="o">=</span> <span class="n">access_term_cache</span><span class="p">(</span><span class="n">node</span><span class="p">)[</span><span class="n">idx</span><span class="p">]</span>
<span class="g g-Whitespace">   </span><span class="mi">1394</span> 
<span class="g g-Whitespace">   </span><span class="mi">1395</span>                         <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">term</span><span class="p">,</span> <span class="n">Variable</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py</span> in <span class="ni">access_term_cache</span><span class="nt">(node)</span>
<span class="g g-Whitespace">   </span><span class="mi">1218</span>                             <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1219</span> 
<span class="ne">-&gt; </span><span class="mi">1220</span>                 <span class="n">input_grads</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">L_op</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span> <span class="n">new_output_grads</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1221</span> 
<span class="g g-Whitespace">   </span><span class="mi">1222</span>                 <span class="k">if</span> <span class="n">input_grads</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py</span> in <span class="ni">L_op</span><span class="nt">(self, inputs, outs, ograds)</span>
<span class="g g-Whitespace">    </span><span class="mi">562</span> 
<span class="g g-Whitespace">    </span><span class="mi">563</span>         <span class="c1"># compute grad with respect to broadcasted input</span>
<span class="ne">--&gt; </span><span class="mi">564</span>         <span class="n">rval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bgrad</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outs</span><span class="p">,</span> <span class="n">ograds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">565</span> 
<span class="g g-Whitespace">    </span><span class="mi">566</span>         <span class="c1"># TODO: make sure that zeros are clearly identifiable</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py</span> in <span class="ni">_bgrad</span><span class="nt">(self, inputs, outputs, ograds)</span>
<span class="g g-Whitespace">    </span><span class="mi">666</span>                 <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">667</span>                 <span class="k">continue</span>
<span class="ne">--&gt; </span><span class="mi">668</span>             <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transform</span><span class="p">(</span><span class="n">scalar_igrad</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">669</span> 
<span class="g g-Whitespace">    </span><span class="mi">670</span>         <span class="k">return</span> <span class="n">ret</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py</span> in <span class="ni">transform</span><span class="nt">(r)</span>
<span class="g g-Whitespace">    </span><span class="mi">657</span>                 <span class="k">return</span> <span class="n">DimShuffle</span><span class="p">((),</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">nd</span><span class="p">)(</span><span class="n">res</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">658</span> 
<span class="ne">--&gt; </span><span class="mi">659</span>             <span class="n">new_r</span> <span class="o">=</span> <span class="n">Elemwise</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="p">{})(</span><span class="o">*</span><span class="p">[</span><span class="n">transform</span><span class="p">(</span><span class="n">ipt</span><span class="p">)</span> <span class="k">for</span> <span class="n">ipt</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">660</span>             <span class="k">return</span> <span class="n">new_r</span>
<span class="g g-Whitespace">    </span><span class="mi">661</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">657</span>                 <span class="k">return</span> <span class="n">DimShuffle</span><span class="p">((),</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">nd</span><span class="p">)(</span><span class="n">res</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">658</span> 
<span class="ne">--&gt; </span><span class="mi">659</span>             <span class="n">new_r</span> <span class="o">=</span> <span class="n">Elemwise</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="p">{})(</span><span class="o">*</span><span class="p">[</span><span class="n">transform</span><span class="p">(</span><span class="n">ipt</span><span class="p">)</span> <span class="k">for</span> <span class="n">ipt</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">660</span>             <span class="k">return</span> <span class="n">new_r</span>
<span class="g g-Whitespace">    </span><span class="mi">661</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py</span> in <span class="ni">transform</span><span class="nt">(r)</span>
<span class="g g-Whitespace">    </span><span class="mi">657</span>                 <span class="k">return</span> <span class="n">DimShuffle</span><span class="p">((),</span> <span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">nd</span><span class="p">)(</span><span class="n">res</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">658</span> 
<span class="ne">--&gt; </span><span class="mi">659</span>             <span class="n">new_r</span> <span class="o">=</span> <span class="n">Elemwise</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="p">{})(</span><span class="o">*</span><span class="p">[</span><span class="n">transform</span><span class="p">(</span><span class="n">ipt</span><span class="p">)</span> <span class="k">for</span> <span class="n">ipt</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span><span class="p">])</span>
<span class="g g-Whitespace">    </span><span class="mi">660</span>             <span class="k">return</span> <span class="n">new_r</span>
<span class="g g-Whitespace">    </span><span class="mi">661</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">__call__</span><span class="nt">(self, *inputs, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span> 
<span class="g g-Whitespace">    </span><span class="mi">252</span>         <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">compute_test_value</span> <span class="o">!=</span> <span class="s2">&quot;off&quot;</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">253</span>             <span class="n">compute_test_value</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span> 
<span class="g g-Whitespace">    </span><span class="mi">255</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">compute_test_value</span><span class="nt">(node)</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> 
<span class="g g-Whitespace">    </span><span class="mi">125</span>     <span class="c1"># Create a thunk that performs the computation</span>
<span class="ne">--&gt; </span><span class="mi">126</span>     <span class="n">thunk</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">make_thunk</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">storage_map</span><span class="p">,</span> <span class="n">compute_map</span><span class="p">,</span> <span class="n">no_recycling</span><span class="o">=</span><span class="p">[])</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span>     <span class="n">thunk</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">storage_map</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span>     <span class="n">thunk</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">storage_map</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">make_thunk</span><span class="nt">(self, node, storage_map, compute_map, no_recycling, impl)</span>
<span class="g g-Whitespace">    </span><span class="mi">632</span>             <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">633</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">634</span>                 <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_c_thunk</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">storage_map</span><span class="p">,</span> <span class="n">compute_map</span><span class="p">,</span> <span class="n">no_recycling</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">635</span>             <span class="k">except</span> <span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">,</span> <span class="n">MethodNotDefined</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">636</span>                 <span class="c1"># We requested the c code, so don&#39;t catch the error.</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">make_c_thunk</span><span class="nt">(self, node, storage_map, compute_map, no_recycling)</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span>                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Disabling C code for </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> due to unsupported float16&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">599</span>                 <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;float16&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">600</span>         <span class="n">outputs</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">make_thunk</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">601</span>             <span class="n">input_storage</span><span class="o">=</span><span class="n">node_input_storage</span><span class="p">,</span> <span class="n">output_storage</span><span class="o">=</span><span class="n">node_output_storage</span>
<span class="g g-Whitespace">    </span><span class="mi">602</span>         <span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">make_thunk</span><span class="nt">(self, input_storage, output_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1201</span>         <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1202</span><span class="s2">         init_tasks, tasks = self.get_init_tasks()</span>
<span class="ne">-&gt; </span><span class="mi">1203</span><span class="s2">         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(</span>
<span class="g g-Whitespace">   </span><span class="mi">1204</span><span class="s2">             input_storage, output_storage, storage_map</span>
<span class="g g-Whitespace">   </span><span class="mi">1205</span><span class="s2">         )</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">__compile__</span><span class="nt">(self, input_storage, output_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1136</span><span class="s2">         input_storage = tuple(input_storage)</span>
<span class="g g-Whitespace">   </span><span class="mi">1137</span><span class="s2">         output_storage = tuple(output_storage)</span>
<span class="ne">-&gt; </span><span class="mi">1138</span><span class="s2">         thunk, module = self.cthunk_factory(</span>
<span class="g g-Whitespace">   </span><span class="mi">1139</span><span class="s2">             error_storage,</span>
<span class="g g-Whitespace">   </span><span class="mi">1140</span><span class="s2">             input_storage,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">cthunk_factory</span><span class="nt">(self, error_storage, in_storage, out_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1632</span><span class="s2">             for node in self.node_order:</span>
<span class="g g-Whitespace">   </span><span class="mi">1633</span><span class="s2">                 node.op.prepare_node(node, storage_map, None, &quot;c&quot;)</span>
<span class="ne">-&gt; </span><span class="mi">1634</span><span class="s2">             module = get_module_cache().module_from_key(key=key, lnk=self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1635</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1636</span><span class="s2">         vars = self.inputs + self.outputs + self.orphans</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py</span> in <span class="ni">module_from_key</span><span class="nt">(self, key, lnk)</span>
<span class="g g-Whitespace">   </span><span class="mi">1189</span><span class="s2">             try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1190</span><span class="s2">                 location = dlimport_workdir(self.dirname)</span>
<span class="ne">-&gt; </span><span class="mi">1191</span><span class="s2">                 module = lnk.compile_cmodule(location)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span><span class="s2">                 name = module.__file__</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span><span class="s2">                 assert name.startswith(location)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">compile_cmodule</span><span class="nt">(self, location)</span>
<span class="g g-Whitespace">   </span><span class="mi">1541</span><span class="s2">             try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1542</span><span class="s2">                 _logger.debug(f&quot;LOCATION </span><span class="si">{location}</span><span class="s2">&quot;)</span>
<span class="ne">-&gt; </span><span class="mi">1543</span><span class="s2">                 module = c_compiler.compile_str(</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span><span class="s2">                     module_name=mod.code_hash,</span>
<span class="g g-Whitespace">   </span><span class="mi">1545</span><span class="s2">                     src_code=src_code,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py</span> in <span class="ni">compile_str</span><span class="nt">(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)</span>
<span class="g g-Whitespace">   </span><span class="mi">2494</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">2495</span><span class="s2">         try:</span>
<span class="ne">-&gt; </span><span class="mi">2496</span><span class="s2">             p_out = output_subprocess_Popen(cmd)</span>
<span class="g g-Whitespace">   </span><span class="mi">2497</span><span class="s2">             compile_stderr = p_out[1].decode()</span>
<span class="g g-Whitespace">   </span><span class="mi">2498</span><span class="s2">         except Exception:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/utils.py</span> in <span class="ni">output_subprocess_Popen</span><span class="nt">(command, **params)</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span><span class="s2">     # we need to use communicate to make sure we don&#39;t deadlock around</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span><span class="s2">     # the stdout/stderr pipe.</span>
<span class="ne">--&gt; </span><span class="mi">254</span><span class="s2">     out = p.communicate()</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span><span class="s2">     return out + (p.returncode,)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/subprocess.py</span> in <span class="ni">communicate</span><span class="nt">(self, input, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1026</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1027</span><span class="s2">             try:</span>
<span class="ne">-&gt; </span><span class="mi">1028</span><span class="s2">                 stdout, stderr = self._communicate(input, endtime, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1029</span><span class="s2">             except KeyboardInterrupt:</span>
<span class="g g-Whitespace">   </span><span class="mi">1030</span><span class="s2">                 # https://bugs.python.org/issue25942</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/subprocess.py</span> in <span class="ni">_communicate</span><span class="nt">(self, input, endtime, orig_timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1866</span><span class="s2">                             &#39;failed to raise TimeoutExpired.&#39;)</span>
<span class="g g-Whitespace">   </span><span class="mi">1867</span><span class="s2"> </span>
<span class="ne">-&gt; </span><span class="mi">1868</span><span class="s2">                     ready = selector.select(timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1869</span><span class="s2">                     self._check_timeout(endtime, orig_timeout, stdout, stderr)</span>
<span class="g g-Whitespace">   </span><span class="mi">1870</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/selectors.py</span> in <span class="ni">select</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">413</span><span class="s2">         ready = []</span>
<span class="g g-Whitespace">    </span><span class="mi">414</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">415</span><span class="s2">             fd_event_list = self._selector.poll(timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">416</span><span class="s2">         except InterruptedError:</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span><span class="s2">             return ready</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>如果您尝试在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中使用 <code class="docutils literal notranslate"><span class="pre">pm.find_map</span></code> 函数，您将收到一条警告消息。由于维数灾难，使用最大后验概率 (MAP) 来表示后验，甚至初始化采样方法通常不是一个好主意。</p>
</div>
<p>可以看下上述 “贝塔-二项模型” 的平方近似的曲线形态：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># analytic calculation</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span> <span class="p">,</span> <span class="n">h</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span>
         <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True posterior&#39;</span><span class="p">)</span>

<span class="c1"># quadratic approximation</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mean_q</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span> <span class="n">std_q</span><span class="p">),</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Quadratic approximation&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;heads = </span><span class="si">{</span><span class="n">h</span><span class="si">}</span><span class="s1">, tails = </span><span class="si">{</span><span class="n">t</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([]);</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-3">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716150097.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716150097.webp" />
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">贝塔-二项分布的平方近似</span><a class="headerlink" href="#fig8-3" title="Permalink to this image">¶</a></p>
</div>
<p>图 8.3 显示，平方近似并没有那么差。严格地说，该方法只能应用于无界变量，也就是 <span class="math notranslate nohighlight">\(\mathbb{R}^N\)</span> 空间中的变量，因为高斯分布是一个无界分布。如果用平方近似法来近似一个有界分布（例如：贝塔分布），会将本来概率密度等于 0 的点错误地估计为正密度（如：贝塔分布中位于定义域 [0，1] 之外的点）。</p>
<p>可以考虑将有界变量变换为无界变量，进而可以使用平方近似法。例如：常用于模拟标准差的半正态分布，定义域制在 [0，∞) 区间内，可以对其取对数，使半正态分布变量转换为无界变量。</p>
<p>平方近似法（拉普拉斯方法）的作用有限，但对某些模型效果很好，并且其生成的近似是后验的解析解，可以大幅度提升推断效率。今年出现一个名为 <code class="docutils literal notranslate"><span class="pre">积分嵌套拉普拉斯近似</span> <span class="pre">(INLA)方法</span></code> 的高级推断方法，其基础构建块也是平方近似。</p>
<p>下节将讨论变分方法，它与拉普拉斯方法有点像，但更灵活、更强大，其中一些方法可自动应用在很多模型中。</p>
</div>
<div class="section" id="id6">
<h3>8.2.3 变分方法<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>大多数现代贝叶斯统计都是使用马尔可夫方法做推断（见下一节），但对于大数据集而言，马尔可夫方法太慢了，而变分方法此时是一个更好的选择。</p>
<p>变分法与拉普拉斯方法有些相似，其基本思想都是 “用一种更简单的分布来近似后验分布”，但变分法没有将近似分布限定为高斯分布，而是推广到任意可参数化的分布，并且通过最优化方法求得近似分布的参数，进而获得一个和真实分布最相似的精细分布。</p>
<p><strong>(1) 目标函数设置 – 证据下界（ ELBO ）</strong></p>
<p>衡量分布之间相似程度的常用方法是使用 <code class="docutils literal notranslate"><span class="pre">Kullback-Leibler(KL)</span> <span class="pre">散度</span></code>（第 5 章中讨论过）。使用 <code class="docutils literal notranslate"><span class="pre">KL</span> <span class="pre">散度</span></code> 可得：</p>
<div class="math notranslate nohighlight">
\[D_{K L}(q(\theta) \| p(\theta \mid y))=\int q(\theta) \log \frac{q(\theta)}{p(\theta \mid y)} d(\theta)  \tag{8.1} \label{式8.1}\]</div>
<p>其中 <span class="math notranslate nohighlight">\(q(\theta)\)</span> 是较简单的分布，用做真实后验分布 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 的近似， <span class="math notranslate nohighlight">\(q(\theta)\)</span> 也被称为<code class="docutils literal notranslate"><span class="pre">『变分分布』</span></code>。通过使用最优化方法，我们试图找出分布 <span class="math notranslate nohighlight">\(q\)</span> 的参数（通常称为变分参数），使其在 <code class="docutils literal notranslate"><span class="pre">KL</span> <span class="pre">散度</span></code> 的度量上尽可能接近后验分布。</p>
<p>此处需要注意 KL 散度的方向，一定是 <span class="math notranslate nohighlight">\(D_{K L}(q(\theta) \| p(\theta \mid y))\)</span>，而不是 <span class="math notranslate nohighlight">\(\left.D_{K L}(p(\theta \mid y)) \| q(\theta)\right)\)</span>，因为 KL 散度的计算不符合交换率。当然，在另一个方向上写 <code class="docutils literal notranslate"><span class="pre">KL</span> <span class="pre">散度</span></code> 并不是一无是处，实际上在其他地方可以发挥作用，不过该讨论不在本文范围内。</p>
<p>（式 8.1） 的问题是尚不知道后验，无法直接使用它，需要找到另一种方式来表达问题。以下步骤显示了处理方法，如果您不关心中间步骤，请跳到（式 8.7）。</p>
<p>首先，用条件分布的定义做替换：</p>
<div class="math notranslate nohighlight">
\[D_{K L}(q(\theta) \| p(\theta \mid y))=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} d(\theta) \tag{8.2} \label{式8.2}\]</div>
<p>然后重排公式 8.2：</p>
<div class="math notranslate nohighlight">
\[=\int q(\theta) \log \left( \frac{q(\theta)}{p(\theta, y)} p(y) \right) d(\theta) \tag{8.3} \label{式8.3}\]</div>
<p>根据对数性质，得到方程：</p>
<div class="math notranslate nohighlight">
\[=\int q(\theta)\left(\log \frac{q(\theta)}{p(\theta, y)}+\log p(y)\right) d(\theta) \tag{8.4} \label{式8.4}\]</div>
<p>重新排列：</p>
<div class="math notranslate nohighlight">
\[=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} d(\theta)+\int q(\theta) \log p(y) d(\theta) \tag{8.5} \label{式8.5}\]</div>
<p>由于和 <span class="math notranslate nohighlight">\(\theta\)</span> 无关，所以可以将 <span class="math notranslate nohighlight">\(\text{log} p(y)\)</span> 移出积分，又有 <span class="math notranslate nohighlight">\(q(\theta)\)</span> 的积分为 1，可得：</p>
<div class="math notranslate nohighlight">
\[=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} d(\theta)+\log p(y) \tag{8.6} \label{式8.6}\]</div>
<p>利用对数性质：</p>
<div class="math notranslate nohighlight">
\[D_{K L}(q(\theta)|| p(\theta \mid y))=-\underbrace{ \int q(\theta) \log \frac{p(\theta, y)}{q(\theta)} d(\theta)}_{\text {evidence lower bound (ELBO) }}+\log p(y) \tag{8.7} \label{式8.7}\]</div>
<p>因为 <span class="math notranslate nohighlight">\(D_{K L} \geq 0\)</span> ，然后 <span class="math notranslate nohighlight">\(\text{log} p(y) \geq ELBO\)</span> ，即证据对数 <span class="math notranslate nohighlight">\(\text{log} p(y)\)</span> 总是大于等于证据下界 <code class="docutils literal notranslate"><span class="pre">ELBO</span></code>。在固定数据集的情况下，证据可视为常量，因此只需关注 <code class="docutils literal notranslate"><span class="pre">ELBO</span></code> 。（式8.7）表明：<strong>最大化 ELBO 相当于最小化 KL 散度</strong>。因此，最优化的目标函数转换为 “使 ELBO 最大化”。</p>
<p><strong>（2）设定近似分布 – 平均场近似法</strong></p>
<p>上述过程尚未引入对后验的任何近似，只是提供了一个求取（近似分布的参数）最优解的框架。实际上，近似是在选择 <span class="math notranslate nohighlight">\(q(.)\)</span> 时才开始发生的。原则上， <span class="math notranslate nohighlight">\(q(.)\)</span> 可以是任何想要的分布形式，但实际上应选择易于处理的分布。</p>
<p>一种设置近似分布的方案是： <strong>假设高维后验可以用若干独立的一维分布来描述</strong>。 该方案在数学上可以表示如下：</p>
<div class="math notranslate nohighlight">
\[q(\theta)=\prod_{j} q_{j}\left(\theta_{j}\right) \tag{8.8} \label{式8.8}\]</div>
<p>上述近似方式被称为<code class="docutils literal notranslate"><span class="pre">平均场近似（Mean-Field</span> <span class="pre">Approximation）</span></code>。平均场近似在物理学中常被用于将（具有许多相互作用的）复杂系统建模为若干相互独立子系统的集合，或者只有在做平均时才考虑相互作用。</p>
<p>理论上，可以人为地为每个参数 <span class="math notranslate nohighlight">\(\theta_j\)</span> 设置一个独特的分布 <span class="math notranslate nohighlight">\(q_j\)</span>。但为简化问题，通常假设 <span class="math notranslate nohighlight">\(q_j\)</span> 取自同一分布族，不同 <span class="math notranslate nohighlight">\(q_j\)</span> 仅参数不同。 实践中最为常用的分布族是指数族分布，包括：正态分布、指数分布、贝塔分布、狄利克雷分布、伽马分布、泊松分布、类别分布和伯努利分布等。</p>
<p>有了上述要素，就可以将推断问题转化为最优化问题，通过最大化 ELBO 来求解近似分布的参数。原理似乎比较简单，不过在实践中可能会稍微复杂一些。</p>
</div>
<div class="section" id="advi">
<h3>8.2.4  一种通用的自动变分方法 – ADVI<a class="headerlink" href="#advi" title="Permalink to this headline">¶</a></h3>
<p>平均场变分法的主要缺点是：<strong>必须为根据模型的近似分布设定，提出一个特定算法</strong>。也就是说，很难形成一个适用所有模型的通用推断引擎，这显然严重影响了变分推断引擎的设计和推广使用。因此，很多人关注了该问题，希望能够提出变分法的自动化方案。</p>
<p>最近提出的一种被称为 <code class="docutils literal notranslate"><span class="pre">自动微分变分推断</span> <span class="pre">(ADVI)</span></code> 的方法，因为对大数据集具有较好的通用性而得到推广，参见<a class="reference external" href="http://arxiv.org/abs/1603.00788">相关论文</a> 。在概念层面，<code class="docutils literal notranslate"><span class="pre">ADVI</span></code> 的主要步骤包括：</p>
<ul class="simple">
<li><p>将所有有界分布转换到实数轴上的无界分布，就像之前在平方近似法中所讨论的那样。</p></li>
<li><p>取用高斯分布作为无界分布的近似（公式 8.8 中的 <span class="math notranslate nohighlight">\(q_j\)</span> ）；此处需注意，无界空间上的高斯在原参数空间上可能是非高斯的。</p></li>
<li><p>使用自动微分作为优化引擎来最大化 ELBO。</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 文档（例如：<a class="reference external" href="https://docs.pymc.io/nb_examples">链接</a>） 提供了许多关于使用变分推断的示例。</p>
</div>
</div>
<div class="section" id="id7">
<h2>8.3 马尔科夫方法<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>有一系列与随机数相关的方法被统称为 <strong>MCMC 方法</strong>。对于贝叶斯统计，只要能够逐点计算出似然（人工建模与似然假设）和先验值（人工设置先验），MCMC 方法就能从真实后验分布中获得样本。这与前面提到的网格法相同，但与网格法在参数空间平均间隔采样不同，MCMC 方法依据概率密度的大小从不同的分布区域采集不同数量的样本，其性能远优于网格法。</p>
<p>也就是说，MCMC 方法根据参数空间中每个区域的相对概率来确定从该区域抽取样本的次数。例如：如果 A 区域的概率值是 B 区域的两倍，那么从 A 区域抽取的样本数量也将是 B 区域的两倍。因此，即使无法解析计算得到整个后验，也可以使用 MCMC 方法从后验中获取足够有效的样本。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>注：后验计算公式中分母的边缘似然项很难计算，进而导致很难获得后验的绝对概率值，但 MCMC 方法并不依据绝对概率值来确定采样数量的多少，而是依据相对概率，有效规避了该问题。</p>
</div>
<p>在统计模型中，人们关心的所有事物，几乎都与某些函数 <span class="math notranslate nohighlight">\(f(\theta)\)</span> 的期望值有关，其本质上是与参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的分布有关：</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}[f]=\int_{\theta} p(\theta) f(\theta) \mathrm{d} \theta \tag{8.9} \label{式8.9}\]</div>
<p>下面是该表达式的一些特例：</p>
<ul class="simple">
<li><p>求后验（公式 1.14）</p></li>
<li><p>求后验预测性分布（公式 1.17）</p></li>
<li><p>求给定模型的边缘似然（公式 5.13）</p></li>
</ul>
<p>（式8.9）基于 <span class="math notranslate nohighlight">\(\theta\)</span> 的连续分布，如果能够从该连续分布中抽取合理的样本集，则可以用有限样本近似式 8.9 的结果，如式8.10 所示。这就是 MCMC 方法的基本出发点，当然前提是 “采样密度符合相对概率”。</p>
<div class="math notranslate nohighlight">
\[\lim _{N \rightarrow \infty} \mathbb{E}_{\pi}[f]=\frac{1}{N} \sum_{n=1}^{N} f\left(\theta_{n}\right) \tag{8.10} \label{式8.10}\]</div>
<p>（式 8.10）的问题是：等式只能渐近成立。也就是说，需要无限数量的采样才成立！但实践中采样数量越多，则推断所需时间越长、效率越低，因此 MCMC 方法必须寻找到能够尽可能快地收敛到正确答案的采样方法，用尽可能少的样本得到正确答案，这是 MCMC 方法的核心问题，也是本节（<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">8.3</span> <span class="pre">节</span> <span class="pre">“马尔可夫方法”</span></code>）的主要内容。</p>
<p>一般来说，要确定 MCMC 样本已经收敛并非易事。因此，实践中必须依靠实证检验来确保有一个可靠的 MCMC 近似 。本书将在<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">8.4</span> <span class="pre">节</span> <span class="pre">“诊断样本”</span> </code>部分讨论该问题。当然，其他近似（包括非马尔可夫方法）也需要实证检验，但本书不会过多讨论。</p>
<p>为了理解什么是 MCMC 方法，后文把该方法分成两个部分：『蒙特卡洛部分』 和 『马尔可夫链部分』 。</p>
<div class="section" id="id8">
<h3>8.3.1 蒙特卡洛<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>蒙特卡洛部分可以用随机数来解释。蒙特卡洛方法是一个非常广泛的算法家族，它使用随机抽样来计算或模拟给定过程。蒙特卡洛是摩纳哥的一个区，那里有一家非常著名的赌场。蒙特卡洛方法的提出者之一 <code class="docutils literal notranslate"><span class="pre">Stan</span></code>，有一个叔叔曾在那儿赌博。</p>
<p><code class="docutils literal notranslate"><span class="pre">Stan</span></code> 的关键思想是：<strong>虽然许多问题比较难解决，甚至无法用确切的方式表达出来，但可以通过从问题中抽取样本来有效地研究它们</strong>。事实上，蒙特卡洛方法的最早动机是找到纸牌游戏中拿到某张特定牌的可能性。解决该问题的常见方法是利用组合数学，但 <code class="docutils literal notranslate"><span class="pre">Stan</span></code> 认为存在另一种更容易的方法：“进行多次单轮游戏，最后计算其中多少次是我们感兴趣的”。</p>
<p>蒙特卡洛方法的第一个应用解决的是核物理问题，不过该问题在当时的工具手段下很难实现。发展到如今，即使个人计算机也足以利用蒙特卡洛方法解决许多问题，因此，蒙特卡洛方法被广泛应用于科学、工程、工业和艺术领域中。</p>
<p>教科书上有关蒙特卡洛方法的经典案例是估计 <span class="math notranslate nohighlight">\(π\)</span> ，可以通过以下蒙特卡洛过程估计：</p>
<p>（1）在边长为 <span class="math notranslate nohighlight">\(2R\)</span> 的正方形内随机撒 <span class="math notranslate nohighlight">\(N\)</span> 个点。</p>
<p>（2）在正方形内画一个半径为 <span class="math notranslate nohighlight">\(R\)</span> 的圆，计算在圆内点的个数 <span class="math notranslate nohighlight">\(inside\)</span> 。</p>
<p>（3）利用比例估计 <span class="math notranslate nohighlight">\(\bar \pi = 4\frac{inside}{N}\)</span> 。</p>
<p>以下是一些注意事项：</p>
<p>（1）圆和正方形的面积，应当分别与圆内点数和总点数成正比，即是一种均匀的随机分布。</p>
<p>（2）认为该点在圆内的判据是： <span class="math notranslate nohighlight">\(\sqrt{\left(x^{2}+y^{2}\right)} \leq R\)</span> 。</p>
<p>（3）正方形的面积是 <span class="math notranslate nohighlight">\((2R)^2\)</span> ，圆的面积是 <span class="math notranslate nohighlight">\(πR^2\)</span> ，因此二者面积之比是 <span class="math notranslate nohighlight">\(4/π\)</span></p>
<p>圆和正方形的面积分别正比于圆内点数 <span class="math notranslate nohighlight">\(inside\)</span> 和总点数 <span class="math notranslate nohighlight">\(N\)</span>，可以通过几行代码来模拟该蒙特卡洛过程，同时计算出估计值与实际值之间的相对误差：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">N</span><span class="p">))</span>
<span class="n">inside</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<span class="n">pi</span> <span class="o">=</span> <span class="n">inside</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">*</span><span class="mi">4</span><span class="o">/</span><span class="n">N</span>
<span class="n">error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">((</span><span class="n">pi</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">/</span> <span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">outside</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">invert</span><span class="p">(</span><span class="n">inside</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">inside</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">inside</span><span class="p">],</span> <span class="s1">&#39;b.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">outside</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">outside</span><span class="p">],</span> <span class="s1">&#39;r.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;π*= </span><span class="si">{</span><span class="n">pi</span><span class="si">:</span><span class="s1">4.3f</span><span class="si">}</span><span class="se">\n</span><span class="s1">error = </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s1">4.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;square&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">framealpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-4">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716361541.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716361541.webp" />
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">蒙特卡洛方法求取圆的面积</span><a class="headerlink" href="#fig8-4" title="Permalink to this image">¶</a></p>
</div>
<p>上面的代码中，<code class="docutils literal notranslate"><span class="pre">outside</span></code> 变量仅用于绘图，在计算 <span class="math notranslate nohighlight">\(\hat \pi\)</span>  过程中没有用到。另外一点需要澄清的是，由于这里用的是单位圆，因此在判断一个点是否在圆内时没有计算平方根。</p>
</div>
<div class="section" id="id9">
<h3>8.3.2 马尔科夫链<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>马尔科夫链是一个数学对象，包含一系列状态以及状态之间的转移概率，如果每个状态转移到其他状态的概率只与当前状态相关，那么这个状态链就称为马尔科夫链。有了马尔科夫链，就可以任取一个初始点，然后根据状态转移概率进行随机游走。</p>
<p>如果能够找到一个马尔科夫链，其状态转移概率正比于待采样的分布（如后验），那么采样过程就变成了简单地在该链上移动。</p>
<p>那么，如何在不知道后验分布的情况下找到这样的状态链呢？有一个概念叫做<code class="docutils literal notranslate"><span class="pre">细节平衡条件（Detailed</span> <span class="pre">Balance</span> <span class="pre">Condition）</span></code> ，直观上讲，该条件是说，我们需要采用一种可逆的方式移动。也就是说，从状态 <span class="math notranslate nohighlight">\(i\)</span> 转移到状态 <span class="math notranslate nohighlight">\(j\)</span> 的概率必须和状态 <span class="math notranslate nohighlight">\(j\)</span> 转移到状态 <span class="math notranslate nohighlight">\(i\)</span> 的概率相等。该条件是充分条件而不一定是必要条件，且比较容易证明，所以被用于大多数 <code class="docutils literal notranslate"><span class="pre">MCMC方法</span></code> 。</p>
<p>总的来说就是，如果我们能够找到满足细节平衡条件的马尔科夫链，就可以保证从中采样得到的样本来自正确的分布。保证细节平衡的最流行的算法是 Metropolis-Hasting 算法。</p>
</div>
<div class="section" id="metropolis-hastings">
<h3>8.3.3 Metropolis-Hastings 算法<a class="headerlink" href="#metropolis-hastings" title="Permalink to this headline">¶</a></h3>
<p>某些分布（如高斯分布）有非常有效的样本获取算法，但对于大多数分布，情况并非如此。<code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 能够从任何概率分布 <span class="math notranslate nohighlight">\(p(x)\)</span> 中获得与其取值概率成比例的样本，而不用计算归一化因子。这非常有用，因为许多问题（不仅是贝叶斯统计）中计算归一化因子都是非常困难的。</p>
<p>为了更形象地理解这个算法，用下面这个例子来类比。假设我们想知道某个湖的水容量以及这个湖中最深的点，湖水很浑浊以至于没法通过肉眼来估计深度，而且这个湖相当大，网格法显然不是个好办法。为了找到一个采样策略，我们请来了两个好朋友小马和小萌。经过讨论之后想出了如下办法，我们需要一个船和一个很长的棍子：</p>
<ol class="simple">
<li><p>随机选一个点，然后将船开过去。</p></li>
<li><p>用棍子测量湖的深度。</p></li>
<li><p>将船移到另一个地点并重新测量。</p></li>
<li><p>按如下方式比较两点的测量结果。</p>
<ul class="simple">
<li><p>如果新的地点比旧的地点水位深，那么在笔记本上记录下新的测量值并重复过程（2）。</p></li>
<li><p>如果新的地点比旧的地点水位浅，那么我们有两个选择：接受或者拒绝。</p>
<ul>
<li><p>接受意味着记录下新的测量值并重复过程（2）；</p></li>
<li><p>拒绝意味着重新回到上一个点，再次记录下上一个点的测量值。</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>如何决定接受还是拒绝新的测量值呢？这里的一个技巧便是使用 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">准则</span></code>，即接受新的测量值的概率正比于新旧两点的测量值之比。</p>
<p>按照以上过程迭代下去，不仅可以得到整个湖的水容量和最深的点，而且可以得到整个湖底的近似曲面。在这个类比中，湖底的曲面其实就是后验分布，而最深的点就是后验的众数。根据小马的说法，迭代的次数越多，近似的效果越好。事实上，理论保证了在这种情形下，如果能采样无数次，最终能得到完整的后验。幸运地是，实际上对于很多问题而言，只需要相对较少地采样就可以得到一个相当准确的近似。</p>
<p>前面的解释足以对 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 有一个概念性的理解。接下来几段包含更详细、更正式的解释。</p>
<p><code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 算法的步骤如下：</p>
<ol>
<li><p>给参数 <span class="math notranslate nohighlight">\(x_i\)</span> 赋一个初始值，通常是随机初始化或者使用某些经验值。</p></li>
<li><p>从某个提议分布（如高斯分布、均匀分布等简单分布） <span class="math notranslate nohighlight">\(q(x_{i+1}|x_i)\)</span> 中随机抽取一个新参数值。这一步可视为对状态 <span class="math notranslate nohighlight">\(x_i\)</span> 的扰动。</p></li>
<li><p>根据 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">准则</span></code> 计算新参数值的接受概率：</p>
<div class="math notranslate nohighlight">
\[p_{a}\left(x_{i+1} \mid x_{i}\right)=\min \left(1, \frac{p\left(x_{i+1}\right) q\left(x_{i} \mid x_{i+1}\right)}{p\left(x_{i}\right) q\left(x_{i+1} \mid x_{i}\right)}\right) \tag{8.11} \label{式8.11}\]</div>
</li>
<li><p>从位于区间 [0,1] 内的均匀分布中随机抽取一个值，如果第（3）步中得到的接受概率比该值大，那么就接受新参数值，否则仍保持原值。</p></li>
<li><p>回到第（2）步重新迭代，直到有足够多的样本（稍后会解释什么叫足够多）。</p></li>
</ol>
<p>有几点需要注意：</p>
<ul class="simple">
<li><p>如果选择的提议分布 <span class="math notranslate nohighlight">\(q(x_{i+1}|x_i)\)</span> 是对称的，那么可以得到式 8.12，通常称为 <code class="docutils literal notranslate"><span class="pre">Metropolis</span> <span class="pre">准则</span></code> 。</p></li>
</ul>
<div class="math notranslate nohighlight">
\[p_{a}\left(x_{i+1} \mid x_{i}\right)=\min \left(1, \frac{p\left(x_{i+1}\right)}{p\left(x_{i}\right)}\right) \tag{8.12} \label{式8.12}\]</div>
<ul class="simple">
<li><p>步骤（3）和步骤（4）表明：我们总是会转移到一个比当前状态（或参数）概率更大的状态（或参数），对于概率更小的，则会以 <span class="math notranslate nohighlight">\(x_{i+1}\)</span> 与 <span class="math notranslate nohighlight">\(x_i\)</span> 之比的概率接受。该准则中的接受步骤使得采样过程相比网格法更高效，同时保证了采样的准确性。</p></li>
<li><p>目标分布（贝叶斯统计中的后验分布）是通过记录下来的采样值来近似的。如果我们接受转移到新的状态 <span class="math notranslate nohighlight">\(x_{i+1}\)</span>，那么我们就记录该采样值 <span class="math notranslate nohighlight">\(x_{i+1}\)</span>。如果拒绝转移到 <span class="math notranslate nohighlight">\(x_{i+1}\)</span>，那么我们就记录 <span class="math notranslate nohighlight">\(x_i\)</span>。</p></li>
</ul>
<p>最后，我们会得到一连串记录值，有时候也称采样链或者迹。如果一切都正常进行，那么这些采样值就是后验的近似。在采样链中出现次数最多的值对应后验中出现概率最大的值（最大后验概率点）。该过程的优点是：<code class="docutils literal notranslate"><span class="pre">后验分析很简单，可以把对后验求积分的过程转化成对采样链求和的过程</span></code> （式 8.10）。</p>
<p>下面的代码展示了 <code class="docutils literal notranslate"><span class="pre">Metropolis</span> <span class="pre">算法</span></code>的一个基本实现。这段代码并不是为了解决什么实际问题，只是用来演示，如果我们知道怎么计算给定点的函数值，就能得到该函数的采样。需要注意代码不包含贝叶斯相关的部分，既没有先验也没有数据。要知道，<code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 是一类能够用于解决很多问题的通用方法。例如，在一个（非贝叶斯的）分子模型中，可能需要一个函数来计算在某个状态 <span class="math notranslate nohighlight">\(x\)</span> 下系统的能量而不是简单地调用 <code class="docutils literal notranslate"><span class="pre">func.pdf(x)</span></code> 函数。<code class="docutils literal notranslate"><span class="pre">metropolis</span></code> 函数的第一个参数是一个 <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> 的分布，假设我们不知道如何从中直接采样。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A very simple Metropolis implementation&quot;&quot;&quot;</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">draws</span><span class="p">)</span>
    <span class="n">old_x</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># func.mean()</span>
    <span class="n">old_prob</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">old_x</span><span class="p">)</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">draws</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">draws</span><span class="p">):</span>
        <span class="n">new_x</span> <span class="o">=</span> <span class="n">old_x</span> <span class="o">+</span> <span class="n">delta</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">new_prob</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">new_x</span><span class="p">)</span>
        <span class="n">acceptance</span> <span class="o">=</span> <span class="n">new_prob</span> <span class="o">/</span> <span class="n">old_prob</span>
        <span class="k">if</span> <span class="n">acceptance</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">():</span>
            <span class="n">trace</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_x</span>
            <span class="n">old_x</span> <span class="o">=</span> <span class="n">new_x</span>
            <span class="n">old_prob</span> <span class="o">=</span> <span class="n">new_prob</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">trace</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_x</span>
    <span class="k">return</span> <span class="n">trace</span>
</pre></div>
</div>
</div>
</div>
<p>在下一个示例中，我们将 <code class="docutils literal notranslate"><span class="pre">func</span></code> 定义为 <code class="docutils literal notranslate"><span class="pre">beta函数</span></code>，原因很简单，因为很容易更改它们的参数获得不同形状。我们将<code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 获得的样本绘制为直方图，并将真实分布绘制为连续(橙色)线：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">trace</span> <span class="o">=</span> <span class="n">metropolis</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">func</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">.99</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;C1-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;True distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="n">trace</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;pdf(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-5">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210608114143f5.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210608114143f5.webp" />
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Metropolis 采样算法的后验估计</span><a class="headerlink" href="#fig8-5" title="Permalink to this image">¶</a></p>
</div>
<p>算法效率很大程度上依赖于提议分布；如果建议状态离当前状态很远，拒绝的机会很高；如果建议状态非常接近，则搜索参数空间的速度很慢。在这两种情况下，都需要比不那么极端的情况下更多的样本。通常，提议分布是多变量高斯分布，其协方差矩阵是在调谐阶段确定的。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 会自适应地调整协方差，基本原则是：一维高斯分布的理想接受度为 50% ， <span class="math notranslate nohighlight">\(n\)</span> 维高斯分布的理想接受度为 23% 左右。</p>
<p>MCMC 方法通常需要一段时间才能开始从目标分布中获取样本。因此，实践中会进行老化步骤。老化是一种实用的技巧，并不是马尔科夫理论的组成部分；事实上，对于无限样本来说，并不需要老化。考虑到我们只能计算有限样本，删除样本的第一部分只是为了获得更好结果的临时技巧。</p>
<p>现在你应该从概念上掌握了 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">算法</span></code>。也许你需要回过头去重新阅读前面几页才能完全消化。此外，我还强烈建议阅读 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 核心作者写的<a class="reference external" href="https://twiecki.io/blog/2015/11/10/mcmc-sampling/">博文</a> 。他用一个简单的例子实现了 <code class="docutils literal notranslate"><span class="pre">metropolis</span></code> 方法，并将其用于求解后验分布，文中用非常好看的图展示了采样的过程，同时简单讨论了最初选取的步长如何影响了最终结果。</p>
</div>
<div class="section" id="id10">
<h3>8.3.4 汉密尔顿蒙特卡洛方法/不掉向采样<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>MCMC 方法（包括 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code>）都在理论上保证如果采样次数足够多，最终会得到后验分布的准确近似。不过，实际中想要采样足够多次可能需要相当长的时间，因此，人们提出了一些 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">算法</span></code>的替代方案。这些替代方案最初都是用来解决统计力学的问题。<code class="docutils literal notranslate"><span class="pre">汉密尔顿蒙特卡洛方法</span></code>，又称 <code class="docutils literal notranslate"><span class="pre">混合蒙特卡洛（Hybrid</span> <span class="pre">Monte</span> <span class="pre">Carlo，HMC）</span></code>，是此类改进方案之一。简单来说，汉密尔顿这个词描述的是物理系统的总能量，而另外一个名称中的“混合”是指将 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">算法</span></code> 与 <code class="docutils literal notranslate"><span class="pre">分子力学</span></code> 相结合。<code class="docutils literal notranslate"><span class="pre">HMC</span> <span class="pre">方法</span></code> 本质上和 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 是一样的，改进的地方在于：原来是随机放置小船，现在有了一个更聪明的办法，将小船沿着湖底方向放置。为什么这个做法更聪明？因为这样做避免了 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">算法</span></code> 的一个主要问题：探索得太慢而且采样结果存在自相关（因为大多数采样结果都被拒绝了）。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>统计力学是物理学的一个分支，主要研究原子和分子系统的特性。</p>
</div>
<p>那么，如何才能不必深入其数学细节而理解汉密尔顿蒙特卡洛方法呢？假设我们还是在湖面上坐着船，为了决定下一步将要去哪，我们从当前位置往湖底扔了一个球，受“球状奶牛”的启发 [3]，我们假设球面是理想的，没有摩擦，因而不会被泥巴和水减速。扔下球之后，让它滚一小会儿，然后把船划到球所在的位置。现在利用 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span> <span class="pre">算法</span></code> 中提到的 <code class="docutils literal notranslate"><span class="pre">Metropolis</span> <span class="pre">准则</span></code> 来选择接受或者拒绝，重复整个过程一定次数。改进后的过程对新位置有更高的接受概率，即使它们的位置相比前一位置距离较远。</p>
<p>现在跳出我们的思维实验，回到现实中来。基于汉密尔顿的方法需要计算函数的梯度。梯度是在多个维度上导数的推广。我们可以用梯度信息来模拟球在曲面上移动的过程。因此，我们面临一个权衡；<code class="docutils literal notranslate"><span class="pre">HMC</span></code> 计算过程要比 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 更复杂，但被接受概率更高。对于一些复杂的问题，<code class="docutils literal notranslate"><span class="pre">HMC</span> <span class="pre">方法</span></code> 更合适一些。<code class="docutils literal notranslate"><span class="pre">HMC</span> <span class="pre">方法</span></code>的另一个缺点是：想要得到很好的采样需要指定一些参数。当手动完成此调优时，需要进行一些试验和错误，还需要有经验的用户，这使得此过程不像我们所希望的那样是一个通用的推理引擎。幸运的是，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 配备了一个相对较新的采样器，名为不掉头采样器 <code class="docutils literal notranslate"><span class="pre">No-U-Turn</span> <span class="pre">Sampler(NUTS)</span></code>。事实证明，该方法在不需要人工干预(或至少将其最小化)的情况下，为求解贝叶斯模型提供了非常好的效率。NUTS 的问题是，它只适用于连续分布，因为我们无法计算离散分布的梯度。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 通过将 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 分配给连续参数，将 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 分配给离散参数来解决此问题。</p>
<p>我强烈推荐 <code class="docutils literal notranslate"><span class="pre">Chi</span> <span class="pre">Feng</span></code> 的 <a class="reference external" href="https://chi-feng.github.io/mcmc-demo/">动画</a> 来补充这部分内容的学习。</p>
</div>
<div class="section" id="id11">
<h3>8.3.5 序贯蒙特卡洛<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 和 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code>（以及其他哈密尔顿蒙特卡洛变种）存在的问题是：如果后验有多个峰，并且这些峰被非常低概率的区域分开，则上述方法可能会陷入某个单一众数，而错过其他值。</p>
<p>解决多重极小值问题的主要方法是 <code class="docutils literal notranslate"><span class="pre">回火法（tempering）</span></code> 。回火法借用了统计力学，物理系统可填充的状态数取决于系统的温度：在绝对温度为 <span class="math notranslate nohighlight">\(0K\)</span> 时，每个系统都停留在单一状态；另一方面，对于无限大的温度，所有可能状态都是同等可能的；通常我们对处于某一中间温度的系统感兴趣。</p>
<p>对于贝叶斯模型，有一种直观方式来适应这种调温的想法，那就是用以下方式写出贝叶斯定理：</p>
<div class="math notranslate nohighlight">
\[p(\theta \mid y)_{\beta}=p(y \mid \theta)^{\beta} p(\theta) \tag{8.13} \label{式8.13}\]</div>
<p>公式 1.4 和 8.13 之间的唯一区别是参数 <span class="math notranslate nohighlight">\(\beta\)</span> ，此处被称为 <code class="docutils literal notranslate"><span class="pre">逆温</span></code> 或 <code class="docutils literal notranslate"><span class="pre">回火参数</span></code> 。请注意，对于 <span class="math notranslate nohighlight">\(\beta=0\)</span> 我们得到 <span class="math notranslate nohighlight">\(p(y \mid \theta)^{\beta}=1\)</span> ，因此调温后的后验 <span class="math notranslate nohighlight">\(p(\theta \mid y)_{\beta}\)</span> 就是先验 <span class="math notranslate nohighlight">\(p(\theta)\)</span>； 并且当 <span class="math notranslate nohighlight">\(\beta=1\)</span> 时，调温后的后验是真实的完整后验。由于从先验采样通常比从后验采样容易（通过增加 <span class="math notranslate nohighlight">\(\beta\)</span> 的值），因此我们可以从更容易的分布开始采样，然后慢慢地将其变形为真正关心的更复杂的分布。</p>
<p>利用该思想的方法很多，<code class="docutils literal notranslate"><span class="pre">序贯蒙特卡洛</span> <span class="pre">(Sequential</span> <span class="pre">Monte</span> <span class="pre">Carlo</span> <span class="pre">,</span> <span class="pre">SMC)</span></code> 就是其中之一。在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中实施的 <code class="docutils literal notranslate"><span class="pre">SMC</span> <span class="pre">方法</span></code> 可总结如下：</p>
<ol class="simple">
<li><p>以 0 初始化参数 <span class="math notranslate nohighlight">\(\beta\)</span> 。</p></li>
<li><p>从回火后的后验中生成 <span class="math notranslate nohighlight">\(N\)</span> 个样本，形成样本集 <span class="math notranslate nohighlight">\(S_{\beta}\)</span>。</p></li>
<li><p>增加一点 <span class="math notranslate nohighlight">\(\beta\)</span>。</p></li>
<li><p>计算 <span class="math notranslate nohighlight">\(N\)</span> 个权重 <span class="math notranslate nohighlight">\(w\)</span> 构成的集合 <span class="math notranslate nohighlight">\(W\)</span> ，权重根据新的回火后验计算得出。</p></li>
<li><p>根据 <span class="math notranslate nohighlight">\(w\)</span> 对 <span class="math notranslate nohighlight">\(S_{\beta}\)</span> 重采样，得到 <span class="math notranslate nohighlight">\(S_w\)</span>。</p></li>
<li><p>运行 <span class="math notranslate nohighlight">\(N\)</span> 条 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code>链，每条链从 <span class="math notranslate nohighlight">\(S_w\)</span> 中的不同样本开始。</p></li>
<li><p>从步骤 3 开始重复，直到 <span class="math notranslate nohighlight">\(\beta \geq 1\)</span>。</p></li>
</ol>
<p>重采样步骤通过移除概率较低的样本并将其替换为概率较高的样本来实现。<code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 步骤扰乱了这些样本，有助于探索参数空间。回火法的效率在很大程度上取决于 <span class="math notranslate nohighlight">\(\beta\)</span> 的中间值（通常称之为冷却计划）。<span class="math notranslate nohighlight">\(\beta\)</span> 的两个相邻值间的差异越小，两个回火后验的距离就越近，从一个阶段转移到下一个阶段就越容易。但如果步长过小，将需要更多中间阶段，会导致大量计算资源浪费，而不会真正提高结果的准确性。</p>
<p>幸运的是，<code class="docutils literal notranslate"><span class="pre">SMC</span></code> 可以自动计算 <span class="math notranslate nohighlight">\(\beta\)</span> 的中间值。精确的冷却计划将根据问题难度进行调整；较难采样的分布将比简单分布需要更多的中间阶段。</p>
<p><code class="docutils literal notranslate"><span class="pre">SMC</span></code> 如图 8.6 所示，第一个子图显示了特定阶段的五个样本（橙色）点。第二个小图显示了这些样本是如何根据它们调温后的后验密度（蓝色）曲线重新加权的。第三个子图显示了从第二个子图中的重新加权样本开始，运行一定数量 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 步长的结果。请注意，后验密度较低的两个样本（最右侧和最左侧的较小圆圈）如何被丢弃，而不是用作新马尔可夫链的种子：</p>
<div class="figure align-center" id="fig8-6">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717005520.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717005520.webp" />
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">序贯蒙特卡洛采样的不同阶段</span><a class="headerlink" href="#fig8-6" title="Permalink to this image">¶</a></p>
</div>
<p>除了 <span class="math notranslate nohighlight">\(\beta\)</span> 的中间值外，还根据前一阶段的接受率动态计算了另外两个参数：每个马尔可夫链的步数和提议分布的宽度。</p>
<p>对于 <code class="docutils literal notranslate"><span class="pre">SMC</span> <span class="pre">算法</span></code> 的第 6 步，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 使用了 <code class="docutils literal notranslate"><span class="pre">Metropolis</span> <span class="pre">算法</span></code>。这不是唯一选择，但是一个非常合理的选项，并受到理论和实践结果推动。值得注意的是，即使 <code class="docutils literal notranslate"><span class="pre">SMC</span> <span class="pre">方法</span></code>使用了 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code>，它也有几个超出 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 优点：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SMC</span></code> 可以从多峰分布中采样。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SMC</span></code> 没有老化期。这是由于重加权过程造成的。权重计算采用了如下方式： <span class="math notranslate nohighlight">\(S_w\)</span> 不是近似 <span class="math notranslate nohighlight">\(p(\theta|y)_{\beta_i}\)</span>，而是 <span class="math notranslate nohighlight">\(p(\theta|y)_{\beta_{i+1}}\)</span> 。因此，在每个阶段中，<code class="docutils literal notranslate"><span class="pre">MCMC</span> <span class="pre">链</span></code> 都近似地从正确的后验分布开始。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SMC</span></code> 可以产生低自相关的样本。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SMC</span></code> 可以用来近似边缘似然，这是 <code class="docutils literal notranslate"><span class="pre">SMC</span> <span class="pre">方法</span></code> 的一个副产品，几乎不需要额外的计算。</p></li>
</ul>
</div>
</div>
<div class="section" id="id12">
<h2>8.4 诊断样本<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>本节重点介绍 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 和 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 的样本诊断。因为我们是用有限数量的样本来近似后验，所以检查是否有一个有效样本很重要，否则任何来自它的后续分析都将是有缺陷的。我们可以进行几种直观或定量的检验，来发现样本的问题。但这些检验无法证明样本是否正确；只能提供样本似乎合理的证据。如果发现样本有问题，可以尝试很多解决方案：</p>
<ul class="simple">
<li><p>增加采样数。</p></li>
<li><p>从轨迹的开头删除一些样本。这就是所谓的老化。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 调优阶段有助于减少老化需求。</p></li>
<li><p>修改采样器参数，例如增加调谐阶段的长度，或增加 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 采样器的 TARGET_ACCEPT 参数。在某些情况下，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 会提供修改建议。</p></li>
<li><p>重新参数化模型，即以不同但等价的方式表达模型。</p></li>
<li><p>转换数据。我们已经看到了一个这样的例子，在第 4 章，推广线性模型和第 5 章，模型比较中，我们展示了将数据居中可以改进线性模型的采样。</p></li>
</ul>
<p>为了使解释更具体，我们将使用具有两个参数的极简分层模型：全局参数 <span class="math notranslate nohighlight">\(a\)</span> 和局部参数 <span class="math notranslate nohighlight">\(b\)</span>（每组参数）。仅此而已，我们在这个模型中甚至没有似然/数据！在这里省略数据是为了强调，我们将讨论的一些属性（特别是在散度一节中）与模型的结构相关，而不是与数据相关。我们将讨论同一模型的两种替代参数化：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">centered_model</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">trace_cm</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
    
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">non_centered_model</span><span class="p">:</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">b_shift</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;b_offset&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="mi">0</span> <span class="o">+</span> <span class="n">b_shift</span> <span class="o">*</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">trace_ncm</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>中心模型和非中心模型的不同之处在于，对于前者，我们直接拟合群组尺度的参数，而对于后者，我们将群组尺度的参数建模为平移和缩放的高斯模型。我们将使用几个曲线图和数字摘要来探索其中的差异。</p>
<div class="section" id="id13">
<h3>8.4.1 收敛性<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">MCMC</span> <span class="pre">采样</span></code>器（如 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 或 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code>) 需要一段时间才能收敛。正如之前解释过的，MCMC 方法在一般条件和无限数量样本下都有收敛的理论保证。不幸的是，在实践中只能获得有限样本，因此必须转而依赖经验的检验，这些检验充其量只能提供一些提示或警告，表明当其失败时，可能会发生糟糕的事情，但不能保证当其没有失败时，一切都是正常的。</p>
<p>直观检查收敛性的一种方法是运行 <code class="docutils literal notranslate"><span class="pre">arviz.plot_trace</span></code> 函数并检查结果。为更好地理解我们在检查这些曲线图时应该查看什么，此处比较一下前面定义的两个模型（参见图 8.6 和 8.7)：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_cm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">],</span> <span class="n">divergences</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-7">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717041601.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717041601.webp" />
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">中心模型的后验分布和迹图</span><a class="headerlink" href="#fig8-7" title="Permalink to this image">¶</a></p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_ncm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-8">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170440ad.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170440ad.webp" />
<p class="caption"><span class="caption-number">Fig. 8 </span><span class="caption-text">非中心模型的后验分布和迹图</span><a class="headerlink" href="#fig8-8" title="Permalink to this image">¶</a></p>
</div>
<p>图 8.8 中的 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 比 8.7 中的 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 更平滑；平滑的 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 是一个好迹象，而不均匀的 KDE 可能表示存在问题，例如需要更多样本或更严重的问题。迹本身（右侧的图）应该看起来像白噪声，这意味着应该看不到任何可识别的模式；我们希望看到一条自由漫游的曲线，如图 8.8 中的迹。当这种情况发生时，我们说有很好的 Burn 。相反，图 8.6 是一个病态行为的例子；如果您仔细地将它与图 8.8 进行比较，会注意到两条链的重叠在 8.8 比 8.7 大，您还会注意到 8.7 中沿着迹的几个区域发生了一些可疑的事情；最清楚的一个是在 500-1000 画之间的区域：您会看到其中一条链（蓝色的）卡住了（基本上是一条水平线）。</p>
<p>图 8.9 显示了一些 Burn 良好（右侧）和 Burn 不良（左侧）的迹的示例。如果有多个区域，例如离散变量或多峰分布，我们希望迹不会在一个值或区域上花费太多时间才移动到其他区域，而是很容易从一个区域跳到另一个区域：</p>
<div class="figure align-center" id="fig8-9">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071705182a.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071705182a.webp" />
<p class="caption"><span class="caption-number">Fig. 9 </span><span class="caption-text">中心模型的后验分布和迹图</span><a class="headerlink" href="#fig8-9" title="Permalink to this image">¶</a></p>
</div>
<p>好 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 样本的另一个特征是自相似的迹。例如，前 10%（大约）应该与迹中的其他部分相似，例如最后 50% 或 10%。再说一次，我们不希望迹中存在某些模式；相反，想要一些嘈杂的东西。使用 <code class="docutils literal notranslate"><span class="pre">az.plot_trace</span></code> 也可以看到这一点。如果迹的第一部分看起来与其他部分不同，这表明需要老化，或者需要更多的样本。如果我们发现其他部分缺乏自相似性，或者看到了某种模式，这可能意味着需要更多的诊断，但通常情况下，我们应该尝试使用不同的参数化。对于困难的模型，我们甚至可能需要应用所有这些策略的组合。</p>
<p>默认情况下，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 将尝试并行运行独立的链（确切数量取决于可用处理器的数量）。这是使用 <code class="docutils literal notranslate"><span class="pre">pm.sample</span></code> 函数中的 <code class="docutils literal notranslate"><span class="pre">chains</span></code> 参数指定的。我们可以使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的  <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> 或 <code class="docutils literal notranslate"><span class="pre">plot_forest</span></code> 函数直观地检查并行链是否彼此相似。然后，可以将并行链合并为一个单独链进行推断，因此请注意，并行运行链并不浪费资源。</p>
<p>比较独立链的一种定量方法是使用统计量 <code class="docutils literal notranslate"><span class="pre">R</span> <span class="pre">帽</span></code> ，其思想是用链内方差计算链间方差。理想情况下，我们应该期望其值为 1。作为经验规则，值低于 1.1 也没问题；值越高越表示不收敛。我们可以使用 <code class="docutils literal notranslate"><span class="pre">az.r_hat</span></code> 函数计算它；我们只需要传递一个 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 迹对象。默认情况下，还会使用 <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 函数以及可选的 <code class="docutils literal notranslate"><span class="pre">az.plot_forest</span></code> 来计算 <code class="docutils literal notranslate"><span class="pre">r_hat</span> <span class="pre">诊断</span></code>，如我们在以下示例中所看到的：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">trace_cm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">],</span> <span class="n">r_hat</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eff_n</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-10">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170617f5.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170617f5.webp" />
<p class="caption"><span class="caption-number">Fig. 10 </span><span class="caption-text">两种模型的森林图</span><a class="headerlink" href="#fig8-10" title="Permalink to this image">¶</a></p>
</div>
<p>对于 <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 也是如此：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summaries</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_cm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]),</span>
                      <span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_ncm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">])])</span>
<span class="n">summaries</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;centered&#39;</span><span class="p">,</span> <span class="s1">&#39;non_centered&#39;</span><span class="p">]</span>
<span class="n">summaries</span>
</pre></div>
</div>
</div>
</div>
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170651ca.webp" class="align-center" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170651ca.webp" />
</div>
<div class="section" id="id14">
<h3>8.4.2 蒙特卡洛误差<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>数字摘要返回的数值之一是 <code class="docutils literal notranslate"><span class="pre">mc_error</span></code>，这是对采样引入误差的估计。该估计考虑到样本并不是真正彼此独立的。<code class="docutils literal notranslate"><span class="pre">mc_error</span></code> 是 <span class="math notranslate nohighlight">\(n\)</span> 个数据块的平均值 <span class="math notranslate nohighlight">\(x\)</span> 的标准误差，每个数据块只是迹的一部分：</p>
<div class="math notranslate nohighlight">
\[\mathrm{mc}_{\mathrm{error}}=\frac{\sigma(x)}{\sqrt{n}} \tag{8.14} \label{式8.14}\]</div>
<p>此误差应低于我们希望在结果中看到的精度。</p>
</div>
<div class="section" id="id15">
<h3>8.4.3 自相关<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>分布（包括后验分布）的理想样本应该具有等于 0 的自相关。当给定迭代的值不独立于其他迭代的采样值时，样本是自相关的。在实践中，MCMC 方法产生的样本是自相关的，特别是 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code>，在较小程度上是 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 和 <code class="docutils literal notranslate"><span class="pre">SMC</span></code> 。<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 提供了一个方便的函数来绘制自相关曲线：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_autocorr</span><span class="p">(</span><span class="n">trace_cm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-11">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071708494c.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071708494c.webp" />
<p class="caption"><span class="caption-number">Fig. 11 </span><span class="caption-text">中心模型中的相关性</span><a class="headerlink" href="#fig8-11" title="Permalink to this image">¶</a></p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">az.plot_autocorr</span></code> 显示采样值与连续点(最多100个点)的平均相关性。理想情况下，应该看不到自相关。在实践中，我们希望样本迅速下降到较低的自相关值。让我们绘制非中心模型的自相关图：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_autocorr</span><span class="p">(</span><span class="n">trace_ncm</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-12">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210608130900c0.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210608130900c0.webp" />
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">非中心模型中的相关性</span><a class="headerlink" href="#fig8-12" title="Permalink to this image">¶</a></p>
</div>
<p>通过比较图 8.11 和图 8.12，可以很容易地看到，非中心模型的样本几乎没有自相关，而中心模型的样本显示出更大的自相关值。</p>
</div>
<div class="section" id="id16">
<h3>8.4.4 有效样本量<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>有自相关性的采样要比没有自相关性的采样包含的信息量更少，给定采样大小和采样的自相关性之后，可以尝试估计出该采样在采样次数为多少时，没有自相关性且包含信息量不变，该值称为有效采样次数。</p>
<p>参数的自相关程度越高，获得给定精度所需的样本数量就越大，换句话说，自相关会减少有效样本的数量。我们可以在 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 中使用 <code class="docutils literal notranslate"><span class="pre">az.effect_n</span></code> 函数计算有效样本量。通过传递 <code class="docutils literal notranslate"><span class="pre">effn=True</span></code> 参数，还可以通过 <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 和 <code class="docutils literal notranslate"><span class="pre">az.plot_forest</span></code> 函数计算有效样本大小（参见图 8.9)。</p>
<p>理想情况下，有效样本量应该接近实际样本量。与 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 相比，<code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 的有效样本量通常比 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 高得多，因此，一般来说，如果您使用 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code>，通常需要的样本比使用 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 时要少。</p>
<p>如果任何参数的有效样本量低于 200，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 都会发出警告。作为一般指南，100 个有效样本应该可以很好地估计分布的平均值，但是拥有更多样本将提供每次重新运行模型时变化较小的估计值，这也是使用 200 作为有效样本大小临界值的部分原因。对于大多数问题值，1,000 到 2,000 个有效样本将绰绰有余。</p>
</div>
<div class="section" id="id17">
<h3>8.4.5 发散性<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<p>我们现在将探索不包含 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 的检验，因为它们基于方法的内部工作，而不是生成的样本的属性。这些检验基于发散性，是诊断样本的一种强大而灵敏的方法。</p>
<p>当我试图设置本书中的模型以避免散度时，您可能已经看到指示出现散度的 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 消息。散度可能表明 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 在后验遇到了无法正确探索的高曲率区域；这告诉我们采样器可能缺少参数空间的一个区域，因此结果将是有偏差的。散度通常比这里讨论的测试敏感得多，因此，即使其余测试通过，它们也可以发出问题的信号。散度的一个很好的特点是，它们往往看起来靠近有问题的参数空间区域，因此我们可以使用它们来识别问题所在。可视化散度的一种方法是使用带有 DISGENCES=True 参数的 az.plot_pair：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
<span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">tr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([</span><span class="n">trace_cm</span><span class="p">,</span> <span class="n">trace_ncm</span><span class="p">]):</span>
    <span class="n">az</span><span class="o">.</span><span class="n">plot_pair</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">],</span> <span class="n">coords</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;b_dim_0&#39;</span><span class="p">:[</span><span class="mi">0</span><span class="p">]},</span>
<span class="n">kind</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span>
                 <span class="n">divergences</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">contour</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="n">divergences_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;color&#39;</span><span class="p">:</span><span class="s1">&#39;C1&#39;</span><span class="p">},</span>
                 <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">([</span><span class="s1">&#39;centered&#39;</span><span class="p">,</span> <span class="s1">&#39;non-centered&#39;</span><span class="p">][</span><span class="n">idx</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-13">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717112515.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717112515.webp" />
<p class="caption"><span class="caption-number">Fig. 13 </span><span class="caption-text">两种模型的散度情况</span><a class="headerlink" href="#fig8-13" title="Permalink to this image">¶</a></p>
</div>
<p>在图 8.13 中，小（蓝色）点是规则样本，较大（黑色和橙色）点表示散度。我们可以看到，中心模型的散度主要集中在漏斗的尖端。我们还可以看到，非中心模型没有发散，尖端更尖锐。采样器通过分叉告诉我们，它很难从漏斗尖端附近的区域取样。我们确实可以在图 8.13 中检查到，居中的模型在尖端附近没有样本，靠近散度集中的地方。这真是太棒了！</p>
<p>散度也用黑色、“|\”标记表示在 ArviZ 的轨迹图中，如图 8.7 所示。请注意，散度是如何集中在轨迹的病理平坦部分周围的。</p>
<p>可视化散度的另一种有用的方法是用平行的曲线图：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_parallel</span><span class="p">(</span><span class="n">trace_cm</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="fig8-14">
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171240da.webp" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171240da.webp" />
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">散度平行曲线图</span><a class="headerlink" href="#fig8-14" title="Permalink to this image">¶</a></p>
</div>
<p>在这里，我们可以看到 b 和 a 的散度都集中在 0 附近。如图 8.13 和 8.14 所示的曲线图非常重要，因为它们让我们知道参数空间的哪一部分可能有问题，还因为它们帮助我们发现误报。让我解释最后一点。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 使用启发式方法来标记散度，有时，这种启发式方法可能会说我们有散度，但实际上并非如此。一般来说，如果散度分散在参数空间中，我们可能会有误报；如果散度集中，那么我们可能会有问题。当产生散度时，通常有三种方法可以摆脱它们，或者至少减少它们的数量：</p>
<p>增加调优步骤的数量，类似于 pm.sample（调优=1000)。将 TARGET_ACCEPT 参数的值从默认值 0.8 增加。最大值为 1，因此您可以尝试使用诸如 0.85 或 0.9 之类的值。重新参数化模型。正如我们刚刚看到的，非中心模型是中心模型的重新参数化，这导致了更好的样本，并且没有分歧。</p>
</div>
<div class="section" id="id18">
<h3>8.4.6 非居中参数化<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>从图 8.13 中，可以看到 <span class="math notranslate nohighlight">\(a\)</span> 和 <span class="math notranslate nohighlight">\(b\)</span> 参数是相关的。因为 <span class="math notranslate nohighlight">\(b\)</span> 是形状 10 的向量，所以我们选择绘制 <span class="math notranslate nohighlight">\(b(0)\)</span> ，但是 <span class="math notranslate nohighlight">\(b\)</span> 的任何其他元素都应该显示相同的模式，事实上，这在图 8.14 中表现得非常清楚。这种相关性和这种特殊的漏斗形状是模型定义和模型部分汇集数据的能力的结果。当 <span class="math notranslate nohighlight">\(a\)</span> 的值减小时，<span class="math notranslate nohighlight">\(b\)</span> 的单个值变得越来越接近全局平均值。换句话说，收缩级别会越来越高，因此数据会越来越集中（直到完全集中）。允许部分池化的相同结构还引入了影响采样器方法性能的相关性。</p>
<p>在第 3 章“线性回归模型”中，我们看到线性模型也会导致相关性（性质不同）；对于这些模型，一个简单的解决办法是将数据居中。我们可能想在这里做同样的事情，但不幸的是，这不会摆脱漏斗形状带来的采样问题。漏斗形状的微妙特征是相关性随参数空间中的位置而变化，因此将数据居中无助于降低这种相关性。MCMC 方法，如 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code>，在探索高度相关的空间时遇到了问题；这些方法找到合适样本的唯一途径是在前一步的邻域中提出一个新的步骤。结果，探索变得高度自相关且缓慢得令人痛苦。缓慢的 Burn 可能会非常剧烈，以至于简单地增加样本（绘制）的数量并不是一个合理或可行的解决方案。</p>
<p><code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 等采样器更适合这项工作，因为它们根据参数空间的曲率提出步骤，但正如我们已经讨论过的，采样过程的效率高度依赖于调优阶段。对于后验的一些几何形状，例如那些由分层模型诱导的几何形状，调整阶段过度调整到链开始的局部邻域，使得对其他区域的探索效率低下，因为新的建议更具随机性，类似于 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 的行为。</p>
</div>
</div>
<div class="section" id="id19">
<h2>8.5 小结<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h2>
<p>在本章中，我们概念性地介绍了一些最常用的计算后验分布的方法，包括变分法和马尔可夫链蒙特卡洛方法。我们特别强调通用推断引擎，即设计用于任何给定模型（或至少广泛的模型）的方法。这些方法是任何概率编程语言的核心，因为它们允许自动推断，让用户专注于迭代模型设计和结果解释。我们还讨论了诊断样本的数值测试和视觉测试。如果不能很好地逼近后验分布，贝叶斯框架的所有优点和灵活性就会消失，因此评估推断过程的质量对于我们对推断过程本身的质量是至关重要的。</p>
</div>
<div class="section" id="id20">
<h2>练习<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h2>
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171503fc.webp" class="align-left" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171503fc.webp" />
<img alt="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071715161a.webp" class="align-left" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071715161a.webp" />
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="chapter07-GaussianProcesses.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">第 7 章 高斯过程</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="chapter09-WheretoGoNext.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">第 9 章 下一步去哪儿？</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>