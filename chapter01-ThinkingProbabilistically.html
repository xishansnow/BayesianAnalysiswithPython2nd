
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>第 1 章 概率思维 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第 2 章 概率编程" href="chapter02-ProgrammingProbabilistically.html" />
    <link rel="prev" title="封面" href="preface.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第 3 章 线性回归模型的贝叶斯视角
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型与分类任务
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter08-InterefenceEngine.html">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-VI-VIforDummies.html">
   变分推断傻瓜书
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-VI-ADVI.html">
   自动微分变分推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-MC-Integration.html">
   蒙特卡洛积分
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-MC-MCMCforDummies.html">
   MCMC采样的傻瓜书
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter01-ThinkingProbabilistically.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   1.1 统计、模型与本书途径
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     （1）与数据共舞
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     （2）贝叶斯建模
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   1.2 概率与不确定性
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     1.2.1 解释概率
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     1.2.2 定义概率
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       （1）概率分布
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       （2）独立同分布变量
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       （3）贝叶斯定理与统计推断
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   1.3 以单参数的贝叶斯推断为例
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     （1）抛硬币问题
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     （2）通用模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     （3）选择似然
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     （4）选择先验
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     （5）计算后验
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id17">
     （6）后验诊断
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     （7）先验的影响以及选择
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id19">
   1.4 报告贝叶斯分析结果
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     1.4.1 模型注释和可视化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     1.4.2 总结后验
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id22">
   1.5 后验预测检验
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id23">
   1.6 总结
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id24">
   1.7 习题
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>第 1 章 概率思维<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>归根到底，概率论不过是把常识化作计算而已。                                ——皮埃尔—西蒙•拉普拉斯</p>
</div>
<p>本章将学习贝叶斯统计中的核心概念以及一些用于贝叶斯分析的基本工具。大部分内容都是理论介绍，其中会涉及一些 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 代码，绝大多数概念会在本书其余章节中反复提到。尽管本章有点偏理论，可能会让你感到不安，但这会让你在后面应用贝叶斯统计方法解决问题时更轻松一些。</p>
<p>本章包含以下主题：</p>
<ul class="simple">
<li><p>统计模型</p></li>
<li><p>概率及不确定性</p></li>
<li><p>贝叶斯理论与统计推断</p></li>
<li><p>单参数推断以及经典抛硬币问题</p></li>
<li><p>如何选择先验</p></li>
<li><p>如何报告贝叶斯分析的结果</p></li>
</ul>
<hr class="docutils" />
<div class="section" id="id2">
<h2>1.1 统计、模型与本书途径<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>统计学主要是收集、组织、分析并解释数据，因此，统计学基础知识对数据分析至关重要。数据分析主要使用两种统计方法：</p>
<ul class="simple">
<li><p><strong>探索性数据分析（ Exploratory Data Analysis ）</strong> ：利用一些数据汇总信息辅助分析的统计方法，主要包括可视化图表、统计摘要两种手段。常见统计摘要信息有均值、众数、标准差等，此类信息也被称为描述性统计；常见可视化手段包括直方图、散点图等。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>假设我们已经有了数据集，通常做法是先探索并可视化，进而能对数据有直观的认识。可通过两步完成探索式数据分析过程：描述性统计、数据可视化。其中：描述性统计指用一些指标或统计值来定量地总结或刻画数据，例如如何用均值、众数、标准差、四分位差等指标来描述数据。数据可视化用生动形象的方式表述数据，直方图、散点图等是常见表现形式。乍一看，探索式数据分析似乎是复杂分析前做的准备工作而不是真正的分析，但它却在理解、解释、检查、总结及交流贝叶斯分析结果过程中非常有用。</p>
</div>
<ul class="simple">
<li><p><strong>推断统计（ Inferential Statistics ）</strong> ：指在当前数据之外做出陈述的统计方法。人们可能想要了解一些特定现象，或者想要对未来（尚未观测到的）数据点做出预测，或者需要对同一观测在几种相互矛盾的解释中做出决策。推断统计提供一套分丰富的方法和工具，帮助我们回答上述类型的问题。</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>有时画画图、对数据做些简单计算就够了。但另外一些时候，希望从数据中挖掘出更一般性的结论。例如：人们可能希望了解数据是怎么生成的，也可能想对未来还未观测到的数据做出预测，又或者是希望从多个对观测值的解释中找出最合理的一个，这些正是统计推断所做的事情。统计推断模型分许多种，但依赖的是概率模型，许多科学研究也都基于模型，大脑不过是对现实进行建模的一台机器。</p>
</div>
<p>本书的重点是：如何执行贝叶斯推断统计，然后使用探索性数据分析来总结、解释、检查和交换贝叶斯推断结果。</p>
<p>大多数统计学课程是作为“食谱集合”来讲授的。大致情形是这样：去 “统计” 食品屋，拿出并打开一个罐头，加些 “数据” 来品尝，搅拌直到你获得一致的 <span class="math notranslate nohighlight">\(p\)</span> 值，最好在 <code class="docutils literal notranslate"><span class="pre">0.05</span></code> 以下。此类课程主要目标是教你如何挑选罐头，而我不喜欢这种方法。</p>
<p>本书采取了一种不同方法：同样还将学习一些食谱，但不是速食罐头，而是自制食品；我们将学习如何混合适合不同美食场景的新鲜食材，以便让你理解和应用超出本书示例的大量概念。</p>
<p>采取这种方法是可能的，有两个原因：</p>
<ul class="simple">
<li><p><strong>本体论层面：</strong>
统计学是在概率论数学框架下一种统一的建模形式。使用概率方法为不同方法提供了一个统一视图，统计方法和机器学习方法在概率视角下看起来更相似。</p></li>
<li><p><strong>技术层面：</strong>
像  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>  这样的现代软件，允许实践者以相对简单的方式定义和求解模型。而就在几年前，许多模型还无法求解，或需要非常高的数学和技术复杂度。</p></li>
</ul>
<div class="section" id="id3">
<h3>（1）与数据共舞<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>数据是统计学和数据科学的重要组成部分。数据的主要来源包括：实验、计算机模拟、调查和实地观测等。如果我们是负责产生或收集数据的人，首先应当仔细考虑想要回答的问题和将使用的方法，然后才着手获取数据。事实上，有完整的统计学分支来应对数据收集工作，即所谓实验设计。在数据泛滥的时代，人们有时会忘记，收集数据并不总是便宜的。例如：虽然大型强子对撞机确实每天产生数百太字节，但它的建造需要多年体力和脑力劳动。</p>
<p>一般可以认为数据生成的过程是随机的，因为存在本体论、技术和/或认知上的不确定性。即系统本质上是随机的，存在噪声或者存在限制高精度测量的技术问题，和/或存在一些隐私限制。鉴于此，人们需要在模型的上下文对数据做出解释，包括心理模型和形式模型。<strong>数据不会说话，而是通过模型说话。</strong></p>
<p>本书将假设已经收集了数据，而且数据干净整洁，以便将注意力集中在主题上。但需要强调，虽然本书没有介绍此方面的技能，但读者应当自行学习和练习，以便成功获取和使用数据。</p>
<p>分析数据时的一项非常有用的技能是懂得如何用编程语言（如 <code class="docutils literal notranslate"><span class="pre">Python</span></code>）编写代码。考虑到我们生活在一个数据混乱的世界，处理数据通常是必要的，而编程有助于完成该任务。即使您的数据非常干净整洁，编程仍然非常有用，因为现代贝叶斯统计主要是通过 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 或 R 等编程语言完成。</p>
<p>如果想了解如何使用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 清洗和操作数据，推荐您阅读 <code class="docutils literal notranslate"><span class="pre">杰克·范德普拉斯</span></code> 的《 <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">数据科学手册</span></code> 》。</p>
</div>
<div class="section" id="id4">
<h3>（2）贝叶斯建模<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p><strong>模型是对给定系统或流程的简化描述</strong>。这些描述被故意设计成只捕获系统中最相关的方面，而不是解释每个细节。这就是为什么更复杂模型并不总是更好的原因。存在许多不同类型的模型，本书中将仅介绍贝叶斯模型。可以使用三个步骤总结贝叶斯建模过程：</p>
<p>（1）设计模型：给定一些数据以及关于数据生成的假设，通过组合以概率分布为主要内容的模块来设计一个模型。模型是粗略近似的，但通常能够满足需要。</p>
<p>（2）拟合模型：利用贝叶斯理论将数据和模型结合起来，根据数据和假设推导出逻辑结论，人们称之为经数据拟合后的模型。</p>
<p>（3）诊断模型：根据多种标准（包括真实数据和领域专业知识），判断模型拟合得是否合理。</p>
<p>当然，你会发现实际建模过程并非严格按照该顺序进行，有时可能会跳到其中任何一步，原因可能是程序编写错误，也可能是有了新的改进模型，又或者是需要增加更多数据。</p>
<p>贝叶斯模型是基于概率构建的，因此也称概率模型。为什么基于概率呢？因为概率能够很好地描述数据中的不确定性，并让我们在满是岔路的花园里不至于迷路。</p>
</div>
</div>
<div class="section" id="id5">
<h2>1.2 概率与不确定性<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>本节不想总结概率论知识体系，只介绍几个对理解贝叶斯方法非常重要的一般性概念。在本书后面部分，将根据需要适度扩展或引入与概率相关的一些概念。要详细学习概率论，建议阅读专门的书籍。推荐 <code class="docutils literal notranslate"><span class="pre">约瑟夫·K·布利茨坦（Joseph</span> <span class="pre">K</span> <span class="pre">Blitzstein）</span></code> 和 <code class="docutils literal notranslate"><span class="pre">杰西卡·黄</span> <span class="pre">（Jessica</span> <span class="pre">Hwang）</span></code> 写的《<code class="docutils literal notranslate"><span class="pre">Introduction</span> <span class="pre">to</span> <span class="pre">Probability</span></code>》。另一本是 <code class="docutils literal notranslate"><span class="pre">渡部住夫</span></code> 的《<code class="docutils literal notranslate"><span class="pre">Mathematical</span> <span class="pre">Theory</span> <span class="pre">of</span> <span class="pre">Bayesian</span> <span class="pre">Statistics</span></code>》，后者比前者更注重贝叶斯，数学方面也更重。</p>
<div class="section" id="id6">
<h3>1.2.1 解释概率<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>虽然概率论是成熟且久负盛名的数学分支，但对概率的解释不止一种。<strong>从贝叶斯角度看，概率是一种量化命题不确定性水平的度量</strong>。根据该定义，询问火星上有生命的概率、电子质量为 <span class="math notranslate nohighlight">\(9.1 \times 10^{-31}\)</span> 千克的概率或布宜诺斯艾利斯 1816 年 7 月 9 日为晴天的概率是完全有效和自然的。注意，火星上存在或不存在生命，原本是一个结果为 <code class="docutils literal notranslate"><span class="pre">是</span></code> 或 <code class="docutils literal notranslate"><span class="pre">否</span></code> 的二元问题。但考虑到不能完全确定这一事实，明智做法是找出火星上有生命的可能性有多大。</p>
<p>由于概率的贝叶斯定义与人类认知心理状态有关，所以也被称为概率的主观定义。但任何有科学头脑的人都不会仅仅用自己的想法来回答概率问题，而是会使用所有有关火星的地球物理数据、有关生命必备条件的生化知识等来推断出答案。因此，贝叶斯统计和人们拥有的任何其他成熟科学方法一样都既是主观又是客观的。</p>
<p>如果没有关于一个问题的任何信息，那么所有可能事件具有相同的可能性，这形式上等同于为每个可能的事件分配相同概率。在没有信息的情况下，不确定性是最大的。相反，如果知道某些事件更有可能发生，那么可以通过给其分配更高概率（或给其他事件分配更少的概率）来形式化表示。此外，用统计语言谈论事件时，通常并不局限于可能发生的事情，例如：小行星撞向地球或姑姑 60 岁的生日派对。事件是一个可以接受任何可能值（或值的集合）的变量，例如：30 岁以上的事件，或去年在世界各地售出的自行车数量。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>参考概率论中有关样本空间、样本点和事件的定义。样本所有可能的值构成样本空间，其中每一个可能的值为样本点，若干样本点的集合构成事件。</p>
</div>
<p>概率的概念还与逻辑学有关。在亚里士多德或古典逻辑中，只有取值为真或假的语句。在概率贝叶斯定义下，确定性只是一个特例：真陈述的概率为 1，假陈述的概率为 0。只有在有确凿数据表明某些东西正在生长、繁殖和其他生物相关活动后，才会将火星生命概率定为 1。然而，将概率指定为 0 更难，因为几乎总是可以认为：由于实验或观测的问题，导致了得出火星上没有生命该可能错误的结论。</p>
<p>与此相关的是克伦威尔规则，该规则指出：应保留使用先验概率 0 或 1 来处理逻辑上正确或错误的陈述。有趣的是，<code class="docutils literal notranslate"><span class="pre">理查德·考克斯（Richard</span> <span class="pre">Cox）</span></code>在数学上证明，如果想要将逻辑扩展到包含不确定性，必须使用概率理论。贝叶斯定理只是概率规则的一个逻辑推论。因此，<strong>贝叶斯统计的另一种思维方式是在处理不确定性时将其作为逻辑的延伸</strong>，当然这与贬义意义上的 “主观推理” 无关。</p>
<p>综上所述，用概率来模拟不确定性并不一定与自然界是“确定性”还是“随机性”的争论有关，也不一定与主观个人信念有关。这是一种纯粹用来建模不确定性的方法论。我们认识到大多数现象很难理解，因为通常不得不处理不完整和（或）有噪声的数据，而本质上人类会受到大脑限制。因此，使用了一种明确考虑不确定性的建模方法。</p>
</div>
<div class="section" id="id7">
<h3>1.2.2 定义概率<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>概率值介于 [0,1] 之间，其计算遵循一些法则，其中之一是乘法法则：</p>
<div class="math notranslate nohighlight">
\[
p(A, B)=p(A \mid B) p(B) \tag{式1.1}
\]</div>
<p>上式的读法是：<span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 同时发生的概率等于 <span class="math notranslate nohighlight">\(B\)</span> 发生的概率乘以在 <span class="math notranslate nohighlight">\(B\)</span> 发生条件下 <span class="math notranslate nohighlight">\(A\)</span> 也发生的概率。其中，<span class="math notranslate nohighlight">\(p(A,B)\)</span> 表示 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 的联合概率，指 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 同时发生的概率； <span class="math notranslate nohighlight">\(p(A|B)\)</span> 表示条件概率 ，指在知识（或证据、事件） <span class="math notranslate nohighlight">\(B\)</span> 支持下，<span class="math notranslate nohighlight">\(A\)</span> 发生的概率。二者的现实意义不同，例如：“路面是湿的” 与 “下雨时路面是湿的” 两个事件的概率截然不同，后者是典型的条件概率。</p>
<p>条件概率 <span class="math notranslate nohighlight">\(p(A|B)\)</span> 可能比原概率 <span class="math notranslate nohighlight">\(p(A)\)</span> 高，也可能低或者相等。从贝叶斯角度，条件概率可以做如下理解：</p>
<ul class="simple">
<li><p>如果事件 <span class="math notranslate nohighlight">\(B\)</span> 并不能提供任何关于事件 <span class="math notranslate nohighlight">\(A\)</span> 的信息，那么 <span class="math notranslate nohighlight">\(p(A|B)=p(A)\)</span> ，即暗示 <span class="math notranslate nohighlight">\(A\)</span> 和 <span class="math notranslate nohighlight">\(B\)</span> 是相互独立的。</p></li>
<li><p>如果事件 <span class="math notranslate nohighlight">\(B\)</span> 能够给出有关事件 <span class="math notranslate nohighlight">\(A\)</span> 的信息，那么根据信息不同，事件 <span class="math notranslate nohighlight">\(A\)</span> 可能发生的概率会变得更高或更低。</p></li>
</ul>
<p>以公平六边形骰子为例，如果我们掷骰子，得到数字 3 的可能性有多大？将是六分之一，因为六个数字中的每一个都有相同机会；假设已经知道点数是奇数，得到数字 3 的概率又是多少？是三分之一，因为唯一可能的奇数数字是 <span class="math notranslate nohighlight">\(\{1,3,5\}\)</span> ，每个数字都有相同几率；如果知道出现的是偶数，得到数字 3 的可能性又是多少呢？是零，因为如果一旦知道数字是偶数，那么可能的数字就是 <span class="math notranslate nohighlight">\(\{2,4,6\}\)</span> ，因此得到 3 是不可能的。</p>
<p>上例表明，通过观测数据的条件作用，可以有效地改变事件发生的概率，即事件的不确定性。条件概率是统计学的核心，不管你的问题是掷骰子还是制造自动驾驶汽车。</p>
<div class="section" id="id8">
<h4>（1）概率分布<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>概率分布是一个数学对象，用来描述不同事件发生的可能性有多大。通常事件以某种方式被限制在一组可能的事件中，例如：骰子的 <span class="math notranslate nohighlight">\(\{1,2,3,4,5,6\}\)</span> 。统计学中一个常见且有用的概念是：<strong>数据是从某个具有未知参数的真实概率分布中生成的</strong>。而<strong>推理是从符合真实概率分布的样本中找出这些参数值的过程</strong>。一般来说，我们无法获得真实的概率分布，因此必须想办法以某种方式创建一个具有近似分布的模型，而概率模型则是通过合理组合概率分布来建立的。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>请注意，一般来说不能确定一个模型是否正确，因此需要评估和批判模型，以便获得信心并说服他人相信模型适用于想要探索或解决的问题。</p>
</div>
<p>如果一个变量 <span class="math notranslate nohighlight">\(X\)</span> 可以用概率分布来描述，即可以称之为随机变量 <span class="math notranslate nohighlight">\(X\)</span> 。一般来说，使用大写字母（如 <span class="math notranslate nohighlight">\(X\)</span>） 来表示一个随机变量，使用大写字母粗体（如 <span class="math notranslate nohighlight">\(mathbb{X}\)</span> ）来表示一个随机向量；并用小写 <span class="math notranslate nohighlight">\(x\)</span> 表示该随机变量的一个实例（取值），使用小写粗体 <span class="math notranslate nohighlight">\(\mathbb{x}\)</span> 表示随机向量的一个实例（取值）。此外，统计学中通常用大写的 <span class="math notranslate nohighlight">\(N\)</span> 表示样本数量， 用小写的 <span class="math notranslate nohighlight">\(p\)</span> 表示随机向量的维度。</p>
<p>让我们看一个使用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 的示例：真实概率分布是均值 <span class="math notranslate nohighlight">\(\mu=0\)</span> 和方差 <span class="math notranslate nohighlight">\(\sigma=1\)</span> 的正态（或高斯）分布；这两个参数完全明确地定义了正态分布。使用 SciPy，可以通过编写 <code class="docutils literal notranslate"><span class="pre">stats.Norm(μ，σ)</span></code> 来定义随机变量，并且使用 <code class="docutils literal notranslate"><span class="pre">rvs</span></code> （random variates 的缩写）方法生成一个实例 <span class="math notranslate nohighlight">\(x\)</span> 。而下面示例中，代码要求提供三个值：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">μ</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">σ</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">μ</span><span class="p">,</span> <span class="n">σ</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p>您会注意到，每次执行此代码（统计术语为：一次试验）时，将获得不同随机结果。同时还需注意，一旦知道了概率分布参数的值，则每个值的概率就是已知的，随机发生的是每次试验中获得的确切值。</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>关于随机的含义，一个常见误解是：可以从随机变量中得到任何可能的值，或认为所有值都是等可能的。</p>
</div>
<p>随机变量的可能值及其概率是由概率分布严格控制的，随机性只是因为人们无法预测在每次试验中将要得到的确切值。每次执行前面的代码，都会得到三个不同数字，但如果重复代码数千次，将能够经验性地检查 <span class="math notranslate nohighlight">\(\mu\)</span> 的平均值是否在零附近，以及 95% 的样本值是否在 [-1.96，+1.96] 范围内。当然如果研究正态分布的数学性质，我们可以得出同样的结论。</p>
<p>统计学中表示变量随参数 <span class="math notranslate nohighlight">\(\mu,\sigma\)</span> 呈正态分布的形式为：</p>
<div class="math notranslate nohighlight">
\[
x \sim \mathcal{N}(\mu,\sigma) \tag{式1.2}
\]</div>
<p>在本书中，当看到波浪号“ <span class="math notranslate nohighlight">\(\sim\)</span> ”符号时，读为：<span class="math notranslate nohighlight">\(x\)</span> 服从 … 分布。</p>
<p>在许多文献中，常用方差而不是标准差来表示正态分布，记作 <span class="math notranslate nohighlight">\(\mathcal{N}(\mu,\sigma^2)\)</span> 。本书中，我们将使用标准差来做正态分布的参数，首先是因为它更容易解释，其次是因为  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>  是这样工作的。</p>
<p>在本书后面将遇到很多概率分布；每次出现一个概率分布，都会花一些时间来介绍它。首先从正态分布开始，因为它类似于概率分布中的宙斯。如果变量值由以下表达式规定，则变量服从高斯分布：</p>
<div class="math notranslate nohighlight">
\[
p(x \mid \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\tag{式1.3}
\]</div>
<p>这是正态分布的概率密度函数。不需要记住公式 1.3，此处只想展示给大家看，这样就能知道数字是从哪里来的。正如已经提到的，<span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 是该分布的参数，通过指定这些参数值，完全可以定义分布；可以从表达式 1.3 中看到这一点，因为其他项都是常量。<span class="math notranslate nohighlight">\(\mu\)</span> 可以取任何实值，即 <span class="math notranslate nohighlight">\(\mu \in \mathbf{R}\)</span> ，并指定分布的平均值 （以及中位数或众数）。<span class="math notranslate nohighlight">\(\sigma\)</span> 是标准差，它只能是正数，表示概率分布的散布情况，值越大分布越分散。因为 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 有无限多个可能组合，所以存在无限多个高斯分布的实例，并且所有实例都属于相同的高斯族。</p>
<p>数学公式简明扼要而且不存在二义性。但必须承认，第一次遇到它会让人害怕，特别是对数学不太感兴趣的人；打破僵局的一个好方法是使用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 来探索它们：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mu_params</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">sd_params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu_params</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">sd_params</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">sd</span> <span class="o">=</span> <span class="n">sd_params</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">([],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;μ = </span><span class="si">{:3.2f}</span><span class="se">\n</span><span class="s2">σ = </span><span class="si">{:3.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span>
                     <span class="n">sd</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;p(x)&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
</pre></div>
</div>
<p>前面大部分代码用于绘图，概率部分由 <code class="docutils literal notranslate"><span class="pre">y=stats.norm(u，sd).pdf(X)</span></code> 执行。在给定一组 <span class="math notranslate nohighlight">\(x\)</span> 值的 <span class="math notranslate nohighlight">\(µ\)</span> 和 <span class="math notranslate nohighlight">\(sd\)</span> 参数的情况下，通过这条线，可以评估正态分布的概率密度函数。前面的代码生成图 1.1。在每个子图中，我们有一条蓝色（深灰色）曲线，表示具有特定参数的高斯分布，并且包含在每个子图的图例中：</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>本书中大多数数字都是直接从它们前面的代码生成的，很多时候甚至没有将代码与数字联系起来的前导短语。使用 Jupyter 笔记本或 Jupyter Lab 的人应该熟悉这种模式。</p>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210430230432_cf.webp" style="zoom:67%;" />
<p>图1.1</p>
</center>
<p>随机变量有两种类型：连续型和离散型。连续变量可以取某个区间中的任何值（可以用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 的浮点数来表示），而离散变量只能取某些值（可以用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 的整数来表示）。正态分布是一种典型的连续变量分布。</p>
<p>请注意，前图中 <code class="docutils literal notranslate"><span class="pre">ytick</span></code> 被省略了；这是故意为之，而不是 <code class="docutils literal notranslate"><span class="pre">bug</span></code>。省略的原因是，这些值不会添加太多相关信息，但可能会让人感到困惑。解释一下：<span class="math notranslate nohighlight">\(y\)</span> 轴上的实际数字其实并不重要，重要的是它们之间的相对值。如果从 <span class="math notranslate nohighlight">\(x\)</span> 中取两个值，比方说 <span class="math notranslate nohighlight">\(x_i\)</span> 和 <span class="math notranslate nohighlight">\(x_j\)</span> ，并且有 <span class="math notranslate nohighlight">\(p(x_i)=2p(x_j)\)</span> （在曲线图中高出两倍），你可以确切地说，<span class="math notranslate nohighlight">\(x_i\)</span> 取值的概率是<span class="math notranslate nohighlight">\(x_j\)</span> 概率的两倍。在处理连续分布时，最棘手的是 <span class="math notranslate nohighlight">\(y\)</span> 轴上的值不是概率，而是概率密度。为得到一个合适的概率，你必须在给定区间内积分。也就是说，必须计算该区间曲线下方的面积。虽然概率不能大于 1，但概率密度可以，不过概率密度曲线下的总面积限制为 1。从数学角度理解概率和概率密度之间的差异是至关重要的。</p>
</div>
<div class="section" id="id9">
<h4>（2）独立同分布变量<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p>许多模型假设不同随机变量的值来自于同一分布中的抽样，但这些随机变量的取值之间彼此独立。此情况通常其为独立同分布（简称iid）变量。 相互独立在数学记数法上可表示为 <span class="math notranslate nohighlight">\(p(x,y)=p(x)p(y)\)</span> ，即对于 <span class="math notranslate nohighlight">\(x\)</span> 和 <span class="math notranslate nohighlight">\(y\)</span> 的每个值，两个变量是独立的。</p>
<p>非iid变量的常见案例是时间序列，其中随机变量间的时间依赖性是需要考虑的关键特征。例如，以下数据来自 <a class="reference external" href="http://cdiac.esd.ornl.gov">http://cdiac.esd.ornl.gov</a> 。该数据记录了从1959年到1997年的大气二氧化碳水平。加载数据并绘制它得到：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;../data/mauna_loa_CO2.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;year&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;$CO_2$ (ppmv)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;B11197_01_02.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</pre></div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210524144726a0.webp" /></p>
<p>图 1.2</p>
</center>
<p>图中每个数据点为一个变量，对应当月测得的大气二氧化碳水平，可以很容易看出每个月的测量数据之间并不独立，数据点之间存在时间依赖性。事实上，图中呈现有两种趋势：一是季节性趋势(与植被的生长和衰退周期有关)，另一种是全球趋势，表明大气中的二氧化碳浓度越来越高。</p>
</div>
<div class="section" id="id10">
<h4>（3）贝叶斯定理与统计推断<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>到目前为止，我们已经学习了一些统计学中的基本概念和词汇，接下来看看神奇的贝叶斯定理：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y)=\frac{p(y \mid \theta) p(\theta)}{p(y)}\tag{式1.4}
\]</div>
<p>看起来稀松平常，跟小学课本里的公式差不多，不过这就是关于贝叶斯统计的全部。首先看看贝叶斯定理是怎么来的。</p>
<p>根据前面提到的概率论中的乘法准则，有以下式子：</p>
<div class="math notranslate nohighlight">
\[
p(\theta, y)=p(\theta \mid y) p(y)\tag{式1.5}
\]</div>
<p>也可以写为：</p>
<div class="math notranslate nohighlight">
\[
p(\theta, y)=p(y \mid \theta) p(\theta)\tag{式1.6}
\]</div>
<p>由于以上式子的左边相等，于是可以得到：</p>
<div class="math notranslate nohighlight">
\[
p ( \theta | y ) p ( y ) = p ( y | \theta ) p ( \theta )\tag{式1.7}
\]</div>
<p>对上式调整下顺序，便得到了公式 1.4 的贝叶斯定理。</p>
<p>现在，看看该式的含义及重要性。首先，上式表明 <span class="math notranslate nohighlight">\(p(\theta|y)\)</span> 和 <span class="math notranslate nohighlight">\(p(y|\theta)\)</span> 不一定相等，日常分析中即使系统学习过统计学和概率论的人也很容易忽略这点。举个简单例子来说明为什么二者不一定相等：“有两条腿的动物就是人” 的概率和 “人有两条腿” 的概率显然不同。几乎所有人都有两条腿，但是有两条腿的动物很多不是人类，比如鸟类。</p>
<p>在贝叶斯定理中，如果将 <span class="math notranslate nohighlight">\(\theta\)</span> 理解为<strong>假设</strong>，将 <span class="math notranslate nohighlight">\(y\)</span> 理解为<strong>数据</strong>，那么贝叶斯定理告诉我们的就是，在给定数据的条件下如何计算假设成立的概率。那么如何把假设融入贝叶斯定理中去呢？答案是概率分布。换句话说，此处假设是一种狭义上的假设，我们所做的实际上是寻找模型的参数（更准确地说是参数的分布）。</p>
<p>贝叶斯定理是贝叶斯统计的核心，正如我们将在第二章中看到的那样，使用  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>  等工具进行概率编程使我们不必在每次构建贝叶斯模型时显式编写贝叶斯定理。尽管如此，知道各部分名称还是很重要得，因为我们将不断引用它们，理解每个部分的含义也很重要，因为这将帮助我们概念化模型，所以定义：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p(\theta)\)</span>：先验分布，简称（Prior）；</p></li>
<li><p><span class="math notranslate nohighlight">\(p(y|\theta)\)</span> ：似然（Likelihood）；</p></li>
<li><p><span class="math notranslate nohighlight">\(p(\theta|y)\)</span>：后验分布，简称（Posterior）；</p></li>
<li><p><span class="math notranslate nohighlight">\(p(y)\)</span>：证据或边缘似然（Marginal likelihood）。</p></li>
</ul>
<p>先验分布反映的是在观测到数据之前我们对参数的了解，如果对参数一无所知，可以用一个不包含太多信息的分布（如均匀分布）来表示。由于引入了先验，有些人会认为贝叶斯统计是偏主观的，但实际上先验不过是构建模型时得一些假设罢了，其主观性跟似然差不多。</p>
<p>似然是指如何在实验分析中引入观测数据，<strong>反映的是在给定参数下得到某组观测数据的可信度</strong>。</p>
<p>后验分布是贝叶斯分析的结果，**反映的是在给定数据和模型条件下我们对问题的全部认知。**需要注意，后验指的是模型中参数的概率分布而不是单个值，该分布正比于先验乘以似然。</p>
<p>曾经有这么个笑话：<strong>贝叶斯学派就像是这样一类人，心里隐约期待着一匹马，偶然间瞥见了一头驴，结果坚信他看到的是一头骡子</strong>。当然，如果要刻意纠正该笑话的话，在先验和似然都比较含糊的情况下，我们会得到一个（模糊的）“骡子”的后验。不过，该笑话也讲出了一个道理：后验其实是对先验和似然的某种折中。</p>
<p>从概念上讲，<strong>后验可以看做是在观测到数据之后对先验的更新</strong>。事实上，某一次分析的后验，在收集到新数据之后，也可以视为下一次分析中的先验。这使得贝叶斯分析特别适合于序列化数据分析，比如：通过实时处理来自气象站和卫星的数据提前预警灾害，感兴趣的读者可以阅读 “在线机器学习” 方面的算法。</p>
<p>最后一个概念是证据，也称作边缘似然。证据是在模型参数取遍所有可能值的条件下得到指定观测值的概率平均。不过，本书大部分内容不关心该概念，可以简单地视其为归一化系数。我们更关心参数的相对值而非绝对值。把证据这一项忽略掉之后，贝叶斯定理可以表示成如下正比形式：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) \propto p(y \mid \theta) p(\theta) \tag{式1.8}
\]</div>
<p>理解其中每个概念可能需要时间和更多例子，本书也将围绕这些内容展开。</p>
</div>
</div>
</div>
<div class="section" id="id11">
<h2>1.3 以单参数的贝叶斯推断为例<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>前面学习了几个重要概念，其中有两个是贝叶斯统计的核心概念，在此再重新强调下：</p>
<ol class="simple">
<li><p><strong>概率是用来衡量我们对参数的不确定性的。</strong></p></li>
<li><p><strong>贝叶斯定理是根据新数据正确更新这些概率的机制，有望减少不确定性。</strong></p></li>
</ol>
<p>接下来从简单例子入手，通过推断单个未知参数来学习如何进行贝叶斯统计。</p>
<div class="section" id="id12">
<h3>（1）抛硬币问题<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p>抛硬币是统计学中的经典问题，其描述如下：随机抛一枚硬币，重复一定次数，记录正面朝上和反面朝上的次数，根据数据回答诸如这枚硬币是否公平，以及更进一步这枚硬币有多不公平等问题。抛硬币是学习贝叶斯统计非常好的例子，一方面是因为几乎人人都熟悉抛硬币的过程，另一方面是因为该模型很简单，可以很容易计算并解决该问题。此外，许多真实问题都包含两个互斥的结果，例如 0 或 1、正或负、奇数或偶数、垃圾邮件或正常邮件、安全或不安全、健康或不健康等。因此，尽管我们讨论的是硬币，该模型也同样适用于前面这些问题。</p>
<p>为了用贝叶斯学派理论估计硬币的偏差，需要数据和一个概率模型。对于抛硬币问题，假设已试验了一定次数并且记录了正面朝上的次数，也就是说数据部分已具备，剩下就是模型部分了。考虑到这是第一个模型，我们会列出所有必要的数学公式，并且一步一步推导。下一章中，我们会重新回顾该问题，并借用  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>  从数值上解决它（也就是说那部分不需要手动推导，而是利用  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>  和计算机来完成）。</p>
</div>
<div class="section" id="id13">
<h3>（2）通用模型<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>首先抽象出一个概念：“偏差”。我们称，如果一枚硬币总是正面朝上，那么其偏差 1，反之，如果总是反面朝上，那么其偏差是 0，如果正面朝上和反面朝上的次数各占一半，那么其偏差是 0.5。这里用参数 <span class="math notranslate nohighlight">\(θ\)</span> 来表示偏差，用 <span class="math notranslate nohighlight">\(y\)</span> 表示 <span class="math notranslate nohighlight">\(N\)</span> 次抛硬币实验中正面朝上的次数。根据贝叶斯定理，需要指定先验 <span class="math notranslate nohighlight">\(p(\theta)\)</span> 和似然 <span class="math notranslate nohighlight">\(p(y|\theta)\)</span> 分别是什么。先从似然开始。</p>
</div>
<div class="section" id="id14">
<h3>（3）选择似然<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>假设多次抛硬币的结果之间相互没有影响，也就是说每次抛硬币都是独立的实验，同时假设结果只有两种可能：正面朝上或反面朝上。基于该假设可以看出，二项分布是不错的似然候选：</p>
<div class="math notranslate nohighlight">
\[
p(y \mid \theta, N)=\frac{N !}{y !(N-y) !} \theta^{y}(1-\theta)^{N-y} \tag{式1.9}
\]</div>
<p>二项分布是一个离散分布，表示给定某个参数值 <span class="math notranslate nohighlight">\(\theta\)</span> ， <span class="math notranslate nohighlight">\(N\)</span> 次抛硬币实验中 <span class="math notranslate nohighlight">\(y\)</span> 次正面朝上的概率（或者更通俗地描述是，<span class="math notranslate nohighlight">\(N\)</span> 次实验中，<span class="math notranslate nohighlight">\(y\)</span> 次成功的概率）。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n_params</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>  <span class="c1"># Number of trials</span>
<span class="n">p_params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>  <span class="c1"># Probability of success</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">n_params</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_params</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_params</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_params</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">p_params</span><span class="p">)):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">n_params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">p_params</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;N = </span><span class="si">{:3.2f}</span><span class="se">\n</span><span class="s2">θ =</span>
                           <span class="p">{:</span><span class="mf">3.2</span><span class="n">f</span><span class="p">}</span><span class="s2">&quot;.format(n,p), alpha=0)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;p(y | θ, N)&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505153120_1a.webp" style="zoom:67%;" />
<p>图1.2</p>
</center>
<p>二项分布是似然的一个合理选择，直观上看，<span class="math notranslate nohighlight">\(θ\)</span> 可以看作抛一次硬币时正面朝上的可能性，并且该过程发生了 <span class="math notranslate nohighlight">\(y\)</span> 次。类似地，可以把 <span class="math notranslate nohighlight">\(1−θ\)</span> 看作抛一次硬币时反面朝上的概率，并且该过程发生了 <span class="math notranslate nohighlight">\(N−y\)</span> 次。</p>
<p>假如知道了 <span class="math notranslate nohighlight">\(θ\)</span>，就可以从二项分布得出硬币正面朝上的分布。如果不知道 <span class="math notranslate nohighlight">\(θ\)</span> 也别灰心，在贝叶斯统计中，当不知道某个参数的时候，就对其赋予一个先验。</p>
</div>
<div class="section" id="id15">
<h3>（4）选择先验<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>此处选用贝叶斯统计中最常见的贝塔分布作为先验，其数学形式如下：</p>
<div class="math notranslate nohighlight">
\[
p(\theta)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta^{\alpha-1}(1-\theta)^{\beta-1} \tag{式1.10}
\]</div>
<p>仔细观察上式可看出，除 <span class="math notranslate nohighlight">\(\Gamma\)</span> 部分之外，贝塔分布和二项分布看起来很像。 <span class="math notranslate nohighlight">\(\Gamma\)</span> 表示伽马函数。现在只需知道，用分数表示的第一项是一个标准化常量，用来保证该分布的积分为 1，此外，<span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 两个参数用来控制分布形态。贝塔分布是到目前为止的第 3 个分布，利用下面的代码，可以深入了解其形态：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;α = </span><span class="si">{:2.1f}</span><span class="se">\n</span><span class="s2">β = </span><span class="si">{:2.1f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">a</span><span class="p">,</span>
                     <span class="n">b</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">f</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;p(θ)&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505153642_8f.webp" style="zoom:67%;" />
<p>图1.3</p>
</center>
<p>为什么要在模型中使用贝塔分布呢？原因之一是：贝塔分布的范围限制在 0 到 1 之间，跟我们的参数一样；另一原因是其通用性，从前图可看出，该分布有多种形状，包括均匀分布、类高斯分布、U 型分布等。第三个原因是：贝塔分布是二项分布的共轭先验。对于贝叶斯定理，似然的共轭先验是指：将该先验与似然组合在一起后，得到的后验与先验分布的表达形式是一样的。简单说，就是用贝塔分布作为先验、二项分布作为似然时，我们会得到一个贝塔分布形式的后验。</p>
<p>除贝塔分布之外还有许多其他共轭先验，例如：高斯分布的共轭先验就是高斯分布。共轭确保了后验的数学可处理性，这一点非常重要，因为贝叶斯统计学中常见的问题是很难或无法解析地计算得到后验分布。在MCMC、变分法等现代后验计算方法出现之前，共轭先验是贝叶斯统计的一项重大突破。不过从第二章概率编程开始，将主要介绍如何使用现代计算方法来解决贝叶斯问题。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>有关共轭先验的知识，参见相关文献。共轭先验是 MCMC、变分等数值推断方法出现前，解决后验概率推断问题的主要方法。</p>
</div>
</div>
<div class="section" id="id16">
<h3>（5）计算后验<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>首先回忆贝叶斯定理：后验正比于似然乘以先验。对于抛硬币问题，须将二项分布和贝塔分布相乘：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) \propto \frac{N !}{y !(N-y) !} \theta^{y}(1-\theta)^{N-y} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha) \Gamma(\beta)} \theta^{\alpha-1}(1-\theta)^{\beta-1}\tag{式1.11}
\]</div>
<p>可以简化该表达式。为了实际考虑，可以去掉所有不依赖的元素，结果仍然有效。相应地，可以写为：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) \propto \theta^{y}(1-\theta)^{N-y} \theta^{\alpha-1}(1-\theta)^{\beta-1}\tag{式1.12}
\]</div>
<p>重新整理之后得到：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) \propto \theta^{y+\alpha-1}(1-\theta)^{N-y+\beta-1}\tag{式1.13}
\]</div>
<p>如果注意会发现，上述表达式与贝塔分布具有相同的函数形式（除了归一化项），其中参数 <span class="math notranslate nohighlight">\(\alpha_{\text {posterior }}=\alpha_{\text {prior }}+y\)</span>  ， 参数 <span class="math notranslate nohighlight">\(\beta_{\text {posterior}}=\beta_{\text {prior }}+N-y\)</span> 。事实上，问题的后验分布依然是贝塔分布：</p>
<div class="math notranslate nohighlight">
\[
p(\theta \mid y) \propto \operatorname{Beta}\left(\alpha_{\text {prior }}+y, \beta_{\text {prior }}+N-y\right)\tag{式1.14}
\]</div>
</div>
<div class="section" id="id17">
<h3>（6）后验诊断<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<p>现在有了后验表达式，可以用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 对其计算并画出结果。下面代码中，其实只有一行是用来计算后验结果的，其余代码都是用来画图的：</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">n_trials</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">48</span><span class="p">]</span>
<span class="n">theta_real</span> <span class="o">=</span> <span class="mf">0.35</span>
<span class="n">beta_params</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_trials</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">a_prior</span><span class="p">,</span> <span class="n">b_prior</span><span class="p">)</span> <span class="ow">in</span> <span class="n">beta_params</span><span class="p">:</span>
        <span class="n">p_theta_given_y</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a_prior</span> <span class="o">+</span> <span class="n">y</span><span class="p">,</span> <span class="n">b_prior</span> <span class="o">+</span> <span class="n">N</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">p_theta_given_y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">theta_real</span><span class="p">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">N</span><span class="si">:</span><span class="s1">4d</span><span class="si">}</span><span class="s1"> trials</span><span class="se">\n</span><span class="si">{</span><span class="n">y</span><span class="si">:</span><span class="s1">4d</span><span class="si">}</span><span class="s1"> heads&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505154649_0f.webp" /></p>
<p>图1.4</p>
</center>
<p>在图 1.4 第一行中，实验次数为 0，因此第一个图中的曲线描绘的是先验分布，其中有 3 条曲线，每条曲线分别表示一种先验。</p>
<ul class="simple">
<li><p>蓝色的线是一个均匀分布先验，其含义是：偏差的所有可能取值是等概率的。</p></li>
<li><p>红色的线与均匀分布有点类似，其含义是：偏差等于 0 或者 1 的概率要比其他值更大一些。</p></li>
<li><p>绿色的线集中在中间值 0.5 附近，其含义是：硬币正面朝上和反面朝上的概率大致差不多。</p></li>
</ul>
<p>剩余子图描绘了后续实验的后验分布，回想一下，后验可看做在给定数据之后更新了的先验。实验次数和正面朝上的次数分别标注在每个子图中。此外每个子图中在横轴 0.35 附近还有一个黑色的竖线，表示的是真实 <span class="math notranslate nohighlight">\(θ\)</span> 。当然在真实情况下，我们并不知道该值，在此标识出来只是为了方便理解。从这幅图中可以学到很多贝叶斯分析方面的知识：</p>
<ol class="simple">
<li><p>贝叶斯分析的结果是后验分布而不是某个值，该分布描述了根据给定数据和模型得到的不同数值的可能性。</p></li>
<li><p>后验最可能的值是根据后验分布的形态决定的，也就是后验分布的峰值。</p></li>
<li><p>后验分布的分散程度与我们对参数的不确定性相关；分布越分散，说明不确定性越大。尽管 1/2 = 4/8 = 0.5，但由图可知，前者不确定性要大于后者。因为我们有了更多数据来支撑推断，该直觉也同时反映在后验分布上。</p></li>
<li><p>在给定足够多数据时，两个或多个不同先验的贝叶斯模型会趋近于收敛到相同的后验结果。极限情况下，如果有无限多数据，不论使用什么样的先验，最终都会得到相同后验。注意：此处无限多是指某种程度而非某个具体数量，也就是说，从实际使用角度，某些情况下无限多数据可以通过比较少量的数据近似。</p></li>
<li><p>不同后验收敛到相同分布的速度取决于数据和模型。从图中可看出，蓝色和红色的后验在经过 8 次实验后就很难看出区别了，而红色曲线则一直到 150 次实验之后才与另外两个后验看起来比较接近。</p></li>
<li><p>有一点从图中不太容易看出来：如果一步一步地更新后验，最后得到的结果跟一次性计算得到的结果是一样的。换句话说，可以对后验分 150 次计算，每次增加一个新的观测数据并将得到的后验作为下一次计算的先验，也可以在得到 150 次抛硬币的结果之后一次性计算出后验，而这两种计算方式得到的结果完全一样。该特点非常有意义，当我们获得新数据时，这会导致我们以一种自然的方式更新估计，这种情况在许多数据分析问题中都很常见。</p></li>
</ol>
</div>
<div class="section" id="id18">
<h3>（7）先验的影响以及选择<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>从前例可清楚地看出，先验可以影响推断。贝叶斯分析的新手或批评者通常对如何选择先验感到不适，因为他们不想让先验充当一个不让数据说话的审查员！这样的想法没有错，但必须记住，数据并不能真正说话，只有在模型（包括数学模型和心理模型）的上下文中，数据才有意义。在科学史上，同样的数据导致人们对相同主题有不同思考的例子很多，即使你的观点建立在正式模型上，这种情况也可能发生。</p>
<p>有些人青睐于使用没有信息量的先验（也称作均匀的、含糊的或者发散的先验）。此类先验对分析过程的影响最小。本书将遵循 Gelman、McElreath 和 Kruschke 三人的建议，倾向于使用带有较弱信息量的先验。在许多问题中，我们对参数可取的值一般都会有些了解（比如，参数只能是正数，或者知道参数近似的取值范围，又或是希望该值接近 0 或大于/小于某值）。此情况下，可以给模型加入一些微弱的先验信息而不必担心该先验会掩盖数据本身的信息。由于此类先验会让后验近似位于某一合理边界内，因此也被称作<strong>正则化先验</strong>。</p>
<p>当然，使用带有较多信息量的强先验也是可以的。根据问题不同，有可能很容易或者很难找到此类先验。例如在作者工作的领域（结构生物信息学）中，人们会尽可能地利用先验信息，通过贝叶斯或者非贝叶斯方式来了解和预测蛋白质的结构。如此做是合理的，因为我们是在数十年间从上千次精心设计的实验中收集的数据，因而有大量可供使用的可信先验信息。如果你有可信的先验信息，没有理由不去使用。试想下，如果汽车工程师每次设计新车时，都要重新发明内燃机、轮子乃至整个汽车，显然不是正确的打开方式。</p>
<p>现在知道了先验有许多种，但缓解不了我们选择先验时的焦虑。或许，最好是没有先验，这样事情就简单了。但不论是否基于贝叶斯，模型都在某种程度上拥有先验，即使先验并没有明确表示出来。事实上，许多频率统计学方面的结果可以看做是贝叶斯模型在一定条件下的特例（常见如均匀先验）。仔细看看前面那幅图，可以看到蓝色后验分布的峰值与频率学派分析中 <span class="math notranslate nohighlight">\(θ\)</span> 的期望值是一致的（此处暗示最大后验估计和最大似然估计在某种先验假设下，得到等价的结果）：</p>
<div class="math notranslate nohighlight">
\[
\hat \theta = \frac { y } { N }\tag{式1.15}
\]</div>
<p>注意，此处 <span class="math notranslate nohighlight">\(\hat \theta\)</span>是点估计而非后验分布。由此看出，很难完全避免先验，但明确在分析中引入先验，会得到概率分布而不只是最可能的单个值。</p>
<p>明确引入先验的另一个好处是，我们会得到更透明的模型（此处可理解为可解释性）。这意味着更容易评判、调试以及优化。构建模型是一个循序渐进的过程，有时可能只需几分钟，有时候则需要数年；有时候整个过程可能只有你自己参与，有时候则可能包含你不认识的人。而且模型的可复现性很重要，而模型中透明的假设能有助于复现。</p>
<p>在特定分析任务中，如果对某个先验或者似然不确定，可以自由使用多个先验或者似然进行尝试。模型构建过程中的一个环节就是质疑假设，而先验就是被质疑的对象之一。不同的假设会得到不同的模型，根据数据和专业领域知识，可以对多个模型进行比较以期得到相对最好的模型，本书第 5 章模型比较部分会深入讨论该内容。</p>
<p>先验是贝叶斯统计中的核心内容之一，如果在这里你感到疑惑，也不用太担心，因为在后面遇到新问题时，我们还会反复讨论它。而且要知道人们在该问题上已经困惑了数十年并且相关的讨论一直在继续。</p>
</div>
</div>
<div class="section" id="id19">
<h2>1.4 报告贝叶斯分析结果<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h2>
<p>创建报告和交流结果是统计和数据科学实践的核心。本节将简要讨论使用贝叶斯模型时的一些特点。在接下来章节中，我们将继续看有关这一重要问题的例子。</p>
<div class="section" id="id20">
<h3>1.4.1 模型注释和可视化<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>根据受众不同，你可能在交流分析结果同时还需要交流模型。以下是一种简单表示概率模型的常见方式：</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\theta &amp;\sim \operatorname{Beta}(\alpha, \beta) \notag \\
y &amp;\sim \operatorname{Bin}(n=1, p=\theta) \tag{式1.16}
\end{align*}\]</div>
<p>这是抛硬币例子用到的模型。符号～表示左边随机变量服从右边的分布形式，也就是说，这里 <span class="math notranslate nohighlight">\(θ\)</span> 服从于参数为 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 的贝塔分布，而 <span class="math notranslate nohighlight">\(y\)</span> 服从于参数为 <span class="math notranslate nohighlight">\(n=1\)</span> 和 <span class="math notranslate nohighlight">\(p=θ\)</span> 的二项分布。该模型还可以用类似 Kruschke 书中的图表示成如下形式：</p>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505155942_31.webp" style="zoom:67%;" />
<p>图1.5</p>
</center>
<p>第一层根据先验生成了 <span class="math notranslate nohighlight">\(θ\)</span> ，然后通过似然生成最下面的数据 <span class="math notranslate nohighlight">\(y\)</span> 。图中箭头表示变量间的依赖关系，符号～表示变量的随机性。</p>
</div>
<div class="section" id="id21">
<h3>1.4.2 总结后验<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>贝叶斯分析的结果是后验分布，该分布包含了有关参数在给定数据和模型下的所有信息。如果可能的话，只需要将后验分布展示给观众即可。但通常还有一个不错的做法：同时给出后验分布的一些统计量。例如：给出后验的均值（或者众数、中位数）统计量，以让大家了解后验分布的中心位置；或给出其他描述分布特点的衡量指标，如标准差，以让大家对后验的离散程度和不确定性有大致了解。</p>
<p>不过用标准差衡量类似正态分布的后验比较合适，但对一些其他类型的分布（如偏态分布）可能会得出误导性结论，因此，还可以采用 <code class="docutils literal notranslate"><span class="pre">最大后验密度（Highest</span> <span class="pre">Posterior</span> <span class="pre">Density，HPD）区间</span></code> 做衡量。</p>
<p>一个 HPD 区间是指包含一定比例概率密度的最小区间，常见的比例包括 <code class="docutils literal notranslate"><span class="pre">95%HPD</span></code> 或 <code class="docutils literal notranslate"><span class="pre">50%HPD</span></code> 等。如果说某个分析的 <code class="docutils literal notranslate"><span class="pre">95%HPD区间</span></code> 是 [2,5]，其含义一般是指：根据模型和数据，模型参数位于 2～5 的概率是 0.95。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>这是一个非常直观的解释，以至于人们经常会将频率学派中的置信区间与贝叶斯方法中的可信区间弄混淆。如果你对频率学派比较熟悉，请注意这两种区间的区别。贝叶斯学派告诉我们的是 “参数取值区间的概率” ，这在频率学派的框架中是不可能的，因为频率学派中的参数是确切值，频率学派的置信区间只包含参数的确切取值。在继续深入前需要注意：选择 <code class="docutils literal notranslate"><span class="pre">95%</span></code> 还是 <code class="docutils literal notranslate"><span class="pre">50%</span></code> 作为 <code class="docutils literal notranslate"><span class="pre">HPD区间</span></code> 的概率密度比例没有什么特殊的地方，只不过是经常使用或约定俗成的值罢了。 其实完全可以选用比例为 <code class="docutils literal notranslate"><span class="pre">91.37%</span></code> 的 <code class="docutils literal notranslate"><span class="pre">HPD区间</span></code>。如果你选的是 <code class="docutils literal notranslate"><span class="pre">95%</span></code> 也完全没问题，究竟选择多大比例需要具体问题具体分析。</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 包，用于贝叶斯模型的探索性数据分析。<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 有许多函数可以帮助我们总结后验结果，例如，az.plot_posterior 可以用来生成具有分布平均值和 HPD 的曲线图。在下例中，我们从贝塔分布生成随机样本，而不是真实分析的后验结果。注意图中报告的 <code class="docutils literal notranslate"><span class="pre">HPD区间</span></code> 为 <code class="docutils literal notranslate"><span class="pre">94%</span></code> 。<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 每次计算和报告 HPD 时，默认情况下使用 0.94（对应于 <code class="docutils literal notranslate"><span class="pre">94%</span> <span class="pre">HPD区间</span></code> )。可通过向 trusted_interval 参数传递值来更改此设置。</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">({</span><span class="s1">&#39;θ&#39;</span><span class="p">:</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)})</span>
</pre></div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505160529_37.webp" style="zoom:67%;" />
<p>图1.6</p>
</center>
</div>
</div>
<div class="section" id="id22">
<h2>1.5 后验预测检验<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h2>
<p>获取特定模型的后验分布后，可以用来模拟生成基于该分布的新数据。这有助于评估模型是否提供了有效预测，以对未来事件进行推断。这些模拟可用于多种目的，其中之一就是：通过对比观测数据和模拟数据的核密度估计值，来检验模拟数据是否类似于观测数据。在评估模型是否与数据生成机制有较好拟合时，需要更正式的后验预测检验方法。任何依赖于参数的统计或差异都可用于后验预测检验。这与先验预测检验的使用方式类似，但在对比观测数据和模拟数据时要更加严苛。</p>
<p>###（1） 后验预测性分布</p>
<p>贝叶斯方法的一个优势是：一旦得到了后验分布 <span class="math notranslate nohighlight">\(p(\theta|y)\)</span> ，就可根据该后验生成未来的数据 <span class="math notranslate nohighlight">\(\hat y\)</span> ，即用来做预测。而后验预测性分布是条件预测相对于后验分布的平均值。</p>
<div class="math notranslate nohighlight">
\[
p(\hat{y} \mid y)=\int p(\hat{y} \mid \theta) p(\theta \mid y) d \theta \tag{式1.17}
\]</div>
<p>从概念和计算上，我们将此积分 1.17 近似为迭代的两步过程：</p>
<ul class="simple">
<li><p>第一步，从后验 <span class="math notranslate nohighlight">\(p(\theta|y)\)</span>  取样 <span class="math notranslate nohighlight">\(\theta\)</span> 值；</p></li>
<li><p>第二步，将 <span class="math notranslate nohighlight">\(\theta\)</span> 值馈给似然，获得一个数据点 <span class="math notranslate nohighlight">\(\hat y\)</span> 。</p></li>
</ul>
<p>请注意该过程如何组合两个不确定性来源：参数不确定性（由后验捕获）；以及采样不确定性（由似然捕获）。</p>
<p>###（2）后验预测检验</p>
<p>当需要进行预测时，可以根据上面两个过程获得预测。当然，也可以用其来比较观测数据和预测数据，进而对模型做出评判，以找出两组数据间的差异，此即为后验预测检验，检验的主要目标是两者的一致性。</p>
<p>生成数据和观测数据应该看起来差不多，否则有可能是建模出了问题或者输入数据到模型时出了问题。不过就算没有出错，两个集合仍然可能出现不同。尝试去理解其中的偏差有助于改进模型，或者至少能知道模型的极限。</p>
<p>即使不知道如何改进模型，能够理解模型或数据捕获（或未捕获）的问题也非常有价值。模型也许能够捕获到均值但无法预测异常值，这或许是个问题，但当我们只关心均值时，模型还是可用的。</p>
<p>换句话说，通常贝叶斯统计分析的总体目标不是宣布某个模型是错误的，而是想了解模型哪一部分是可信任的，并尝试检验该模型是否适合特定目的。一个人对一个模型有多大信心，在不同学科间肯定不一样。物理学可以使用高级理论在高度受控条件下研究系统，因此模型通常被视为对现实的很好描述；而其他学科研究复杂的、难以孤立的系统时，模型常具有较弱认识论地位。尽管如此，无论从事哪个学科，都应始终对模型做检验，后验预测性检查和探索性数据分析的想法是检验模型的好方法。</p>
</div>
<div class="section" id="id23">
<h2>1.6 总结<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h2>
<p>我们的贝叶斯之旅首先围绕统计建模、概率论和贝叶斯定理做了一些简短讨论，然后用抛硬币的例子介绍了贝叶斯建模和数据分析，借用该经典例子传达了贝叶斯统计中的一些重要思想，比如用概率分布构建模型并用概率分布表示不确定性。此外我们尝试揭示了如何选择先验，并将其与数据分析中的一些其他问题置于同等地位（怎么选择似然，为什么要解决该问题等）。本章最后讨论了如何解释和报告贝叶斯分析的结果。我们对贝叶斯分析的一些主要方面做了简要总结，后面还会重新回顾这些内容，从而充分理解和吸收，并为后面理解更高级的内容打下基础。</p>
<p>下图以渡边住友的工作流程为基础，总结本章所述的贝叶斯工作流程：</p>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505163234_92.webp" style="zoom:67%;" />
<p>图1.7</p>
</center>
<p>我们假设存在一个总体未知的真分布，从该分布中可以通过实验、调查、观察或模拟获得有限样本。为了从真分布中学到一些东西，假设我们只观察到一个样本，建立了一个概率模型。概率模型由两个部分组成：先验和似然。我们使用模型和样本进行贝叶斯推断，得到一个后验分布；该分布封装了给定模型和数据的所有关于问题的信息。从贝叶斯的角度来看，后验分布是主要感兴趣的对象，其他一切都是从它衍生出来的，包括后验预测分布形式的预测。由于后验分布（以及由此得出的任何其他量）是模型和数据的结果，因此贝叶斯推断的有用性受到模型和数据质量的限制。评估模型的一种方法是将后验预测分布与之前获得的有限样本进行比较。请注意，后验分布是模型中参数的分布（以观测样本为条件），而后验预测分布是预测样本的分布（在后验分布上平均）。模型验证过程至关重要，不是因为想要确保拥有正确模型，而是因为我们知道几乎从来没有正确的模型。我们检查模型以评估它们在特定上下文中是否足够有用，如果不是，则深入了解如何改进它们。</p>
<p>在本章中，我们简要总结了进行贝叶斯数据分析的主要方面。在本书的其余部分，我们将重新审视这些想法，以便真正吸收它们，并将它们用作更高级概念的脚手架。在下一章中，我们将介绍  <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> ，这是一个用于贝叶斯建模和概率机器学习的 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，以及 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code>，它是一个用于贝叶斯模型探索性分析的 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库。</p>
</div>
<div class="section" id="id24">
<h2>1.7 习题<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<p>我们尚不清楚大脑是如何运作的，是按照贝叶斯方式？还是类似贝叶斯的某种方式？又或许是进化过程中形成的某种启发式的方式？不管如何，我们至少知道自己是通过数据、例子和练习来学习的，尽管你可能对此有不同的意见，不过我仍然强烈建议你完成以下练习。</p>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505165349_d4.webp" />
<img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505165408_07.webp" /></p>
</center>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="preface.html" title="previous page">封面</a>
    <a class='right-next' id="next-link" href="chapter02-ProgrammingProbabilistically.html" title="next page">第 2 章 概率编程</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>