# 第2章　概率编程

上一章对贝叶斯统计有了基本了解，本章将学习如何使用计算工具构建概率模型。我们将学习使用 PyMC3 进行概率编程。其基本思想是使用代码指定模型，然后以或多或少自动的方式求解它们。选择编程的背后原因是：许多模型无法得到闭合的解析解，因此只能使用数值方法来求解。

学习概率编程的另一个原因是，现代贝叶斯统计主要是通过编写代码来完成的，既然已经了解 Python，为什么还要用另一种方式呢？概率编程提供了一种构建和求解复杂模型的有效方法，使我们可以更多地关注模型设计、评估和解释，而更少地关注数学或计算细节。在本章以及本书的其余部分中，我们将使用 PyMC3 和 ArviZ ，PyMC3 是一个非常灵活的概率编程 Python 库，ArviZ 是一个新的 Python 库，它将帮助我们解释概率模型的结果。了解 PyMC3 和 ArviZ 还将帮助我们以更实际的方式学习先进的贝叶斯概念。

本章涵盖以下主题：

- 概率编程；
- 推断引擎；
- PyMC3 指南；
- 重温抛硬币问题；
- 模型检查和诊断；
- 高斯模型和学生$t$模型；
- 分组比较和有效容量；
- 分层模型和收缩。



## 2.1　概率编程

贝叶斯统计在概念上非常简单：我们有已知和未知的量；我们使用贝叶斯定理将后者以前者为条件。如果我们幸运的话，这个过程将减少未知量的不确定性。通常，我们把已知量称为**数据**并将其视为常数，将未知量称为参数并将其视为概率分布。在更正式的术语中，我们给未知量分配先验概率分布；然后利用贝叶斯定理将其先验概率分布转化为后验分布。尽管概念简单，但全概率公式常常导致难以解析的表达式。多年来，该问题是阻碍贝叶斯方法广泛采用的主要原因之一。

随着计算时代的到来，数值方法使得解决任何推理问题成为可能。这极大改变了贝叶斯数据分析的应用。我们可以把这些数值方法看作通用推理引擎，或者 PyMC3 核心开发者 <u>Thomas Wiecki</u> 所称呼的推理按钮。自动化推理过程的可能性导致了**概率编程语言（PPL）**的发展，它允许模型创建和推理之间的明确分离。

随着计算时代的到来，数值化方法的发展使得计算几乎任意模型的后验成为了可能，这极大地促进了贝叶斯方法的应用。我们可以把这些数值化方法当作通用引擎，按照PyMC3的核心开发者之一ThomasWiecki的说法，只需要按下按钮，推断部分就可以自动完成了。

自动化推断促进了概率编程语言的发展，从而使得模型构建和推断相分离。在概率编程语言的框架中，用户只需要寥寥数行代码描述概率模型，后面的推断过程就能自动完成了。概率编程使得人们能够更快速地构建复杂的概率模型并减少出错的可能，可以预见，这将给数据科学和其他学科带来极大的影响。

我认为，编程语言对科学计算的影响可以与60多年前Fortran语言



59 



的问世相对比。尽管如今Fortran语言风光不再，不过在当时Fortran语言被认为是相当革命性的。科学家们第一次从计算的细节中解放出
来，开始用一种更自然的方式关注构建数值化的方法、模型和仿真系统。类似地，概率编程将处理概率和推断的过程对用户隐藏起来，从而使得用户更多的去关注模型构建和结果分析。
2.1.1　推断引擎
即便某些情况下不太可能从分析的角度得到后验，我们也有办法将后验计算出来，其中一些方法列举如下。

（1）非马尔科夫方法：

网格计算；二次近似；变分方法。

（2）马尔科夫方法：

Metropolis-Hastings算法；
汉密尔顿蒙特卡洛方法（HamiltonianMonteCarlo）/不掉向采样（NoU-TurnSampler，NUTS）。

如今，贝叶斯分析主要是通过马尔科夫链蒙特卡洛（Markov
ChainMonteCarlo，MCMC）方法进行，同时变分方法也越来越流
行，特别是在一些较大的数据集上。学习贝叶斯分析并不需要完全掌握这些方法，不过从概念层面上对它们的工作原理有一定了解会很有帮助，比如调试模型。

非马尔科夫方法


60 



我们首先讨论基于非马尔科夫方法的推断引擎。非马尔科夫方法在低维的问题上要比马尔科夫方法更快，对于某些问题，这类方法非常有用，而对另外一些问题，这类方法只能提供真实后验的粗略近
似，不过没关系，它们可以为马尔科夫方法提供一个不错的初始点，后面我们会介绍马尔科夫的含义。


1．网格计算


网格计算是一种暴力穷举的方法。即便你无法计算出整个后验，你也可以根据一些点计算出先验和似然。假设我们要计算某个单参数模型的后验，网格近似可以按照如下方式进行：

确定参数的一个合理区间（先验会给你点提示）；在以上区间确定一些网格点（通常是等距离的）；对于网格中的每个点计算先验和似然。

视情况，我们可能会对计算结果进行归一化（把每个点的计算结果除以所有点的计算结果之和）。

很容易看出，选的点越多（网格越密）近似的结果就越好。事实上，如果使用无限多的点，我们可以得到准确的后验。网格计算的方法不能很好地适用于多参数（又或者称多维度）的场景，随着参数的增加，采样空间相比后验空间会急剧增加，换言之，我们花费了大量时间计算后验值，但对于估计后验却几乎没有帮助，因而使得该方法对于大多数统计学和数据科学的问题都不太实用[1]。

下面的代码用网格计算的方法解决第一章中的抛硬币问题：

defposterior_grid(grid_points=100,heads=6,tosses=9):

61 



    """
    Agridimplementationforthecoin-flipproblem
    """
    grid=np.linspace(0,1,grid_points)
    prior=np.repeat(5,grid_points)
    likelihood=stats.binom.pmf(heads,tosses,grid)
    unstd_posterior=likelihood*prior
    posterior=unstd_posterior/unstd_posterior.sum()returngrid,posterior

假设4次抛硬币实验中只有一次观测到正面朝上，那么就有：

points=15
h,n=1,4
grid,posterior=posterior_grid(points,h,n)
plt.plot(grid,posterior,'o-',label='heads={}\ntosses={}'.format(h,n))
plt.xlabel(r'$\theta$')
plt.legend(loc=0)



















2．二次近似


二次近似，也称拉普拉斯方法或者正态近似，利用的是高斯分
布来近似后验。该方法通常很有效，原因是后验分布众数附近的区域
通常是服从正态分布的，事实上很多情况下就是高斯分布。二次近似


62 



的计算过程分为两步。首先，找出后验分布的峰值，该值可以通过一些最优化算法得到（有许多开箱即用的算法用来求解函数的最大值或最小值），这样我们得到了用来近似的高斯分布的均值；然后估计函数在众数附近的曲率，根据该曲率可以得出近似高斯分布的标准差。在介绍完PyMC3之后，我们会讲解如何使用该方法。


3．变分方法


现代的贝叶斯统计学大多都采用马尔科夫方法（下一节会介
绍），不过该方法对某些问题求解很慢而且不能很好地并行计算。一种简单的做法是同时运行多个马尔科夫链，然后将结果合并，不过对大多数问题而言这并不是一个合适的解决方案，如何找到有效的并行
计算方式是当前的一个研究热点。

对于较大的数据集或是某些计算量很大的似然而言，变分方法是一个更好的选择。此外，这类方法能快速得到后验的近似，为
MCMC方法提供初始点。

变分方法的基本思想是用一个更简单的分布去近似后验，这听起来有点像拉普拉斯近似，不过深入细节你会发现二者有很大不同。变分方法的最大缺点是我们必须对每个模型设计一个特定的算法，因而变分方法并不是一个通用的推断引擎，而是与模型相关的。

当然，许多人都在尝试将变分方法自动化。最近提出的一个方法是自动差分变分推断（AutomaticDifferentiationVariational
Inference，ADVI）（查看http://arxiv.org/abs/1603.00788了解更多）。从概念层面上讲，ADVI是按下面步骤工作的。



63 



（1）对参数进行变换从而使得它们位于整个实轴上。例如，假设一个参数限定为正数，对其求log后得到的值位于无界区间
内。

（2）用高斯分布对无界参数近似。需要注意，转换后参数空间里的高斯分布在原来参数空间内是非高斯的，这也是与拉普拉斯近似
方法的不同点。

（3）采用某种优化算法使得高斯近似的结果尽可能接近后验，该过程通过最大化证据下界（EvidenceLowerBound，ELBO）实现。如何衡量两个分布的相似性以及证据下界的具体含义都是一些数学细节。

ADVI算法已经在PyMC3中实现了，本书后面会使用到。
马尔科夫方法

有许多相关的方法都称MCMC方法。对于网格计算近似方法而
言，我们需要根据给定的点计算出似然和先验，并且近似出整个后验
分布。MCMC方法要比网格近似更好，这是因为其设计思想是将更
多的时间用于高概率区域的计算，而在较低概率区间花费较少时间。事实上，MCMC方法会根据相对概率访问参数空间中的不同区间。
如果区间A的概率是区间B的两倍，那么我们从区间A采样的次数可能是从区间B采样次数的两倍。因此，即使我们无法从分析的角度得到整个后验，我们也可以采用MCMC的方法从中采样，并且采样数越
多，效果越好。

要理解MCMC方法，我们先将其拆分成两个MC部分，即蒙特卡洛部分和马尔科夫链部分。



64 



1．蒙特卡洛


蒙特卡洛这部分可以用随机数的应用来解释。蒙特卡洛方法是一系列应用非常广泛的算法，其思想是通过随机采样来计算或模拟给定过程。蒙特卡洛是位于摩纳哥公国的一个非常有名的城市，蒙特卡洛方法的开发者之一是StanislawUlam。Stan正是基于这一核心思想
——尽管很多问题都难以求解甚至无法准确用公式表达，但我们可以通过采样或者模拟来有效地研究。据传，起因是为了计算单轮游戏中的概率，解决该问题的方法之一是组合分析法；另一种是Stan声称
的，进行多次单轮游戏，最后计算其中有多少次是我们感兴趣的。这听起来似乎是显而易见的，或者至少是相当合理的，比如，你可能已经用重采样的方法来解决统计问题。不过这个实验是早在70年前进行的，当时，第一台计算机才刚开始研发。该方法首次应用于一个核物理问题。如今，个人计算机都已经足够强大，用蒙特卡洛方法可以解决许多有趣的问题，因此，该方法也被广泛应用到科学、工程、工业以及艺术等各个方面。

在使用蒙特卡洛方法计算数值的例子中，一个教科书上非常经典的是估计π。实际使用中有更好的方法来计算π，不过这个例子仍然具有教学意义。我们可以通过以下过程估计π：

（1）在边长为2R的正方形内随机撒N个点。

（2）在正方形内画一个半径为R的圆，计算在圆内的点的个
数。


（3）得出的估计值	。




65 



需要注意：如果一个点满足以下条件，我们认为该点位于圆内：



正方形的面积是(2R)2，圆的面积是πR2，因此二者的面积之比是4/π，而圆和正方形的面积分别正比于圆内的点的个数和总的点数N。
我们可以通过几行简单的代码来模拟该蒙特卡洛过程计算π值，同时计算出估计值与实际值之间的相对误差：

N=10000

x,y=np.random.uniform(-1,1,size=(2,N))inside=(x**2+y**2)　<=1
pi=inside.sum()*4/N
error=abs((pi-np.pi)/pi)*100
outside=np.invert(inside)
plt.plot(x[inside],y[inside],'b.')
plt.plot(x[outside],y[outside],'r.')
plt.plot(0,0,label='$\hat\pi$={:4.3f}\nerror={:4.3f}%'.format(pi,error),alpha=0)
plt.axis('square')
plt.legend(frameon=True,framealpha=0.9,fontsize=16);






















66 




上面的代码中，outside是用来绘图的，在计算	的过
程中没有用到。另外一点需要澄清的是，由于这里用的是单位圆，因此在判断一个点是否在圆内时没有计算平方根。


2．马尔科夫链


马尔科夫链是一个数学对象，包含一系列状态以及状态之间的转移概率，如果每个状态转移到其他状态的概率只与当前状态相关，那么这个状态链就称为马尔科夫链。有这样一个马尔科夫链之后，我们可以任取一个初始点，然后根据状态转移概率进行随机游走。假设能够找到这样一个马尔科夫链，其状态转移概率正比于我们想要采样的分布（如贝叶斯分析中的后验分布），采样过程就变成了简单地在该状态链上移动的过程。那么，如何在不知道后验分布的情况下找到这样的状态链呢？有一个概念叫做细节平衡条件（DetailedBalance
Condition），直观上讲，这个条件是说，我们需要采用一种可逆的方式移动（可逆过程是物理学中的一个常见的近似）。也就是说，从状态i转移到状态j的概率必须和状态j转移到状态i的概率相等。

总的来说就是，如果我们能够找到满足细节平衡条件的马尔科夫链，就可以保证从中采样得到的样本来自正确的分布。保证细节平衡的最流行的算法是Metropolis-Hasting算法。


3．Metropolis-Hasting算法


为了更形象地理解这个算法，我们用下面这个例子来类比。假设
我们想知道某个湖的水容量以及这个湖中最深的点，湖水很浑浊以至


67 



于没法通过肉眼来估计深度，而且这个湖相当大，网格近似法显然不是个好办法。为了找到一个采样策略，我们请来了两个好朋友小马和小萌。经过讨论之后想出了如下办法，我们需要一个船（当然，也可以是竹筏）和一个很长的棍子，这比声呐可便宜多了，而且我们已经把有限的钱都花在了船上。

（1）随机选一个点，然后将船开过去。

（2）用棍子测量湖的深度。

（3）将船移到另一个地点并重新测量。

（4）按如下方式比较两点的测量结果。

如果新的地点比旧的地点水位深，那么在笔记本上记录下新的测量值并重复过程（2）。
如果新的地点比旧的地点水位浅，那么我们有两个选择：接受或者拒绝。接受意味着记录下新的测量值并重复过程（2）；拒绝意味着重新回到上一个点，再次记录下上一个点的测量值。

如何决定接受还是拒绝新的测量值呢？这里的一个技巧便是使用Metropolis-Hastings准则，即接受新的测量值的概率正比于新旧两点的测量值之比。

按照以上过程迭代下去，我们不仅可以得到整个湖的水容量和最深的点，而且可以得到整个湖底的近似曲率。你也许已经猜到了，在这个类比中，湖底的曲率其实就是后验的分布，而最深的点就是后验的众数。根据小马的说法，迭代的次数越多，近似的效果越好。

事实上，理论保证了在这种情形下，如果我们能采样无数次，最


68 



终能得到完整的后验。幸运地是，实际上对于很多问题而言，我们只需要相对较少地采样就可以得到一个相当准确的近似。

现在让我们从更正式的角度来看看该算法。对于很多分布而言
（如高斯分布），我们有相当高效的算法对其采样，但对于一些其他
分布，情况就变了。Metropolis-Hastings算法使得我们能够从任意分
布中以概率p(x)得到采样值，只要我们能算出某个与p(x)成比例的
值。这一点很有用，因为在类似贝叶斯统计的许多问题中，最难的部分是计算归一化因子，也就是贝叶斯定理中的分母。Metropolis-
Hastings算法的步骤如下。
（1）给参数xi赋一个初始值，通常是随机初始化或者使用某些
经验值。

（2）从某个简单的分布	中选一个新的值，如高斯分布或者均匀分布。这一步可以看做是对状态的扰动。

（3）根据Metropolis-Hastings准则计算接受一个新的参数值的概
率：




（4）从位于区间[0,1]内的均匀分布中随机选一个值，如果第
（3）步中得到的概率值比该值大，那么就接受新的值，否则仍保持
原来的值。

（5）回到第（2）步重新迭代，直到我们有足够多的样本，稍后会解释什么叫足够多。

有几点需要注意。


69 


如果选取的分布	是对称的，那么可以得到
，这通常称为Metropolis准则。

步骤（3）和步骤（4）表明：我们总是会转移到一个比当前状态（或参数）概率更大的状态（或参数），对于概率更小的，则会以xi+1与xi之比的概率接受。该准则中的接受步骤使得采样过程
相比网格近似方法更高效，同时保证了采样的准确性。

目标分布（贝叶斯统计中的后验分布）是通过记录下来的采样值
来近似的。如果我们接受转移到新的状态xi+1，那么我们就记录
该采样值xi+1。如果我们拒绝转移到xi+1，那么我们就记录xi。
最后，我们会得到一连串记录值，有时候也称采样链或者迹。如果一切都正常进行，那么这些采样值就是后验的近似。在采样链中出现次数最多的值就是对应后验中最可能的值。该过程的一个优点是：后验分析很简单，我们把对后验求积分的过程转化成了对采样链所构成的向量求和的过程。

下面的代码展示了Metropolis算法的一个基本实现。这段代码并
不是为了解决什么实际问题，只是在这里用来演示，如果我们知道怎
么计算给定点的函数值，我们就可能得到该函数的采样。需要注意下面的代码中不包含贝叶斯相关的部分，既没有先验也没有数据。要知道，MCMC是一类能够用于解决很多问题的通用方法。例如，在一
个（非贝叶斯的）分子模型中，我们可能需要一个函数来计算在某个状态x下系统的能量而不是简单地调用func.pdf(x)函数。

metropolis函数的第一个参数是一个SciPy的分布，假设我们不
知道如何从中直接采样。



70 



defmetropolis(func,steps=10000):
"""AverysimpleMetropolisimplementation"""samples=np.zeros(steps)
old_x=func.mean()
old_prob=func.pdf(old_x)
foriinrange(steps):
new_x=old_x+np.random.normal(0,0.5)new_prob=func.pdf(new_x)
acceptance=new_prob/old_prob
ifacceptance>=np.random.random():
samples[i]=new_x
old_x=new_x
old_prob=new_prob
else:
samples[i]=old_x
returnsamples

下面的例子中，我们把func定义成一个beta函数，因为beta函数
可以通过改变参数调整分布的形状。我们把metropolis函数的结果
用直方图画出来，同时用红色的线表示真实的分布。

func=stats.beta(0.4,2)
samples=metropolis(func=func)
x=np.linspace(0.01,.99,100)
y=func.pdf(x)
plt.xlim(0,1)
plt.plot(x,y,'r-',lw=3,label='Truedistribution')
plt.hist(samples,bins=30,normed=True,label='Estimateddistribution')plt.xlabel('$x$',fontsize=14)
plt.ylabel('$pdf(x)$',fontsize=14)
plt.legend(fontsize=14)
















71 



















现在你应该从概念上掌握了Metropolis-Hastings算法。也许你需
要回过头去重新阅读前面几页才能完全消化。此外，我还强烈建议阅
读PyMC3核心作者之一写的博文
http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/[2]。他用一个简单的例子实现了metropolis方法，并将其用于求解后验分布，文中
用非常好看的图展示了采样的过程，同时简单讨论了最初选取的步长是如何影响结果的。


4．汉密尔顿蒙特卡洛方法/不掉向采样


MCMC方法，包括Metropolis-Hastings，都在理论上保证如果采
样次数足够多，最终会得到后验分布的准确近似。不过，实际中想要
采样足够多次可能需要相当长的时间，因此，人们提出了一些
Metropolis-Hastings算法的替代方案。这些替代方案，包括Metropolis-Hastings算法本身，最初都是用来解决统计力学中的问题。统计力学是物理学的一个分支，主要研究原子和分子系统的特性。汉密尔顿蒙特卡洛方法，又称混合蒙特卡洛（HybridMonteCarlo，HMC），是
这类改进方案之一。简单来说，汉密尔顿这个词描述的是物理系统的

72 



总能量，而另外一个名称中的“混合”是指将Metropolis-Hastings算法
与分子力学（分子系统中广泛应用的一种仿真技巧）相结合。HMC
方法本质上和Metropolis-Hastings是一样的，改进的地方在于：原来
是随机放置小船，现在有了一个更聪明的办法，将小船沿着湖底方向
放置。为什么这个做法更聪明？因为这样做避免了Metropolis-
Hastings算法的主要问题之一：探索得太慢而且采样结果自相关（因为大多数采样结果都被拒绝了）。

那么，如何才能不必深入其数学细节而理解汉密尔顿蒙特卡洛方法呢？假设我们还是在湖面上坐着船，为了决定下一步将要去哪，我们从当前位置往湖底扔了一个球，受“球状奶牛”的启发[3]，我们假设球面是理想的，没有摩擦，因而不会被泥巴和水减速。扔下球之后，让它滚一小会儿，然后把船划到球所在的位置。现在利用Metropolis-Hastings算法中提到的Metropolis准则来选择接受或者拒绝，重复整个过程一定次数。改进后的过程有更高的概率接受新的位置，即使它们的位置相比前一位置距离较远。

现在跳出我们的思维实验，回到现实中来。基于汉密尔顿的方法需要计算函数的梯度。梯度是在多个维度上导数的推广。我们可以用梯度信息来模拟球在曲面上移动的过程。因此，我们面临一个权衡；HMC计算过程要比Metropolis-Hastings更复杂，但是被接受概率更
高。对于一些复杂的问题，HMC方法更合适一些。HMC方法的另一个缺点是：想要得到很好的采样需要指定一些参数。如果手动指定，需要反复尝试，这要求使用者有一定的经验。幸运地是，PyMC3中
有一个相对较新的不掉向采样算法，该方法被证实可以有效提升
HMC方法的采样效率，同时不必手动调整参数。


5．其他MCMC方法

73 



MCMC的方法很多，而且人们还在不断提出新的方法。如果你
认为你能提升采样效率，会有很多人对你的想法感兴趣。讨论所有这
类方法及其优缺点显然超出了本书的范围。不过，有些方法仍值得一提，因为你可能经常会听到人们讨论它们，所以最好是了解下他们都在讨论些什么。

在分子系统模拟中广泛应用的另外一种采样方法是副本交换
（ReplicaExchange），也称并行退火（ParallelTempering）或
者MetropolisCoupledMCMC（MC3；好多MC……）。该方法的基本思想是并行模拟多个不同的副本，每个副本都按照Metropolis-Hastings算法执行。多个副本之间的唯一不同是一个叫做温度的参数（又受到物理学的启发！），该参数用来控制接受低概率采样点的可能性。每隔一段时间，该方法都尝试在多个副本之间进行切换，切换过程同时遵循Metropolis-Hastings准则来接受或拒绝，只不过现在考虑的是不同副本之间的温度。切换过程可以在状态链上进行随机切换，不过，通常更倾向于在相邻副本之间切换，也就是说，具有相似温度的副本会有更高的接受概率。该方法的直观理解是：如果我们提高温度，接受新位置的概率也会提升，反之则会降低。温度更高的副本可以更自由地探索系统，因为这些副本的表面会变得相当平坦从而更容易探索。对于温度无限高的副本，所有状态都是等概率的。副本之间的切换避免了较低温度的副本陷在局部最低点，因而该方法很适合探索有多个最低点的系统。












74 




2.2　PyMC3介绍

PyMC3是一个用于概率编程的Python库，当前最新的版本号是
2016年10月4号发布的3.0.rc2。PyMC3提供了一套非常简洁直观的语
法，非常接近统计学中描述概率模型的语法，可读性很高。PyMC3
是用Python写的，其中的核心计算部分基于NumPy和Theano。Theano是一个用于深度学习的Python库，可以高效地定义、优化和求解多维数组的数学表达式。PyMC3使用Theano的主要原因是某些采样算法
（如NUTS）需要计算梯度，而Theano可以很方便地进行自动求导。而且，Theano将Python代码转化成了C代码，因而PyMC3的速度相当快。关于Theano就需要了解这些，如果你想深入学习更多可以阅读
Theano官网上的教程http://deeplearning.net/software/theano/tutorial/
index.html#tutorial。
2.2.1　用计算的方法解决抛硬币问题
让我们重新回顾下抛硬币问题，这次我们使用PyMC3。首先我
们需要获取数据，这里我们使用手动构造的数据。由于数据是我们自
己生成，所以知道真实的参数，以下代码中用theta_real变量表
示。显然，在真实数据中，我们并不知道参数的真实值，而是要将其估计出来。

np.random.seed(123)
n_experiments=4
theta_real=0.35
data=stats.bernoulli.rvs(p=theta_real,size=n_experiments)print(data)
array([1,0,0,0])
模型描述



75 



现在有了数据，需要再指定模型。回想一下，模型可以通过指定似然和先验的概率分布完成。对于似然，我们可以用参数分别为
和的二项分布来描述，对于先验，我们可以用参数为
的beta分布描述。这个beta分布与[0,1]区间内的均匀分布是
一样的。我们可以用数学表达式描述如下：





这个统计模型与PyMC3的语法几乎一一对应。第1行代码先构建了一个模型的容器，PyMC3使用with语法将所有位于该语法块内的代码都指向同一个模型，你可以把它看作是简化模型描述的“语法糖”，这里将模型命名为our_first_model。第2行代码指定了先
验，可以看到，语法与数学表示很接近。我们把随机变量命名为，
需要注意的是，这里变量名与Beta函数的第1个参数名一样；保持相
同的名字是个好习惯，这样能避免混淆。然后，我们通过变量名从后
验采样中提取信息。这里变量是一个随机变量，我们可以将该变量
看做是从某个分布（在这里是beta分布）中生成数值的方法而不是某个具体的值。第3行代码用跟先验相同的语法描述了似然，唯一不同的是我们用observed变量传递了观测到的数据，这样就告诉了
PyMC3我们的似然。其中，data可以是一个Python列表或者Numpy
数组或者Pandas的DataFrame。这样我们就完成了模型的描述。

withpm.Model()asour_first_model:
theta=pm.Beta('theta',alpha=1,beta=1)
y=pm.Bernoulli('y',p=theta,observed=data)
按下推断按钮
对于抛硬币这个问题，后验分布既可以从分析的角度计算出来，也可以通过PyMC3用几行代码从后验的采样中得到。代码中的第1

76 



行，调用了find_MAP函数，该函数调用SciPy中常用的优化函数尝试返回最大后验（MaximumaPosteriori，MAP）。调用find_MAP是可
选的，有时候其返回值能够为采样方法提供一个不错的初始点，不过有时候却并没有多大用，因此大多数时候会避免使用它。然后，下一行定义了采样方法。这里用的是Metropolis-Hastings算法，函数名取
了简写Metropolis。PyMC3可以让我们将不同的采样器赋给不同的随机变量；眼下我们的模型只有一个参数，不过后面我们会有多个参
数。我们也可以省略该行，PyMC3会根据不同参数的特性自动地赋
予一个采样器，例如，NUTS算法只对连续变量有用，因而不能用于离散的变量，Metropolis算法能够处理离散的变量，而另外一些类型
的变量有专门的采样方法。总的来说，我们可以让PyMC3为我们选
一个采样方法。最后一行是执行推断，其中第1个参数是采样次数，第2个和第3个参数分别是采样方法和初始点，可以看到这两个参数是可选的。

    start=pm.find_MAP()
    step=pm.Metropolis()
    trace=pm.sample(1000,step=step,start=start)

这样，只需要几行代码我们就完成了整个模型的描述和推断。感谢PyMC3的开发者们为我们提供了这么棒的库。
诊断采样过程
现在我们根据有限数量的样本对后验做出了近似，接下来要做的第一件事就是检查我们的近似是否合理。我们可以做一些测试，有些是可视化的，有些是定量的。这些测试会尝试从样本中发现问题，但并不能证明我们得到的分布是正确的，它们只能提供证据证明样本看起来是合理的。如果我们通过样本发现了问题，解决办法有如下几
种。


77 



增加样本次数。
从样本链（迹）的前面部分去掉一定数量的样本，称为老化
（Burn-in）。在实践中，MCMC方法通常需要经过一段时间的
采样之后，才得到真正的目标分布。老化在无限多次的采样中并不是必须的，因为这部分并没有包含在马尔科夫理论中。事实
上，去掉前面部分的样本只不过是在有限次采样中提升结果的一个小技巧。需要注意，不要被数学对象和数学对象的近似弄糊涂了，球体、高斯分布以及马尔科夫链等数学对象只存在于柏拉图式的想象世界中，并不存在于不完美但却真实的世界中。
重新参数化你的模型，也就是说换一种不同但却等价的方式描述模型。
转换数据。这么做有可能得到更高效的采样。转换数据的时候需要注意对结果在转换后的空间内进行解释，或者再重新转换回
去，然后再解释结果。

本书剩余部分将会详细讲解这些方案。

收敛性
通常，我们要做的第一件事就是查看结果长什么样，traceplot
函数非常适合该任务：

burnin=100
chain=trace[burnin:]
pm.traceplot(chain,lines={'theta':theta_real});

对于未观测到的变量，我们得到了两幅图。左图是一个核密度估计（KernelDensityEstimation，KDE）图，可以看做是平滑之后的直方图。右图描绘的是每一步采样过程中得到的采样值。注意图中红色的线表示变量theta_real的值。


78 








在得到这些图之后，我们需要观察什么呢？首先，KDE图看起来应该是光滑的曲线。通常，随着数据的增加，根据中心极限定理[4]，参数的分布会趋近于高斯分布。当然，这并不一定是正确的。右侧的图看起来应该像白噪声，也就是说有很好的混合度（mixing），我们看不到任何可以识别的模式，也看不到向上或者向下的曲线，相反，我们希望看到曲线在某个值附近震荡。对于多峰分布或者离散分布，我们希望曲线不要在某个值或区域停留过多时间，我们希望看到采样值在多个区间自由移动。此外，我们希望迹表现出稳定的相似性，也就是说，前10%看起来跟后50%或者10%差不多。再次强调，我们不
希望看到规律的模式，相反我们期望看到的是噪声。下图展示了一些迹呈现较好混合度（右侧）与较差混合度（左侧）的对比。


















如果迹的前面部分跟其他部分看起来不太一样，那就意味着需要进行老化处理，如果其他部分没有呈现稳定的相似性或者可以看到某种模式，那这意味着需要更多的采样，或者需要更换采样方法或者参


79 



数化方法。对于一些复杂的模型，我们可能需要结合使用前面所有的策略。

PyMC3可以实现并行地运行一个模型多次，因而对同一个参数
可以得到多条并行的迹。这可以通过在采样函数中指定njobs参数实
现。此时使用traceplot函数，便可在同一幅图中得到同一个参数的
所有迹。由于每组迹都是相互独立的，所有的迹看起来都应该差不
多。除了检查收敛性之外，这些并行的迹也可以用于推断，我们可以将这些并行的迹组合起来提升采样大小而不是扔掉多余的迹：

withour_first_model:
step=pm.Metropolis()
multi_trace=pm.sample(1000,step=step,njobs=4)
burnin=0
multi_chain=multi_trace[burnin:]
pm.traceplot(multi_chain,lines={'theta':theta_real});






一种定量地检测收敛性的方法是Gelman-Rubin检验。该检验的
思想是比较不同迹之间的差异和迹内部的差异，因此，需要多组迹来
进行该检验。理想状态下，我们希望得到	。根据经验，我们认为如果得到的值低于1.1，那么可以认为是收敛的了，更高的值则意
味着没有收敛：

pm.gelman_rubin(multi_chain)
{'theta':1.0074579751170656,'theta_logodds':1.009770031607315}

我们还可以用forestplot函数将和每个参数的均值、50%HPD和95%HPD可视化地表示出来：



80 



pm.forestplot(multi_chain,varnames=['theta']);





















函数summary提供了对后验的文字描述，它可以提供后验的均值、标准差和HPD区间：

pm.summary(multi_chain)
theta:
MeanSDMCError95%HPDinterval-------------------------------------------------------------------0.3390.1730.006[0.037,0.659]Posteriorquantiles:
2.52550
7597.5
|--------------|==============|==============|--------------|
0.0630.2060.318
0.4550.709

此外，df_summary函数会返回类似的结果，不过类型是Pandas中的DataFrame：

pm.df_summary(multi_chain)




81 



mean	sd	mc_error	hpd_2.5	hpd_97.5


theta	0.33883	0.17305	0.00592	0.03681	0.65916



其中，返回值之一是mc_error，这是对采样引入误差的估计
值，该值考虑的是所有的采样值并非真的彼此独立。mc_error是迹
中不同块的均值的标准差，每一块是迹中的一部分：




该误差值显然低于我们结果的准确度。由于采样方法是随机的，每次重跑的时候，summary或者df_summary返回的值都会不同，不过没关系，mc_error的值应该是相似的，如果返回的值有很大不
同，则说明我们可能需要更多的样本。

自相关
最理想的采样应该不会是自相关的，也就是说，某一点的值应该与其他点的值是相互独立的。在实际中，从MCMC方法（特别是Metropolis-Hastings）中得到的采样值是自相关的。由于参数之间的相互依赖关系，可能模型会导致更多的自相关采样。PyMC3有一个很方便的函数用来描述自相关。

pm.autocorrplot(chain)











82 



该图显示了采样值与相邻连续点（最多100个）之间的平均相关性。理想状态下，我们不会看到自相关性，实际中我们希望看到自相
关性降低到较低水平。参数越自相关，要达到指定精度的采样次数就需要越多，也就是说，自相关性不利于降低采样次数。

有效采样大小
一个有自相关性的采样要比没有自相关性的采样所包含的信息量更少，因此，给定采样大小和采样的自相关性之后，我们可以尝试估计出该采样的大小为多少时，该采样没有自相关性而且包含的信息量不变，该值称为有效采样大小。理想情况下，两个值是一模一样的；二者越接近，我们的采样效率越高。有效采样大小可以作为我们的一个参考，如果我们想要估计出一个分布的均值，我们需要的最小采样数至少为100；如果想要估计出依赖于尾部分布的量，比如可信区间
的边界，那么我们可能需要1000到10000次采样。

pm.effective_n(multi_chain)['theta']667

显然，提高采样效率的一个方法是换一个更好的采样方法；另一个办法是转换数据或者对模型重新设计参数，此外，还有一个常用的办法是对采样链压缩。所谓压缩其实就是每隔k个观测值取一个，在
Python中我们称为切片。压缩会降低自相关性，但代价是同时降低了样本量。因此，实际使用中通常更倾向于增加样本量而不是切片。不过有时候，压缩会很有用，比如降低存储空间。如果仍不能避免高自相关性，我们就只能算出更长的采样链，模型中的参数很多的话，存储量会是个问题。而且，我们可能还会对后验做一些计算量很大的后处理，此时在自相关性尽可能小的前提下，采样数量的大小就显得尤为重要。



83 



目前为止，所有的诊断测试都是经验性而非绝对的。实际使用
中，我们会先运行一些测试，如果看起来没什么问题，我们就继续往
下分析。如果发现了一些问题，就需要回过头解决它们，这也是建模过程的一部分。要知道，进行收敛性检查并非贝叶斯理论的一部分，由于我们是用数值的方式在计算后验，因而这只是贝叶斯实践过程中的一部分。









































84 




2.3　总结后验

我们已经知道，贝叶斯分析的结果是后验分布，其包含了在已有数据和模型下，参数的所有信息。我们可以使用PyMC3中的
plot_posterior函数对后验分布进行可视化总结，这个函数的核心参数是一个PyMC3的迹和或者一个NumPy的数组，默认情况下，该函数会画出参数的直方图以及分布的均值，此外图像的底端还有一个黑色的粗线用来表示95%HPD区间。可以通过设置alpha_level参数来改变HPD区间。我们将这类图称为Kruschke图，这是因为JohnK.Kruschke第一次在他的《DoingBayesianDataAnalysis》一书中引入了这种图。

pm.plot_posterior(chain,kde_plot=True)











2.3.1　基于后验的决策
有时候，仅仅描述后验还不够，我们还需要根据推断结果做决
策，即将连续的估计值收敛到一个二值化结果上：是或不是、受污染
了还是安全的等等。回到抛硬币问题上，我们需要回答硬币是不是公平的。一枚公平的硬币是指的值为0.5，严格来说，出现这种情况的概率是0，因而，实际中我们会对定义稍稍放松，假如一枚硬币的值在0.5左右，我们就认为这枚硬币是公平的。这里“左右”的具体含义


85 



依赖于具体的问题，并没有一个满足所有问题的普适准则。因此决策也是偏主观的，我们的任务就是根据我们的目标做出最可能的决策。

直观上，一个明智的做法是将HPD区间与我们感兴趣的值进行比较，在我们的例子中，该值是0.5。前面的图中可以看出HPD的范围是0.06～0.71，包含0.5这个值，不过根据后验分布来看，硬币似乎倾向于反面朝上，我们无法就此裁定一个硬币是公平的。或许，我们需要收集更多的数据来降低数据的分散程度，从而得到一个更确定的决策；又或者是因为我们漏掉了某些关键信息，以至我们没能找到更完备的先验。

ROPE
基于后验做决策的一种方案是实用等价区间（RegionOfPracticalEquivalence，ROPE），其实就是在感兴趣值附近的一个区间，例如我们可以说[0.45,0.55]是0.5的一个实用性等价区间。同样，ROPE是根据实际情况决定的。接下来我们可以将ROPE与HPD对比，结果至少有以下3种情况。

ROPE与HPD区间没有重叠，因此我们可以说硬币是不公平的。ROPE包含整个HPD区间，我们可以认为硬币是公平的。
ROPE与HPD区间部分重叠，此时我们不能判断硬币是否公平。

当然，如果选择区间[0,1]作为ROPE，那么不管结果怎样我们都会说这枚硬币是公平的，不过恐怕没人会同意我们对ROPE的定义。plot_posterior函数可以用来画ROPE。从图中可以看到，ROPE是一段较宽的半透明的红色线段，同时上面有两个数值表示ROPE的两个端点。

pm.plot_posterior(chain,kde_plot=True,rope=[0.45,0.55])

86 













我们还可以给plot_posterior传递一个参考值，例如0.5，用来
和后验进行对比。从图中可以看出我们会得到一个绿色的垂直线以及大于该值和小于该值的后验比例。

pm.plot_posterior(chain,kde_plot=True,ref_val=0.5)











关于如何使用ROPE的更多细节，你可以阅读JohnKruschke写的《DoingBayesianDataAnalysis》一书的第12章。这一章还讨论了在贝叶斯框架下如何做假设检验，以及一些（贝叶斯或者非贝叶斯的）假设检验方面的警告。

损失函数

如果你觉得ROPE准则有些杂乱，想要更正式一些的形式，那么损失函数就是你想要的。做好决策很重要的一点是，参数的估计值要
有很高的精度，同时还要考虑到预测出错的代价。对于收益/损失的
权衡可以从数学形式上用代价函数来描述，有时候也称为损失函数。损失函数刻画的是当Y（硬币是不公平的）成立时预测X（硬币是公


87 



平的）成立时的代价。在许多问题中，决策的代价函数是不对称的，例如，在决定5岁以下的儿童是否应该接种某种疫苗这件事上，决定接种或者不接种可能造成完全不同的影响，一旦做出错误的决策，可能会导致上千人死亡，而假如能决定接种某种非常安全同时又相对便宜的疫苗，则可能避免一场健康危机。人们对如何在有限信息下做出决策的问题已经研究许多年了，该学科被称为决策理论。









































88 




2.4　总结

本章，我们学习了概率编程，同时体会到了推断引擎的强大力量。我们从概念上讨论了MCMC方法的核心思想及其在现代贝叶斯数据分析中的地位。此外，我们第一次见证了PyMC3的强大和易用性。我们还重新回顾了前一章中的抛硬币问题，这次，我们使用
PyMC3重新定义并解决了这个问题，同时还做了建模过程中非常重要的模型检查和模型诊断。

下一章会继续学习贝叶斯分析的一些技巧，我们将学习如何处理多个参数的模型，以及如何协调多个参数之间的层次关系。































89 




2.5　深入阅读

PyMC3的文档，一定要记得查看例子部分：https://pymc-
devs.github.io/pymc3/。
《贝叶斯方法——概率编程与贝叶斯推断》（注：该书已出
版），这本书最初是用PyMC2写的，目前已经转成PyMC3了：
https://github.com/quantopian/Probabilistic-Programming-and-
Bayesian-Methods-for-Hackers。
《WhileMyMCMCGentlySamples》，PyMC3核心开发者之
一，ThomasWiecki的博客。
《StatisticalRethinking》，RichardMcElreath写的一本关于贝叶
斯分析的入门书。书中的例子是用R/Stan写的，我将这本书中的例子转成了Python/PyMC3，相关代码可以查看
https://github.com/aloctavodia/Statistical-Rethinking-with-Python-
and-PyMC3。
《DoingBayesianDataAnalysis》，JohnK.Kruschke写的另一本关于贝叶斯分析的入门书，也有跟前面一本书类似的问题，该书第1版中的大部分例子也都转成了Python/PyMC3，相关代码可以查看
https://github.com/aloctavodia/Doing_bayesian_data_analysis。[5]













90 




2.6　练习

（1）用其他先验尝试网格算法。例如，尝试将代码改成prior
=(grid<=0.5).astype(int)或者prior=abs(grid-
0.5)，或者你可以将其定义成你所想的任意形式。换一些其他数据
重复实验，例如增加总的样本数或者将样本数根据你看到的正面朝上的次数适当调整。

（2）在我们估计p值的代码中，将N固定，重复多次实验。注意由于我们使用了随机数，每次的结果都会不一样，不过检查一下可以
发现误差应该差不多。尝试把N调大然后再重跑，你能猜出N与误差
之间的关系吗？你可能需要修改下代码，将N作为一个参数传给计算误差的函数，这样方便估计N与误差之间的关系。对于相同的N值，
可以重复跑多次后计算误差的平均值和这些误差的标准差，然后使用
matplotlib中的errobar()函数将它们画出来。可以尝试一些类似
100、1000、10000的数作为N的值（每次提高一个数量级）。

（3）修改传给metropolis函数的参数。尝试使用第1章中用到
的先验。将这段代码与网格计算进行比较，看一下哪部分需要修改后才能用于解决贝叶斯推断问题。

（4）将前一题的答案与下面链接中ThomasWiechi的代码进行比较：http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/。

（5）修改beta先验分布的参数以匹配前1章中的分布，试比较2者的结果。将beta分布替换成区间为[0,1]的均匀分布，其结果是否与beta(a=1,b=1)相等？采样速度相比是更快？还是更慢？或者是相等？如果换成更大的区间，比如[-1,2]呢？模型是否能正常运行？你

91 



得到的错误是什么意思？如果你不调用find_MAP()函数的话呢？（记得将sample函数的第1个参数也去掉，如果你是在
Jupyter/IPython记事本中运行代码，尤其需要注意这点。）

（6）修改退化的数量。尝试将退化的数量修改为0或者500，还
可以尝试不用find_MAP()函数，结果的差别有多大？提示：这里采
样的模型非常简单，记住这个练习，后面在其他章节中我们还会在更复杂的模型上进行尝试。

（7）使用自己的数据。用你自己感兴趣的数据重新跑一边本章的内容，这个练习适用于本书剩余的所有章节。

（8）阅读PyMC3文档中的煤矿灾变模型：http://pymc-
devs.github.io/pymc3/notebooks/getting_started.html#Case-study-2:-Coal-mining-disasters，试着自己实现并运行该模型。

除了每章最后的练习之外，你还可以将已经学到的内容应用到你感兴趣的问题上。也许，你需要重新定义你的问题，或者需要扩展或者修改你已经学到的模型。试着修改模型，如果你觉得这个任务已经超出了你实际掌握的部分，那么先将问题记下来，等读完本书其余章节后再回过头来重新思考这些问题。如果最后本书仍然无法解决你的问题，那么你可以查看下PyMC3的例子（http://pymc-
devs.github.io/pymc3/examples.html），或者在PyMC3的论坛
（https://discourse.pymc.io）上提问。


[1]　可阅读https://zh.wikipedia.org/wiki/维数灾难，了解更多信息。——译者注

[2]　该文章notebook形式的翻译见

92 



https://github.com/findmyway/Bayesian-Analysis-with-
Python/blob/master/MCMC-sampling-for-dummies.ipynb。——译者注

[3]　“球状奶牛”起源于一个物理学家的笑话，具体含义可自行搜索维基百科。——译者注

[4]　此处已根据原书的勘误更正。——译者注

[5]　第2版也有人转成了Python，
https://github.com/JWarmenhoven/DBDA-python。——译者注