# 第2章　概率编程

上一章对贝叶斯统计有了基本了解，本章将学习如何使用计算工具构建概率模型。我们将学习使用 PyMC3 进行概率编程。其基本思想是使用代码指定模型，然后以或多或少自动的方式求解它们。选择编程的背后原因是：许多模型无法得到闭合的解析解，因此只能使用数值方法来求解。

学习概率编程的另一个原因是，现代贝叶斯统计主要是通过编写代码来完成的，既然已经了解 Python，为什么还要用另一种方式呢？概率编程提供了一种构建和求解复杂模型的有效方法，使我们可以更多地关注模型设计、评估和解释，而更少地关注数学或计算细节。在本章以及本书的其余部分中，我们将使用 PyMC3 和 ArviZ ，PyMC3 是一个非常灵活的概率编程 Python 库，ArviZ 是一个新的 Python 库，它将帮助我们解释概率模型的结果。了解 PyMC3 和 ArviZ 还将帮助我们以更实际的方式学习先进的贝叶斯概念。

本章涵盖以下主题：

- 概率编程；
- 推断引擎；
- PyMC3 指南；
- 重温抛硬币问题；
- 模型检查和诊断；
- 高斯模型和学生$t$模型；
- 分组比较和有效容量；
- 分层模型和收缩。



## 2.1　概率编程

贝叶斯统计在概念上非常简单：我们有已知和未知的量；我们使用贝叶斯定理将后者以前者为条件。如果我们幸运的话，这个过程将减少未知量的不确定性。通常，我们把已知量称为**数据**并将其视为常数，将未知量称为参数并将其视为概率分布。在更正式的术语中，我们给未知量分配先验概率分布；然后利用贝叶斯定理将其先验概率分布转化为后验分布。尽管概念简单，但全概率公式常常导致难以解析的表达式。多年来，该问题是阻碍贝叶斯方法广泛采用的主要原因之一。

随着计算时代的到来，数值方法使得解决任何推理问题成为可能。这极大改变了贝叶斯数据分析的应用。我们可以把这些数值方法看作通用推理引擎，或者 PyMC3 核心开发者 <u>Thomas Wiecki</u> 所称呼的推理按钮。自动化推理过程的可能性导致了**概率编程语言（PPL）**的发展，它允许模型创建和推理之间的明确分离。

在概率编程语言的框架中，用户只需要寥寥数行代码描述概率模型，后面的推断过程就能自动完成了。概率编程使得人们能够更快速地构建复杂的概率模型并减少出错的可能，可以预见，这将给数据科学和其他学科带来极大的影响。我认为，编程语言对科学计算的影响可以与60多年前 Fortran 语言的问世相对比。尽管如今Fortran语言风光不再，不过在当时Fortran 语言被认为是相当革命性的。科学家们第一次从计算的细节中解放出来，开始用一种更自然的方式关注构建数值化的方法、模型和仿真系统。类似地，概率编程将处理概率和推断的过程对用户隐藏起来，从而使得用户更多的去关注模型构建和结果分析。

在本章中，我们将学习如何使用 PyMC3 定义和求解模型。我们将把推断按钮看作一个黑盒，它给我们提供了来自后验分布的适当样本。我们将要使用的方法是随机的，所以每次我们运行它们时，样本都会有所不同。然而，如果推理过程如预期的那样工作，样本将代表后验分布，因此我们将从这些样本中的任何一个获得相同的结论。当我们按下推理按钮时，引擎盖下会发生什么，以及如何检查样本是否确实值得信任，这些细节将在第8章-推理引擎中解释。

## 2.2 PyMC3 简介

PyMC3 是一个 Python 库，用于概率编程。撰写本文时的最后一个版本是 3.6 。PyMC3 提供了非常简单直观的语法，易于阅读，与统计文献中用于描述概率模型的语法非常接近。PyMC3 的基本代码是用 Python 编写的，计算要求高的部分是用 NumPy 和 Theano 编写的。

Theano 是为深度学习而开发的一个 Python 库，允许我们高效地定义、优化和计算涉及多维数组的数学表达式。PyMC3 使用 Theano 的主要原因是，有些采样方法需要计算梯度，而 Theano 知道如何使用自动微分来计算梯度。此外，Theano 将 Python 代码编译成 C 代码，因此 PyMC3 非常快。这是关于 Theano 的所有信息，我们必须使用 PyMC3 。

如果您还想了解更多，请开始阅读http://deeplearning.net/software/theano/tutorial/index.html#tutorial上的官方 Theano教程。

>你可能听说过 Theano 已经不再开发了，但这没什么好担心的。PyMC 开发人员将接管 Theano 维护，确保 Theano 在未来几年内继续为 PyMC3 服务。与此同时，PyMC 开发人员正在迅速行动，以创建 PyMC3 的继任者。这可能会基于 TensorFlow 作为后端，尽管其他选项也在分析中。有关这方面的更多信息，请访问以下博客：https://medium.com/@pymc_devs/theano-tensorflow-and-the-future-of-pymc-6c9987bb19d5

### 2.2.1 用PyMC3的方法解决抛硬币问题

让我们重新回顾下抛硬币问题，这次我们使用PyMC3。首先我们需要获取数据，这里我们使用手动构造的数据。由于数据是我们自己生成，所以知道真实的参数，以下代码中用theta_real变量表示。显然，在真实数据中，我们并不知道参数的真实值，而是要将其估计出来。

```python
np.random.seed(123)
n_experiments=4
theta_real=0.35
data=stats.bernoulli.rvs(p=theta_real,size=n_experiments)print(data)
array([1,0,0,0])
```



#### （1）模型描述

现在有了数据，需要再指定模型。回想一下，模型可以通过指定似然和先验的概率分布完成。对于似然，我们可以用参数分别为和的二项分布来描述，对于先验，我们可以用参数为的beta分布描述。这个beta分布与[0,1]区间内的均匀分布是
一样的。我们可以用数学表达式描述如下：



这个统计模型与PyMC3的语法几乎一一对应。第1行代码先构建了一个模型的容器，PyMC3使用with语法将所有位于该语法块内的代码都指向同一个模型，你可以把它看作是简化模型描述的“语法糖”，这里将模型命名为our_first_model。第2行代码指定了先
验，可以看到，语法与数学表示很接近。我们把随机变量命名为，
需要注意的是，这里变量名与Beta函数的第1个参数名一样；保持相
同的名字是个好习惯，这样能避免混淆。然后，我们通过变量名从后
验采样中提取信息。这里变量是一个随机变量，我们可以将该变量
看做是从某个分布（在这里是beta分布）中生成数值的方法而不是某个具体的值。第3行代码用跟先验相同的语法描述了似然，唯一不同的是我们用observed变量传递了观测到的数据，这样就告诉了
PyMC3我们的似然。其中，data可以是一个Python列表或者Numpy
数组或者Pandas的DataFrame。这样我们就完成了模型的描述。

withpm.Model()asour_first_model:
theta=pm.Beta('theta',alpha=1,beta=1)
y=pm.Bernoulli('y',p=theta,observed=data)
按下推断按钮
对于抛硬币这个问题，后验分布既可以从分析的角度计算出来，也可以通过PyMC3用几行代码从后验的采样中得到。代码中的第1

76 



行，调用了find_MAP函数，该函数调用SciPy中常用的优化函数尝试返回最大后验（MaximumaPosteriori，MAP）。调用find_MAP是可
选的，有时候其返回值能够为采样方法提供一个不错的初始点，不过有时候却并没有多大用，因此大多数时候会避免使用它。然后，下一行定义了采样方法。这里用的是Metropolis-Hastings算法，函数名取
了简写Metropolis。PyMC3可以让我们将不同的采样器赋给不同的随机变量；眼下我们的模型只有一个参数，不过后面我们会有多个参
数。我们也可以省略该行，PyMC3会根据不同参数的特性自动地赋
予一个采样器，例如，NUTS算法只对连续变量有用，因而不能用于离散的变量，Metropolis算法能够处理离散的变量，而另外一些类型
的变量有专门的采样方法。总的来说，我们可以让PyMC3为我们选
一个采样方法。最后一行是执行推断，其中第1个参数是采样次数，第2个和第3个参数分别是采样方法和初始点，可以看到这两个参数是可选的。

    start=pm.find_MAP()
    step=pm.Metropolis()
    trace=pm.sample(1000,step=step,start=start)

这样，只需要几行代码我们就完成了整个模型的描述和推断。感谢PyMC3的开发者们为我们提供了这么棒的库。
诊断采样过程
现在我们根据有限数量的样本对后验做出了近似，接下来要做的第一件事就是检查我们的近似是否合理。我们可以做一些测试，有些是可视化的，有些是定量的。这些测试会尝试从样本中发现问题，但并不能证明我们得到的分布是正确的，它们只能提供证据证明样本看起来是合理的。如果我们通过样本发现了问题，解决办法有如下几
种。


77 



增加样本次数。
从样本链（迹）的前面部分去掉一定数量的样本，称为老化
（Burn-in）。在实践中，MCMC方法通常需要经过一段时间的
采样之后，才得到真正的目标分布。老化在无限多次的采样中并不是必须的，因为这部分并没有包含在马尔科夫理论中。事实
上，去掉前面部分的样本只不过是在有限次采样中提升结果的一个小技巧。需要注意，不要被数学对象和数学对象的近似弄糊涂了，球体、高斯分布以及马尔科夫链等数学对象只存在于柏拉图式的想象世界中，并不存在于不完美但却真实的世界中。
重新参数化你的模型，也就是说换一种不同但却等价的方式描述模型。
转换数据。这么做有可能得到更高效的采样。转换数据的时候需要注意对结果在转换后的空间内进行解释，或者再重新转换回
去，然后再解释结果。

本书剩余部分将会详细讲解这些方案。

收敛性
通常，我们要做的第一件事就是查看结果长什么样，traceplot
函数非常适合该任务：

burnin=100
chain=trace[burnin:]
pm.traceplot(chain,lines={'theta':theta_real});

对于未观测到的变量，我们得到了两幅图。左图是一个核密度估计（KernelDensityEstimation，KDE）图，可以看做是平滑之后的直方图。右图描绘的是每一步采样过程中得到的采样值。注意图中红色的线表示变量theta_real的值。


78 








在得到这些图之后，我们需要观察什么呢？首先，KDE图看起来应该是光滑的曲线。通常，随着数据的增加，根据中心极限定理[4]，参数的分布会趋近于高斯分布。当然，这并不一定是正确的。右侧的图看起来应该像白噪声，也就是说有很好的混合度（mixing），我们看不到任何可以识别的模式，也看不到向上或者向下的曲线，相反，我们希望看到曲线在某个值附近震荡。对于多峰分布或者离散分布，我们希望曲线不要在某个值或区域停留过多时间，我们希望看到采样值在多个区间自由移动。此外，我们希望迹表现出稳定的相似性，也就是说，前10%看起来跟后50%或者10%差不多。再次强调，我们不
希望看到规律的模式，相反我们期望看到的是噪声。下图展示了一些迹呈现较好混合度（右侧）与较差混合度（左侧）的对比。


















如果迹的前面部分跟其他部分看起来不太一样，那就意味着需要进行老化处理，如果其他部分没有呈现稳定的相似性或者可以看到某种模式，那这意味着需要更多的采样，或者需要更换采样方法或者参


79 



数化方法。对于一些复杂的模型，我们可能需要结合使用前面所有的策略。

PyMC3可以实现并行地运行一个模型多次，因而对同一个参数
可以得到多条并行的迹。这可以通过在采样函数中指定njobs参数实
现。此时使用traceplot函数，便可在同一幅图中得到同一个参数的
所有迹。由于每组迹都是相互独立的，所有的迹看起来都应该差不
多。除了检查收敛性之外，这些并行的迹也可以用于推断，我们可以将这些并行的迹组合起来提升采样大小而不是扔掉多余的迹：

withour_first_model:
step=pm.Metropolis()
multi_trace=pm.sample(1000,step=step,njobs=4)
burnin=0
multi_chain=multi_trace[burnin:]
pm.traceplot(multi_chain,lines={'theta':theta_real});






一种定量地检测收敛性的方法是Gelman-Rubin检验。该检验的
思想是比较不同迹之间的差异和迹内部的差异，因此，需要多组迹来
进行该检验。理想状态下，我们希望得到	。根据经验，我们认为如果得到的值低于1.1，那么可以认为是收敛的了，更高的值则意
味着没有收敛：

pm.gelman_rubin(multi_chain)
{'theta':1.0074579751170656,'theta_logodds':1.009770031607315}

我们还可以用forestplot函数将和每个参数的均值、50%HPD和95%HPD可视化地表示出来：



80 



pm.forestplot(multi_chain,varnames=['theta']);





















函数summary提供了对后验的文字描述，它可以提供后验的均值、标准差和HPD区间：

pm.summary(multi_chain)
theta:
MeanSDMCError95%HPDinterval-------------------------------------------------------------------0.3390.1730.006[0.037,0.659]Posteriorquantiles:
2.52550
7597.5
|--------------|==============|==============|--------------|
0.0630.2060.318
0.4550.709

此外，df_summary函数会返回类似的结果，不过类型是Pandas中的DataFrame：

pm.df_summary(multi_chain)




81 



mean	sd	mc_error	hpd_2.5	hpd_97.5


theta	0.33883	0.17305	0.00592	0.03681	0.65916



其中，返回值之一是mc_error，这是对采样引入误差的估计
值，该值考虑的是所有的采样值并非真的彼此独立。mc_error是迹
中不同块的均值的标准差，每一块是迹中的一部分：




该误差值显然低于我们结果的准确度。由于采样方法是随机的，每次重跑的时候，summary或者df_summary返回的值都会不同，不过没关系，mc_error的值应该是相似的，如果返回的值有很大不
同，则说明我们可能需要更多的样本。

自相关
最理想的采样应该不会是自相关的，也就是说，某一点的值应该与其他点的值是相互独立的。在实际中，从MCMC方法（特别是Metropolis-Hastings）中得到的采样值是自相关的。由于参数之间的相互依赖关系，可能模型会导致更多的自相关采样。PyMC3有一个很方便的函数用来描述自相关。

pm.autocorrplot(chain)











82 



该图显示了采样值与相邻连续点（最多100个）之间的平均相关性。理想状态下，我们不会看到自相关性，实际中我们希望看到自相
关性降低到较低水平。参数越自相关，要达到指定精度的采样次数就需要越多，也就是说，自相关性不利于降低采样次数。

有效采样大小
一个有自相关性的采样要比没有自相关性的采样所包含的信息量更少，因此，给定采样大小和采样的自相关性之后，我们可以尝试估计出该采样的大小为多少时，该采样没有自相关性而且包含的信息量不变，该值称为有效采样大小。理想情况下，两个值是一模一样的；二者越接近，我们的采样效率越高。有效采样大小可以作为我们的一个参考，如果我们想要估计出一个分布的均值，我们需要的最小采样数至少为100；如果想要估计出依赖于尾部分布的量，比如可信区间
的边界，那么我们可能需要1000到10000次采样。

pm.effective_n(multi_chain)['theta']667

显然，提高采样效率的一个方法是换一个更好的采样方法；另一个办法是转换数据或者对模型重新设计参数，此外，还有一个常用的办法是对采样链压缩。所谓压缩其实就是每隔k个观测值取一个，在
Python中我们称为切片。压缩会降低自相关性，但代价是同时降低了样本量。因此，实际使用中通常更倾向于增加样本量而不是切片。不过有时候，压缩会很有用，比如降低存储空间。如果仍不能避免高自相关性，我们就只能算出更长的采样链，模型中的参数很多的话，存储量会是个问题。而且，我们可能还会对后验做一些计算量很大的后处理，此时在自相关性尽可能小的前提下，采样数量的大小就显得尤为重要。



83 



目前为止，所有的诊断测试都是经验性而非绝对的。实际使用
中，我们会先运行一些测试，如果看起来没什么问题，我们就继续往
下分析。如果发现了一些问题，就需要回过头解决它们，这也是建模过程的一部分。要知道，进行收敛性检查并非贝叶斯理论的一部分，由于我们是用数值的方式在计算后验，因而这只是贝叶斯实践过程中的一部分。









































84 




2.3　总结后验

我们已经知道，贝叶斯分析的结果是后验分布，其包含了在已有数据和模型下，参数的所有信息。我们可以使用PyMC3中的
plot_posterior函数对后验分布进行可视化总结，这个函数的核心参数是一个PyMC3的迹和或者一个NumPy的数组，默认情况下，该函数会画出参数的直方图以及分布的均值，此外图像的底端还有一个黑色的粗线用来表示95%HPD区间。可以通过设置alpha_level参数来改变HPD区间。我们将这类图称为Kruschke图，这是因为JohnK.Kruschke第一次在他的《DoingBayesianDataAnalysis》一书中引入了这种图。

pm.plot_posterior(chain,kde_plot=True)











2.3.1　基于后验的决策
有时候，仅仅描述后验还不够，我们还需要根据推断结果做决
策，即将连续的估计值收敛到一个二值化结果上：是或不是、受污染
了还是安全的等等。回到抛硬币问题上，我们需要回答硬币是不是公平的。一枚公平的硬币是指的值为0.5，严格来说，出现这种情况的概率是0，因而，实际中我们会对定义稍稍放松，假如一枚硬币的值在0.5左右，我们就认为这枚硬币是公平的。这里“左右”的具体含义


85 



依赖于具体的问题，并没有一个满足所有问题的普适准则。因此决策也是偏主观的，我们的任务就是根据我们的目标做出最可能的决策。

直观上，一个明智的做法是将HPD区间与我们感兴趣的值进行比较，在我们的例子中，该值是0.5。前面的图中可以看出HPD的范围是0.06～0.71，包含0.5这个值，不过根据后验分布来看，硬币似乎倾向于反面朝上，我们无法就此裁定一个硬币是公平的。或许，我们需要收集更多的数据来降低数据的分散程度，从而得到一个更确定的决策；又或者是因为我们漏掉了某些关键信息，以至我们没能找到更完备的先验。

ROPE
基于后验做决策的一种方案是实用等价区间（RegionOfPracticalEquivalence，ROPE），其实就是在感兴趣值附近的一个区间，例如我们可以说[0.45,0.55]是0.5的一个实用性等价区间。同样，ROPE是根据实际情况决定的。接下来我们可以将ROPE与HPD对比，结果至少有以下3种情况。

ROPE与HPD区间没有重叠，因此我们可以说硬币是不公平的。ROPE包含整个HPD区间，我们可以认为硬币是公平的。
ROPE与HPD区间部分重叠，此时我们不能判断硬币是否公平。

当然，如果选择区间[0,1]作为ROPE，那么不管结果怎样我们都会说这枚硬币是公平的，不过恐怕没人会同意我们对ROPE的定义。plot_posterior函数可以用来画ROPE。从图中可以看到，ROPE是一段较宽的半透明的红色线段，同时上面有两个数值表示ROPE的两个端点。

pm.plot_posterior(chain,kde_plot=True,rope=[0.45,0.55])

86 













我们还可以给plot_posterior传递一个参考值，例如0.5，用来
和后验进行对比。从图中可以看出我们会得到一个绿色的垂直线以及大于该值和小于该值的后验比例。

pm.plot_posterior(chain,kde_plot=True,ref_val=0.5)











关于如何使用ROPE的更多细节，你可以阅读JohnKruschke写的《DoingBayesianDataAnalysis》一书的第12章。这一章还讨论了在贝叶斯框架下如何做假设检验，以及一些（贝叶斯或者非贝叶斯的）假设检验方面的警告。

损失函数

如果你觉得ROPE准则有些杂乱，想要更正式一些的形式，那么损失函数就是你想要的。做好决策很重要的一点是，参数的估计值要
有很高的精度，同时还要考虑到预测出错的代价。对于收益/损失的
权衡可以从数学形式上用代价函数来描述，有时候也称为损失函数。损失函数刻画的是当Y（硬币是不公平的）成立时预测X（硬币是公


87 



平的）成立时的代价。在许多问题中，决策的代价函数是不对称的，例如，在决定5岁以下的儿童是否应该接种某种疫苗这件事上，决定接种或者不接种可能造成完全不同的影响，一旦做出错误的决策，可能会导致上千人死亡，而假如能决定接种某种非常安全同时又相对便宜的疫苗，则可能避免一场健康危机。人们对如何在有限信息下做出决策的问题已经研究许多年了，该学科被称为决策理论。









































88 




2.4　总结

本章，我们学习了概率编程，同时体会到了推断引擎的强大力量。我们从概念上讨论了MCMC方法的核心思想及其在现代贝叶斯数据分析中的地位。此外，我们第一次见证了PyMC3的强大和易用性。我们还重新回顾了前一章中的抛硬币问题，这次，我们使用
PyMC3重新定义并解决了这个问题，同时还做了建模过程中非常重要的模型检查和模型诊断。

下一章会继续学习贝叶斯分析的一些技巧，我们将学习如何处理多个参数的模型，以及如何协调多个参数之间的层次关系。































89 




2.5　深入阅读

PyMC3的文档，一定要记得查看例子部分：https://pymc-
devs.github.io/pymc3/。
《贝叶斯方法——概率编程与贝叶斯推断》（注：该书已出
版），这本书最初是用PyMC2写的，目前已经转成PyMC3了：
https://github.com/quantopian/Probabilistic-Programming-and-
Bayesian-Methods-for-Hackers。
《WhileMyMCMCGentlySamples》，PyMC3核心开发者之
一，ThomasWiecki的博客。
《StatisticalRethinking》，RichardMcElreath写的一本关于贝叶
斯分析的入门书。书中的例子是用R/Stan写的，我将这本书中的例子转成了Python/PyMC3，相关代码可以查看
https://github.com/aloctavodia/Statistical-Rethinking-with-Python-
and-PyMC3。
《DoingBayesianDataAnalysis》，JohnK.Kruschke写的另一本关于贝叶斯分析的入门书，也有跟前面一本书类似的问题，该书第1版中的大部分例子也都转成了Python/PyMC3，相关代码可以查看
https://github.com/aloctavodia/Doing_bayesian_data_analysis。[5]













90 




2.6　练习

（1）用其他先验尝试网格算法。例如，尝试将代码改成prior
=(grid<=0.5).astype(int)或者prior=abs(grid-
0.5)，或者你可以将其定义成你所想的任意形式。换一些其他数据
重复实验，例如增加总的样本数或者将样本数根据你看到的正面朝上的次数适当调整。

（2）在我们估计p值的代码中，将N固定，重复多次实验。注意由于我们使用了随机数，每次的结果都会不一样，不过检查一下可以
发现误差应该差不多。尝试把N调大然后再重跑，你能猜出N与误差
之间的关系吗？你可能需要修改下代码，将N作为一个参数传给计算误差的函数，这样方便估计N与误差之间的关系。对于相同的N值，
可以重复跑多次后计算误差的平均值和这些误差的标准差，然后使用
matplotlib中的errobar()函数将它们画出来。可以尝试一些类似
100、1000、10000的数作为N的值（每次提高一个数量级）。

（3）修改传给metropolis函数的参数。尝试使用第1章中用到
的先验。将这段代码与网格计算进行比较，看一下哪部分需要修改后才能用于解决贝叶斯推断问题。

（4）将前一题的答案与下面链接中ThomasWiechi的代码进行比较：http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/。

（5）修改beta先验分布的参数以匹配前1章中的分布，试比较2者的结果。将beta分布替换成区间为[0,1]的均匀分布，其结果是否与beta(a=1,b=1)相等？采样速度相比是更快？还是更慢？或者是相等？如果换成更大的区间，比如[-1,2]呢？模型是否能正常运行？你

91 



得到的错误是什么意思？如果你不调用find_MAP()函数的话呢？（记得将sample函数的第1个参数也去掉，如果你是在
Jupyter/IPython记事本中运行代码，尤其需要注意这点。）

（6）修改退化的数量。尝试将退化的数量修改为0或者500，还
可以尝试不用find_MAP()函数，结果的差别有多大？提示：这里采
样的模型非常简单，记住这个练习，后面在其他章节中我们还会在更复杂的模型上进行尝试。

（7）使用自己的数据。用你自己感兴趣的数据重新跑一边本章的内容，这个练习适用于本书剩余的所有章节。

（8）阅读PyMC3文档中的煤矿灾变模型：http://pymc-
devs.github.io/pymc3/notebooks/getting_started.html#Case-study-2:-Coal-mining-disasters，试着自己实现并运行该模型。

除了每章最后的练习之外，你还可以将已经学到的内容应用到你感兴趣的问题上。也许，你需要重新定义你的问题，或者需要扩展或者修改你已经学到的模型。试着修改模型，如果你觉得这个任务已经超出了你实际掌握的部分，那么先将问题记下来，等读完本书其余章节后再回过头来重新思考这些问题。如果最后本书仍然无法解决你的问题，那么你可以查看下PyMC3的例子（http://pymc-
devs.github.io/pymc3/examples.html），或者在PyMC3的论坛
（https://discourse.pymc.io）上提问。


[1]　可阅读https://zh.wikipedia.org/wiki/维数灾难，了解更多信息。——译者注

[2]　该文章notebook形式的翻译见

92 



https://github.com/findmyway/Bayesian-Analysis-with-
Python/blob/master/MCMC-sampling-for-dummies.ipynb。——译者注

[3]　“球状奶牛”起源于一个物理学家的笑话，具体含义可自行搜索维基百科。——译者注

[4]　此处已根据原书的勘误更正。——译者注

[5]　第2版也有人转成了Python，
https://github.com/JWarmenhoven/DBDA-python。——译者注