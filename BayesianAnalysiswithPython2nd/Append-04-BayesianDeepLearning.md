---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.12.0
kernelspec:
  display_name: Python 3
  language: ipython3
  name: python3
---

# 附录 D：贝叶斯神经网络的实践 -- 面向深度学习用户的教程

[原文](https://arxiv.org/abs/2007.06823)

[作者]
- LAURENT VALENTIN JOSPIN,University of Western Australia
- WRAY BUNTINE,Monash University
- FARID BOUSSAID,University of Western Australia
- HAMID LAGA,Murdoch university
- MOHAMMED BENNAMOUN,University of Western Australia

[引用]
Laurent Valentin Jospin, Wray Buntine, Farid Boussaid, Hamid Laga, and Mohammed Bennamoun. 2020.Hands-on Bayesian Neural Networks - a Tutorial for Deep Learning Users.ACM Comput. Surv.1, 1 ( July 2020),35 pages

<style>p{text-indent:2em;2}</style>

现代深度学习方法已经为研究人员和工程师提供了令人难以置信的强大工具，以解决以前似乎不可能解决的问题。然而，由于深度学习方法是作为黑箱操作的，与他们的预测相关的不确定性往往是难以量化的。贝叶斯统计学提供了一个形式化的方法来理解和量化与深度神经网络预测相关的不确定性。本文为正在使用机器学习，特别是深度学习的研究人员和科学家提供了一个相关文献的概述和一个完整的工具集来设计、实现、训练、使用和评估贝叶斯神经网络。

## 1 简介

深度学习导致了机器学习的革命，为解决现实生活中复杂而具有挑战性的问题提供了解决方案。然而，深度学习模型容易过拟合，这对其泛化能力产生了不利影响。深度学习模型也倾向于对其预测结果过于自信（当他们提供一个置信区间时）。所有这些对于诸如自动驾驶汽车 [74]、医疗诊断 [38] 或交易和金融 [11] 等应用来说都是有问题的，因为无声的失败会导致戏剧性的结果。因此，人们提出了许多方法来减轻风险，特别是通过随机神经网络来估计模型预测的不确定性。贝叶斯范式为分析和训练随机神经网络提供了严格框架，并且更广泛地支持了学习算法的发展。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig01.webp)
图 1.  本文所涉及的主题的思维导图。这些可以大致分为贝叶斯深度神经网络的概念、不同的（严格意义上的或近似于贝叶斯的）学习方法、评估方法，以及研究人员可用于实施的工具集。

## 2 

## 3 深度学习中贝叶斯方法的动机

一些用户认为定义模型参数的先验 $p(θ)$ 即便可能，也会很难。为简单模型定义先验通常是直观的，例如：明确地添加一个正则化项以支持低次多项式函数或平滑函数 [54]。但对深度学习中使用的多层模型来说，定义先验比较困难。

那么，既然在定义先验时很难理解深度神经网络的行为，为什么还要为其使用贝叶斯方法呢？

人工神经网络所编码的函数关系隐含代表了条件概率 $p(y|x,θ)$ 。贝叶斯公式是用来反转条件概率的合适工具，即使人们事先对 $p(θ)$ 没有什么信息。虽然有很强的理论原则和模式可以作为贝叶斯公式的基础 [76]，但本节重点讨论使用贝叶斯深度网络的一些实际好处。

（1）贝叶斯方法提供了一种方法来量化深度学习中的不确定性。贝叶斯神经网络通常比经典神经网络有更好的校准 [46,58,66]，即其预测的不确定性与观测误差更加一致。与非贝叶斯神经网络相比，它们既不过度自信，也不缺乏自信。使用贝叶斯神经网络可以区分认知不确定性（epistemic uncertainty）和偶然不确定性（aleatoric uncertainty）。前者是由于缺乏知识而产生的不确定性，用 $p(θ|D)$ 来测量，随着数据的增加该不确定性在减少；后者是由于数据的偶然性质而产生的不确定性，用 $p(y|x，θ)$ 来测量 [14,44] 。这使得贝叶斯神经网络具有非常高的数据效率：在学习时，它可以从一个小数据集开始，而不会产生过拟合；在预测时，超出训练集范围的数据只会产生认知不确定性。因此，贝叶斯神经网络成为主动学习（activate learning）的有趣工具 [19,88]，因为人们可以解释模型的预测结果，查看对于相同输入，不同（可能的）参数是否会导致不同预测结果。

（2）机器学习“没有免费的午餐定理” [94] 可以被解释为任何监督学习算法都包括隐含先验（虽然这种解释更多是哲学而非数学的），而贝叶斯方法则明确了先验。虽然并非不可能，但现在的黑盒工具确实在整合先验知识方面非常困难。而在贝叶斯深度学习中，先验被认为是一种软约束，类似于正则化。大多数用于点估计神经网络的正则化方法，基本都可以从贝叶斯角度理解为设置了某种先验（见第 5.3 节）。此外，当新数据出现时，以前学到的后验可循环使用，这使贝叶斯神经网络成为在线学习的重要工具 [64]。

（3）贝叶斯范式能够分析学习方法，并在它们之间建立联系。一些最初不被视为贝叶斯的方法可以被隐含地理解为近似贝叶斯方法，如正则化（见第 5.3 节）或集成概念（第 8.2.2 节）。这也解释了“为什么某些很好用的非贝叶斯算法，也仍然能给出贝叶斯理解？”。实践中大多数贝叶斯神经网络架构都依赖于近似或隐含的贝叶斯方法（见第 8 节），因为精确算法往往太昂贵了。贝叶斯范式还提供了一个系统框架来设计新的学习和正则化策略，即使模型是面向点估计的。

## 4 用于贝叶斯深度学习的随机模型

在设计贝叶斯神经网络时，我们需要选择一个深度网络架构（即功能模型），同时还要选择一个随机模型（即哪些变量被视为随机变量以及其先验分布）。本教程中不会涉及功能模型的设计，因为几乎所有用于点估计的网络模型都可用于贝叶斯深度学习，而且已经有关于功能模型的丰富文献 [71]。

此处将介绍概率图模型（Probabilistic Graphical Models, 概率图模型），一种用来表示随机变量及其条件依赖关系的工具。特别是贝叶斯统计中常使用的一种概率图模型：贝叶斯信念网络。然后展示如何从概率图中实现贝叶斯神经网络的随机模型。

### 4.1 概率图模型

概率图模型是统计学家用于表示多个随机变量之间的相互依赖性，并用图形方式来分解其概率分布的一种工具。概率图涵盖了大量模型，而本教程中只讨论其中的贝叶斯信念网络（有时也称为信念网络或贝叶斯网络）, 贝叶斯信念网络是用有向无环图表示的概率图模型。

```{note}
有关概率图模型的详细回顾，请参考 [9]。
```

虽然贝叶斯信念网络（随机模型）和贝叶斯神经网络（功能模型）都表示为有向无环图，但两者完全不是一回事。贝叶斯神经网络模型表示一组函数关系，如公式（2）所示，具有先验分布；而贝叶斯信念网络则表示模型中所考虑变量的联合概率分布。在构思贝叶斯神经网络时，相应的贝叶斯信念网络代表先验的基础结构，最终在使用变分推断时则代表了变分后验（见第 7.2 节）。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig05.webp)


在概率图模型中，图中的节点代表随机变量，用不同符号来区分所考虑的变量性质（图 5）。贝叶斯信念网络中仅允许有向链接，这意味着目标随机变量的概率分布是以源随机变量为条件来定义的（反过来不成立）。根据乘法法则，这种条件依赖性使得贝叶斯信念网络中所有变量 $v_i$ 的联合概率分布，能够被分解为局部随机变量某些概率分布的组合。

$$
p\left(\boldsymbol{v}_{1}, \ldots, \boldsymbol{v}_{n}\right)=\prod_{i=1}^{n} p\left(\boldsymbol{v}_{i} \mid \operatorname{parents}\left(\boldsymbol{v}_{i}\right)\right)
$$

为完成贝叶斯信念网络，必须定义所有的概率分布 $p(v_i | parents(v_i))$ 。所用分布类型取决于上下文。一旦定义了 $p(v_i|parents(v_i))$ ，则贝叶斯信念网络描述了一个数据生成过程。有向无环图的约束条件，使得父变量总是在其子孙变量前被抽样，而所有变量一起形成了联合概率分布 $p(v_1,...,v_n)$ 的一个样本。

模型通常基于同一分布中采样出的多个样本进行学习。为强调这一事实，引入了板（plate）符号（图 5e）。一个板表示其所封装的子图中所有变量 $(v_1,...,v_n)$ 会按照指定批次维度进行重复，这也意味着板种所有节点在批次之间存在独立性。这种独立性质可被用来计算某个批次 $B={(v_1,...,v_n)_b:b=1,...,|B|}$ 的联合概率。

$$
p(B)=\prod_{\left(\boldsymbol{v}_{1}, \ldots, \boldsymbol{v}_{n}\right) \in B} p\left(\boldsymbol{v}_{1}, \ldots, \boldsymbol{v}_{n}\right)
$$

在概率图模型中，需要区分观测变量和非观测变量，前者用灰色圆圈表示（图 5a），作为数据来处理；后者用白色圆圈表示（图 5b），作为假设来处理。从概率图模型得出的联合概率来看，使用贝叶斯公式可以直接定义给定观测变量的潜变量后验。

$$
p\left(\boldsymbol{v}_{\text {latent }} \mid \boldsymbol{v}_{o b s}\right)=\frac{p\left(\boldsymbol{v}_{o b s}, \boldsymbol{v}_{\text {latent }}\right)}{\int_{\boldsymbol{v}_{\text {latent }}} p\left(\boldsymbol{v}_{\text {obs }}, \boldsymbol{v}_{\text {latent }}\right) d \boldsymbol{v}_{\text {latent }}} \propto p\left(\boldsymbol{v}_{\text {obs }}, \boldsymbol{v}_{\text {latent }}\right)
$$

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig06.webp)
### 4.2 根据概率图模型定义贝叶斯神经网络的随机模型

考虑图 6 中的两个模型，贝叶斯神经网络和相应的贝叶斯信念网络都被画出来了。将权重视为随机变量情况下的贝叶斯信念网络（图 6a）可以代表以下数据生成过程，假设神经网络是为了做回归。

$$
\begin{aligned}
&\theta \sim p(\theta)=\mathcal{N}(\mu, \Sigma) \\
&\boldsymbol{y} \sim p(\boldsymbol{y} \mid x, \theta)=\mathcal{N}\left(N N_{\theta}(x), \Sigma\right)
\end{aligned}
$$

模型中选择正态分布 $\mathcal{N}(\mu, \Sigma)$ 完全是随意的，不过在实践中比较常见。

如果神经网络是为了做分类，那么该模型将有一个类别分布 $Cat(pi)$ 来对预测进行采样，而不是正态分布。

$$
\begin{aligned}
&\theta \sim p(\theta)=\mathcal{N}(\mu, \Sigma) \\
&y \sim p(\boldsymbol{y} \mid x, \theta)=\operatorname{Cat}\left(N N_{\theta}(x)\right)
\end{aligned}
$$

可以利用训练集中数据点相互独立这一假设，即用图 6 中的“板”符号表示，将训练集的概率写成：

$$
p\left(D_{y} \mid D_{x}, \theta\right)=\prod_{(x, y) \in D} p(\boldsymbol{y} \mid x, \theta)
$$

图 6b 中所示的将激活视为随机变量的情况，数据生成过程可能变成：
$$
\begin{aligned}
&l_{0}=x \\
&l_{i} \sim p\left(l_{i} \mid l_{i-1}\right)=n l_{i}\left(\mathcal{N}\left(W_{i} l_{i-1}+b_{i}, \Sigma\right)\right) \quad \forall i \in[1, n] \\
&y=l_{n}
\end{aligned}
$$

贝叶斯公式的联合概率公式稍微复杂一些，因为必须考虑贝叶斯信念网络跨越多个潜在变量 $l_{[1, n-1]}$ 的链式依赖关系：

$$
p\left(D_{\boldsymbol{y}}, \boldsymbol{l}_{[1, n-1]} \mid D_{x}\right)=\prod_{\left(l_{0}, l_{n}\right) \in D}\left(\prod_{i=1}^{n} p\left(\boldsymbol{l}_{i} \mid \boldsymbol{l}_{i-1}\right)\right)
$$

定义 $p\left(\boldsymbol{l}_{i} \mid \boldsymbol{l}_{i-1}\right)$ 有时是可能的，而且通常是可取的。例如：图 6a 和图 6b 中所描述的贝叶斯信念网络可以被认为是等效的，例如，以下 $l$ 的采样：

$$
\begin{aligned}
&W \sim \mathcal{N}\left(\mu_{W}, \Sigma_{W}\right) \\
&b \sim \mathcal{N}\left(\mu_{b}, \Sigma_{b}\right) \\
&l=n l\left(W l_{-1}+b\right)
\end{aligned}
$$

等价于如下对 $l$ 的采样：

$$
l \sim n l\left(\mathcal{N}\left(\mu_{W} l_{-1}+\mu_{b},\left(I \otimes l_{-1}\right)^{\top} \Sigma_{W}\left(I \otimes l_{-1}\right)+\Sigma_{b}\right)\right)
$$

其中 $⊗$ 表示克罗内克积。

图 6a 中描绘的贝叶斯回归架构在实践中更为常见。有时会使用图 6b 中的替代公式，因为它有助于在使用变分推断时压缩参数的数量 [92]。这为定义先验提供了不同的选择。

## 5 设置先验

为小型的、因果的概率模型先验非常直接。但对于深层神经网络来说，情况不一样，设置一个好的先验往往是一项繁琐而不直观的任务。主要问题是：对于具有大量参数和非微观结构的模型，如人工神经网络，如何对给定的参数进行归纳，并不十分明确 [98]。

本节将介绍与人工神经网络的 “统计不可辨识性” 有关的常见做法和相关问题。然后，在第 5.3 节，介绍贝叶斯深度学习中的先验如何与点估计方法的正则化相关。在那里会展示传统正则化方法如何帮助我们选择合适的先验，以及贝叶斯分析如何帮助传统方法设计新的目标函数。

### 5.1 良好的缺省先验

对于基本架构，如图 6a 中所示的带有人工神经网络的贝叶斯回归，标准程序是对网络系数采用均值为 $0$ 、对角线协方差为 $σ_I$ 的正态先验：

$$
P(θ) = \mathcal{N}(0，σI)
$$

正如在第 5.3 节中将证明的，在训练点估计网络时，该方法等同于权重为 $1/σ$ 的加权 ℓ2 正则化。概率编程语言 `Stan[10]` 提供了一些在知道所考虑参数预期规模的情况下，如何选择 $σ$ 的例子 [21]。

但是，虽然该方法在实践中被普遍使用，但并没有理论上的依据表明其优于任何其他表示 [80]。正态分布因其数学特性和其对数的简单表示而受到青睐，因为大多数学习算法中都使用了概率分布的对数。

## 5.2 解决贝叶斯神经网络中的不可辨识性问题

贝叶斯深度学习的主要问题之一是，深度神经网络可能是一个过度参数化的模型，即其中许多参数之间存在等价关系[59]。这被称为统计学上的不可辨识性问题，即推断不会产生唯一的结果。在训练贝叶斯神经网络时，这会导致很难取样和近似的复杂多模态后验。有两种解决方案来处理该问题：一是调整功能模型的参数化形式；二是约束先验的支持度以消除不可辨识性。

人工神经网络中最常见的两类非唯一性是：权重空间对称性和缩放对称性。两者都不是点估计神经网络的关注点，但对于贝叶斯神经网络来说则可能是。

（1）权重空间对称性

权重空间对称性意味着我们可以通过改变其中一个隐藏层的权重 $W_i$（不考虑偏差 $b_i$ ）中的两行和下面一层权重矩阵 $W_{i+1}$ 中的相应列来建立一个至少有一个隐藏层的人工神经网络的等效参数化。这意味着，随着隐层和隐层中单元数量的增加，等价表征的数量也会以阶乘形式增长，这些表征大致对应于后验分布中的众数。一种缓解策略是强制每层的偏置向量按升序或降序排列。然而，其实际效果未知，在优化的早期阶段，权重空间对称性可能隐含着对参数空间探索的支持。

（2）缩放对称性 

缩放对称性是在使用具有 $nl(αx)=αnl(x)$ 性质的非线因子时产生的不可辨识性问题，典型如：RELU 和 Leaky-RELU 这两个现代机器学习中最受欢迎的非线性因子。在这种情况下，给层 $l$ 和 $l+1$ 赋于权重 $W_l,W_{l+1}$ 就严格等同于赋 $αWl,1/αWl+1$。这可能会降低点估计神经网络的收敛速度，该问题在实践中可通过各种激活的归一化技术来解决 [1]。对于贝叶斯神经网络来说，问题稍微复杂一些，因为缩放对称性会影响后验，使得它更难近似其真实形状。一些作者提议使用 `Givens 变换`（有时也称 `Givens 旋转`）来约束隐藏层的范数 [70]，以解决缩放对称问题。

在实践中，使用高斯先验已经减少了缩放对称问题，因为它将有利于每个层上具有相同 `Frobenius 范数` 的权重。如第 5.4 节所述，激活归一化的软版本也可以通过使用一致性条件来实现。从计算复杂度角度来看，在受限空间中对网络参数进行采样的额外复杂性是不值得的。

### 5.3 正则化和先验之间的联系

点估计神经网络的通常学习程序是找到使某些损失函数最小的参数集 $θ$ ，该参数集是用训练集数据学习得到的。

$$
\hat{\theta}=\underset{\theta}{\arg \min } \operatorname{loss}_{D_{\boldsymbol{x}}, D_{y}}(\theta)
$$

假设损失为减去对数似然函数（总是这样的，最多是一个加法常数），问题可以重写为：

$$
\hat{\boldsymbol{\theta}}=\underset{\boldsymbol{\theta}}{\arg \max } p\left(D_{\boldsymbol{y}} \mid D_{\boldsymbol{x}}, \boldsymbol{\theta}\right)
$$

根据贝叶斯范式，这是模型的前一半。现在假设我们也有一个关于 $θ$ 的先验，并且想从后验中找到最可能的点估计。那么问题就变成了:

$$
\hat{\theta}=\underset{\theta}{\arg \max } p\left(D_{\boldsymbol{y}} \mid D_{\boldsymbol{x}}, \boldsymbol{\theta}\right) p(\theta)
$$

接下来，由于更容易优化，再次转换回对数似然的公式：

$$
\hat{\theta}=\underset{\theta}{\arg \min } \operatorname{loss}_{D_{x}, D_{y}}(\theta)+\operatorname{reg}(\theta)
$$

如果这个公式看起来很熟悉，那并不奇怪。这正是正则化在机器学习和许多其他领域的应用方式。这里暗含以下思想：

作为先验，我们有

$$
p(\theta) \propto e^{-r e g(\theta)+c s t}
$$

对于某些在实践中使用的正则化，这可能是一个不理想的分布，但一般的想法是存在的。另一个不太正式的论点是，正则化作为搜索空间的软约束，与先验对后验的作用相同。

### 5.4 满足一致性条件的先验

使用方程 25 中的表述，在某些情况下可以使用函数模型的预期行为来扩展先验。为此，人们通常定义一个一致性条件 $C(θ,x)$ 来评估在输入 $x$ 和参数集 $θ$ 下的预测的相对对数似然。例如，$C$ 可以被设置为有利于稀疏或有规律的预测，鼓励预测与某些输入变量的同调性（例如：得流感的概率随年龄的增长而增加），或者在进行半监督学习时有利于低密度区域的决策边界（第 6 节）。

$$
C(\theta)=\int_{\boldsymbol{x}} C(\theta, x) p(x) d x
$$

在实践中，$p(x)$ 是未知的，$C(\theta)$ 是从训练集的特征中近似估计出来的： 
 
$$
C(\theta) \approx \frac{1}{\left|D_{x}\right|} \sum_{\boldsymbol{x} \in\left|D_{x}\right|} C(\theta, x)
$$
 
 现在可以写一个与包含一致性条件的先验成比例的函数：
 
$$
p\left(\theta \mid D_{\boldsymbol{x}}\right) \propto p(\theta) \exp \left(-\frac{1}{\left|D_{x}\right|} \sum_{\boldsymbol{x} \in\left|D_{\boldsymbol{x}}\right|} C(\theta, \boldsymbol{x})\right)
$$
 
 其中 $p(θ)$ 是没有一致性条件的先验。 
 
 ## 5 监督的程度和先验知识的替代形式
 
 到目前为止介绍的架构主要集中在贝叶斯神经网络在监督学习环境中的使用。然而，在现实世界的应用中，获得地面真实标签可能是昂贵的，因此应该采用新的学习策略 [72]。我们现在介绍如何使贝叶斯神经网络适应不同程度的监督。在这样做的同时，我们还展示了贝叶斯后验的表述，它来自于下面介绍的不同的贝叶斯后验（图 8、9 和 10），可以用来（第 5.3 节）获得一个合适的最大后验估计器的损失函数，在这种情况下，一个点估计神经网络足以满足所考虑的使用情况。

 ## 6 监督程度和先验知识的替代形式

到目前为止，所提出的架构主要集中在贝叶斯神经网络在监督学习环境中的使用。然而，在现实世界的应用中，获得地面真实标签可能是昂贵的，因此应该采用新的学习策略[72]。我们现在介绍如何使贝叶斯神经网络适应不同程度的监督。在这样做的同时，我们还展示了PGM（主要是贝叶斯信念网络）如何有助于设计或解释学习策略。

特别是，贝叶斯后验的表述，是由下面介绍的不同的PGM得出的（图8、9和10），可以用来（第5.3节）获得一个合适的损失函数，用于在点估计神经网络足以满足所考虑的使用情况下的最大后验估计器。

### 6.1 噪声标签和半监督学习

训练集的输入可能是不确定的，要么是因为标签Dyare被噪声破坏[61]，要么是因为一些点没有标签，即半监督学习方法的设置

在有噪声标签的情况下，我们应该扩展BBN，为噪声标签增加一个新的变量--以y为条件（图7a）。由于噪声水平本身往往是未知的，所以添加一个变量σ来描述噪声是很常见的。Frenay和Veleysen[16]提出了在PGM中集成σ的不同方法的分类法（图8），他们区分了三种情况：完全随机噪声（NCAR）；随机噪声（NAR）；非随机噪声（NNAR）模型。在NCAR模型中，σ是独立于任何其他变量的，根据定义，噪声是同调的。在NAR模型中，σ依赖于真实标签，但仍然独立于特征，而NNAC模型也考虑了特征x的影响，例如，如果图像中的噪声水平增加了图像被误标的机会。NAR和NNAC模型都表示异方差（即同方差的反义词）噪声。

这些模型比第4节中介绍的纯监督BNN稍微复杂一些，但可以用类似的方式来处理，即从PGM中推导出后验公式（公式12）并应用所选择的推理算法。我们在此介绍NNAR模型的程序，这是最通用的一种。后验成为

在预测阶段，对于从后验中取样的每个元组(y,σ,θ)，y和σ可以不被考虑。

在部分标记数据的情况下，也被称为半监督学习，（图7b），数据集D被分成标记的L和未标记的U的例子。理论上，这种PGM可以被认为等同于图6a中描述的监督学习情况，但在这种情况下，未观察到的数据U不会带来任何信息。未标记的数据的额外信息来自于先验，也只有先验。在传统的机器学习中，最常见实施半监督学习的方法要么使用某种数据驱动的正则化[86]，要么依赖伪标签[82]，贝叶斯学习也不例外。

（1） 数据驱动正则化

数据驱动的正则化意味着修改先验假设，从而修改随机模型，以便能够从未标记的数据集U中提取有意义的信息。有两种常见的方法来处理这个过程

第一种方法是将模型参数的先验分布限定在未标记的例子上，以利于模型的某些属性，如低密度区域的决策边界，即使用分布p(θ|U)而不是p(θ)。这意味着将随机模型写成：
p(θ|D)∝p(Ly|Lx,θ)p(θ|U),(30)
其中p(θ|U)是一个具有一致性条件的先验，如公式28中定义。

第二种方式是假设数据集中的观察和非观察样本之间存在某种依赖关系。这种类型的贝叶斯半监督学习依赖于非定向PGM[96]来建立先验，或者至少不假设不同训练对（x,y）之间的独立性[48]。为了简单起见，我们在图7b中通过去掉y周围的板块来表示这一事实。这样，后验就以通常的方式写出来了（公式4），主要区别在于现在p(Dy|Dx,θ)的选择是为了在整个数据集中强制执行某种一致性。例如，它可以通过假设两个靠近的点（根据某种取决于输入空间的接近度概念）有可能具有类似的标签y，其不确定性水平随距离的增加而增加。

这两种方法都有类似的效果，选择哪种方法取决于建立模型时喜欢的数学公式。

半监督学习策略也可以被重新表述为有一个弱预测，能够给出一些伪标签～y，有时还具有一定的置信度。许多用于半监督学习的算法使用一个初始版本的模型，用已标记的例子来训练[51]，以产生伪标签～y，并用这些标签来训练最终模型。这对贝叶斯神经网络来说是有问题的，因为如果预测的不确定性被计算在内，那么，就不可能减少与未标记数据相关的不确定性，至少在先验中没有额外的假设。使用更简单的模型[53]来获得伪标签，即使在实践中不太现实，也可以帮助缓解这个问题。

### 6.2 数据增强

数据增强是一种策略，可以大大增加可用于训练深度模型的数据的多样性，而无需实际收集新的数据。它依赖于在不改变标签的情况下，生成一个增强的数据集A(D)，例如，在图像中应用旋转、翻转或添加噪音。数据增强现在是图像处理[82]和越来越多的自然语言处理[3]中最先进技术的前沿。

从贝叶斯的角度来看，额外的信息是由增强过程的知识带来的，而不是实际的额外数据。A(D)可以包含初始数据集的无限可能的变体，例如，当使用连续变换，如旋转或额外的噪声时。在实践中，A(D)是在训练过程中不断采样的，而不是事先在训练集中缓存所有可能的增强。在训练点估计神经网络时，这个过程是直接的，但在应用贝叶斯统计学时有一些微妙的地方。主要的问题是，感兴趣的后验是p(φ|D,Auд)，其中Auд代表关于增强的一些知识，而不是p(φ|A(D),D)。这意味着，从贝叶斯的角度来看，数据增强不应该，或者至少不应该仅仅被视为额外的数据，而应该被视为模型的隐性转换，以其他方式说明，作为先验。此外，在传统的统计学背景下，数据增殖的概念反而与缺失值的建模有关[84]，这是一个相关但不同的问题

增加更多的数据点或多次计算类似的数据点的效果将是使后验更加集中在MAP点估计值周围，即假设一个模型具有给定的可能性p(y|x,θ)，计算相同的数据点相当于将可能性改为。

从贝叶斯的角度来看，这并不是不正确的，因为它可以通过修改原始随机模型中的似然来完成。然而，当增加的数据集的规模变得无限大时，这就带来了一个问题，即正确地解释认识上的不确定性。

可以说，数据增强应该在随机模型中实现。这个想法是，如果一个人得到了数据D，那么他也可能得到了数据D′，其中D中的每一个元素都被增强所替代。那么D′就是数据D′的一个不同角度。作为模型，我们有一个增强分布p(x′|x,Auд)，使用增强模型Auд对观察到的数据进行增强，以产生（概率上）x′。这个x′是x附近的数据（图9）。然后x′可以被边缘化以简化随机模型。

通过设置：


我们可以将增强的贝叶斯后验定义为：。


这是与邻近风险[12]相对应的一种概率。使用这种形式的增强似然，可以避免上述天真的方法会出现的多重计数。


在实践中，这意味着我们可以用蒙特卡洛方法进行方程（33）中的积分，所以我们根据top(x′|x,Auд)对一小部分增量Ax进行取样，然后平均


那么，在训练中使用的相关成本函数就变成了：

Axc可以包含少至一个元素，只要它在每次优化迭代中被重新采样即可。这大大简化了方程（36），特别是当指数家族的分布被用于建立随机模型时。

这种方法的一个延伸是在半监督学习的背景下，加入一个训练成本，以鼓励增强下的预测的一致性[82,95]，其中未标记的数据被用来建立一致性项的样本。请注意，这并不是给未标记的例子添加标签。它增加了一个术语来鼓励无标签数据的标签和其增强的一致性。

### 6.3 元学习、转移学习和自我监督学习

广义的元学习[33]，是指使用机器学习算法来协助其他机器学习模型的训练和优化。通过元学习获得的元知识可以区别于标准知识，因为它适用于一组相关的任务，而不是单一的任务。

转移学习指的是在给定问题上获得的一些中间知识被重新用于解决一个不同的问题的方法。在深度学习中，它主要用于领域适应，当标记的数据可用时，在与感兴趣的领域有某种相似的丰富的数据，而在感兴趣的领域却很稀缺[67]。另外，一些预训练的模型[73]也是一种解决方案，用于研究架构，以至于从头开始多次训练在实践中变得很不方便。

自监督学习是一种由数据本身提供标签的学习策略[36]。由于数据直接获得的标签与感兴趣的任务不匹配，所以问题被当作元学习来处理，在感兴趣的任务之外还有一个借口（或代理）任务。使用自我监督的产品现在被普遍认为是某些领域的必要步骤。例如，在自然语言处理中，大多数先进的方法都使用这些预训练的模型[73] 。

在我们对元学习的贝叶斯理解中，从上面的广义定义中得出，我们认为转移学习和自我监督学习都是元学习的特例。

贝叶斯统计中元学习的一个常见方法是将问题重塑为层次贝叶斯[25]，其中每个任务的先验p(θt|ξ)都以一个新的全局变量ξ为条件（图。ξ可以代表一些连续的元参数（本教程的重点）或关于BNN结构的离散信息（学习可能的功能模型的情况）或PGM的底层子图（学习可能的随机模型的情况）。如果需要的话，可以增加多个层次来组织更复杂的任务，但我们将只介绍的情况下，作为一般化的一个层次是直截了当的。一般的后验成为

因此，在实践中，通常用经验贝叶斯法来处理问题（第7.4节），只考虑全局变量的点估计值ξ，最好是通过边际化p(θ,ξ|D)并选择最可能的点来获得MAP估计值，但这并不总是如此

在迁移学习中，通常的方法是设置ξ=θm，θm是主任务的系数。然后，新的先验可以从ξ中获得，例如

未选择的参数按惯例被赋予0的平均值，但也可以使用其他方法来设计先验参数的这些部分。如果BNN已经为主要任务进行了训练，那么σ可以在以前的后验上进行估计，但仍然需要略微放大以考虑额外的不确定性。

自我监督学习可以分两步实现，首先学习预言任务，然后使用转移学习。这可能被认为是过于复杂，但如果预设任务具有较高的计算复杂性（例如，自然语言处理中的BERT模型[73]），则可能需要这样做。最近的贡献表明，联合学习预设任务和最终任务（图10b）可以改善自我监督学习中获得的结果[4]。这种方法更接近于hierarchical Bayes，也允许一次性设置先验，同时仍然保留了自我监督学习的优点。

## 7 贝叶斯推断算法

先验地，使用BNN时不必经历学习阶段，只需对后验进行抽样并进行模型平均化（见公式（4）和（6））。但在一般情况下，对后验进行采样并不容易。如果数据的条件概率P(D|H)和模型的概率P(H)是由我们的先验和模型给出的，那么证据项∫HP(D|H′)P(H′)dH′的积分可能就很难计算。对于非微观模型，即使已经计算了证据，，也很难直接对后验进行采样，由于高维度的抽样空间和均匀随机变量的样本的非微妙的转变。不使用传统的方法对后验进行抽样，如反转抽样或拒绝抽样，而是使用专门的算法。最流行的是马尔科夫链蒙特卡洛方法，这是一种对后验进行精确采样的算法系列，或者是变异推理，这是一种学习后验近似值的方法（图4）。本节回顾这些方法

### 7.1 马尔科夫链蒙特卡洛

马尔科夫链蒙特卡洛方法的思想是构建一个马尔科夫链，一个随机样本序列Si，其概率上只取决于前一个样本Si-1，这样序列中的元素最终会按照一个期望的分布进行分布。与标准的、简单的、低维的抽样方法不同，如拒绝抽样或反转抽样，大多数MCMC算法在底层马尔可夫链收敛到所需分布之前，需要一些初始烧录时间。另外，连续的Sim可能是自相关的。这意味着必须生成一大批样本Θ，并进行子采样，以便从基础分布中获得近似独立的样本。此外，一定数量的初始样本必须在序列开始时被丢弃，而准确的数量并不总是容易定义。最后但并非最不重要的是，最终的样本集合Θ必须在训练后被缓存，这可能是非常昂贵的，即使对于平均规模的深度学习模型。

尽管有其固有的缺点，MCMC方法可以被认为是贝叶斯统计学中从精确后验分布中取样的最佳可用和最流行的解决方案之一[2]。然而，并非所有的MCMC算法都与贝叶斯深度学习有关。例如，吉布斯抽样[22]在一般统计学和无监督机器学习中非常流行，但很少用于BNNs。与贝叶斯神经网络最相关的一类MCMC方法是Metropolis-Hastings算法[13]。使得Metropolis-Hastings算法流行的特性是，它们不需要知道确切的概率分布P(x)来进行抽样。相反，一个与该分布成正比的函数f(x)就足够了。这就是贝叶斯后验分布的情况，除了证据项之外，它通常很容易计算。

Metropolis-Hasting算法的基本思想是以一个随机的初始猜测x0开始，然后在前一个候选点的 "周围 "抽取一个新候选点。如果这个候选点比前一个候选点更有可能（根据我们想要取样的分布），那么它就被接受。如果它的可能性较小，那么它将以一定的概率被接受，否则被拒绝。

更正式地说，算法，见算法1，是用一个提议分布Q(x′|x)构建的，它告诉我们如何 "围绕 "先前的样本进行采样

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig40.webp)

算法1的接受概率可以被证明是产生所有可逆的Makrov链中接受度最高的。此外，如果选择Q是对称的，即Q(x′|xn)=Q(xn|x′)，则概率可以简化，接受率的公式为

在这种情况下，该算法被简单地称为Metropolis方法。Q的常见选择可以是正态分布Q(x′|xn)=N(xn,σ2)，或均匀分布Q(x′|xn)=U(xn-ε,xn+ε)，以先前的样本为中心。但有时，我们必须处理非对称分布，例如，为了适应模型中的约束，比如所考虑的分布域是有界的。在这种情况下，我们必须考虑到完整的Metropolis-Hasting算法所带来的修正项

建议分布的范围必须加以调整。如果它太大，拒绝率会太高。如果它太小，样本就会有更多的自动关联性。目前还没有调整这些参数的一般方法。然而，一个巧妙的策略来获得新提议的样本x′可以减少这些参数的影响。这就是为什么Hamilton Monte-Carlo方法被提出来了

Hamiltonian Monte-Carlo算法[62]是Metropolis-Hasting算法的另一个例子，该算法为连续分布设计了一个巧妙的方案来抽取新的提议x′，以确保尽可能少的样本被拒绝，并且样本之间的相关性尽可能少。此外，燃烧的时间也非常短。产生新跳跃的过程是基于汉密尔顿力学的。首先，我们假设从实际位置xn开始，我们将以初始随机速度v从一个提议分布Q(v)中移动。然后，我们定义系统的哈密顿力学为。

势能，loд(P(x))被认为是势能，loд(Q(v))是动能。我们让系统在给定的时间T内运动。相应的动力系统被以下PDE参数化。

的初始条件x′0=xnandv0=v′。这样做的好处是，我们仍然需要知道分布P，但只需要知道一个比例系数。我们接受拟议的样本x′T，其概率yp计算为：。

现在，由于哈密顿人随着时间的推移而保存下来，所以P应该等于1，而且新闻样本永远不会被拒绝。问题是，如果不是不可能的话，得到一个精确的解决方案往往是很难的，所以我们必须依靠数字积分来代替。要做到这一点，需要使用一个对称积分器。这是一个代表离散哈密顿系统H′(x,v)的积分器，与原来的连续系统H(x,v)相比，最好只受到轻微的扰动。这就保留了MCMC算法底层马尔科夫链的重要特性，其中最主要的是，如果所考虑的哈密尔顿路径在起点x0上循环，数值积分器也会在x0上循环。请注意，大多数数值积分器，包括流行的Runge-Kutta方案，不是对称性的。交互式积分器的一个很好的选择是跃迁式，其时间步长∆t

有了这个对称积分器，我们在原哈密顿H(x,v)和修正的哈密顿H′(x,v)之间有如下关系

这意味着很容易适应性地调整整合步骤∆t来调整接受概率p

现在的问题是选择提议分布Q(v)和积分时间T。Q(v)通常被选择为正态分布N(0,Σ)。对Σ最明显的选择是σ2I.σ2可以增加，以提高对远离先前样本的新点的采样几率。如果它太短，那么连续的样本就有可能是自相关的。如果它太大，那么哈密顿路径可能会循环，大量的时间将被浪费在反复积分相同的东西上。

有人提出了对经典HMC算法的改进，以自动调整积分时间[31]，称为No-U-Turn采样器（简称NUTS），大多数贝叶斯统计软件包都实现了这一点。

## 7.2 变分推断



![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig01.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig02.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig03.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig04.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig05.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig06.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig07.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig08.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig09.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig10.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig11.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig12.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig13.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig14.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210918_fig15.webp)

