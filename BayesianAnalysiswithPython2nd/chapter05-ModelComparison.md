# 第 5 章 模型比较

<style>p{text-indent:2em;2}</style>

```{note}
地图不是它所代表的领土，但如果正确的话，它的结构与该领土相似。---阿尔弗雷德·科日布斯基
```

模型应该被设计成帮助我们理解特定问题或某类相关问题的近似值。模型并不是真实世界的翻版，因此所有模型都是错误的，就像地图不是领土一样。即使在先验情况下，每个模型也都是错误的。但每个模型的错误可能不同：一些模型比其他模型更好地描述给定的问题。前面章节将注意力集中在推断问题上，即如何从数据中学习参数值。本章将重点讨论一个互补问题：如何比较用于解释相同数据的两个或多个模型。这是数据分析需要解决的核心问题之一。

本章将讨论以下内容：

1. 后验预测检查
2. 奥卡姆剃刀---简单性和准确性
3. 过拟合和欠拟合
4. 信息准则
5. 贝叶斯因子
6. 正则化先验

## 5.1 后验预测性检查

第一章“概率思维”介绍了后验预测检查的概念，本章将用它来评估拟合出的模型对相同数据的解释程度。后验预测检查的目的并非断定某个模型是否错误，而是通过后验预测检查更好地把握模型的局限性，并做出适当改进。模型不会再现问题所有方面，但这并不是问题，因为构建模型都有特定目的，而后验预测检查是在该目的背景下评估模型的一种方式；因此，如果我们有多个模型，可以使用后验预测检查来比较它们。

让我们上传并绘制一个非常简单的数据集：

```python
dummy_data = np.loadtxt('../data/dummy.csv')
x_1 = dummy_data[:, 0]
y_1 = dummy_data[:, 1]
order = 2
x_1p = np.vstack([x_1**i for i in range(1, order+1)])
x_1s = (x_1p - x_1p.mean(axis=1, keepdims=True)) / x_1p.std(axis=1, keepdims=True)
y_1s = (y_1 - y_1.mean()) / y_1.std()
plt.scatter(x_1s[0], y_1s)
plt.xlabel('x')
plt.ylabel('y')
```
<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510111807b3.webp)
图 5.1 
</center>

现在，将用两个略有不同的模型来拟合数据，一个是线性模型，另一个是二阶多项式，也称为抛物线或二次模型：

```python
with pm.Model() as model_l:
α = pm.Normal('α', mu=0, sd=1)
β = pm.Normal('β', mu=0, sd=10)
ϵ = pm.HalfNormal('ϵ', 5)
μ = α + β * x_1s[0]
y_pred = pm.Normal('y_pred', mu=μ, sd=ϵ, observed=y_1s)
trace_l = pm.sample(2000)

with pm.Model() as model_p:
α = pm.Normal('α', mu=0, sd=1)
β = pm.Normal('β', mu=0, sd=10, shape=order)
ϵ = pm.HalfNormal('ϵ', 5)
μ = α + pm.math.dot(β, x_1s)
y_pred = pm.Normal('y_pred', mu=μ, sd=ϵ, observed=y_1s)
trace_p = pm.sample(2000)
```

现在，我们将绘制这两个模型的平均拟合曲线：

```python
x_new = np.linspace(x_1s[0].min(), x_1s[0].max(), 100)
α_l_post = trace_l['α'].mean()
β_l_post = trace_l['β'].mean(axis=0)
y_l_post = α_l_post + β_l_post *x_new
plt.plot(x_new, y_l_post, 'C1', label='linear model')
α_p_post = trace_p['α'].mean()
β_p_post = trace_p['β'].mean(axis=0)
idx = np.argsort(x_1s[0])
y_p_post = α_p_post + np.dot(β_p_post, x_1s)
plt.plot(x_1s[0][idx], y_p_post[idx], 'C2', label=f'model order {order}')
α_p_post = trace_p['α'].mean()
β_p_post = trace_p['β'].mean(axis=0)
x_new_p = np.vstack([x_new**i for i in range(1, order+1)])
y_p_post = α_p_post + np.dot(β_p_post, x_new_p)
plt.scatter(x_1s[0], y_1s, c='C0', marker='.')
plt.legend()
```

<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510112129a4.webp)
图 5.2 
</center>

二阶模型似乎做得更好，但线性模型并没有那么糟糕。让我们使用 PyMC3 来获得两个模型的后验预测样本：

```python
y_l = pm.sample_posterior_predictive(trace_l, 2000, model=model_l)['y_pred']
y_p = pm.sample_posterior_predictive(trace_p, 2000, model=model_p)['y_pred']
```

正如我们已经看到的，后验预测检查通常使用可视化来执行，如下例所示：

```python
plt.figure(figsize=(8, 3))
data = [y_1s, y_l, y_p]
labels = ['data', 'linear model', 'order 2']
for i, d in enumerate(data):
mean = d.mean()
err = np.percentile(d, [25, 75])
plt.errorbar(mean, -i, xerr=[[-err[0]], [err[1]]], fmt='o')
plt.text(mean, -i+0.2, labels[i], ha='center', fontsize=14)
plt.ylim([-i-0.5, 0.5])
plt.yticks([])
```
<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510112319ed.webp)
图 5.3
</center>

上图显示了数据、线性模型和二次模型的平均值和四分位数范围 (IQR) 。该图对每个模型的后验预测样本进行平均，可以看到，两个模型的平均值都复现得很好，分位数范围也不是很差，但在实际问题中，有一些小差异可能值得注意。可以做更多不同曲线图来探索后验预测分布。例如，可以绘制平均值和四分位数间相对于均值的离散度。下图就是这样一个例子：

```python
fig, ax = plt.subplots(1, 2, figsize=(10, 3), constrained_layout=True)
def iqr(x, a=0):
return np.subtract(*np.percentile(x, [75, 25], axis=a))
for idx, func in enumerate([np.mean, iqr]):
T_obs = func(y_1s)
ax[idx].axvline(T_obs, 0, 1, color='k', ls='--')
for d_sim, c in zip([y_l, y_p], ['C1', 'C2']):
T_sim = func(d_sim, 1)
p_value = np.mean(T_sim >= T_obs)
az.plot_kde(T_sim, plot_kwargs={'color': c},
label=f'p-value {p_value:.2f}', ax=ax[idx])
ax[idx].set_title(func.__name__)
ax[idx].set_yticks([])
ax[idx].legend()
```
<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051011245094.webp)
图 5.4
</center>

图 5.4 中黑色虚线表示根据数据计算的平均值和四分位数。因为只有一个数据集，所以只有一个统计值，而不是分布。图中曲线（与图 5.3 相同颜色代码）表示根据后验预测样本计算得出的平均值分布（左图）或四分位数范围分布（右图）。图 5.4 还包括标记为 `p-value` 的值，该值来自于预测数据与实际数据的比较和计算。对于两个预测数据集合，我们计算了其平均值和四分位数范围，然后计算了两个统计量等于或大于根据实际数据统计量的比例。一般而言，如果数据和预测结果一致，预期的 `p-value` 值在 0.5 左右，否则将处于有偏的后验预测分布。

```{tip}
贝叶斯 p 值只是一种衡量后验预测检查拟合度的数字方法。
```

贝叶斯 `p-value` 与频率派的 `p-value` 名字相似，定义基本上也相同：

$$
\text{Bayesian p-value}\triangleq p\left(T_{s i m} \geq T_{o b s} \mid y \right)
$$

可以解释为：从模拟数据中获得比观测数据相同或更高统计量值的概率。$T$ 几乎可以是数据的任意统计量。在图 5.4 中，是左侧的平均值和右侧的四分位数范围。$T$ 应该在最初定义推断问题时就选择。

这些 `p-value` 是贝叶斯的，因为其采样自后验预测分布。需要注意的是：贝叶斯的 `p-value` 不需要频率注意的任何零假设作为条件；事实上，我们拥有基于观测数据的整个后验分布。此外，贝叶斯也没有使用类似置信度的任何预定义阈值来声明统计显著性，当然也没有执行假设检验。这里只是试图计算一个数字来评估后验预测分布与数据集的拟合度。

后验预测检查，无论是使用曲线图还是数字摘要（如贝叶斯 `p-value` ），甚至是两者组合，都是非常灵活的想法。该概念可以让分析师想出不同方法来探索后验预测分布，并使用任何合适的方法来讲述一个数据驱动的故事，包括但不限于模型比较。在接下来几节中，我们将探索一些其他模型比较的方法。

## 5.2 奥卡姆剃刀 --- 简约性与准确性

假设对于同一个问题/数据有两个模型，二者对数据解释得同样好，应该选哪个模型呢？有一个准则叫做奥卡姆剃刀，描述的是：如果对于同一现象有两种不同假说，应该选用比较简单的那一种。关于奥卡姆剃刀的论证有很多，其中之一与波普尔的可证伪性有关，还有一种说法是从实用角度提出的，因为简单模型相比复杂模型更容易理解，另外还有一种论证是基于贝叶斯统计。这里暂且不深入讨论细节，只是将该准则当做一个有用而合理的常识。

在比较模型时，通常需要同时考虑模型的准确性，即模型对数据拟合得怎么样。我们已见过一些衡量准确性的指标，如： $R^2$ 系数可视为线性回归中可解释方差的比例。但如果有两个模型，其中一个模型对数据的解释比另一个更准确，我们是否应该选更准确率的模型呢？

直觉上，我们似乎倾向于那些准确度高并且简单的模型。但如果更简单的模型准确度最差，该怎么办？如何才能平衡这两种要素呢？本章比前面几章更偏理论些。为简化问题，引入一个例子来帮助理解如何平衡准确性与复杂性，实现从感性认识到理论证明的跨越。

该例中将使用一系列逐渐复杂的多项式来拟合一个非常简单的数据集，为方便理解，这里没有采用贝叶斯方法，而是采用最小二乘方估计来拟合线性模型。当然，最小二乘估计其实可以转化成一个带均匀先验的贝叶斯模型，因此，理解成贝叶斯方法也没有问题。

```python
x = np.array([4., 5., 6., 9., 12, 14.])
y = np.array([4.2, 6., 6., 9., 10, 10.])
plt.figure(figsize=(10, 5))
order = [0, 1, 2, 5]
plt.plot(x, y, 'o')
for i in order:
    x_n = np.linspace(x.min(), x.max(), 100)
    coeffs = np.polyfit(x, y, deg=i)
    ffit = np.polyval(coeffs, x_n)
    p = np.poly1d(coeffs)
    yhat = p(x)
    ybar = np.mean(y)
    ssreg = np.sum((yhat-ybar)**2)
    sstot = np.sum((y - ybar)**2)
    r2 = ssreg / sstot
    plt.plot(x_n, ffit, label=f'order {i}, $R^2$= {r2:.2f}')
plt.legend(loc=2)
plt.xlabel('x')
plt.ylabel('y', rotation=0)
```
<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210512104113_44.webp)
图 5.5 
</center>

### 5.1.1 参数太多导致过拟合

从图 5.5 中可看出，当模型复杂度增加时，对应的 $R^2$ 系数也在上升。当多项式为 5 阶时，模型完美拟合了数据。前面章节中我们讨论过，用多项式去解决实际问题并不是一个特别好的办法。

为什么 5 阶多项式能够完美地拟合所有数据呢？原因是模型中参数的个数与样本个数相同，都是 6，因此，模型只是用另一种方式对数据进行了编码，此时模型并没有从数据中学到任何内容，只是记住了全部的数据。此外，如果用不同的模型做预测时，5 阶多项式模型对数据的预测看起来非常奇怪。

假设我们收集了更多数据点。例如，我们收集到点 [(10，9)，(7，7)] （参见图 5.6)。与 1 阶或 2 阶模型相比，5 阶模型对这些点的解释效果如何？不是很好，对吧？5 阶模型没有在数据中学习任何有趣的模式；相反，它只是记住了一些东西，因此 5 阶模型在泛化到未来的数据方面做得非常糟糕：

<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210512104753_be.webp)
图 5.6
</center>

当一个模型与最初用于学习其参数的数据集非常吻合，但在拟合其他数据集却非常差时，被称为过拟合。这是统计学和机器学习中一个普遍问题。描述过拟合问题的有用方法是认为数据集`信号`和`噪声`两部分组成。信号是我们想要从数据中了解到的任何东西，如果我们使用数据集，那是因为认为那里有一个信号，否则将是无用的训练。另一方面，噪声是无用的，往往是测量错误、数据生成或捕获方式的限制、数据损坏等因素的产物。当一个模型非常灵活，甚至可以学习噪声，从而隐藏信号时，这个模型就会变得过拟合。这也是奥卡姆剃刀的实际理由。上例告诉我们，如果仅仅关注模型对数据的解释能力，很可能会被误导，因为理论上始终可以通过增加模型参数数量来提高准确率。

### 5.1.2 参数太少导致欠拟合

继续同样的例子，不过这次重点关注的不是非常复杂的模型，而是 0 阶的模型。在 0 阶模型中，所有的 $\beta$ 参数都为 0，因而两个变量间的线性关系变成了只是描述因变量的一个高斯模型，注意对于 0 阶模型来说，自变量对模型不再有任何影响，而且模型只能捕捉到因变量的均值。换句话说，模型认为数据能够通过因变量的均值以及一些高斯噪声来解释。我们称这种模型是欠拟合的，因为它实在太简单了，以至于并不能从数据中获取到有意义的模式。通常，一个参数很少的模型容易出现欠拟合。

### 5.1.3 简洁性与准确性之间的平衡

经常与奥卡姆剃刀准则一起提到的是爱因斯坦的一句名言"事情应该尽可能简单，但不必过于简单"。这就好像健康饮食，我们在建模的时候也需要保持某种平衡。理想状态下，我们希望模型既不过拟合又不欠拟合，因此，通常需要优化或者调整我们的模型来权衡二者。

这种权衡通常是从`方差（variance）`和 `偏置（bias）`角度来讨论的：

- 高偏置（ `bias` ）是模型适应数据的能力不足导致的。高偏置可能使得模型不能捕捉到数据中一些关键的模式，因而导致欠拟合。
- 高方差（ `variance`）是模型对数据中细节高敏感导致的。高方差会导致模型捕捉到数据中的噪声，因而可能导致过拟合。


在图 5.5 中，0 阶模型具有较高的偏置（和较低的方差），因为它偏向于在变量 $y$ 的平均值处返回一条平坦直线，而与 $x$ 值无关。5 阶模型具有较高的方差（和较低的偏置），你可以采用差别很大的方式设置六个点，你会发现它将完全适合其中的大多数。

具有高偏置的模型是具有更多偏见或惯性的模型，而具有高方差的模型是一个思想更开放的模型。太有偏见的问题是你没有能力容纳新证据；太开放的问题是你最终会相信荒唐的东西。总的来说，如果提升一个方面，就会导致另一方面下降，这也是为什么人们称之 `偏差-方差平衡`，而我们最希望得到的是二者平衡的模型。

### 5.1.4 衡量预测的准确度

在前面的例子中，很容易看出 0 阶模型非常简单，而 5 阶模型对于数据来说太复杂了，但是其他两个模型呢？要回答这个问题，我们需要一种更有原则的方式，一方面考虑准确性，另一方面考虑简单性。要做到这一点，我们需要引入几个新概念：

- 样本内精度：基于拟合模型的数据而测量得到的模型精度。
- 样本外精度：用拟合模型的数据以外的数据测量得到的模型精度（也称为 `预测精度`）。

对于数据和模型的任意组合，样本内精度平均将小于样本外精度。因此，使用样本内精确度会误导我们，使我们认为拥有一个比实际更好的模型。样本外测量比样本内测量更可取。但总体来说还是问题的。因此，我们需要放弃一部分数据--不是用于拟合模型，而是用于测试它。但对于大多数分析师来说，这可能是一种奢侈。为避免该问题，人们花费了大量精力来设计只使用样本内的数据来估计样本外精度的方法。其中两种方法包括：

- 交叉验证：这是一种经验性的策略，将数据分成多个子集，然后轮流将其中一个子集作为测试集，将剩余的子集作为训练集进行评估。
- 信息准则：这是几个相对简单的表达式的总称，可认为这些表达式能够近似执行交叉验证后获得的结果。
  

#### （1） 交叉验证（Cross-validation）

交叉验证是一种简单且在大多数情况下有效的解决方案，可以在不遗漏数据的情况下评估模型。此过程汇总在下图中。我们把数据分成大致相等的 $K$ 个部分，用其中 $K-1$ 部分来训练模型 $A_1$，剩下的一部分用来测试模型；然后，从训练集中重新选择不同的 $K-1$ 部分用于训练模型 $A_2$，并用剩余部分测试模型；如此直到完成所有 $K$ 轮，得到模型 $A_K$；然后将结果 $A$ 求平均。这就是所谓的 `K-折交叉验证` 。当 $K$ 等于数据点的数量时，就是所谓的 `留一法交叉验证(LOOCV)`。有时，在执行 `LOOCV` 时，如果数据点数量太大，则轮数可能会少于数据点总数：

<center>

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210512112629_82.webp)
图 5.7
</center>

交叉验证是机器学习从业者的谋生之本，有关更多细节，可以阅读Sebastian Raschka的《Python Machine Learning》一书，或Jack Vanderplas的《Python Data Science Handbook》。

交叉验证是一个非常简单而且强大的思想，不过对于某些模型或者某些量很大的数据而言，交叉验证的计算量可能超出能接受的范围。许多人尝试提出了一些其他更容易计算的量，来得到近似交叉验证的结果，或者应用到不能直接使用交叉验证的情况，如信息量准则。

#### （2） 信息量准则

信息量准则是一系列用来比较模型对数据拟合程度的方法，这类方法引入了一个惩罚项来平衡模型的复杂度。换句话说，信息量准则形式化地表示了我们在本章开头建立的一些直觉，用一种合适的方式平衡模型对数据的解释能力和模型的复杂程度。这些衡量方式的推导过程与信息论相关，不过这超出了本书的范围，我们只从实用的角度去理解这些概念。

**公式1：Log 似然与偏差**

一种衡量模型对数据的拟合程度的方法是计算模型预测结果与真实数据之间的均方差:

$$
\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\mathrm{E}\left(y_{i} \mid \theta\right)\right)^{2} 
$$

其中，$E(y_i|\theta)$ 是根据预估参数值得到的预测值。

可以看到基本上就是观察值和预测值之间的平均差异，求平方是为保证误差为正，不会相互抵消，此外相比其他的衡量指标（比如绝对值误差），该衡量标准更强调较大的误差。更通用的一种方法是计算 log 似然：

$$
\sum_{i=1}^{n} \log p\left(y_{i} \mid \theta\right) 
$$

当似然为正态分布时，这与二次均方误差成正比。由于历史原因，实践中人们通常不直接使用 log 似然，而是使用一个称作偏差平方和的量：

$$
-2 \sum_{i=1}^{n} \log p\left(y_{i} \mid \theta\right) 
$$

偏差平方和在贝叶斯方法和非贝叶斯方法中类似，区别在于，贝叶斯框架中 $θ$ 是来自后验的抽样。而在非贝叶斯方法中，$θ$ 是一个点估计。在使用偏差平方和的时候，需要注意以下两点：

- 偏差平方和越小，log 似然值越大，模型的预测结果与数据越吻合。因此我们**希望偏差平方和越小越好**。
- 偏差平方和衡量的是样本内的模型准确率，因而复杂模型通常会比简单模型的偏差平方和小，此时需要给复杂模型加入惩罚项。

下面我们将学习几个不同的信息量准则方法，它们的共同点是都使用了偏差平方和及正则项，区别在于偏差平方和和惩罚项的计算方式不同。

**公式2：AIC 信息量准则**

AIC 信息量准则（Akaike Information Criterion）是一个广泛应用的信息量准则，其定义如下：

$$
A I C=-2 \sum_{i=1}^{n} \log p\left(y_{i} \mid \hat{\theta}_{m l e}\right)+2 p A I C 
$$

其中, $pAIC$ 表示参数的个数， $\hat{\theta}_{m l e}$ 时 $\theta$ 的最大似然估计。最大似然估计在非贝叶斯方法中经常用到，等价于使用贝叶斯方法中的均匀先验的最大后验估计。注意这里 $\hat{\theta}_{mle}$ 是点估计而不是分布。

同样，这里的 −2 是出于历史原因。从实用角度来看，上式中的第 1 项考虑的是模型对数据的拟合效果，第 2 项衡量的是模型复杂度。因此，如果两个模型对数据的解释能力相同，但是其中一个比另一个的参数更多的话，AIC 会告诉我们应该选择参数更少的那个。

AIC 对于非贝叶斯方法来说很有用，但是对于贝叶斯方法可能会有些问题。原因之一是 AIC 没有使用后验，因而将估计中的不确定信息丢失了，此外假设用到的是均匀先验，因而该准则对于使用非均匀先验的模型来说不太合适。在使用非均匀先验时，不能简单地计算模型中参数的个数。合理使用非均匀先验相当于对模型使用了正则，因而会降低过拟合的可能，也就是说带正则模型的有效参数个数比真实参数个数要少。类似的情况在多层模型中同样会出现，毕竟多层模型可以看作是从数据中学习先验的有效方式。

**公式3：WAIC 通用信息量准则**
通用信息量准则（WidelyAvailableInformationCriterion，WAIC）是 `AIC` 的完全贝叶斯版本。与 `AIC` 一样，`WAIC` 有两个项：一项衡量模型对数据的拟合效果；另外一项衡量模型的复杂程度。

$$
\text{WAIC}=-2 l p p d+2 p_{W A I C} 
$$

这里* lppd *是点预测的 log，可以用下式近似：

![](C:/ProgramFiles/Typora/media/image1888.png){width="2.654928915135608in"height="0.46854877515310583in"}

这里首先从后验中采样* S *个样本并计算似然的均值，然后对于数据集中的* N *个数据点都重复该过程并求和。此外得到的有效参数个数可以用如下形式计算：

![](C:/ProgramFiles/Typora/media/image1889.png){width="2.4571106736657917in"height="0.2707163167104112in"}

也就是说，我们根据从后验中得到的* S *个采样值计算 log 似然的偏差，然后对* N *个数据点都重复该过程并求和。直观上看这似乎与 DIC 中计算有效参数个数的方法一样。在前面 AIC 部分讨论过，模型越灵活，就越倾向于得到分布更广（更分散）的后验。

贝叶斯信息准则

与逻辑回归的名字一样，该名称同样有误导性。贝叶斯信息、
准则（BayesianInformationCriterion，BIC）是用来校正 AIC 的一些问

题的，作者提出了一种贝叶斯校正方法。不过 BIC 实际上不是贝叶斯的方法，而是更像 AIC，因而假设先验是平坦的并使用最大似然估、
计。

235

更重要的是，BIC 与我们见过的其他信息准则都不一样，它更像后面章节中会讨论到的贝叶斯因子。基于这些理由，同时参考了 AndrewGelman 的建议，这里暂不深入讨论或使用 BIC。

一种获取贝叶斯形式的 AIC 的方法是从后验中获取信息，同时从模型和数据中估计出参数的个数，这可以用偏差信息量准则、
（DevianceInformationCriterion，DIC）来衡量：

![](C:/ProgramFiles/Typora/media/image1877.png){width="2.2488801399825022in"height="0.35401465441819774in"}

![](C:/ProgramFiles/Typora/media/image1878.png){width="0.333167104111986in"height="0.2394805336832896in"}可以看到 DIC 和 AIC 非常像，区别在于现在是从计算的偏差，即*θ*的后验均值，而且我们现在使用来代表模型的有效参数个数，用下式来表示：

![](C:/ProgramFiles/Typora/media/image1880.png){width="1.145262467191601in"height="0.35401465441819774in"}

![](C:/ProgramFiles/Typora/media/image1881.png){width="8.32917760279965e-2in"height="0.1770067804024497in"}上式的含义是偏差的均值减去均值的偏差。如果得到的是一个有峰值的后验，*θ*聚集在附近，那么上式中的左右两项会比较相似，因而会很小，相反，如果后验分布很广，那么会有更多的*θ*偏离，

![](C:/ProgramFiles/Typora/media/image1884.png){width="0.3852241907261592in"height="0.21865594925634296in"}因而会很大，从而也就很大。

可以说，DIC 是更偏贝叶斯形式的 AIC，不过，DIC 没有使用完、
整的后验，而且对于弱先验来说，根据 DIC 计算得到的参数的有效个

数会有些问题，为解决该问题，有一些替代方案。不过 DIC 对于这里的讨论来说足够了，PyMC3 中也已经实现了 DIC。

#### （3）帕累托平滑重要性采样与留一交叉验证

该方法用于近似 LOOCV 的结果，不过不需要真的计算 LOOCV。这里不过多深入其细节，其核心思想是通过对似然重采样去近似 LOOCV，可以通过一种重要性采样的技巧实现。该方法的问题是得到的结果不稳定，为解决稳定性的问题，有人提出了一种新的方法叫做 PSIS，可以用于计算更可靠的 LOOCV 估计，其含义类似，值越小，模型得到的估计预测准确率越高。

## 5.4 贝叶斯因子

在贝叶斯的世界中，评估和比较模型的另一种方式是使用贝叶斯因子。

使用贝叶斯因子时，在单个模型中可能存在某些先验对后验分布没有实际影响，但却对贝叶斯因子有较大影响。前面的例子中你可能注意到了，通常一个标准差为 100 的正态先验与标准差为 1000 的正态

先验对后验的效果差不多，而贝叶斯因子则会受到模型中这类变化的影响。贝叶斯因子的另外一个问题是计算起来可能要比推断过程更复杂。最后一点是，贝叶斯因子可以用来做假设检验，这本来不是什么问题，不过许多作者指出，类似本书提到的基于模型和推断的思维，要比基于假设检验的这类思维在大多数问题上更好。为更好地理解什么是贝叶斯因子，这里我们再重新写一遍贝叶斯理论：

![](C:/ProgramFiles/Typora/media/image1941.png){width="1.9157130358705161in"height="0.4477241907261592in"}

其中，*y *表示数据，*θ*表示参数，你也可以写成如下形式：

![](C:/ProgramFiles/Typora/media/image1942.png){width="2.842334864391951in"height="0.45813648293963255in"}

两个式子的唯一区别是：重写后的式子中显式地描述了推断过程中依赖的模型* M*。其中分母称为证据或者边缘似然。目前为止，得益于推断引擎（如 Metropolis 和 NUTS），我们将本项省略了。这里

可以将证据表示成如下：

![](C:/ProgramFiles/Typora/media/image1943.png){width="3.0713877952755904in"height="0.19783136482939634in"}

![](C:/ProgramFiles/Typora/media/image1944.png){width="0.666334208223972in"height="0.187419072615923in"}也就是说，为计算出证据，我们需要边缘化（通过求

243

![](C:/ProgramFiles/Typora/media/image1945.png){width="0.666334208223972in"height="0.187419072615923in"}和或者积分）所有可能的，即根据给定模型边缘化所有*θ*的先验。

![](C:/ProgramFiles/Typora/media/image1944.png){width="0.666334208223972in"height="0.187419072615923in"}本身没有多少信息量，就像信息准则一样，重要的是其、
相对值，因此，当我们希望比较两个不同模型的时候，我们会计算其

证据的比例，从而得到贝叶斯因子：

![](C:/ProgramFiles/Typora/media/image1948.png){width="1.3639041994750656in"height="0.45813648293963255in"}

当* BF*\1 时，模型 0 比模型 1 对数据解释得更好。有人总结出了下面的列表来表示模型 0 与模型 1 的对比。

1-3：微弱、
3-10：中等、
10-30：强、
30-100：很强、100：非常强

注意，这些准则都是一些经验性的指导，最终结果一定要放在具体场景中去解释，同时还应该给出足够多的信息方便别人检查，从而确定是否同意我们的结论。得出结论所需的证据在不同场合下是不一样的。比如说你是在做粒子物理学，或是在法庭上，又或者是决定是否要撤离一个城镇以防止数百人死亡。

5.4.1 类比信息量准则

如果对贝叶斯因子求 log，我们可以将两个边缘似然的比值转换、
成做差，这样比较边缘似然就与前面比较信息准则类似了。不过，衡

量模型对数据的拟合程度的项以及惩罚项去哪儿了呢？前者包含在了

244

似然的部分，而后者是对先验取平均的部分。参数越多，先验空间相比似然就越大，因而平均之后似然就会较低，而且参数越多，先验就会越分散，因而在计算证据的时候惩罚越大。这也是为什么人们说贝叶斯理论会很自然地惩罚更复杂的模型，或者称贝叶斯理论自带奥卡姆剃刀。

5.4.2 计算贝叶斯因子

![](C:/ProgramFiles/Typora/media/image1955.png){width="0.7392147856517935in"height="0.187419072615923in"}贝叶斯因子的计算可以视作分层模型的应用，其中高层的参数可以看作是从一个类别分布中采样后将序号赋给每个模型。换句话说，我们同时对两个（或多个）模型进行推断，同时用一个离散的变量在模型之间做选择。对每个模型的采样次数正比于，为计算

贝叶斯因子，我们有下式：

![](C:/ProgramFiles/Typora/media/image1955.png){width="2.4258759842519684in"height="0.45813648293963255in"}

等式右边的第一项称作后验相对可能性，第 2 项称作先验相对可能性。回忆一下前面我们对相对可能性的定义。如果你好奇等式是怎

![](C:/ProgramFiles/Typora/media/image1957.png){width="0.7288035870516185in"height="0.187419072615923in"}么来的，根据贝叶斯理论将和展开后相除即可。为展示贝叶斯因子的计算过程，这里再次以抛硬币问题为例。

coins=30

heads=9

y=np.repeat([0,1],[coins-heads,heads])

用 Kruschke 图将我们的模型表示出来，如图所示，该例子中，我们选用了两个 beta 先验：一个趋近于 0；另一个趋近于 1。

245

![](C:/ProgramFiles/Typora/media/image1964.png){width="3.768956692913386in"height="5.268577209098862in"}

注意这里我们计算贝叶斯因子时比较的是模型之间先验的不同，当然，模型之间的似然或者两者同时都有可能不同，本质上思想是一致的。接下来用 PyMC3 构建模型。为切换先验，我们使用了

pm.switch() 函数，如果该函数的第一个参数为 0，则返回第 2 个参、
数，否则返回第 3 个参数。这里我们同样使用 pm.math.eq() 函数去检查 model_index 变量是否为 0。

![](C:/ProgramFiles/Typora/media/image1965.png){width="3.818897637795276e-2in"height="1.8915616797900263in"}withpm.Model()asmodel_BF:\
p=np.array([0.5,0.5])\
model_index=pm.Categorical('model_index',p=p)

m_0=(4,8)\
m_1=(8,4)\
m=pm.switch(pm.math.eq(model_index,0),m_0,m_1)

theta=pm.Beta('theta',m[0],m[1])

y=pm.Bernoulli('y',theta,observed=y)

246![](C:/ProgramFiles/Typora/media/image1968.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}

![](C:/ProgramFiles/Typora/media/image1970.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}trace_BF=pm.sample(5000)chain_BF=trace_BF[500:]\
pm.traceplot(chain_BF)

![](C:/ProgramFiles/Typora/media/image1974.png){width="5.643024934383202in"height="1.7596620734908137in"}

现在我们可以通过变量 model_index 计算贝叶斯因子，注意我们已经有了每个模型的先验：

pM1=chain_BF['model_index'].mean()pM0=1-pM1

BF=(pM0/pM1)\*(p[1]/p[0])

最终得到的贝叶斯因子的值约为 11，也就是说，我们更倾向于使用模型 0。该结论完全合理，因为对于*θ*=5 的情况，正面朝上出现得更少，两个模型之间的唯一区别是模型 0 更适用于*θ*\<0.5（反面朝上多于正面朝上），而模型 1 更适用于*θ*\0.5（正面朝上多于反面朝上）。

下面讲一下计算贝叶斯因子的一些常见问题。

用我们定义的方式计算贝叶斯因子会有一些问题，比如当其中一个模型比另一个模型更好时，根据定义，我们会对更好的该模型采样次数更多，这可能会导致我们对另外一个模型欠采样。另外，第 1

个问题是：即使某些参数没有用于拟合数据，也会更新。也就是说，当模型 0 被选择时，模型 1 中的参数也会更新，不过由于这部分参数并没有用于解释数据，值受限于先验。如果先验太模糊，有可能当我们选到模型 1 时，参数值距离上一次被接受的值太远了，因而该步被拒

绝，从而导致采样会出现问题。

247

程。

为避免遇到这些问题，我们对模型做了两处修改来改进采样过

理想情况下，如果两个模型都访问相同次数，我们会得到一个更好的采样，因此我们对模型的先验做出调整（前一个模型中的* p *值），从而向原来访问频次较低的模型倾斜。该过程对贝叶斯因子的计算不会有多大影响，因为我们在计算过程中包含了先、
验。\
根据 Kruschke 以及其他人的建议，可以使用伪先验，其思想很简单：当没被选择的模型的参数出现自由漂移时，可以尝试手动限制它们，不过是在该模型没被使用的时候。你可以在 Kruschke 的书中找到使用伪先验的例子，我将对应的例子转成了、
Python/PyMC3，可以查看这里：\
[https://github.com/aloctavodia/Doing*bayesian_data*](https://github.com/aloctavodia/Doingbayesian_data)analysis。

248

5.5 贝叶斯因子与信息量准则

前面我们已经说过，贝叶斯因子对先验过于敏感，做推断时某些参数对推断结果几乎没有影响，但得到的贝叶斯因子却有很大区别。这也是许多贝叶斯学派的人不喜欢贝叶斯因子的原因之一。现在我

们来看一个例子，帮助我们理解什么是贝叶斯因子以及信息准则。回到抛硬币例子中定义数据的部分，现在我们将硬币数量设为 300 个，90 个正面朝上。该比例与之前的类似，不过现在的数据量是之前的 10 倍，然后单独运行每个模型。

withpm.Model()asmodel_BF_0:

theta=pm.Beta('theta',4,8)

y=pm.Bernoulli('y',theta,observed=y)

trace_BF_0=pm.sample(5000)chain_BF_0=trace_BF_0[500:]\
pm.traceplot(trace_BF_0);

![](C:/ProgramFiles/Typora/media/image1989.png){width="5.643024934383202in"height="0.791327646544182in"}

withpm.Model()asmodel_BF_1:

theta=pm.Beta('theta',8,4)

y=pm.Bernoulli('y',theta,observed=y)trace_BF_1=pm.sample(5000)\
pm.traceplot(trace_BF_1);

![](C:/ProgramFiles/Typora/media/image1994.png){width="5.643024934383202in"height="0.8017399387576553in"}

对后验进行检查，尽管二者的先验不同，可以看到两个模型的预测结果很相似。原因是我们有足够的数据，从而将先验的效果削弱了（尽管效果还在）。现在对两个模型计算贝叶斯因子，可以得到结果

249

约为 25，该结果意味着我们更倾向于模型 0。可以看出，当我们增加数据个数的时候，不同模型之间的对比更明显了，本点完全合、
理，因为数据更多的时候，我们更加确定模型 1 的先验假设与实际的数据不符。不过需要注意，当我们增加数据的时候，两个模型都倾向于得出相同的*θ*值，实际上两个模型得到的值都接近 0.3。因此，如果打算用*θ*做预测，那么两个模型其实没有特别大的区别。在该例子中，贝叶斯因子告诉我们一个模型要比另外一个模型更好，某种程度上是在帮助我们找到真正的模型，不过如果只是根据两个模型估计出来的参数做预测，二者的结果差不多。

再比较下 WAIC 和 LOO（如图）；模型 0 和模型 1 的 WAIC 分别约、
为 368.4 和 368.6，LOO 分别约为 365.4 和 365.7。直观上看区别似乎很小，不过重要的是在 30 个硬币中应该有 9 个正面朝上的情况下，模型 0 和模型 1 的 WAIC 分别为 38.1 和 39.4，LOO 分别为 35.6 和 38.0。也就是说，相对差别随着数据量的增加而减少了，*θ*的估计值越相似，根据信息准则得到的预测准确率的结果也越相似。该例子应该能澄清贝叶斯因子与信息准则之间的区别了。

下图显示了 WAIC 和 LOO 以及它们的标准差，第 1 行对应抛硬币问题中的 30 个样本中 9 次正面朝上的情况；第 2 行对应 300 个样本中 90

个正面朝上的情况。

250

![](C:/ProgramFiles/Typora/media/image1997.png){width="5.643024934383202in"height="3.8004560367454068in"}

251

## 5.5 正则先验

使用（弱）信息先验是给模型引入偏差的一种方式，如果引入得合理是一件好事，因为这有利于避免过拟合。

正则化的思想非常强大，在贝叶斯框架之外也有许多应用。在一些领域中，这种思想称作吉洪诺夫正则化。在非贝叶斯统计中，对于最小二乘法，正则化的思想有两种形式，分别是：岭回归和 Lasso 回归。从贝叶斯的角度来看，岭回归可以解释为对（线性回归中的）beta 系数使用了正态分布的先验，而且该正态分布的标准差很小（而不是习惯上的很大），因而达到把 beta 系数限制在 0 附近的目的，而 Lasso 回归则可以看作是对 beta 系数使用了拉普拉斯先验。标准形式的岭回归和 Lasso 回归对应的是点估计。如果严格应用贝叶斯分析的话是没法得到后验分布的。

在继续深入之前，我们先花点时间讨论下拉普拉斯分布。该分布与高斯分布很像，不过它的 1 阶导数在 0 附近没有定义，因为该分布在 0 附近有一个很尖锐的峰值（具体可以看下图）。拉普拉斯分布相

比高斯分布整体更靠近 0，因而当我们使用它作为先验的时候，会使得参数趋近于 0。也就是说，Lasso 可以用于正则化和变量筛选（将某些特征或变量从模型中去掉）。

下面的代码生成了 4 组中心为 0 的不同尺度的拉普拉斯分布，此外还有一个均值为零的标准差为 1 的高斯分布作为比较。

![](C:/ProgramFiles/Typora/media/image1845.png){width="3.818897637795276e-2in"height="1.2355938320209974in"}plt.figure(figsize=(8,6))

x_values=np.linspace(-10,10,300)

fordfin[1,2,5,15]:

distri=stats.laplace(scale=df)

x_pdf=distri.pdf(x_values)

plt.plot(x_values,x_pdf,label='\$b\$={}'.format(df))

227

![](C:/ProgramFiles/Typora/media/image1850.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}

x_pdf=stats.norm.pdf(x_values)

plt.plot(x_values,x_pdf,label='Gaussian')

plt.xlabel('x')

plt.ylabel('p(x)',rotation=0)

plt.legend(loc=0,fontsize=14)

plt.xlim(-7,7);

plt.savefig('B04958_06_03.png',dpi=300,figsize=[5.5,5.5])

![](C:/ProgramFiles/Typora/media/image1854.png){width="5.643024934383202in"height="4.248180227471566in"}

非常值得注意的一点是，这种人们广泛接受的正则化的思想非常自然地融合进了贝叶斯体系中。有人甚至说，既然大家都认同正则化是一个相当棒的思想，那么可以说每个人都在某种程度上是贝叶斯

的，尽管他们并没有意识到甚至拒绝该标签。

5.2.1 正则先验和多层模型

与我们刚才讨论的相一致，多层模型也可以被认为是一种正则化的方法。也就是通过引入超先验，将多层模型看作是从数据中学习先验的一种方法。所以，从某种意义上说，因为我们正在从数据中

228

学习先验，所以我们正在进行正规化，并且让数据告诉我们正规化的强度。这也许是对多层模型和收缩更深刻的理解。你可以思考一下在第四章里当我们使用多层模型对单个数据点拟合一条直线时，如何从正则化概念的角度来解释。

229







5.6 总结

本章开始我们先建立了这样一种直观感受：好的模型应该能简单有效地解释数据。基于该直觉，我们讨论了统计学和机器学习中的过拟合和欠拟合问题，首先分析了传统的 AIC，然后是与之类似的更符合贝叶斯的 DIC，接下来讨论了基于二者的改进版 WAIC。同时我们

还简单讨论了经验性的交叉验证方法以及采用 LOO 对其结果进行近似的方法。本章还从另外一个角度简要讨论了先验与多层模型。最后，我们讨论了贝叶斯因子，如何计算贝叶斯因子，以及如何解决一些与之相关的采样问题。本章的最后还解释了使用贝叶斯因子与信息准则的不同目的。

252

5.7 深入阅读

《StatisticalRethinking》中的第 6 章。

《DoingBayesianDataAnalysis,SecondEdition》中的第 10 章。《BayesianDataAnalysis,ThirdEdition》中的第 7 章。

JakeVanderPlas 关于模型选择的一篇博客：

<http://jakevdp.github.io/blog/2015/08/07/frequentism-and-\
bayesianism-5-model-selection/。\
用 LOOCV 和 WAIC 对贝叶斯模型进行评估：\
[http://arxiv.org/abs/1507.04544。](http://arxiv.org/abs/1507.04544。)

253

5.8 练习

（1）本题与正则先验有关。在生成数据部分的代码中，\
将 order=2 改成其他值，比如 order=5，然后拟合 model_p 并画出结

果的曲线。重复该过程，用 st=100 的 beta 分布替换 st=1 的 beta 分布并画出结果曲线。两种情况下的曲线有什么不同？如果换做、
sd=np.array([10,0.1,0.1,0.1,0.1]) 呢？

（2）重复上面的练习，将数据的个数增加到 500。

（3）用 3 阶的数据去拟合，计算 WAIC 和 LOO，画出结果，将它们与线性和抛物线模型进行比较。

（4）用 pm.sample_ppc() 重跑 PPC 的例子，不过画出* y *的值而非其均值。

（5）阅读并运行 PyMC3 官方文档中后验预测的例子：\
[https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html。](https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html。特别留意 Theano 中共享变量的使用。)

[特别留意 Theano 中共享变量的使用。](https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html。特别留意 Theano 中共享变量的使用。)

（6）分别用均匀先验 beta(1,1) 和其他先验（如 beta(0.5,0.5)）比、
较抛硬币问题中的贝叶斯因子。将数据个数设为 30，其中 15 次正面朝

上。将推断结果与第 1 章中得到的结果进行比较。

（7）重复本章最后一个例子，减少样本大小，然后再比较贝叶斯因子与信息量准则。

254