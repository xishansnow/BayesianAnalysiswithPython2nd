 #  第 8 章 推断引擎

<style>p{text-indent:2em;2}</style>

到目前为止，我们的重点是建立模型、解释结果和批判模型。依靠 `pm.sample` 函数的魔力计算后验分布。现在，我们将重点学习此函数背后的推断引擎。概率编程工具（如 `PyMC3` ）的目的是使用户不用关心如何进行采样，但了解如何从后验获取样本对于全面理解推断过程很重要，还可以帮助我们了解这些方法何时会失败、为什么失败、如何处理。如果您对了解近似后验的方法原理不感兴趣，可以跳过本章的大部分内容，但强烈建议您至少阅读样本诊断一节，因为这一节提供了一些指导原则，可以帮助您检查后验样本是否可靠。

计算后验分布的方法有很多。本章将讨论一些基本思想，并将重点介绍在 `PyMC3` 中实现的最重要的方法。

在本章中，我们将学习：
- 变分方法
- Metropolis-Hastings
- 汉密尔顿蒙特卡罗
- 序贯蒙特卡罗
- 样本诊断
  
---

## 8.1 几类推断引擎

虽然概念上很简单，但贝叶斯方法在数学和数值上都极具挑战性。主要原因是：贝叶斯定理（公式 1.4）中的分母边缘似然通常采用难以处理或计算昂贵的积分形式来求解。为此，后验估计通常使用马尔可夫链蒙特卡罗 (MCMC) 家族的算法或变分算法进行数值估计。这些方法有时被称为推断引擎，因为它们能够近似任何概率模型的后验分布。虽然在实践中推断并不总是那么好用，但这些方法也推动了概率编程语言（如 `PyMC3`) 的发展。

概率编程语言的目标是将建模过程与推断过程分开，以促进模型构建、评估和修改/扩展的迭代步骤。通过将推断过程视为黑匣子，`PyMC3` 等概率编程语言的用户可以将注意力放在他们关心的具体问题上，而让 `PyMC3` 为他们处理计算细节。这也是本书到目前为止一直在做的事情。因此，你可能会认为这是显而易见的方法。实际上，在概率编程语言出现之前，做概率模型的人习惯于编写自己的采样方法，通常是根据其模型量身定做的，或者习惯于简化模型，使其适合于某些数学近似。事实上，在一些学术界，这仍然是正确的。这种量身定制的方法更优雅，甚至可以提供一种更有效的后验计算方法，但也容易出错和耗时，即便对专家来说也是如此。

此外，定制方法不适合大多数用概率模型解决问题的从业者。像 `PyMC3` 这样的软件欢迎各种背景的人使用概率模型，从而降低了数学和计算的入门门槛。前面的章节主要是关于学习贝叶斯建模的基础知识；现在将在概念层面上学习如何实现自动推断，何时以及为什么失败，以及当失败时该怎么做。

目前有几种数值计算后验分布的方法。我把它们分成两大类：

**非马尔可夫方法**
- 网格计算法
- 二次逼近法或拉普拉斯近似法
- 变分方法
- 集成嵌入拉普拉斯近似（INLA）方法
  
**马尔可夫方法**
- Metropolis-Hastings法
- 哈密顿蒙特卡罗法
- 序贯蒙特卡罗法

## 8.2 非马尔可夫方法

首先讨论非马尔科夫方法的推断引擎。对于某些问题，此类方法非常有效，而对另外一些问题，此类方法只能提供真实后验的粗略近似。

### 8.2.1 网格计算法

网格计算法是一种暴力穷举的方法。即便你无法计算出整个后验，也可以根据一些点计算出先验和似然。假设我们要计算某个单参数模型的后验，网格近似法可以按照如下方式进行：

- 确定参数的一个合理区间（先验会给你点提示）；
- 在以上区间确定一些网格点（通常是等距离的）；
- 对于网格中的每个点计算先验和似然。
  
视情况，可能会对计算结果进行归一化（把每个点的计算结果除以所有点的计算结果之和）。很容易看出，选的点越多（网格越密）近似的结果就越好。事实上，如果使用无限多点，可以得到准确的后验。

网格计算法对于多参数的场景不太适用，因为随着参数增加，采样空间相比后验空间会急剧增加，换言之，我们花费了大量
时间计算后验值，但对于估计后验却几乎没有帮助（计算后验的时间比用后验做预测和推断的时间还长很多），因而该方法对于大多数统计学和数据科学问题不太实用。

下面的代码用网格计算法解决第一章中的抛硬币问题：

```python
def posterior_grid(grid_points=50, heads=6, tails=9):
    """
    A grid implementation for the coin-flipping problem
    """
    grid = np.linspace(0, 1, grid_points)
    prior = np.repeat(1/grid_points, grid_points)  # uniform prior
    likelihood = stats.binom.pmf(heads, heads+tails, grid)
    posterior = likelihood * prior
    posterior /= posterior.sum()
    return grid, posterior
```

假设我们抛硬币 13 次，观察到 3 个头：

```python
data = np.repeat([0, 1], (10, 3))
points = 10
h = data.sum()
t = len(data) - h
grid, posterior = posterior_grid(points, h, t)
plt.plot(grid, posterior, 'o-')
plt.title(f'heads = {h}, tails = {t}')
plt.yticks([])
plt.xlabel('θ');
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716063392.webp)

很容易注意到，点数量越多（或者等效地：网格越小），可以得到更好的近似值。事实上，在无限个点的限制下，我们会以增加计算资源为代价得到精确的后验结果。

网格法最大的问题是：此方法不能很好地随参数（也称为维度）数量进行调整。可以通过一个简单的例子来了解这一点。假设我们想要采样一个单位区间（参见图 8.2)，就像抛硬币问题一样，使用四个等距点。这意味着分辨率为 0.25 个单位。现在假设有一个 2D 问题（图 8.2 中的正方形），并且想使用具有相同分辨率的网格，将需要 16 个点，而对于 3D 问题，我们将需要 64 个点（参见图 8.2 中的立方体）。本例中从边场为 1 的立方体采样所需的资源是长度为 1、分辨率为 0.25 的线采样的 16 倍。如果决定需要 0.1 个单位的分辨率，则必须对直线采样 10 个点，对立方体采样 1000 个点：

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607160809ce.webp)

除了点数增加，还有另一种现象，它不是网格法的属性，也不是其他方法的属性，而是高维空间的特性。随着`参数数量`增加，与采样体积相比，大部分后验集中在参数空间中越来越小的区域。这是统计学和机器学习中的普遍现象，通常被称为`维度诅咒`，或者数学家更喜欢将其称为 `量度集中`。

名称中的`维度诅咒`用来讨论各种相关现象，这些现象在低维空间中不存在，但在高维空间中存在。以下是这些现象的一些例子：

- 随着维数增加，任意一对样本之间的欧几里得距离变得越来越近。也就是说，在高维空间中，大多数点彼此之间的距离基本相同。
- 对于超立方体，大部分体积在其角落，而不是在中间。对于超球体，大部分体积在其表面，而不在中间。
- 在高维中，多变量高斯分布的大部分质量并不非聚集在平均值或众数，而是在其周围的壳层中，而且随着维数增加，壳层从高斯分布的平均值向尾部移动。
  
有关其中一些事实的代码示例，请查看 [链接](https:/​/​gihub.​com/aloctavodia/​BAP)

所有这些事实都意味着，如果不明智地选择在哪里评估后验，我们将花费大部分时间来计算对后验贡献几乎为零的值，从而浪费宝贵的资源。网格法不是一种选择在哪里评估后验分布的明智方法，特别是对于高维问题。

### 8.2.2 二次近似法

二次近似法，也称为 `拉普拉斯方法` 或 `正态近似法`，包括用高斯分布 $q(x)$ 来近似后验分布 $p(x)$。

此方法由两个步骤组成：

- 找出真实后验分布的众数，并将其作为 $q(x)$ 的均值。
- 计算 Hessian 矩阵。由此可以计算出的 $q(x)$ 的标准差。
  
第一步可以使用最优化方法进行数值计算，也就是找出函数的最大值或最小值，有许多现成的方法。对于高斯分布，众数和均值相等，所以可以使用众数作为近似分布 $q(x)$ 的平均值。第二步稍微复杂些，通过计算众数/平均值处的曲率来近似计算 $q(x)$ 的标准差。这可以通过计算海森矩阵的平方根的倒数来实现。海森矩阵是函数二阶导数的矩阵，其逆矩阵为协方差矩阵。使用 `PyMC3`，可以执行以下操作：

```python
with pm.Model() as normal_approximation:
     p = pm.Beta('p', 1., 1.)
     w = pm.Binomial('w',n=1, p=p, observed=data)
     mean_q = pm.find_MAP()
     std_q = ((1/pm.find_hessian(mean_q, vars=[p]))**0.5)[0] mean_q['p'], std_q
```

```{note}
如果您尝试在 `PyMC3` 中使用 pm.find_map 函数，您将收到一条警告消息。由于维数灾难，使用最大后验概率 (MAP) 来表示后验，甚至初始化采样方法通常不是一个好主意。
```

让我们看看贝塔-二项模型的二次近似是什么样子：

```python
# analytic calculation
x = np.linspace(0, 1, 100)
plt.plot(x, stats.beta.pdf(x , h+1, t+1),
         label='True posterior')
# quadratic approximation
plt.plot(x, stats.norm.pdf(x, mean_q['p'], std_q),label='Quadratic
         approximation')
plt.legend(loc=0, fontsize=13)
plt.title(f'heads = {h}, tails = {t}')
plt.xlabel('θ', fontsize=14)
plt.yticks([]);
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716150097.webp)

图 8.3 显示，二次近似并没有那么差。严格地说，我们只能将拉普拉斯法应用于无界变量，也就是 $\mathcal{R}^N$ 空间中的变量，因为高斯分布是一个无界分布。所以用它来近似一个有界分布（比如贝塔分布），会将实际密度为 0 点估计为正密度（如：贝塔分布的 [0，1] 区间之外）。可以考虑将有界变量变换为无界变量，进而使用拉普拉斯方法。例如，我们通常使用半正态分布来精确地模拟标准差，因为它被限制在 [0，∞) 区间内，可以通过取其对数来使半正态分布变量无界。

拉普拉斯方法的作用是有限的，但对某些模型可以很好地工作，并且可用来获得近似后验的解析解，进而提升推断的效率。拉普拉斯方法也是最近一种高级 `积分嵌套拉普拉斯近似 (INLA)方法` 的构建块之一。

下一节将讨论变分方法，其在某种程度上类似于拉普拉斯方法，但更灵活、更强大，其中一些方法可自动应用于各种模型。

### 8.2.3 变分方法

大多数现代贝叶斯统计都是使用马尔可夫方法（见下一节）完成的，但对于某些问题，马尔可夫方法可能太慢了。变分方法是一种替代方法，特别是对于大数据集和/或计算成本过高的后验而言，变分方法是更好的选择。

变分法的基本思想是用一种更简单的分布来近似后验分布，这类似于拉普拉斯方法，但采用更精细的方式。可以通过解决一个最优化问题来找到这个更简单的分布，这个最优化问题包括在某种度量相似程度的方法下找到与后验最接近的可能分布。衡量分布之间相似程度的常用方法是使用 `Kullback-Leibler(KL) 散度`（第 5 章中讨论过）。使用 `KL 散度` 可得：

$$
D_{K L}(q(\theta) \| p(\theta \mid y))=\int q(\theta) \log \frac{q(\theta)}{p(\theta \mid y)} d(\theta)  \tag{8.1}
$$

其中 $q(\theta)$ 是较简单的分布，用于近似后验分布 $p(\theta)$， $q(\theta)$ 通常被称为变分分布。通过使用最优化方法，我们试图找出分布 $q$ 的参数（通常称为变分参数），使其在 `KL 散度` 的度量上尽可能接近后验分布。注意，我们写了$ D_{K L}(q(\theta) \| p(\theta \mid y)) $，没有写$ \left.D_{K L}(p(\theta \mid y)) \| q(\theta)\right) $，因为这让问题表达更方便，此外两者之间并不等价。不过，在另一个方向上写 `KL 散度` 也是有用的，实际上导致了另一组本书不讨论的方法。

表达式 8.1 的问题是我们不知道后验，所以不能直接使用它。需要找到另一种方式来表达问题。以下步骤显示了如何做到这一点。如果您不关心中间步骤，请跳到公式 8.7。

首先，用条件分布的定义做替换：

$$
D_{K L}(q(\theta) \| p(\theta \mid y))=\int q(\theta) \log \frac{q(\theta)}{\underline{p(\theta, y)}} d(\theta) \tag{8.2}
$$

然后重排公式 8.2：

$$
=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} p(y) d(\theta) \tag{8.3}
$$

根据对数性质，得到方程：

$$
=\int q(\theta)\left(\log \frac{q(\theta)}{p(\theta, y)}+\log p(y)\right) d(\theta) \tag{8.4}
$$

重新排列：

$$
=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} d(\theta)+\int q(\theta) \log p(y) d(\theta) \tag{8.5}
$$

$q(\theta) 的积分是 1，可以将 $\text{log} p(\theta)$ 移出积分，然后得到：

$$
=\int q(\theta) \log \frac{q(\theta)}{p(\theta, y)} d(\theta)+\log p(y) \tag{8.6}
$$

利用对数性质：

$$
D_{K L}(q(\theta)|| p(\theta \mid y))=\underbrace{-\int q(\theta) \log \frac{p(\theta, y)}{q(\theta)} d(\theta)}_{\text {evidence lower bound (ELBO) }}+\log p(y)) \tag{8.7}
$$

因为 $ D_{K L} \geq 0 $ ，然后 $D_{KL} \geq 0 $ ，或者换句话说，证据（或边缘似然）总是等于或大于 `ELBO`，这就是其命名的原因。既然证据是一个常量，我们可以只关注 `ELBO` 。最大化 `ELBO` 的值相当于最小化 `KL 散度`。因此，使 `ELBO 最大化` 是一种使其尽可能接近后验的方法。

注意我们还没有引入任何近似，只是在做一些代数。在我们选择 $q(.)$ 时开始引入近似。原则上， $q(.)$ 可以是想要的任何东西，但实际上应该选择易于处理的分布。一种解决方案是假设高维后验可以用若干独立的一维分布来描述；在数学上，可以表示如下：

$$
q(\theta)=\prod_{j} q_{j}\left(\theta_{j}\right) \tag{8.8}
$$

这被称为平均场近似。平均场近似在物理学中很常见，在物理学中，它被用来将具有许多相互作用的复杂系统建模为根本不相互作用的子系统集合，或者在一般情况下，只有在平均的情况下才会考虑相互作用。

我们可为每个参数 $\theta_j$ 选择不同的分布 $q_j$。通常，$q_j$ 取自指数族分布，因为其易于处理。指数族包括正态分布、指数分布、贝塔分布、狄利克雷分布、伽马分布、泊松分布、绝对分布和伯努利分布等。

有了上述元素，可以有效地将推断问题转化为优化问题；至少在概念上，我们需要解决的所有问题就是使用一些现成的优化方法最大化 `ELBO` ，不过在实践中事情会稍微复杂一些。

### 8.2.4 自动微分变分推断方法

上述平均场变分法的主要缺点是：必须为每个模型提出一个特定算法。我们无法形成一个通用推断引擎的配方，而是生成一个需要用户干预的特定模型方法的配方。幸运的是，许多人注意到了该问题，并提出了以 `变分方法自动化` 为重点的解决方案。最近提出的一种方法是 `自动微分变分推断法 (ADVI)`（参见[链接](http:/​/​arxiv.org/​abs/​1603.​00788) 。在概念层面上，`ADVI` 采取的主要步骤是：

- 转换所有有界分布到实数轴上，如之前在拉普拉斯方法中讨论的那样。
- 用高斯分布来近似无界参数（公式 8.8 中的 $q_j$ ）；注意变换后的参数空间上的高斯在原参数空间上是非高斯的。
- 使用自动微分来最大化 `ELBO`。

`PyMC3` 文档（例如：[链接](https:/​/​docs.​pymc.​io/​nb_​examples)） 提供了许多关于使用变分推断的示例。

## 8.2 马尔科夫方法

有一系列相关方法被统称为 MCMC 方法。只要我们能够逐点计算似然和先验值，这些随机方法就能够从真实后验分布中获得样本。显然这与网格法所需条件相同，但 MCMC 方法的性能优于网格法。因为 MCMC 方法能够从高概率区域采集比低概率区域更多的样本。实际上，MCMC 方法会根据参数空间中每个区域的相对概率来访问它们。如果区域 A 的概率是区域 B 的两倍，那么从 A 获得的样本将是从 B 获得样本的两倍。因此，即使不能解析计算出整个后验结果，我们也可以使用 MCMC 方法从中获取样本。

在最基础层面上，我们在统计模型中关心的所有事务，基本上都是关于计算预期的，比如：

$$
\mathbb{E}[f]=\int_{\theta} p(\theta) f(\theta) \mathrm{d} \theta \tag{8.9}
$$

下面是这个一般表达式的一些特殊例子：
- 后验（公式 1.14）
- 后验预测性分布（公式 1.17）
- 给定模型的边缘似然（公式 5.13）

使用 MCMC 方法，可以使用有限样本近似公式 8.9：

$$
\lim _{N \rightarrow \infty} \mathbb{E}_{\pi}[f]=\frac{1}{N} \sum_{n=1}^{N} f\left(\theta_{n}\right) \tag{8.10}
$$

等式 8.10 的一大问题是：等式仅渐近成立。也就是说，对于无限数量的样本成立！但实践中仅有有限数量样本，因此我们希望 `MCMC 方法` 尽可能快地收敛到正确答案，即用尽可能少的样本得到正确答案。

一般来说，要确定 `MCMC` 的特定样本已经收敛并非易事。因此，实践中必须依靠实证检验来确保有一个可靠的 `MCMC 近似` 。我们将在诊断样本部分讨论 `MCMC 样本`的此类检验。同时要注意，其他近似（包括非马尔可夫方法）也需要实证检验，但本书不会讨论它们。

对 `MCMC 方法` 有一个概念性了解可以帮助我们从这些方法中诊断样本。为了理解什么是 `MCMC 方法`，我们将把该方法分成两个部分：`蒙特卡罗部分` 和 `马尔可夫链部分` 。

### 8.3.1 蒙特卡洛

蒙特卡洛部分可以用随机数来解释。蒙特卡罗方法是一个非常广泛的算法家族，它使用随机抽样来计算或模拟给定过程。蒙特卡洛是摩纳哥的一个区，那里有一家非常著名的赌场。蒙特卡洛方法的开发者之一 `Stanislaw Ulam`有一个叔叔曾在那里赌博。`Stan` 的关键思想是，虽然许多问题很难解决，甚至很难用确切方式表达出来，但可以通过从这些问题中抽取样本来有效地研究它们。事实上，其动机是回答有关在纸牌游戏中拿到一张特定牌的可能性问题。解决该问题的常见方法是组合分析法。但 `Stan` 认为存在另一种方法，进行多次单轮游戏，最后计算其中有多少次是我们感兴趣的。这听起来似乎是显而易见的，或者至少是相当合理的，比如，你可能已经用重采样的方法来解决统计问题。不过这个实验是早在 70 年前进行的，当时，第一台计算机才刚开始研发。

蒙特卡罗方法的第一个应用是解决核物理问题，这是当时用工具很难解决的问题。如今，即使是个人计算机也足以使用蒙特卡罗方法解决许多有趣的问题；因此，这些方法被应用于科学、工程、工业和艺术中的各种问题。

在使用蒙特卡洛方法计算数值的例子中，一个教科书上非常经典的是估计 $π$ 。实际使用中有更好的方法来计算 $π$ ，不过这个例子仍然具有教学意义。我们可以通过以下过程估计 $π$ ：
（1）在边长为 $2R$ 的正方形内随机撒 $N$ 个点。
（2）在正方形内画一个半径为 $R$ 的圆，计算在圆内点的个数。
（3）利用比例估计 $\bar \pi = 4\frac{inside}{N}$ 。

以下是一些注意事项：

（1）圆和正方形的面积分别与圆内的点数和总点数成正比。
（2）如果关系 $\sqrt{\left(x^{2}+y^{2}\right)} \leq R$ 成立，则认为该点在圆内。
（3）正方形的面积是 $(2R)^2$ ，圆的面积是 $πR^2$ ，因此二者面积之比是 $4/π$ 

圆和正方形的面积分别正比于圆内点数和总点数 $N$。我们可以通过几行简单的代码来模拟该蒙特卡洛过程计算 $π$ 值，同时计算出估计值与实际值之间的相对误差：

```python
N = 10000
x, y = np.random.uniform(-1, 1, size=(2, N))
inside = (x**2 + y**2) <= 1
pi = inside.sum()*4/N
error = abs((pi - np.pi) / pi) * 100
outside = np.invert(inside)
plt.figure(figsize=(8, 8))
plt.plot(x[inside], y[inside], 'b.')
plt.plot(x[outside], y[outside], 'r.')
plt.plot(0, 0, label=f'π*= {pi:4.3f}\nerror = {error:4.3f}', alpha=0)
plt.axis('square')
plt.xticks([])
plt.yticks([])
plt.legend(loc=1, frameon=True, framealpha=0.9);
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060716361541.webp)

上面的代码中，`outside` 变量仅用于绘图，在计算 $\hat \pi$  过程中没有用到。另外一点需要澄清的是，由于这里用的是单位圆，因此在判断一个点是否在圆内时没有计算平方根。

### 8.3.2 马尔科夫链

马尔科夫链是一个数学对象，包含一系列状态以及状态之间的转移概率，如果每个状态转移到其他状态的概率只与当前状态相关，那么这个状态链就称为马尔科夫链。有这样一个马尔科夫链之后，我们可以任取一个初始点，然后根据状态转移概率进行随机游走。假设能够找到这样一个马尔科夫链，其状态转移概率正比于我们想要采样的分布（如贝叶斯分析中的后验分布），采样过程就变成了简单地在该状态链上移动的过程。那么，如何在不知道后验分布的情况下找到这样的状态链呢？有一个概念叫做细节平衡条件（Detailed Balance Condition），直观上讲，这个条件是说，我们需要采用一种可逆的方
式移动（可逆过程是物理学中的一个常见的近似）。也就是说，从状态 i 转移到状态 j 的概率必须和状态 j 转移到状态 i 的概率相等。
总的来说就是，如果我们能够找到满足细节平衡条件的马尔科夫链，就可以保证从中采样得到的样本来自正确的分布。保证细节平衡的最流行的算法是 Metropolis-Hasting 算法。

### 8.3.3 Metropolis-Hastings 算法

为了更形象地理解这个算法，我们用下面这个例子来类比。假设
我们想知道某个湖的水容量以及这个湖中最深的点，湖水很浑浊以至于没法通过肉眼来估计深度，而且这个湖相当大，网格近似法显然不
是个好办法。为了找到一个采样策略，我们请来了两个好朋友小马和
小萌。经过讨论之后想出了如下办法，我们需要一个船（当然，也可
以是竹筏）和一个很长的棍子，这比声呐可便宜多了，而且我们已经
把有限的钱都花在了船上。
1）随机选一个点，然后将船开过去。
（2）用棍子测量湖的深度。
（3）将船移到另一个地点并重新测量。
（4）按如下方式比较两点的测量结果。
如果新的地点比旧的地点水位深，那么在笔记本上记录下新的测
量值并重复过程（2）。
如果新的地点比旧的地点水位浅，那么我们有两个选择：接受或
者拒绝。接受意味着记录下新的测量值并重复过程（2）；拒绝
意味着重新回到上一个点，再次记录下上一个点的测量值。

如何决定接受还是拒绝新的测量值呢？这里的一个技巧便是使用
Metropolis-Hastings 准则，即接受新的测量值的概率正比于新旧两点
的测量值之比。

按照以上过程迭代下去，我们不仅可以得到整个湖的水容量和最
深的点，而且可以得到整个湖底的近似曲率。你也许已经猜到了，在
这个类比中，湖底的曲率其实就是后验的分布，而最深的点就是后验
的众数。根据小马的说法，迭代的次数越多，近似的效果越好。

事实上，理论保证了在这种情形下，如果我们能采样无数次，最
终能得到完整的后验。幸运地是，实际上对于很多问题而言，我们只
需要相对较少地采样就可以得到一个相当准确的近似。
现在让我们从更正式的角度来看看该算法。对于很多分布而言
（如高斯分布），我们有相当高效的算法对其采样，但对于一些其他
分布，情况就变了。Metropolis-Hastings 算法使得我们能够从任意分
布中以概率 p(x) 得到采样值，只要我们能算出某个与 p(x) 成比例的
值。这一点很有用，因为在类似贝叶斯统计的许多问题中，最难的部
分是计算归一化因子，也就是贝叶斯定理中的分母。Metropolis-
Hastings 算法的步骤如下。

（1）给参数 xi 赋一个初始值，通常是随机初始化或者使用某些
经验值。
（2）从某个简单的分布 中选一个新的值 ，如高斯
分布或者均匀分布。这一步可以看做是对状态 的扰动。
（3）根据 Metropolis-Hastings 准则计算接受一个新的参数值的概
率：
（4）从位于区间 [0,1] 内的均匀分布中随机选一个值，如果第
（3）步中得到的概率值比该值大，那么就接受新的值，否则仍保持
原来的值。
（5）回到第（2）步重新迭代，直到我们有足够多的样本，稍后
会解释什么叫足够多。

有几点需要注意。

如果选取的分布 是对称的，那么可以得到
，这通常称为 Metropolis 准则。
步骤（3）和步骤（4）表明：我们总是会转移到一个比当前状态
（或参数）概率更大的状态（或参数），对于概率更小的，则会
以 xi+1 与 xi 之比的概率接受。该准则中的接受步骤使得采样过程
相比网格近似方法更高效，同时保证了采样的准确性。
目标分布（贝叶斯统计中的后验分布）是通过记录下来的采样值
来近似的。如果我们接受转移到新的状态 xi+1，那么我们就记录
该采样值 xi+1。如果我们拒绝转移到 xi+1，那么我们就记录 xi。

最后，我们会得到一连串记录值，有时候也称采样链或者迹。如
果一切都正常进行，那么这些采样值就是后验的近似。在采样链中出
现次数最多的值就是对应后验中最可能的值。该过程的一个优点是：
后验分析很简单，我们把对后验求积分的过程转化成了对采样链所构
成的向量求和的过程。
下面的代码展示了 Metropolis 算法的一个基本实现。这段代码并
不是为了解决什么实际问题，只是在这里用来演示，如果我们知道怎
么计算给定点的函数值，我们就可能得到该函数的采样。需要注意下
面的代码中不包含贝叶斯相关的部分，既没有先验也没有数据。要知
道，MCMC 是一类能够用于解决很多问题的通用方法。例如，在一
个（非贝叶斯的）分子模型中，我们可能需要一个函数来计算在某个
状态 x 下系统的能量而不是简单地调用 func.pdf(x) 函数。
metropolis 函数的第一个参数是一个 SciPy 的分布，假设我们不
知道如何从中直接采样。

现在你应该从概念上掌握了 Metropolis-Hastings 算法。也许你需
要回过头去重新阅读前面几页才能完全消化。此外，我还强烈建议阅
读 `PyMC3` 核心作者之一写的博文
http://twiecki.github.io/blog/2015/11/10/mcmc-sampling/[2]。他用一个简
单的例子实现了 metropolis 方法，并将其用于求解后验分布，文中
用非常好看的图展示了采样的过程，同时简单讨论了最初选取的步长
是如何影响结果的。

### 8.3.4 汉密尔顿蒙特卡洛方法/不掉向采样

MCMC 方法，包括 Metropolis-Hastings，都在理论上保证如果采
样次数足够多，最终会得到后验分布的准确近似。不过，实际中想要
采样足够多次可能需要相当长的时间，因此，人们提出了一些
Metropolis-Hastings 算法的替代方案。这些替代方案，包括 Metropolis-
Hastings 算法本身，最初都是用来解决统计力学中的问题。统计力学
是物理学的一个分支，主要研究原子和分子系统的特性。汉密尔顿蒙
特卡洛方法，又称混合蒙特卡洛（Hybrid Monte Carlo，HMC），是
这类改进方案之一。简单来说，汉密尔顿这个词描述的是物理系统的
总能量，而另外一个名称中的“混合”是指将 Metropolis-Hastings 算法
与分子力学（分子系统中广泛应用的一种仿真技巧）相结合。HMC
方法本质上和 Metropolis-Hastings 是一样的，改进的地方在于：原来
是随机放置小船，现在有了一个更聪明的办法，将小船沿着湖底方向
放置。为什么这个做法更聪明？因为这样做避免了 Metropolis-
Hastings 算法的主要问题之一：探索得太慢而且采样结果自相关（因
为大多数采样结果都被拒绝了）。

那么，如何才能不必深入其数学细节而理解汉密尔顿蒙特卡洛方
法呢？假设我们还是在湖面上坐着船，为了决定下一步将要去哪，我
们从当前位置往湖底扔了一个球，受“球状奶牛”的启发 [3]，我们假设
球面是理想的，没有摩擦，因而不会被泥巴和水减速。扔下球之后，
让它滚一小会儿，然后把船划到球所在的位置。现在利用 Metropolis-
Hastings 算法中提到的 Metropolis 准则来选择接受或者拒绝，重复整个
过程一定次数。改进后的过程有更高的概率接受新的位置，即使它们
的位置相比前一位置距离较远。

现在跳出我们的思维实验，回到现实中来。基于汉密尔顿的方法
需要计算函数的梯度。梯度是在多个维度上导数的推广。我们可以用
梯度信息来模拟球在曲面上移动的过程。因此，我们面临一个权衡；
HMC 计算过程要比 Metropolis-Hastings 更复杂，但是被接受概率更
高。对于一些复杂的问题，HMC 方法更合适一些。HMC 方法的另一
个缺点是：想要得到很好的采样需要指定一些参数。如果手动指定，
需要反复尝试，这要求使用者有一定的经验。幸运地是，`PyMC3` 中
有一个相对较新的不掉向采样算法，该方法被证实可以有效提升
HMC 方法的采样效率，同时不必手动调整参数。

### 8.3.5 序贯蒙特卡罗
Metropolis-Hastings 和 NUTS（以及其他哈密尔顿蒙特卡罗变种）的一个警告是，如果后方有多个峰，并且这些峰被非常低概率的区域分开，这些方法可能会陷入单一模式，错过其他方法！
为克服这个多重极小值问题而开发的许多方法都是基于回火的思想。这个想法又一次借用了统计力学。物理系统可以填充的状态数取决于系统的温度；在 0 开尔文（可能的最低温度）时，每个系统都停留在单一状态。在另一个极端，对于无限大的温度，所有可能的状态都是同等可能的。一般来说，我们对处于某一中间温度的系统感兴趣。对于贝叶斯模型，有一种非常直观的方式来适应这种调和的想法，那就是用扭曲的方式写下贝叶斯定理。

表达式 1.4 和 8.13 之间的唯一区别是参数的规格，这被称为逆温或回火参数。请注意，对于我们得到的，因此调和后的后部，只是之前的，并且当，调和后的后部是实际的完全后部。由于从先验采样通常比从后验采样容易（通过增加的值），我们从更容易的分布开始采样，然后慢慢地将其变形为我们真正关心的更复杂的分布。

利用这一思想的方法有很多，其中之一就是顺序蒙特卡罗 (SMC)。在 `PyMC3` 中实施的 SMC 方法可以总结如下：

1. 从回火后的后部生成样本。2. 增加一点。3. 计算一组权重。权重是根据新的 4. 调整后的后验来计算的。根据重新取样获得。5. 运行 Metropolis Chains，从中的不同样本开始。6. 重复步骤 3，直到。

重采样步骤通过移除概率较低的样本并将其替换为概率较高的样本来实现。大都会步骤扰乱了这些样本，有助于探索参数空间。
回火方法的效率在很大程度上取决于通常所说的冷却计划的中间值。的两个相继数值之间的差异越小，两个相继回火后的相距就越近，因此从一个阶段过渡到下一个阶段就越容易。但如果步长太小，我们将需要许多中间阶段，超过某个点，这将转化为浪费大量计算资源，而不会真正提高结果的准确性。

幸运的是，SMC 可以自动计算的中间值。精确的冷却时间表将根据问题的难度进行调整；较难采样的分布将比较简单的分布需要更多的阶段。

SMC 如图 8.6 所示，第一个子图显示了特定阶段的五个样本（橙色）点。第二个小图显示了这些样本是如何根据它们调和后的后验密度（蓝色）曲线重新加权的。第三个子图显示了从第二个子图中的重新加权样本开始，运行一定数量的 Metropolis 步长的结果；请注意，后验密度较低的两个样本（最右侧和最左侧的较小圆圈）如何被丢弃，而不是用于播种新的马尔可夫链：

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717005520.webp)

除了的中间值外，还根据前一阶段的接受率动态计算了另外两个参数：每个马尔可夫链的步数和建议分布的宽度。

对于 SMC 算法的第 6 步，`PyMC3` 使用 Metropolis 算法；这不一定是唯一的选择，但这是一个非常合理的选择，并受到理论和实践论证的推动。值得注意的是，即使 SMC 方法使用 Metropolis 方法，它也比它有几个优点：

它可以从多峰分布中采样。它没有老化期。这是由于重新称重的步骤造成的。权重的计算方式不是近似，而是在每个阶段，MCMC 链近似地从正确的后验分布开始。它可以产生低自相关的样本。它可以用来近似边缘似然（参见第 5 章，模型比较），这只是 SMC 方法的一个副作用，几乎不需要额外的计算

### 8.3.6 其他 MCMC 方法

MCMC 的方法很多，而且人们还在不断提出新的方法。如果你
认为你能提升采样效率，会有很多人对你的想法感兴趣。讨论所有这
类方法及其优缺点显然超出了本书的范围。不过，有些方法仍值得一
提，因为你可能经常会听到人们讨论它们，所以最好是了解下他们都
在讨论些什么。
在分子系统模拟中广泛应用的另外一种采样方法是副本交换
（Replica Exchange），也称并行退火（Parallel Tempering）或
者 Metropolis Coupled MCMC（MC3；好多 MC……）。该方法的基
本思想是并行模拟多个不同的副本，每个副本都按照 Metropolis-
Hastings 算法执行。多个副本之间的唯一不同是一个叫做温度的参数
（又受到物理学的启发！），该参数用来控制接受低概率采样点的可
能性。每隔一段时间，该方法都尝试在多个副本之间进行切换，切换
过程同时遵循 Metropolis-Hastings 准则来接受或拒绝，只不过现在考
虑的是不同副本之间的温度。切换过程可以在状态链上进行随机切
换，不过，通常更倾向于在相邻副本之间切换，也就是说，具有相似
温度的副本会有更高的接受概率。该方法的直观理解是：如果我们提
高温度，接受新位置的概率也会提升，反之则会降低。温度更高的副
本可以更自由地探索系统，因为这些副本的表面会变得相当平坦从而
更容易探索。对于温度无限高的副本，所有状态都是等概率的。副本
之间的切换避免了较低温度的副本陷在局部最低点，因而该方法很适
合探索有多个最低点的系统。

## 8.4 诊断样本

本节重点介绍大都会和螺母的诊断样本。因为我们是用有限数量的样本来近似后验的，所以检查我们是否有一个有效的样本是很重要的-否则任何来自它的分析都将是完全有缺陷的。我们可以进行几种测试，有些是直观的，有些是定量的。这些测试旨在发现我们样本的问题，但它们无法证明我们的分布是正确的；它们只能提供样本似乎合理的证据。如果我们发现样本有问题，有很多解决方案可以尝试：

增加采样数。从轨迹的开头删除一些样本。这就是所谓的老化。`PyMC3` 调优阶段有助于减少老化需求。修改采样器参数，例如增加调谐阶段的长度，或增加螺母采样器的 TARGET_ACCEPT 参数。在某些情况下，`PyMC3` 会提供修改建议。重新参数化模型，即以不同但等价的方式表达模型。转换数据。我们已经看到了一个这样的例子，在第 4 章，推广线性模型和第 5 章，模型比较中，我们展示了将数据居中可以改进线性模型的采样。

为了使解释更具体，我们将使用具有两个参数的极简主义分层模型：全局参数 a 和局部参数 b（每组参数）。仅此而已，我们在这个模型中甚至没有可能性/数据！我在这里省略数据是为了强调，我们将讨论的一些属性（特别是在散度一节中）与模型的结构相关，而不是与数据相关。我们将讨论同一模型的两种替代参数化：

```python
with pm.Model() as centered_model:
    a = pm.HalfNormal('a', 10)
    b = pm.Normal('b', 0, a, shape=10)
    trace_cm = pm.sample(2000, random_seed=7)
with pm.Model() as non_centered_model:
    a = pm.HalfNormal('a', 10)
    b_shift = pm.Normal('b_offset', mu=0, sd=1, shape=10)
    b = pm.Deterministic('b', 0 + b_shift * a)
    trace_ncm = pm.sample(2000, random_seed=7)
```

中心模型和非中心模型的不同之处在于，对于前者，我们直接拟合群级参数，而对于后者，我们将群级参数建模为平移和缩放的高斯模型。我们将使用几个曲线图和数字总结来探索其中的差异。

### 8.4.1 收敛性

MCMC 采样器（如 NUTS 或 Metropolis) 可能需要一段时间才能收敛；也就是说，它从正确的分布开始采样。正如我们之前解释过的，MCMC 方法在非常一般的条件和无限数量的样本下都有收敛的理论保证。不幸的是，在实践中，我们只能获得有限的样本，因此我们必须转而依赖经验测试，这些测试充其量只能提供一些提示或警告，表明当它们失败时，可能会发生糟糕的事情，但不能保证当它们没有失败时，一切都是正常的。

直观检查收敛的一种方法是运行 ArviZ PLOT_TRACE 函数并检查结果。为了更好地理解我们在检查这些曲线图时应该查看什么，让我们比较一下前面定义的两个模型的结果（参见图 8.6 和 8.7)：

```python
az.plot_trace(trace_cm, var_names=['a'], divergences='top')
```
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717041601.webp)

```python
az.plot_trace(trace_ncm, var_names=['a'])
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170440ad.webp)

请注意，图 8.8 中的 KDE 比 8.7 中的 KDE 更平滑；平滑的 KDE 是一个好迹象，而不平坦的 KDE 可能表示存在问题，例如需要更多样本或更严重的问题。轨迹本身（右侧的图）应该看起来像白噪声，这意味着我们应该看不到任何可识别的模式；我们希望看到一条自由漫游的曲线，如图 8.8 中的轨迹。当这种情况发生时，我们说我们有很好的混合。相反，图 8.6 是一个病理行为的例子；如果您仔细地将它与图 8.8 进行比较，您会注意到两条链的重叠在 8.8 比 8.7 大，您还会注意到 8.7 中沿着轨迹的几个区域发生了一些可疑的事情；最清楚的一个是在 500-1000 画之间的区域：您会看到其中一条链（蓝色的）卡住了（基本上是一条水平线）。

图 8.9 显示了一些混合良好（右侧）和混合不良（左侧）的痕迹的附加示例。如果有多个区域，例如离散变量或多模态分布，我们预计跟踪不会在一个值或区域上花费太多时间，然后移动到其他区域，而是轻松地从一个区域跳到另一个区域：

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071705182a.webp)

好的 MCMC 样本的另一个特征是自相似跟踪；例如，前 10%（大约）应该与跟踪中的其他部分相似，例如最后 50%或 10%。再说一次，我们不想要模式；相反，我们想要一些嘈杂的东西。使用 az.ploytrace 也可以看到这一点。如果轨迹的第一部分看起来与其他部分不同，这表明需要老化，或者需要更多的样本。如果我们发现其他部分缺乏自相似性，或者我们看到了一种模式，这可能意味着我们需要更多的绘图，但通常情况下，我们应该尝试使用不同的参数化。对于困难的模型，我们甚至可能需要应用所有这些策略的组合。

默认情况下，`PyMC3` 将尝试并行运行独立的链（确切数量取决于可用处理器的数量）。这是使用 pm.sample 函数中的 chains 参数指定的。我们可以使用 PLOT_TRACE 或 Plot_Forest ArviZ 函数直观地检查平行链是否彼此相似。然后，我们可以将并行链合并为一个单独的链进行推断，因此请注意，并行运行链并不浪费资源。

比较独立链的一种定量方法是使用 RHAT 统计量。这个测试的思想是用链内的方差计算链之间的方差。理想情况下，我们应该期望值为 1。作为经验规则，值低于 1.1 也没问题；值越高表示不收敛。我们可以使用 az.r_hat 函数计算它；我们只需要传递一个 `PyMC3` 跟踪对象。默认情况下，还会使用 az.Summary 函数（您可能还记得在前几章中的内容）以及可选的 az.lot_Forest（使用 r_hat=True 参数）来计算 rhat 诊断，如我们在以下示例中所看到的：

```python
az.plot_forest(trace_cm, var_names=['a'], r_hat=True, eff_n=True)
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170617f5.webp)

对于 az.Summary 也是如此：

```python
summaries = pd.concat([az.summary(trace_cm, var_names=['a']),
                      az.summary(trace_ncm, var_names=['a'])])
summaries.index = ['centered', 'non_centered']
summaries
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607170651ca.webp)

### 8.4.2 蒙特卡罗误差

摘要返回的数量之一是 MC_ERROR。这是对采样方法引入的误差的估计。该估计考虑到样本并不是真正彼此独立的。Mcerror 是 n 个数据块的平均值 x 的标准误差，每个数据块只是轨迹的一部分：

$$
\mathrm{mc}_{\mathrm{error}}=\frac{\sigma(x)}{\sqrt{n}} \tag{8.14}
$$

此误差应低于我们希望在结果中显示的精度。

### 8.4.3 自相关

分布（包括后验分布）的理想样本应该具有等于零的自相关（除非我们期望时间序列中的相关）。当给定迭代的值不独立于其他迭代的采样值时，样本是自相关的。在实践中，MCMC 方法产生的样本将是自相关的，特别是 Metropolis-Hastings，在较小程度上是 NUTS 和 SMC。ArviZ 提供了一个方便的函数来绘制自相关曲线：

az.plot_autocorr(trace_cm, var_names=['a'])

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071708494c.webp)

通过比较图 8.11 和图 8.12，我们可以很容易地看到，非中心模型的样本几乎没有自相关，而中心模型的样本显示出更大的自相关值。

### 8.4.4 有效样本量

具有自相关的样本比没有自相关的相同大小的样本具有更少的信息。事实上，我们可以使用自相关来估计给定样本的大小，在具有等价信息的情况下，而不是在自相关的情况下。这称为有效样本量。参数的自相关程度越高，获得给定精度所需的样本数量就越大，换句话说，自相关会减少有效样本的数量。我们可以在 ArviZ 中使用 az.Effect_n 函数计算有效样本量。通过传递 effn=True 参数，还可以通过 az.Summary（就像我们在前一页和前几章中所做的那样）和 az.lot_Forest 函数计算有效样本大小（参见图 8.9)。

理想情况下，有效样本量应该接近实际样本量。与 Metropolis 相比，NUTS 的一个优点是，NUTS 的有效样本量通常比 Metropolis 高得多，因此，一般来说，如果您使用 NUTS，通常需要的样本比使用 Metropolis 时要少。

如果任何参数的有效样本量低于 200，`PyMC3` 都会发出警告。作为一般指南，100 个有效样本应该可以很好地估计分布的平均值，但是拥有更多的样本将提供每次重新运行模型时变化较小的估计值，这也是您使用 200 作为有效样本大小临界值的部分原因。对于大多数问题值，1,000 到 2,000 个有效样本将绰绰有余。如果我们想要高精度的数量依赖于分布的尾部或非常罕见的事件，我们将需要一个更大的有效样本量。

### 8.4.5 散度

我们现在将探索不包含坚果的测试，因为它们基于方法的内部工作，而不是生成的样本的属性。这些测试是基于所谓的散度，是诊断样本的一种强大而灵敏的方法。

当我试图设置本书中的模型以避免散度时，您可能已经看到指示出现散度的 `PyMC3` 消息。散度可能表明坚果在后部遇到了无法正确探索的高曲率区域；这告诉我们采样器可能缺少参数空间的一个区域，因此我们的结果将是有偏差的。散度通常比这里讨论的测试敏感得多，因此，即使其余测试通过，它们也可以发出问题的信号。散度的一个很好的特点是，它们往往看起来靠近有问题的参数空间区域，因此我们可以使用它们来识别问题所在。可视化散度的一种方法是使用带有 DISGENCES=True 参数的 az.lot_air：

```python
_, ax = plt.subplots(1, 2, sharey=True, figsize=(10, 5),
constrained_layout=True)
for idx, tr in enumerate([trace_cm, trace_ncm]):
    az.plot_pair(tr, var_names=['b', 'a'], coords={'b_dim_0':[0]},
kind='scatter',
                 divergences=True, contour=False,
divergences_kwargs={'color':'C1'},
                 ax=ax[idx])
    ax[idx].set_title(['centered', 'non-centered'][idx])
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021060717112515.webp)

在图 8.13 中，小（蓝色）点是规则样本，较大（黑色和橙色）点表示散度。我们可以看到，中心模型的散度主要集中在漏斗的尖端。我们还可以看到，非中心模型没有发散，尖端更尖锐。采样器通过分叉告诉我们，它很难从漏斗尖端附近的区域取样。我们确实可以在图 8.13 中检查到，居中的模型在尖端附近没有样本，靠近散度集中的地方。这真是太棒了！

散度也用黑色、“|\”标记表示在 ArviZ 的轨迹图中，如图 8.7 所示。请注意，散度是如何集中在轨迹的病理平坦部分周围的。

可视化散度的另一种有用的方法是用平行的曲线图：

```python
az.plot_parallel(trace_cm)
```

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171240da.webp)

在这里，我们可以看到 b 和 a 的散度都集中在 0 附近。如图 8.13 和 8.14 所示的曲线图非常重要，因为它们让我们知道参数空间的哪一部分可能有问题，还因为它们帮助我们发现误报。让我解释最后一点。`PyMC3` 使用启发式方法来标记散度，有时，这种启发式方法可能会说我们有散度，但实际上并非如此。一般来说，如果散度分散在参数空间中，我们可能会有误报；如果散度集中，那么我们可能会有问题。当产生散度时，通常有三种方法可以摆脱它们，或者至少减少它们的数量：

增加调优步骤的数量，类似于 pm.sample（调优=1000)。将 TARGET_ACCEPT 参数的值从默认值 0.8 增加。最大值为 1，因此您可以尝试使用诸如 0.85 或 0.9 之类的值。重新参数化模型。正如我们刚刚看到的，非中心模型是中心模型的重新参数化，这导致了更好的样本，并且没有分歧。

### 8.4.6 非居中参数化

我已经将非中心模型描述为解决采样问题的魔术。让我们做个动作来掩饰这个把戏并移除魔力。

从图 8.13 中，我们可以看到 a 和 b 参数是相关的。因为 b 是形状 10 的向量，所以我们选择绘制 b(0)，但是 b 的任何其他元素都应该显示相同的模式，事实上，这在图 8.14 中表现得非常清楚。这种相关性和这种特殊的漏斗形状是模型定义和模型部分汇集数据的能力的结果。当 a 的值减小时，b 的单个值变得越来越接近全局平均值。换句话说，收缩级别会越来越高，因此数据会越来越集中（直到完全集中）。允许部分池化的相同结构还引入了影响采样器方法性能的相关性。

在第 3 章“线性回归建模”中，我们看到线性模型也会导致相关性（性质不同）；对于这些模型，一个简单的解决办法是将数据居中。我们可能想在这里做同样的事情，但不幸的是，这不会帮助我们摆脱漏斗形状带来的采样问题。漏斗形状的微妙特征是相关性随参数空间中的位置而变化，因此将数据居中无助于降低这种相关性。正如我们所看到的，MCMC 方法，如 Metropolis-Hastings，在探索高度相关的空间时遇到了问题；这些方法找到合适样本的唯一途径是在前一步的邻域中提出一个新的步骤。结果，探索变得高度自相关且缓慢得令人痛苦。缓慢的混合可能会非常剧烈，以至于简单地增加样本（绘制）的数量并不是一个合理或可行的解决方案。螺母等采样器更适合这项工作，因为它们根据参数空间的曲率提出步骤，但正如我们已经讨论过的，采样过程的效率高度依赖于调优阶段。对于后部的一些几何形状，例如那些由分层模型诱导的几何形状，调整阶段过度调整到链开始的局部邻域，使得对其他区域的探索效率低下，因为新的建议更具随机性，类似于 Metropolis-Hastings 的行为。

## 8.5 小结

在本章中，我们概念性地介绍了一些最常用的计算后验分布的方法，包括变分法和马尔可夫链蒙特卡罗方法。我们特别强调通用推断引擎，即设计用于任何给定模型（或至少广泛的模型）的方法。这些方法是任何概率编程语言的核心，因为它们允许自动推断，让用户专注于迭代模型设计和结果解释。我们还讨论了诊断样本的数值测试和视觉测试。如果不能很好地逼近后验分布，贝叶斯框架的所有优点和灵活性就会消失，因此评估推断过程的质量对于我们对推断过程本身的质量是至关重要的。

## 练习

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210607171503fc.webp)
![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202106071715161a.webp)
