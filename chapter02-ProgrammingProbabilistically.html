
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>第 2 章 概率编程 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e2363ea40746bee74734a24ffefccd78.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第 3 章 线性回归模型的贝叶斯视角" href="chapter03-ModellingwithLinearRegression.html" />
    <link rel="prev" title="第 1 章 概率思维" href="chapter01-ThinkingProbabilistically.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  书籍正文
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第 3 章 线性回归模型的贝叶斯视角
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter08-InterefenceEngine.html">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  附录阅读
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Append-01-MCMCforDummies.html">
   附录 A： MCMC 随机近似性推断的傻瓜书
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-02-VIforDummies.html">
   附录 B： 变分法确定性近似推断的傻瓜书
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-03-BayesianDeepLearningWithPymc3.html">
   附录 C：贝叶斯深度学习的初步尝试
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-04-BayesianDeepLearning.html">
   附录 D：贝叶斯神经网络的实践 – 面向深度学习用户的教程
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/chapter02-ProgrammingProbabilistically.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter02-ProgrammingProbabilistically.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd/issues/new?title=Issue%20on%20page%20%2Fchapter02-ProgrammingProbabilistically.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xishansnow/BayesianAnalysiswithPython2nd/master?urlpath=lab/tree/chapter02-ProgrammingProbabilistically.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/xishansnow/BayesianAnalysiswithPython2nd&urlpath=lab/tree/BayesianAnalysiswithPython2nd/chapter02-ProgrammingProbabilistically.md&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   2.1 概率编程
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pymc3">
   2.2 用
   <code class="docutils literal notranslate">
    <span class="pre">
     PyMC3
    </span>
   </code>
   做后验推断
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     2.2.1 建立模型
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     2.2.2 执行推断
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     2.2.3 诊断推断结果
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       2.2.3.1 诊断工具和方法
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       2.2.3.2 常用解决办法
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id8">
       2.2.3.3 收敛性问题
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       2.2.3.4 自相关问题
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       2.2.3.5 有效后验采样次数
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     2.2.4 基于后验推断的决策
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   2.3 随处可见的高斯分布
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     2.3.1 高斯推断
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     2.3.2 更稳健的推断
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id15">
       （1）剔除异常值
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id16">
       （2）调整模型
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id17">
   2.4 组间比较与假设检验
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cohen-s-d">
     2.4.1 Cohen’s d
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     2.4.2 优势概率
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     2.4.3 小费数据集
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id20">
   2.5 分层模型
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     2.5.1 什么是分层模型？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id22">
     2.5.2 收缩
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id23">
     2.5.3 另一个例子
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id24">
   2.6 总结
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id25">
   2.7 练习
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>第 2 章 概率编程<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>上一章对贝叶斯统计有了基本了解，本章将学习如何使用计算工具构建概率模型。我们将学习使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 进行概率编程。其基本思想是使用代码指定模型，然后以或多或少自动的方式求解它们。选择编程的背后原因是：许多模型无法得到闭合的解析解，因此只能使用数值方法来求解。学习概率编程的另一个原因是，现代贝叶斯统计主要是通过编写代码来完成的，既然已经了解 <code class="docutils literal notranslate"><span class="pre">Python</span></code> ，为什么还要用另一种方式呢？概率编程提供了一种构建和求解复杂模型的有效方法，使我们可以更多地关注模型设计、评估和解释，而更少地关注数学或计算细节。在本章以及本书的其余部分中，我们将使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> ， <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 是一个非常灵活的概率编程 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 是一个新的 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，它将帮助我们解释概率模型的结果。了解 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 和 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 还将帮助我们以更实际的方式学习先进的贝叶斯概念。</p>
<p>本章涵盖以下主题：</p>
<ul class="simple">
<li><p>概率编程</p></li>
<li><p>推断引擎</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 指南</p></li>
<li><p>重温抛硬币问题</p></li>
<li><p>模型检查和诊断</p></li>
<li><p>高斯模型和学生 <span class="math notranslate nohighlight">\(t\)</span> 模型</p></li>
<li><p>分组比较和有效容量</p></li>
<li><p>分层模型和收缩</p></li>
</ul>
<hr class="docutils" />
<div class="section" id="id2">
<h2>2.1 概率编程<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>贝叶斯统计在概念上非常简单：我们有已知和未知的量；我们使用贝叶斯定理将后者以前者为条件。如果我们幸运的话，该过程将减少未知量的不确定性。通常，我们把已知量称为<strong>数据</strong>并将其视为常数，将未知量称为参数并将其视为概率分布。在更正式的术语中，我们给未知量分配先验概率分布；然后利用贝叶斯定理将其先验概率分布转化为后验分布。尽管概念简单，但全概率公式常常导致难以解析的表达式。多年来，该问题是阻碍贝叶斯方法广泛采用的主要原因之一。</p>
<p>随着计算时代的到来，数值方法使得解决任何推断问题成为可能。这极大改变了贝叶斯数据分析的应用。我们可以把这些数值方法看作通用推断引擎，或者 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 核心开发者 <code class="docutils literal notranslate"><span class="pre">Thomas</span> <span class="pre">Wiecki</span></code> 所称呼的推断按钮。自动化推断过程的可能性导致了 <strong>概率编程语言（PPL）</strong> 的发展，它允许模型创建和推断之间的明确分离。</p>
<p>在概率编程语言的框架中，用户只需要寥寥数行代码描述概率模型，后面的推断过程就能自动完成了。概率编程使得人们能够更快速地构建复杂的概率模型并减少出错的可能，可以预见，这将给数据科学和其他学科带来极大的影响。我认为，编程语言对科学计算的影响可以与 60 多年前 <code class="docutils literal notranslate"><span class="pre">Fortran</span></code> 语言的问世相对比。尽管如今 <code class="docutils literal notranslate"><span class="pre">Fortran</span></code> 语言风光不再，不过在当时 <code class="docutils literal notranslate"><span class="pre">Fortran</span></code> 语言被认为是相当革命性的。科学家们第一次从计算的细节中解放出来，开始用一种更自然的方式关注构建数值化的方法、模型和仿真系统。类似地，概率编程将处理概率和推断的过程对用户隐藏起来，从而使得用户更多的去关注模型构建和结果分析。</p>
<p>在本章中，我们将学习如何使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 定义和求解模型。我们将把推断按钮看作一个黑盒，它给我们提供了来自后验分布的适当样本。我们将要使用的方法是随机的，所以每次我们运行它们时，样本都会有所不同。然而，如果推断过程如预期的那样工作，样本将代表后验分布，因此我们将从这些样本中的任何一个获得相同的结论。当我们按下推断按钮时，引擎盖下会发生什么，以及如何检查样本是否确实值得信任，这些细节将在第 8 章-推断引擎中解释。</p>
</div>
<div class="section" id="pymc3">
<h2>2.2 用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 做后验推断<a class="headerlink" href="#pymc3" title="Permalink to this headline">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，用于概率编程。撰写本文时的最后一个版本是 3.6 。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 提供了非常简单直观的语法，易于阅读，与统计文献中用于描述概率模型的语法非常接近。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的基本代码是用 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 编写的，计算要求高的部分是用 <code class="docutils literal notranslate"><span class="pre">Numpy</span></code> 和 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 编写的。</p>
<p><code class="docutils literal notranslate"><span class="pre">Theano</span></code> 是为深度学习而开发的一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，允许我们高效地定义、优化和计算涉及多维数组的数学表达式。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 使用 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 的主要原因是，有些采样方法需要计算梯度，而 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 知道如何使用自动微分来计算梯度。此外，<code class="docutils literal notranslate"><span class="pre">Theano</span></code> 将 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 代码编译成 C 代码，因此 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 非常快。这是关于 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 的所有信息，我们必须使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 。</p>
<p>如果您还想了解更多，请阅读<a class="reference external" href="http://deeplearning.net/software/theano/tutorial/index.html#tutorial">官方 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 教程</a>。</p>
<blockquote>
<div><p>你可能听说过 Theano 已经不再开发了，但这没什么好担心的。PyMC 开发人员将接管 Theano 维护，确保 Theano 在未来几年内继续为 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 服务。与此同时，PyMC 开发人员正在迅速行动，以创建 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的继任者。这可能会基于 TensorFlow 作为后端，尽管其他选项也在分析中。有关这方面的更多信息，请访问<a class="reference external" href="https://medium.com/&#64;pymc_devs/theano-tensorflow-and-the-future-of-pymc-6c9987bb19d5">博客</a> 。</p>
</div></blockquote>
<p>重新回顾抛硬币问题，这次使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 。首先获取数据，此处使用手动构造的数据。由于数据是我们通过代码生成的，所以知道真实参数值，以下代码中用 <code class="docutils literal notranslate"><span class="pre">theta_real</span></code> 变量表示。显然，在实际数据中，通常并不知道参数的真实值，而是要将其估计出来。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;arviz-darkgrid&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">trials</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">theta_real</span> <span class="o">=</span> <span class="mf">0.35</span> <span class="c1"># unknown value in a real experiment</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bernoulli</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">theta_real</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">trials</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>2.2.1 建立模型<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>现在有了数据，需要进一步指定模型。回想一下，模型可通过指定似然函数和先验分布完成。对于似然，可用参数为 <span class="math notranslate nohighlight">\(n=1\)</span> 和 <span class="math notranslate nohighlight">\(p=\theta\)</span> 的二项分布来描述，对于先验，用参数为 <span class="math notranslate nohighlight">\(\alpha=\beta=1\)</span> 的贝塔分布描述，该贝塔分布与 [0,1] 区间内的均匀分布等价。用数学表达式描述如下：</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.1} \label{式2.1} 
\theta &amp;\sim \operatorname{Beta}(\alpha, \beta) \\
y &amp;\sim \operatorname{Bern}(p=\theta) 
\end{align*}\]</div>
<p>该统计模型与 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的语法几乎一一对应。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">our_first_model</span><span class="p">:</span>
  <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
  <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_1818</span><span class="o">/</span><span class="mf">931022958.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">our_first_model</span><span class="p">:</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>   <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">3</span>   <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>   <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/distributions/distribution.py</span> in <span class="ni">__new__</span><span class="nt">(cls, name, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">120</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span>             <span class="n">dist</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">122</span>         <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">Var</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dist</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">total_size</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="n">dims</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">123</span> 
<span class="g g-Whitespace">    </span><span class="mi">124</span>     <span class="k">def</span> <span class="nf">__getnewargs__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/model.py</span> in <span class="ni">Var</span><span class="nt">(self, name, dist, data, total_size, dims)</span>
<span class="g g-Whitespace">   </span><span class="mi">1175</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1176</span>             <span class="k">with</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1177</span>                 <span class="n">var</span> <span class="o">=</span> <span class="n">ObservedRV</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1178</span>                     <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1179</span>                     <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/model.py</span> in <span class="ni">__init__</span><span class="nt">(self, type, owner, index, name, data, distribution, total_size, model)</span>
<span class="g g-Whitespace">   </span><span class="mi">1826</span> 
<span class="g g-Whitespace">   </span><span class="mi">1827</span>             <span class="bp">self</span><span class="o">.</span><span class="n">missing_values</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">missing_values</span>
<span class="ne">-&gt; </span><span class="mi">1828</span>             <span class="bp">self</span><span class="o">.</span><span class="n">logp_elemwiset</span> <span class="o">=</span> <span class="n">distribution</span><span class="o">.</span><span class="n">logp</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1829</span>             <span class="c1"># The logp might need scaling in minibatches.</span>
<span class="g g-Whitespace">   </span><span class="mi">1830</span>             <span class="c1"># This is done in `Factor`.</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/distributions/discrete.py</span> in <span class="ni">logp</span><span class="nt">(self, value)</span>
<span class="g g-Whitespace">    </span><span class="mi">450</span>         <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">451</span>             <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span>
<span class="ne">--&gt; </span><span class="mi">452</span>             <span class="k">return</span> <span class="n">bound</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">453</span>                 <span class="n">tt</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">tt</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">),</span> <span class="n">tt</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)),</span> <span class="n">value</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">value</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="mi">1</span>
<span class="g g-Whitespace">    </span><span class="mi">454</span>             <span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/distributions/dist_math.py</span> in <span class="ni">bound</span><span class="nt">(logp, *conditions, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">80</span>         <span class="n">alltrue</span> <span class="o">=</span> <span class="n">alltrue_scalar</span>
<span class="g g-Whitespace">     </span><span class="mi">81</span> 
<span class="ne">---&gt; </span><span class="mi">82</span>     <span class="k">return</span> <span class="n">tt</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">alltrue</span><span class="p">(</span><span class="n">conditions</span><span class="p">),</span> <span class="n">logp</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">83</span> 
<span class="g g-Whitespace">     </span><span class="mi">84</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/pymc3/distributions/dist_math.py</span> in <span class="ni">alltrue_elemwise</span><span class="nt">(vals)</span>
<span class="g g-Whitespace">     </span><span class="mi">86</span>     <span class="n">ret</span> <span class="o">=</span> <span class="mi">1</span>
<span class="g g-Whitespace">     </span><span class="mi">87</span>     <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">vals</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">88</span>         <span class="n">ret</span> <span class="o">=</span> <span class="n">ret</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="n">c</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">89</span>     <span class="k">return</span> <span class="n">ret</span>
<span class="g g-Whitespace">     </span><span class="mi">90</span> 

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/tensor/var.py</span> in <span class="ni">__mul__</span><span class="nt">(self, other)</span>
<span class="g g-Whitespace">    </span><span class="mi">126</span>         <span class="c1"># and the return value in that case</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span>         <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">128</span>             <span class="k">return</span> <span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">129</span>         <span class="k">except</span> <span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">130</span>             <span class="k">return</span> <span class="bp">NotImplemented</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">__call__</span><span class="nt">(self, *inputs, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">251</span> 
<span class="g g-Whitespace">    </span><span class="mi">252</span>         <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">compute_test_value</span> <span class="o">!=</span> <span class="s2">&quot;off&quot;</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">253</span>             <span class="n">compute_test_value</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span> 
<span class="g g-Whitespace">    </span><span class="mi">255</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">compute_test_value</span><span class="nt">(node)</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> 
<span class="g g-Whitespace">    </span><span class="mi">125</span>     <span class="c1"># Create a thunk that performs the computation</span>
<span class="ne">--&gt; </span><span class="mi">126</span>     <span class="n">thunk</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">make_thunk</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">storage_map</span><span class="p">,</span> <span class="n">compute_map</span><span class="p">,</span> <span class="n">no_recycling</span><span class="o">=</span><span class="p">[])</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span>     <span class="n">thunk</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">storage_map</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span>     <span class="n">thunk</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">storage_map</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">make_thunk</span><span class="nt">(self, node, storage_map, compute_map, no_recycling, impl)</span>
<span class="g g-Whitespace">    </span><span class="mi">632</span>             <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">633</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">634</span>                 <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_c_thunk</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">storage_map</span><span class="p">,</span> <span class="n">compute_map</span><span class="p">,</span> <span class="n">no_recycling</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">635</span>             <span class="k">except</span> <span class="p">(</span><span class="ne">NotImplementedError</span><span class="p">,</span> <span class="n">MethodNotDefined</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">636</span>                 <span class="c1"># We requested the c code, so don&#39;t catch the error.</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/graph/op.py</span> in <span class="ni">make_c_thunk</span><span class="nt">(self, node, storage_map, compute_map, no_recycling)</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span>                 <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Disabling C code for </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2"> due to unsupported float16&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">599</span>                 <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;float16&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">600</span>         <span class="n">outputs</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">make_thunk</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">601</span>             <span class="n">input_storage</span><span class="o">=</span><span class="n">node_input_storage</span><span class="p">,</span> <span class="n">output_storage</span><span class="o">=</span><span class="n">node_output_storage</span>
<span class="g g-Whitespace">    </span><span class="mi">602</span>         <span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">make_thunk</span><span class="nt">(self, input_storage, output_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1201</span>         <span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">   </span><span class="mi">1202</span><span class="s2">         init_tasks, tasks = self.get_init_tasks()</span>
<span class="ne">-&gt; </span><span class="mi">1203</span><span class="s2">         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(</span>
<span class="g g-Whitespace">   </span><span class="mi">1204</span><span class="s2">             input_storage, output_storage, storage_map</span>
<span class="g g-Whitespace">   </span><span class="mi">1205</span><span class="s2">         )</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">__compile__</span><span class="nt">(self, input_storage, output_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1136</span><span class="s2">         input_storage = tuple(input_storage)</span>
<span class="g g-Whitespace">   </span><span class="mi">1137</span><span class="s2">         output_storage = tuple(output_storage)</span>
<span class="ne">-&gt; </span><span class="mi">1138</span><span class="s2">         thunk, module = self.cthunk_factory(</span>
<span class="g g-Whitespace">   </span><span class="mi">1139</span><span class="s2">             error_storage,</span>
<span class="g g-Whitespace">   </span><span class="mi">1140</span><span class="s2">             input_storage,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">cthunk_factory</span><span class="nt">(self, error_storage, in_storage, out_storage, storage_map)</span>
<span class="g g-Whitespace">   </span><span class="mi">1632</span><span class="s2">             for node in self.node_order:</span>
<span class="g g-Whitespace">   </span><span class="mi">1633</span><span class="s2">                 node.op.prepare_node(node, storage_map, None, &quot;c&quot;)</span>
<span class="ne">-&gt; </span><span class="mi">1634</span><span class="s2">             module = get_module_cache().module_from_key(key=key, lnk=self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1635</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1636</span><span class="s2">         vars = self.inputs + self.outputs + self.orphans</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py</span> in <span class="ni">module_from_key</span><span class="nt">(self, key, lnk)</span>
<span class="g g-Whitespace">   </span><span class="mi">1189</span><span class="s2">             try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1190</span><span class="s2">                 location = dlimport_workdir(self.dirname)</span>
<span class="ne">-&gt; </span><span class="mi">1191</span><span class="s2">                 module = lnk.compile_cmodule(location)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span><span class="s2">                 name = module.__file__</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span><span class="s2">                 assert name.startswith(location)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/basic.py</span> in <span class="ni">compile_cmodule</span><span class="nt">(self, location)</span>
<span class="g g-Whitespace">   </span><span class="mi">1541</span><span class="s2">             try:</span>
<span class="g g-Whitespace">   </span><span class="mi">1542</span><span class="s2">                 _logger.debug(f&quot;LOCATION </span><span class="si">{location}</span><span class="s2">&quot;)</span>
<span class="ne">-&gt; </span><span class="mi">1543</span><span class="s2">                 module = c_compiler.compile_str(</span>
<span class="g g-Whitespace">   </span><span class="mi">1544</span><span class="s2">                     module_name=mod.code_hash,</span>
<span class="g g-Whitespace">   </span><span class="mi">1545</span><span class="s2">                     src_code=src_code,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py</span> in <span class="ni">compile_str</span><span class="nt">(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)</span>
<span class="g g-Whitespace">   </span><span class="mi">2494</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">2495</span><span class="s2">         try:</span>
<span class="ne">-&gt; </span><span class="mi">2496</span><span class="s2">             p_out = output_subprocess_Popen(cmd)</span>
<span class="g g-Whitespace">   </span><span class="mi">2497</span><span class="s2">             compile_stderr = p_out[1].decode()</span>
<span class="g g-Whitespace">   </span><span class="mi">2498</span><span class="s2">         except Exception:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/site-packages/theano/utils.py</span> in <span class="ni">output_subprocess_Popen</span><span class="nt">(command, **params)</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span><span class="s2">     # we need to use communicate to make sure we don&#39;t deadlock around</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span><span class="s2">     # the stdout/stderr pipe.</span>
<span class="ne">--&gt; </span><span class="mi">254</span><span class="s2">     out = p.communicate()</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span><span class="s2">     return out + (p.returncode,)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/subprocess.py</span> in <span class="ni">communicate</span><span class="nt">(self, input, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1026</span><span class="s2"> </span>
<span class="g g-Whitespace">   </span><span class="mi">1027</span><span class="s2">             try:</span>
<span class="ne">-&gt; </span><span class="mi">1028</span><span class="s2">                 stdout, stderr = self._communicate(input, endtime, timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1029</span><span class="s2">             except KeyboardInterrupt:</span>
<span class="g g-Whitespace">   </span><span class="mi">1030</span><span class="s2">                 # https://bugs.python.org/issue25942</span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/subprocess.py</span> in <span class="ni">_communicate</span><span class="nt">(self, input, endtime, orig_timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1866</span><span class="s2">                             &#39;failed to raise TimeoutExpired.&#39;)</span>
<span class="g g-Whitespace">   </span><span class="mi">1867</span><span class="s2"> </span>
<span class="ne">-&gt; </span><span class="mi">1868</span><span class="s2">                     ready = selector.select(timeout)</span>
<span class="g g-Whitespace">   </span><span class="mi">1869</span><span class="s2">                     self._check_timeout(endtime, orig_timeout, stdout, stderr)</span>
<span class="g g-Whitespace">   </span><span class="mi">1870</span><span class="s2"> </span>

<span class="nn">/opt/hostedtoolcache/Python/3.8.11/x64/lib/python3.8/selectors.py</span> in <span class="ni">select</span><span class="nt">(self, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">413</span><span class="s2">         ready = []</span>
<span class="g g-Whitespace">    </span><span class="mi">414</span><span class="s2">         try:</span>
<span class="ne">--&gt; </span><span class="mi">415</span><span class="s2">             fd_event_list = self._selector.poll(timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">416</span><span class="s2">         except InterruptedError:</span>
<span class="g g-Whitespace">    </span><span class="mi">417</span><span class="s2">             return ready</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<p>第 1 行代码构建了一个模型的容器， <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 使用 <code class="docutils literal notranslate"><span class="pre">with</span></code> 语法将所有位于该语法块内的代码都指向同一个模型，你可以把它看作是简化模型描述的“语法糖”，此处将模型命名为 <code class="docutils literal notranslate"><span class="pre">our_first_model</span></code> 。</p>
<p>第 2 行代码指定了先验，可以看到语法与数学表示很接近。</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>需要注意的是，我们把随机变量命名为 θ ，此处变量名与贝塔函数的第 1 个参数名一样；保持相同的名字是个好习惯，这样能避免混淆。然后，我们通过变量名从后验采样中提取信息。此处变量是一个随机变量，我们可以将该变量看做是从某个分布（在此处是贝塔分布）中生成数值的方法而不是某个具体的值。</p>
</div>
<p>第 3 行代码用跟先验相同的语法描述了似然，唯一不同的是我们用 <code class="docutils literal notranslate"><span class="pre">observed</span></code> 变量传递了观测到的数据，这样就告诉了 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 似然。其中，<code class="docutils literal notranslate"><span class="pre">data</span></code> 可以是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 列表或者 <code class="docutils literal notranslate"><span class="pre">Numpy</span></code> 数组或者 <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> 的 <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> 。</p>
</div>
<div class="section" id="id4">
<h3>2.2.2 执行推断<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>最后一行可以视为推断按钮。我们要求从后验中做 1000 次采样， 并且将其白存在 <code class="docutils literal notranslate"><span class="pre">trace</span></code> 对象中。在这行代码背后，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 在执行数百个贝叶斯推断任务！如果您运行该代码，您将收到如下消息：</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [θ]
100%|██████████| 3000/3000 [00:00&lt;00:00, 3695.42it/s]
</pre></div>
</div>
<p>第一行和第二行告诉我们，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 已经自动分配了 NUTS 采样器（一个非常适用于连续变量的推断引擎），并使用了一种方法来初始化该采样器。第三行说明 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 将并行运行两个链，因此我们从后端可以同时获得两个独立样本。链的确切数量是根据计算机中处理器数量计算的，您可以使用 <code class="docutils literal notranslate"><span class="pre">sample</span></code> 函数的 <code class="docutils literal notranslate"><span class="pre">chains</span></code> 参数来更改它。</p>
<p>下一行告诉我们哪些变量是由哪个采样器采样的。对于此特定情况，此行不会添加新信息。因为 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 是用来对我们拥有的唯一变量 <span class="math notranslate nohighlight">\(θ\)</span> 进行采样的。但情况并不总是如此，因为 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 可以将不同采样器分配给不同变量。这是由 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 根据变量属性自动完成的，以确保为每个变量使用尽可能好的采样器。用户可以使用 <code class="docutils literal notranslate"><span class="pre">sample</span></code> 函数的 <code class="docutils literal notranslate"><span class="pre">step</span></code> 参数手动分配采样器。</p>
<p>最后一行是进度条，其中有几个相关度量指示采样器的工作速度，包括每秒迭代的次数。如果运行代码，您将看到进度条更新得非常快。在此处，我们看到的是采样器完成其工作的最后一个阶段。数字是 <code class="docutils literal notranslate"><span class="pre">3000/3000</span></code>，其中第一个数字是运行采样器编号（从 1 开始），最后一个数字是样本总数。您会注意到，我们要求了 1,000 个样本，但 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 正在计算 3,000 个样本。我们每条链有 500 个样本来自动调整采样算法（本例中为 NUTS）。默认情况下，此示例将被丢弃。我们每条链也有 1,000 个生产图纸，因此总共生成了 3,000 个样本。调谐阶段帮助 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 从后端提供可靠样本。我们可以使用 <code class="docutils literal notranslate"><span class="pre">sample</span></code> 函数的 <code class="docutils literal notranslate"><span class="pre">tune</span></code> 参数更改调优步骤数。</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>注意：本书第一版中稍有不同，有人工定义起点和采样方法的设置。</p>
</div>
</div>
<div class="section" id="id5">
<h3>2.2.3 诊断推断结果<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<div class="section" id="id6">
<h4>2.2.3.1 诊断工具和方法<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>现在我们根据有限数量的样本对后验做出了（近似）推断，接下来要做的是检查推断是否合理。可以通过可视化的或者定量的手段做一些测试，从中尝试发现样本中的问题。诊断并不能证明得到的分布是正确的，但能够提供证据证明样本看起来是合理的。<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> 函数非常适合执行此任务：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504190255_62.webp" /></p>
<p>通过使用 <code class="docutils literal notranslate"><span class="pre">az.plot_trace</span></code>，我们可以为每个非观测变量绘制两个子图。我们模型中唯一的非观测变量是 <span class="math notranslate nohighlight">\(\theta\)</span> 。请注意： <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 表示观测变量，因其值已知，不需采样。上图中，左边为核密度估计（ <code class="docutils literal notranslate"><span class="pre">KDE</span></code> ）图，该图类似于直方图的平滑版本；右图为采样过程中每一步的采样值，称为轨迹图。轨迹图中可以直观地查看从后端获得的采样结果。你可以尝试将 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的结果与上一章通过解析获得的结果进行比较。</p>
<p><code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 还提供了其他几个绘图来帮助解释轨迹图，我们将在后面看到它们。此外 <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 可以提供 <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> 形式的摘要数据。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504200055_94.webp" /></p>
<p>通过上图所示的摘要数据，可以得到均值、标准差和 <code class="docutils literal notranslate"> <span class="pre">94%</span> <span class="pre">HPD</span></code> 区间（<code class="docutils literal notranslate"><span class="pre">HPD</span> <span class="pre">3%</span></code>和 <code class="docutils literal notranslate"><span class="pre">HPD</span> <span class="pre">97%</span></code> )。正如在第一章“概率思维”中所讨论，可以使用这些数字来解释和报告贝叶斯推断的结果。后两个指标与诊断样本相关。详细信息请参阅第 8 章-推断引擎。</p>
<p>另一种直观总结后验的方法是使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 附带的 <code class="docutils literal notranslate"><span class="pre">plot_posterior</span></code> 函数。默认情况下，<code class="docutils literal notranslate"><span class="pre">plot_posterior</span></code> 为离散变量显示直方图，为连续变量显示 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 。我们还获得了分布的均值（可以使用 <code class="docutils literal notranslate"><span class="pre">point_estimate</span></code> 参数指定中位数或其他模式），<code class="docutils literal notranslate"><span class="pre">94%</span> <span class="pre">HPD</span></code> 作为图底部的一条黑线。可以使用 <code class="docutils literal notranslate"><span class="pre">credible_interval</span></code> 参数为 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 设置不同的间隔值。此类型的图由 <code class="docutils literal notranslate"><span class="pre">John</span> <span class="pre">K.Kruschke</span></code> 在其著作《 <code class="docutils literal notranslate"><span class="pre">Doing</span> <span class="pre">Bayesian</span> <span class="pre">Data</span> <span class="pre">Analysis</span></code> 》中引入。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504200820_a7.webp" /></p>
</div>
<div class="section" id="id7">
<h4>2.2.3.2 常用解决办法<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>如果通过样本发现了问题，解决办法有如下几种：</p>
<p><strong>（1）增加样本数量</strong></p>
<p>从样本链（迹）的前面部分去掉一定数量的样本，称为老化（<code class="docutils literal notranslate"><span class="pre">Burn-in</span></code>）。在实践中，<code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 方法通常需要经过一段时间的采样之后，才得到真正的目标分布。老化在无限多次采样中并不是必须的，因为这部分并没有包含在马尔科夫理论中。事实上，去掉前面部分样本只不过是在有限次采样中提升结果的一个小技巧。需注意，不要被数学对象和数学对象的近似弄糊涂了，球体、高斯分布以及马尔科夫链等数学对象只存在于柏拉图式想象世界中，并不存在于不完美但却真实的世界中。</p>
<p><strong>（2）重新参数化你的模型</strong></p>
<p>也就是说换一种不同但却等价的方式描述模型。</p>
<p><strong>（3）转换数据</strong></p>
<p>这么做有可能得到更高效的采样。转换数据的时候需要注意对结果在转换后的空间内进行解释，或者再重新转换回去，然后再解释结果。</p>
</div>
<div class="section" id="id8">
<h4>2.2.3.3 收敛性问题<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h4>
<p>在 <code class="docutils literal notranslate"><span class="pre">az.plot_trace</span></code> 图中，我们需要观察什么呢？首先，<code class="docutils literal notranslate"><span class="pre">KDE</span></code> 图看起来应该是光滑曲线。通常随着数据的增加，根据中心极限定理，参数分布会趋近于高斯分布。当然，这并不一定是正确的。右侧图看起来应该像白噪声，也就是说有很好的混合度，通常不希望看到任何可以识别的模式，相反希望看到曲线在某个值附近震荡。对于多峰分布或者离散分布，我们希望曲线不要在某个值或区域停留过多时间，我们希望看到采样值在多个区间自由移动。此外，我们希望迹表现出稳定的相似性，也就是说，前 10% 看起来跟后 50% 或者 10% 差不多。再次强调，我们不希望看到规律的模式，相反期望看到的是噪声。下图展示了一些迹呈现较好混合度（右侧）与较差混合度（左侧）的对比。</p>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504202103_98.webp" style="zoom:67%;" />
<p>如果迹的前面部分跟其他部分看起来不太一样，那就意味着需要进行老化处理，如果其他部分没有呈现稳定的相似性或者可以看到某种模式，那这意味着需要更多的采样，或者需要更换采样方法或者参数化方法。对于一些复杂的模型，我们可能需要结合使用前面所有的策略。</p>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 可以实现并行地运行一个模型多次，因而对同一个参数可以得到多条并行的迹。这可以通过在采样函数中指定 <code class="docutils literal notranslate"><span class="pre">njobs</span></code> 参数实现。此时使用 <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> 函数，便可在同一幅图中得到同一个参数的所有迹。由于每组迹都是相互独立的，所有的迹看起来都应该差不多。除了检查收敛性之外，这些并行的迹也可以用于推断，我们可以将这些并行的迹组合起来提升采样大小而不是扔掉多余的迹：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">our_first_model</span><span class="p">:</span>
 <span class="n">step</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Metropolis</span><span class="p">()</span>
 <span class="n">multi_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">multi_trace</span><span class="p">,</span> <span class="n">lines</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;theta&#39;</span><span class="p">:</span><span class="n">theta_real</span><span class="p">});</span>
</pre></div>
</div>
</div>
</div>
<p>一种定量检测收敛性的方法是 <strong>Gelman-Rubin 检验</strong> （ <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 输出的表格中的 <span class="math notranslate nohighlight">\(\hat R\)</span> 值）。该检验的思想是比较不同迹之间的差异和迹内部的差异，因此，需要多组迹来执行检验。理想状态下，我们希望得到 <span class="math notranslate nohighlight">\(\hat R=1\)</span> 。但根据经验，值低于 1.1 也可以认为是收敛的，更高的值则意味着不收敛。</p>
</div>
<div class="section" id="id9">
<h4>2.2.3.4 自相关问题<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p>最理想的采样应该不会是自相关的，也就是说，某点的值应该与其他点的值相互独立。在实际中，从 <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> 方法（特别是 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code>）中得到的采样值通常是自相关的。由于参数间的相互依赖关系，模型会导致更多自相关采样。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 有一个很方便的函数用来描述自相关。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_autocorr</span><span class="p">(</span><span class="n">trace</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="image-20210504203037224" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504203039_fe.webp" /></p>
<p>该图显示了采样值与相邻连续点之间的平均相关性。理想状态下，不应看到自相关性，实际中希望看到自相关性降低到较低水平。参数越自相关，要达到指定精度的采样次数就需要越多，也就是说，自相关性不利于降低采样次数。</p>
</div>
<div class="section" id="id10">
<h4>2.2.3.5 有效后验采样次数<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>有自相关性的采样要比没有自相关性的采样包含的信息量更少，给定采样大小和采样的自相关性之后，可以尝试估计出该采样在采样次数为多少时，没有自相关性且包含信息量不变，该值称为有效采样次数（ <code class="docutils literal notranslate"><span class="pre">az.summary</span></code> 输出表格中的 <code class="docutils literal notranslate"><span class="pre">eff_n</span></code> 值）。理想情况下，两个值是一模一样的；二者越接近，采样效率越高。有效采样次数可以作为一个参考，如果想要估计出分布的均值，需要的最小采样数至少为 100；如果想要估计出依赖于尾部分布的量，比如可信区间的边界，那么可能需要 1000 到 10000 次采样。</p>
<p>提高采样效率的一个方法是换一个更好的采样方法；另一个办法是转换数据或者对模型重新设计参数，此外，还有一个常用的办法是对采样链压缩。所谓压缩其实就是每隔 k 个观测值取一个，在 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 中我们称为切片。压缩会降低自相关性，但代价是同时降低了样本量。因此，实际使用中通常更倾向于增加样本量而不是切片。</p>
</div>
</div>
<div class="section" id="id11">
<h3>2.2.4 基于后验推断的决策<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>有时候，仅描述后验还不够，还需要根据推断结果做决策。也就是说，我们不得不将一个连续的估计（后验分布）简化为一个二分法，如：是还是否、健康还是生病、污染还是安全等。回到抛硬币问题上，我们需要回答硬币是否公平。一枚公平的硬币 <span class="math notranslate nohighlight">\(\theta\)</span> 值应当恰好是 0.5，严格来说，出现这种情况的概率为 0，因而实际中会对定义稍稍放松，即假如一枚硬币的 <span class="math notranslate nohighlight">\(\theta\)</span> 值在 0.5 左右，就可以认为判定该硬币是公平的。此处“左右”的具体含义依赖于具体问题，并没有一个满足所有问题的普适准则。因此决策是偏主观的，我们的任务就是根据目标做出最可能的决策。</p>
<p>直观上，一个明智的做法是将 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间与我们感兴趣的值进行比较，在抛硬币的例子中，该值是 0.5。前面的图中可以看出 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 的范围是 0.02～0.71 ，包含 0.5 ，根据后验分布来看，硬币似乎倾向于反面朝上，但我们并不能完全排除这枚硬币的公平的。如果想要一个更清晰的决定，将需要收集更多数据来减少后验数据的扩散，或者需要找出如何定义一个更有信息量的先验。</p>
<p><strong>（1）<code class="docutils literal notranslate"><span class="pre">ROPE</span></code></strong></p>
<p>严格地说，恰好观察到 0.5 的机会为零。此外，实践中我们通常不关心确切结果，而是在一定范围内的结果。因此，可以放宽公平的定义，例如我们可以说区间 [0.45，0.55] 中的任何值实际上等于 0.5。我们称这个区间为实际等效区间（<code class="docutils literal notranslate"><span class="pre">ROPE</span></code>）。一旦定义了 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code>，将其与最高后验密度（<code class="docutils literal notranslate"><span class="pre">HPD</span></code>）比较，至少可以得到三个场景：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 与 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间没有重叠，因此我们可以说硬币是不公平的。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 包含整个 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间，我们可以认为硬币是公平的。</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 与 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间部分重叠，此时我们不能判断硬币是否公平。</p></li>
</ul>
<p>当然，如果选择区间 [0,1] 作为 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code>，那么不管结果怎样我们都会说这枚硬币是公平的，不过恐怕没人会同意我们对 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 的定义。</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 是根据背景或专业知识选择的任意区间，假设在该区间内的任何值都具有实际等效性。</p>
</div></blockquote>
<p>plot_posterior 函数可以用来刻画 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code>。从图中可以看到，<code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 是一段较宽的半透明的红色线段，同时上面有两个数值表示 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 的两个端点。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">ROPE</span><span class="o">=</span><span class="p">[</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">.55</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504204839_cb.webp" /></p>
<p>我们还可以给 <code class="docutils literal notranslate"><span class="pre">plot_posterior</span></code> 传递一个参考值，例如 0.5，用来和后验进行对比。从图中可以看出我们会得到一个橙色的垂直线以及大于该值和小于该值的后验比例。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span><span class="n">ref_val</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504204959_25.webp" /></p>
<p>关于如何使用 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 的更多细节，可以阅读 Kruschke 的《<code class="docutils literal notranslate"><span class="pre">Doing</span> <span class="pre">Bayesian</span> <span class="pre">Data</span> <span class="pre">Analysis</span></code>》一书的第 12 章。该章还讨论了在贝叶斯框架下如何做假设检验，以及一些（贝叶斯或者非贝叶斯的）假设检验方面的警告。</p>
<p><strong>（2）损失函数</strong></p>
<p>如果你认为 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 准则听起来有点笨拙，而你想要更正式的东西，那么损失函数就是你想要的！要做出好的决策，重要的是参数的估计值有尽可能高的精度，但也要考虑犯错的代价。成本/收益的权衡在数学上可以使用损失函数形式化。损失函数或其逆函数的名称在不同的领域中各不相同，可以找到成本函数、目标函数、适应度函数、效用函数等名称。无论名称如何，关键思想都是使用一个函数来捕获参数的真实值和估计值的差别。损失函数值越大，估计就越差（根据损失函数）。损失函数的一些常见示例包括：</p>
<ul class="simple">
<li><p>二次损失 <span class="math notranslate nohighlight">\((\theta-\hat{\theta})^{2}\)</span></p></li>
<li><p>绝对损失 <span class="math notranslate nohighlight">\(|\theta-\hat{\theta}|\)</span></p></li>
<li><p>0-1 损失 <span class="math notranslate nohighlight">\(I(\theta \neq \hat{\theta})\)</span> ，其中 <span class="math notranslate nohighlight">\(I\)</span> 为指示函数</p></li>
</ul>
<p>实践中通常手头没有真实参数 <span class="math notranslate nohighlight">\(\theta\)</span> 的值，仅有一个后验分布形式的估计。因此，我们能做的就是找出最小化期望损失函数的 <span class="math notranslate nohighlight">\(\hat \theta\)</span> 值。期望损失函数是指整个后验分布的平均损失函数。在下面代码块中，我们有两个损失函数：绝对损失（ <code class="docutils literal notranslate"><span class="pre">lossf_a</span></code>）和平方损失（ <code class="docutils literal notranslate"><span class="pre">lossf_b</span></code>）。我们将尝试超过 200 个网格的 <span class="math notranslate nohighlight">\(\hat \theta\)</span> 值，然后绘制其曲线，还将包括最小化每个损失函数的 <span class="math notranslate nohighlight">\(\hat \theta\)</span> 值：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">θ_pos</span> <span class="o">=</span> <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;θ&#39;</span><span class="p">]</span>
<span class="n">lossf_a</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">θ_pos</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">]</span>
<span class="n">lossf_b</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">i</span> <span class="o">-</span> <span class="n">θ_pos</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">]</span>
<span class="k">for</span> <span class="n">lossf</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">lossf_a</span><span class="p">,</span> <span class="n">lossf_b</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="s1">&#39;C1&#39;</span><span class="p">]):</span>
 <span class="n">mini</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">lossf</span><span class="p">)</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">lossf</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">],</span> <span class="n">lossf</span><span class="p">[</span><span class="n">mini</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">]),</span>
     <span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">],</span> <span class="n">lossf</span><span class="p">[</span><span class="n">mini</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.03</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39; $\hat \theta $ &#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504210053_d2.webp" /></p>
<p>正如我们所看到的，结果显示 <code class="docutils literal notranslate"><span class="pre">lossf_a</span></code> 的最优解是 <span class="math notranslate nohighlight">\(\hat \theta=0.32\)</span> ，<code class="docutils literal notranslate"><span class="pre">lossf_b</span></code> 的最优解是 <span class="math notranslate nohighlight">\(\hat \theta=0.33\)</span> ​ 。该结果中比较有趣的是，前一个值等于后验的中位数，后一个值等于后验的平均值。通过计算 <code class="docutils literal notranslate"><span class="pre">np.Means(θ_pos)</span></code>、<code class="docutils literal notranslate"><span class="pre">np.Medium(θ_pos)</span></code> 可以检查这个情况。这似乎在暗示：不同的损失函数与不同的点估计有关。</p>
<p>OK，如果想要形式化的结果并给出点估计，必须决定想要哪个损失函数，或者反过来，如果选择一个给定点估计，就隐含地（甚至可能是无意识地）决定了一个损失函数。显式选择损失函数的好处是可以根据问题调整函数，而不是使用一些可能不适合特定情况的预定义规则。</p>
<p>在许多问题中，做出决定的成本是不对称的；例如，决定给五岁以下的儿童接种疫苗还是不接种疫苗。一个糟糕的决定可能会造成数千人生命损失，并产生健康危机，而这场危机本可以通过接种一种廉价而安全的疫苗来避免。因此，如果问题需要的话，可以构造一个不对称损失函数。</p>
<p>同样重要的是要注意，由于后验分布是数字采样的形式，因此理论上可以计算任意复杂的损失函数，而不需要受数学形式上的限制。</p>
<p>以下只是一个愚蠢的例子：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lossf</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">grid</span><span class="p">:</span>
 <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">θ_pos</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">θ_pos</span><span class="p">))</span>
 <span class="k">else</span><span class="p">:</span>
  <span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">θ_pos</span><span class="p">))</span>
 <span class="n">lossf</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">mini</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">lossf</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">lossf</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">],</span> <span class="n">lossf</span><span class="p">[</span><span class="n">mini</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">]),</span>
    <span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="n">mini</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">lossf</span><span class="p">[</span><span class="n">mini</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39; $\hat \theta $ &#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504211017_cb.webp" /></p>
<p>话虽如此，我想澄清一点。这并不是说，每次人们使用点估计时，他们都是真的在考虑损失函数。事实上，在我或多或少熟悉的许多科学领域，损失函数并不是很常见。人们经常选择中位数，只是因为它对异常值比平均值更可靠，或者仅仅因为它是一个简单而熟悉的概念，或者因为他们认为它们的可观测性真的是某种程度上某个过程的平均值，比如分子相互弹跳，或者基因与自己和环境相互作用。</p>
<p>我们刚刚看到对损失函数的简单而浅显的介绍。如果你想了解更多这方面知识，可以尝试阅读决策理论，这是一个研究正式决策的领域。</p>
</div>
</div>
<div class="section" id="id12">
<h2>2.3 随处可见的高斯分布<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>前面我们用贝塔–二项分布模型介绍了贝叶斯思想，该模型很简单。另外一个非常简单的模型是高斯分布或者叫正态分布。从数学的角度来看，高斯分布非常受欢迎的原因是它处理起来非常简单，例如，高斯分布的均值，其共轭先验还是高斯分布。此外，许多现象都可以用高斯分布来近似；本质上来说，每当测量某种均值时，只要采样样本量足够大，观测值的分布就会呈现高斯分布。至于这种近似什么时候是对的，什么时候是错的，可以了解下中心极限定理。此处举一个例子，身高（以及其他描述人的特征）是受到基因和许多环境因素影响的，因而我们观测到的成年人的身高符合高斯分布。不过事实上，我们得到的其实是一个双峰分布，男人和女人的身高分布重叠在了一起。总的来说，高斯分布用起来很简单，而且自然界中随处可见，这也是为什么你了解或者听说过的许多统计方法都基于高斯分布。学习如何构建这类模型非常重要，此外，学会如何放宽正态分布的假设也同等重要，该点在贝叶斯框架中利用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 之类的现代计算工具很容易处理。</p>
<div class="section" id="id13">
<h3>2.3.1 高斯推断<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>下面的例子与核磁共振实验有关，核磁共振是一种研究分子和生物的技术。下面这组数据，可能来自一群人身高的测量值、回家的平均时间、从超市买回来橙子的重量、大壁虎的伴侣个数或者任何可以用高斯分布近似的测量值。在这个例子中，我们有 48 个测量值：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="s1">&#39;../data/chemical_shifts.csv&#39;</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_kde</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p>除了两个远离平均值的数据点外，该数据集的 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 图显示出类似高斯的分布：</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504212534_30.webp" /></p>
<p>暂且先不考虑偏离均值的那两个点，假设以上分布就是高斯分布。由于我们不知道均值和方差，需要先对这两个变量设置先验。然后，顺理成章地得到如下模型：</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.2} \label{式2.2} 
\mu &amp;\sim U(l, h)  \\
\sigma &amp;\sim\left|\mathcal{N}\left(0, \sigma_{\sigma}\right)\right|  \\
y &amp;\sim \mathcal{N}(\mu, \sigma) 
\end{align*}\]</div>
<p>其中， <span class="math notranslate nohighlight">\(\mu\)</span> 来自上下界分别为 <span class="math notranslate nohighlight">\(l\)</span> 和 <span class="math notranslate nohighlight">\(h\)</span> 的均匀分布， <span class="math notranslate nohighlight">\(\sigma\)</span> 来自标准差为 <span class="math notranslate nohighlight">\(\sigma_\sigma\)</span> 的半正态分布。半正态分布和普通正态分布很像，不过只包含正数，看起来就好像将普通的正态分布沿着均值对折了。通过从正态分布中采样，然后取绝对值，可以获取半正态分布的样本。最后，在我们的模型中，数据 <span class="math notranslate nohighlight">\(y\)</span> 来自参数分别为 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 的正态分布，可以用 Kruschke 风格的图将其画出来：</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504213129_7f.webp" /></p>
<p>如果不知道 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 的值，可以通过先验来表示该未知信息。例如，可以将均匀分布的上下界分别设为（<span class="math notranslate nohighlight">\(l\)</span> = 40, <span class="math notranslate nohighlight">\(h\)</span> = 75），该范围要比数据本身的范围稍大一些。或者，可以根据先验知识设得更广一些，比如知道这类观测值不可能小于 0 或者大于 100 ，可以将均匀先验参数设为（<span class="math notranslate nohighlight">\(l\)</span> = 0, <span class="math notranslate nohighlight">\(h\)</span> = 100）。对于半正态分布而言，可以把 <span class="math notranslate nohighlight">\(\sigma_\sigma\)</span> 的值设为 10，该值相对于数据分布而言算是较大的。 利用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> ，我们可以将模型表示如下：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_g</span><span class="p">:</span>
  <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>
  <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
  <span class="n">trace_g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504213401_14.webp" /></p>
<p>您可能已经注意到了，使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的 <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> 函数生成的图中，每个未知参数都有一行。对于这个模型，后验是二维的，所以上图显示了每个参数的边缘分布。我们可以使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">plot_joint</span></code> 函数来查看二维的后验分布是什么样子，以及 <span class="math notranslate nohighlight">\(μ\)</span> 和 <span class="math notranslate nohighlight">\(σ\)</span> 的边缘分布：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_joint</span><span class="p">(</span><span class="n">trace_g</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;kde&#39;</span><span class="p">,</span> <span class="n">fill_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="image-20210504213715796" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504213728_51.webp" /></p>
<p>如果要访问存储在跟踪对象中的任何参数值，可以使用相关参数的名称做为跟踪索引。因此，您将获得一个 NumPy 数组。尝试执行 <code class="docutils literal notranslate"><span class="pre">trace_g['σ']</span></code> 或 <code class="docutils literal notranslate"><span class="pre">az.plot_kde(trace_g['σ'])</span></code>。顺便说一下，使用 Jupyter Notebook/lab，您可以通过在代码单元格中写入 \sigma，然后按 Tab 键来获取字符。</p>
<p>我们将打印该摘要以供以后使用：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504213925_74.webp" /></p>
<p>现在已经计算了后验概率，可以用它来模拟数据，并检查模拟数据与观测数据的一致性。如果你还记得第1章“概率思维”，这种比较被称为后验预测检查，因为使用后验进行预测，并使用这些预测来检验模型。如果使用 <code class="docutils literal notranslate"><span class="pre">sample_posterior_predictive</span></code> 函数，使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 可以非常容易获得后验预测样本。使用以下代码，我们将从后端生成 100 个预测，每个预测的大小与数据相同。请注意，我们必须将跟踪和模型传递给 <code class="docutils literal notranslate"><span class="pre">sample_posterior_predictive</span></code> ，而其他参数是可选的：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_g</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">model_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">y_pred_g</span></code> 变量是一个字典，<code class="docutils literal notranslate"><span class="pre">keys</span></code> 是模型中观察到的变量名称，<code class="docutils literal notranslate"><span class="pre">values</span></code> 是形状为（<code class="docutils literal notranslate"><span class="pre">samples</span></code>、<code class="docutils literal notranslate"><span class="pre">size</span></code>）的数组，在本例中为 <span class="math notranslate nohighlight">\((100，len(data))\)</span> 。我们有一本字典，因为至少有一个可观测变量的模型。可以使用 <code class="docutils literal notranslate"><span class="pre">plot_ppc</span></code> 函数进行可视化后验预测检查：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_ppc</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace_g</span><span class="p">,</span> <span class="n">posterior_predictive</span><span class="o">=</span><span class="n">y_pred_g</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">data_ppc</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504214541_d9.webp" /></p>
<p>上图中，黑色的线是观测数据的 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> ，半透明（青色）线反映了我们对预测数据的推断分布的不确定性。有时，当你只有很少数据点时。像此类曲线图可能会显示预测曲线是毛茸茸的或摇摇晃晃的；这是由于 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 在 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 中的实现方式所致。密度是在传递给 <code class="docutils literal notranslate"><span class="pre">KDE</span></code> 函数的数据的实际范围内估计的，而在这个范围之外，密度被假定为零。虽然有些人可能认为这是一个错误，但我认为这是一个功能，因为它反映了数据的一个属性，而不是过度平滑。</p>
<p>从上图中，可以看到模拟数据的平均值稍微向右移动，并且模拟数据的方差似乎比实际数据方差更大。这是从大量数据中分离出来的两个观察结果的直接结果。我们能不能用这张图自信地说，模型有问题，需要改变？像往常一样，模型的解释和评估取决于上下文。根据测量经验和数据使用方式，我个人认为该模型是一个足够合理的数据表示方法，对我的大多数分析都够了。但在下一节中，我们会学习如何改进 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 并获得与数据更接近的预测。</p>
</div>
<div class="section" id="id14">
<h3>2.3.2 更稳健的推断<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<p>对于 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 模型，您可能会有异议，那就是假设是正态分布，但是实际数据分布的尾部有两个特殊的数据点，使得假设有点勉强。对于正态分布，其尾部应随远离平均值而迅速下降，因此，当尾部出现这两个点时，正态分布的直接反应就是均值向此点移动，同时可能增加标准差。因此，可以想象这些点对决定正态分布的参数具有过大的影响，那么怎么处理呢？ 有两个最常用的做法，一是将两个点作为异常样本剔除，二是调整模型。</p>
<div class="section" id="id15">
<h4>（1）剔除异常值<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h4>
<p>对于第一种做法，将两个点看做异常并将其剔除，主要是因为有可能这些点是仪器异常或者人为疏忽导致，又或是处理数据时代码出了问题，但更多时候，我们希望有一些可以遵循的处理规则来自动消除异常点，其中的两个规则如下：</p>
<ul class="simple">
<li><p>低于下四分位数 1.5 倍的四分位数范围或高于上四分位数 1.5 倍的任何数据点都是异常值</p></li>
<li><p>任何低于或大于数据标准差两倍的数据点都应被宣布为异常值，并从数据中剔除</p></li>
</ul>
</div>
<div class="section" id="id16">
<h4>（2）调整模型<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h4>
<p>除了改变原始数据外，还可以修改模型。按照贝叶斯思想，我们更倾向于通过使用不同的先验或似然将假设编码到模型中，而不是通过剔除异常值这种方法。一个解决异常值的常用方法是将高斯分布替换成 <span class="math notranslate nohighlight">\(t\)</span> 分布。 <span class="math notranslate nohighlight">\(t\)</span> 分布有 3 个参数：<code class="docutils literal notranslate"><span class="pre">均值</span> <span class="pre">mean</span> </code>、<code class="docutils literal notranslate"><span class="pre">尺度</span> <span class="pre">scale</span></code>（类似标准差）和<code class="docutils literal notranslate"><span class="pre">自由度</span> <span class="pre">df</span></code>（通常用 <span class="math notranslate nohighlight">\(\nu\)</span> 表示，取值范围为[0,∞] )。根据 Kruschke 的命名方式，我们将 <span class="math notranslate nohighlight">\(\nu\)</span> 称为正态参数，因为该参数决定了 <span class="math notranslate nohighlight">\(t\)</span> 分布与正态分布的相似程度。 <span class="math notranslate nohighlight">\(t\)</span> 分布在不同领域也称柯西分布或者洛伦兹分布：</p>
<ul class="simple">
<li><p>当 <span class="math notranslate nohighlight">\(\nu=1\)</span> 时</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(t\)</span> 分布的尾部比高斯分布重（尾部更重的意思是：相比高斯分布，更有可能观测到偏离均值的点，亦即该分布不像高斯分布那样聚集在均值附近）;</p></li>
</ul>
</li>
<li><p>当 <span class="math notranslate nohighlight">\(\nu \to \infty\)</span> 时</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(t\)</span> 分布就是高斯分布， 尺度趋近于标准差；</p></li>
</ul>
</li>
<li><p>当 <span class="math notranslate nohighlight">\(\nu \leq 1\)</span> 时</p>
<ul>
<li><p>该分布没有准确定义的均值（当然，实际从 <span class="math notranslate nohighlight">\(t\)</span> 分布得到的采样终究是一些数字，总是可以算出经验性的均值，不过理论上还没有一个准确定义的均值）。 直观地说，这可以理解为：<span class="math notranslate nohighlight">\(t\)</span> 分布的尾部太重了，以至于随时可能从距离真实直线的几乎任何地方获得采样值，所以如果一直得到数字，该数字永远不会收敛于某个固定值。</p></li>
</ul>
</li>
<li><p>当 <span class="math notranslate nohighlight">\(\nu \leq 2\)</span>时</p>
<ul>
<li><p>分布的方差没有明确定义，因此，需要注意 <span class="math notranslate nohighlight">\(t\)</span> 分布的尺度参数与标准差不是同一个概念。对于的分布，方差并没有明确定义，因而也没有明确定义的标准差。</p></li>
<li></li>
</ul>
</li>
</ul>
<p>你可以尝试多次运行下面的代码，查看是否有稳定的均值（ 其中 <code class="docutils literal notranslate"><span class="pre">df</span></code> 为自由度）。将参数 <code class="docutils literal notranslate"><span class="pre">df</span></code> 换成一个更大100在尝试一下。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>下面的代码绘制了自由度为 1，2，5，30 时的 <span class="math notranslate nohighlight">\(t\)</span> 分布曲线：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">]:</span>
  <span class="n">distri</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
  <span class="n">x_pdf</span> <span class="o">=</span> <span class="n">distri</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">x_pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">r</span>\<span class="s1">&#39;\ $</span><span class="se">\\</span><span class="s1">nu\ $ = </span><span class="si">{}</span><span class="se">\&#39;</span><span class="s1">.format(df))</span>
<span class="n">x_pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_values</span><span class="p">)</span>\
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">x_pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">r</span>\<span class="s1">&#39;\ $</span><span class="se">\\</span><span class="s1">nu = </span><span class="se">\\</span><span class="s1">infty\ $</span><span class="se">\&#39;</span><span class="s1">) plt.xlabel(</span><span class="se">\&#39;</span><span class="s1">x</span><span class="se">\&#39;</span><span class="s1">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span>\<span class="s1">&#39;p(x)</span><span class="se">\&#39;</span><span class="s1">, rotation=0)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210513181355ce.webp" /></p>
<p>利用 <span class="math notranslate nohighlight">\(t\)</span> 分布可以将模型调整为如下形式：</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.3} \label{式2.3} 
\mu &amp;\sim U(l, h) \\
\sigma &amp;\sim\left|\mathcal{N}\left(0, \sigma_{\sigma}\right)\right| \\
\nu &amp;\sim \operatorname{Exp}(\lambda) \\
 y &amp;\sim \mathcal{T}(\mu, \sigma, \nu) 
 \end{align*}\]</div>
<p>此模型与高斯模型的主要区别是：似然调整为 <span class="math notranslate nohighlight">\(t\)</span> 分布，由于 <span class="math notranslate nohighlight">\(t\)</span> 分布多了一个新的参数 <span class="math notranslate nohighlight">\(\nu\)</span>，需要为其增加一个先验。此处计划采用均值为 30 的指数分布。通过上图可以看出，当 <span class="math notranslate nohighlight">\(\nu = 30\)</span> 时， <span class="math notranslate nohighlight">\(t\)</span> 分布看起来与高斯分布很相似。 从图中也可以看出， <span class="math notranslate nohighlight">\(\nu\)</span> 在 30 附近是一个比较适中的值，既可以调大也可以调小，因此属于弱信息先验。我们的模型可以表示如下：</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210513182721ce.webp" /></p>
<p>同样， <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 让我们只需要几行代码便可修改模型。唯一需要 注意的是， <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中指数分布的参数用的是分布均值的倒数。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ν</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;ν&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">ν</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="n">trace_t</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051318284221.webp" /></p>
<p>图 2.14</p>
</center>
<p>将 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 的轨迹图（图2.9）与 <code class="docutils literal notranslate"><span class="pre">model_t</span></code> 的跟踪（图2.14）进行比较。现在，打印 <code class="docutils literal notranslate"><span class="pre">model_t</span></code> 的摘要，并将其与 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 的摘要进行比较。在继续阅读之前，请花点时间找出两个结果之间的差异。你注意到什么有趣的事情了吗？</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051318370550.webp" /></p>
</center>
<p>可以看到，高斯分布模型和基于 <span class="math notranslate nohighlight">\(t\)</span> 分布模型对 <span class="math notranslate nohighlight">\(µ\)</span> 的估计比较接近，只相差 0.5 左右，而 <span class="math notranslate nohighlight">\(σ\)</span> 的估计则从 3.5 变成了 2.1，这是因为 <span class="math notranslate nohighlight">\(t\)</span> 分布对于偏离均值的点赋予的权重较小。此外还可以看到， <span class="math notranslate nohighlight">\(\nu\)</span> 的值接近 4.5，也就是说，该分布并不太像高斯分布，而是更接近重尾分布。</p>
<p>接下来对 <span class="math notranslate nohighlight">\(t\)</span> 分布模型做后验检查，并将其与高斯分布对比：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_ppc_t</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span>
    <span class="n">trace_t</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">model_t</span><span class="p">,</span> <span class="n">random_seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">y_pred_t</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_pymc3</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">posterior_predictive</span><span class="o">=</span><span class="n">y_ppc_t</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">y_pred_t</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">70</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051318400612.webp" /></p>
<p>可以看到，使用 <span class="math notranslate nohighlight">\(t\)</span> 分布之后，从分布的峰值和形状来看，模型的预测值与观测数据更吻合了。留意预测值远离观测值中心的部分，那是因为 <span class="math notranslate nohighlight">\(t\)</span> 分布希望看到在偏离数据中心的两个方向上都有数据。</p>
<p>在新模型中 <span class="math notranslate nohighlight">\(t\)</span> 分布的估计值更稳健，因为异常点降低了自由度 <span class="math notranslate nohighlight">\(\nu\)</span> 的值，而不是将均值拉向异常点方向并且增加方差。也就是说，均值和尺度的估计给占多数的数据点的权值要大于异常点（注意：尺度不是标准差）。同样要记住，尺度不是标准差，但是尺度确实与数据的分散程度有关，其值越低，则分布越集中。此外，对应自由度 <span class="math notranslate nohighlight">\(\nu\)</span> 大于等于 2 的情况，尺度值倾向于接近剔除异常值后的标准差。因此，对于大的 <span class="math notranslate nohighlight">\(\nu\)</span> 值，可以近似将 <span class="math notranslate nohighlight">\(t\)</span> 分布的尺度视为剔除异常值后的数据标准差。</p>
</div>
</div>
</div>
<div class="section" id="id17">
<h2>2.4 组间比较与假设检验<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<p>统计分析中一个常见任务是对不同组进行比较，例如：想知道病人对某种药的反应如何、引入某种交通法规后车祸数量是否会降低、学生对不同教学方式的表现如何等。</p>
<p>传统频率主义通常将此类问题统一归入<code class="docutils literal notranslate"><span class="pre">假设检验</span></code>的框架下，其目的是得到统计学意义上的显著性。但仅依赖统计显著性可能会带来很多问题：一方面，统计显著性并非实际显著性；另一方面，即使作用不明显，只要收集尽可能多数据，假设都会被看做具有显著性。此外，统计显著性的核心思想往往需要计算 <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">值</span></code> ，但其与显著性之间并非本质联系，而是一种文化联系，人们习惯于这样做，主要因为在大多数统计学入门课程中学来的。已有很多文章和研究记录表明，<code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">值</span></code> 会被错误地使用和解释，即使每天与统计打交道的科学家也难以避免。</p>
<p>在贝叶斯框架下，不做假设检验，而是走一条不同的技术路线。贝叶斯方法将重点放在估计效应大小 （<code class="docutils literal notranslate"><span class="pre">effect</span> <span class="pre">size</span></code>）上，也就是量化两组之间的差异。从效果大小角度思考的好处是，我们不会去回答是或不是的问题，比如：它起作用了吗？有什么效果吗？或者更细微的问题，比如：它工作得有多好？影响有多大？</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>效应大小是量化两个组之间差异大小的一种方法。</p>
</div>
<p>在比较不同组的数据时，人们往往会将其分为一个实验组和一个对照组（也可能超过一个），例如当测试一个新药时，希望将使用新药的组（实验组）和不使用新药的组（对照组）进行对比，以便知道对于治疗某种疾病，使用药物对比不用药物（通常使用安慰剂）的作用有多大。另一个有趣的问题是：与治疗某种疾病最常用的（已经被审批的）药相比，新药效果如何？此时，对照组不再是使用安慰剂的组，而是使用其他药物的组。</p>
<p>从统计学上讲，使用假对照组是一种不错的撒谎方式，例如：假设某家乳制品公司想要卖某种含过量糖分的酸奶给小朋友，同时告诉家长乳酸有利于免疫系统。为证明该说法，他们可以和牛奶或者水做对照，而不是选择更便宜、糖更少、市场更小的其他酸奶品种。人们的关注点有时会趋向于主题，而忽略了参照物的选择。因此，下次再听到有人说某种东西更好、更快、更强时，记得问一下他对比的基准是什么。</p>
<p>要在组间做比较，必须决定使用哪些特征进行比较。一个常见特征是每组的平均值。与频率主义不同，贝叶斯方法致力于获得组间均值差异的后验分布，而不仅仅获得差异的点估计。为帮助解释后验，会使用三个工具：</p>
<ul class="simple">
<li><p>绘制带有参照值的后验图件</p></li>
<li><p>计算 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 值</p></li>
<li><p>计算<code class="docutils literal notranslate"><span class="pre">优势概率（The</span> <span class="pre">probability</span> <span class="pre">of</span> <span class="pre">superiority）</span></code></p></li>
</ul>
<p>在之前的案例中，已经看到了如何使用 <code class="docutils literal notranslate"><span class="pre">az.plot_posterior</span></code> 函数绘制带参考值的后验。主要的新概念是 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 和 <code class="docutils literal notranslate"><span class="pre">优势概率</span></code> 。</p>
<div class="section" id="cohen-s-d">
<h3>2.4.1 Cohen’s d<a class="headerlink" href="#cohen-s-d" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 是一种用来描述效应值的常见方式：</p>
<div class="math notranslate nohighlight">
\[\frac{\mu_{2}-\mu_{1}}{\sqrt{\frac{\sigma_{2}^{2}+\sigma_{1}^{2}}{2}}}  \tag{式2.4} \label{式2.4} \]</div>
<p>根据该表达式，效应大小是在合并两组标准差的情况下，各组均值相对于合并标准差的差异。因为可以得到均值和标准差的后验分布，所以可以计算 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 的后验分布，而不是某个具体值。当然，如果只需要或只想要一个值，可以计算  <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code>  后验的平均值，得到一个  <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 值。通常在计算合并标准差时，会显式考虑每组的样本量，但前面的公式省略样本量，主要是因为从后验得到标准偏差值中，已经体现了其不确定性。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Cohen‘s d是一种测量效应大小的方法，其中均值的差异是通过考虑两组的合并标准差来标准化的。</p>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Cohen‘s</span> <span class="pre">d</span></code> 通过使用各组标准差来引入每组的差异性。这点很重要，因为在相同的绝对差情况下，标准差为 0.1的组显然应当比标准差为10的组效应变化更明显。一组数据相比另一组数据变化了 <span class="math notranslate nohighlight">\(x\)</span> 个单位，可能是每个点都整体变化了 <span class="math notranslate nohighlight">\(x\)</span> 个单位，也可能是其中一半的数据没有变化而另外一半数据变化了 <span class="math notranslate nohighlight">\(2x\)</span> ，还可能是其他组合方法。因此，将组内方差包含在公式中，将有助于将绝对差放在合理上下文中做比较。这种类似对绝对差做标准化的方法，有助于我们正确理解不同组之间差异的重要性。</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>根据 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 得到的效应值可以看做是 <code class="docutils literal notranslate"><span class="pre">Z-score</span></code>，因而 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 为 0.5 可以解释为一组数据相比另一组数据的差别是 0.5 倍的标准差。</p>
</div>
<p>即使将均值的差异做了标准化，我们可能仍然需要基于给定问题的上下文来校准自己，以便能够判断给定值是大、中、小等等。还好，这种校准可以通过足够的练习获得。举例来说，如果我们对相同类型的问题执行多个分析，如果 <code class="docutils literal notranslate"><span class="pre">Cohen‘s</span> <span class="pre">d</span> <span class="pre">=1</span></code> 是个经验值，那么当分析遇到 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span> <span class="pre">=2</span> </code> 时，意味着有重要的事情发生。如果您还没有这样的经验，可以向<a class="reference external" href="http://rpsychologist.com/d3/cohend">领域专家</a>咨询。该网页可以用于了解 不同 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 值都长什么样，此外，还可以看到描述效应值的其他方式。</p>
</div>
<div class="section" id="id18">
<h3>2.4.2 优势概率<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>优势概率是表示效应值的另一种方式，描述的是从一组数据中取出的一个点大于从另外一组中取出的点的概率。假设两个组中数据的分布都是正态分布，我们可以通过以下表达式从 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 中得到优势概率：</p>
<div class="math notranslate nohighlight">
\[ps=\Phi\left(\frac{\delta}{\sqrt{2}}\right) \tag{式2.5} \label{式2.5} \]</div>
<p>此处， <span class="math notranslate nohighlight">\(\Phi \)</span> 是累积正态分布， <span class="math notranslate nohighlight">\(\delta \)</span> 是 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code>。我们可以计算优势概率的点估计，也可以计算值的整个后验分布。如果同意正态假设，可以使用该公式从 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code> 中计算得到优势概率。否则，当有后验样本时，可通过后验样本计算它。这是马尔可夫链蒙特卡罗 (<code class="docutils literal notranslate"><span class="pre">MCMC</span></code>) 方法的一个优点：一旦从后验获得样本，就可以从它计算出很多量。</p>
</div>
<div class="section" id="id19">
<h3>2.4.3 小费数据集<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>接下来，使用 <code class="docutils literal notranslate"><span class="pre">seaborn</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">tips</span></code> 数据集来讨论前面提到的想法。我们希望知道星期几对于餐馆小费数量的影响。该例中实际并没有明确的实验组和对照组之分，只是观察性的实验。如果愿意，可以任选一天（例如星期四）作为实验组，或者对照组。需注意的一点是：对于观察性实验，没法得出某种因果关系，能得到相关性。事实上，如何从数据中得出因果关系是非常热门的研究问题，我们会在第 4 章重新讨论该问题。现在，首先用一行代码将数据导入成 <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code>，<code class="docutils literal notranslate"><span class="pre">tail</span></code> 函数返回数据中的最后一条（当然你也可以用 <code class="docutils literal notranslate"><span class="pre">head</span></code> 函数返回第一条数据）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tips</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/tips.csv&#39;</span><span class="p">)</span>
<span class="n">tips</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504182713_db.webp" /></p>
<p>对于该数据集，我们只关心 <code class="docutils literal notranslate"><span class="pre">day</span></code> 和 <code class="docutils literal notranslate"><span class="pre">tip</span></code> 列，利用 <code class="docutils literal notranslate"><span class="pre">seaborn</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">violinplot</span></code> 函数可以将其画出来：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;tip&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">tips</span><span class="p">)</span><span class="n">t</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504182600_5a.webp" /></p>
<p>图 2.16</p>
</center>
<p>把问题简化下，我们创建两个变量：变量 <code class="docutils literal notranslate"><span class="pre">y</span></code>表示 <code class="docutils literal notranslate"><span class="pre">tips</span></code>；变量 <code class="docutils literal notranslate"><span class="pre">idx</span></code> 表示分类变量的编码。即用数字 0、1、2、3 表示星期四、星期五、星期六和星期天。 groups 则包含其中每一组的数量。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tip</span> <span class="o">=</span> <span class="n">tips</span><span class="p">[</span><span class="s1">&#39;tip&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">tips</span><span class="p">[</span><span class="s1">&#39;day&#39;</span><span class="p">],</span>
      <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Thur&#39;</span><span class="p">,</span> <span class="s1">&#39;Fri&#39;</span><span class="p">,</span> <span class="s1">&#39;Sat&#39;</span><span class="p">,</span> <span class="s1">&#39;Sun&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">codes</span>
<span class="n">groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>该模型几乎与 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 相同；唯一区别是， <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\sigma\)</span> 为向量而不是标量。对于这种情况，<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 语法非常有用：可以用向量化方式编写模型，而不用编写 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环。这意味着对于先验和似然，我们可以使用 <code class="docutils literal notranslate"><span class="pre">idx</span></code> 变量正确地索引到其 <code class="docutils literal notranslate"><span class="pre">mean</span></code> 和 <code class="docutils literal notranslate"><span class="pre">sd</span></code> 变量：</p>
<p>的时候，我们会得到 4 个和 4 个。 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 的语法能够很好地适应该场景，我们可以直接用向量的方式表示模型，而不用使用 <code class="docutils literal notranslate"><span class="pre">for</span></code> 循环，代码的变化相比前面的模型很小。对应先验，我们需要传一个维度变量 <code class="docutils literal notranslate"><span class="pre">shape</span></code>，对于似然，我们需要对和正确地进行编码，这也是 为什么创建了 <code class="docutils literal notranslate"><span class="pre">idx</span></code> 变量。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">comparing_groups</span><span class="p">:</span>
 <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">tip</span><span class="p">)</span>
 <span class="n">trace_cg</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_cg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504182332_b3.webp" /></p>
<p>图 2.17</p>
</center>
<p>下面的代码只是绘制差异的一种方式，而不重复比较。我们不是绘制All-And-All矩阵，而是绘制上三角部分：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">comparisons</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>
<span class="n">pos</span> <span class="o">=</span> <span class="p">[(</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
<span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">comparisons</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
    <span class="n">means_diff</span> <span class="o">=</span> <span class="n">trace_cg</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">][:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">trace_cg</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">][:,</span> <span class="n">j</span><span class="p">]</span>
    <span class="n">d_cohen</span> <span class="o">=</span> <span class="p">(</span><span class="n">means_diff</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">trace_cg</span><span class="p">[</span><span class="s1">&#39;σ&#39;</span><span class="p">][:,</span> <span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>
<span class="n">trace_cg</span><span class="p">[</span><span class="s1">&#39;σ&#39;</span><span class="p">][:,</span> <span class="n">j</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">d_cohen</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">az</span><span class="o">.</span><span class="n">plot_posterior</span><span class="p">(</span><span class="n">means_diff</span><span class="p">,</span> <span class="n">ref_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;$\mu_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">-\mu_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Cohen&#39;s d = </span><span class="si">{</span><span class="n">d_cohen</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s2">Prob sup = </span><span class="si">{</span><span class="n">ps</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504182144_09.webp" />
图 2.18</p>
</center>
<p>前面的例子中，一种解释结果的方式是将参考值与 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间进行 比较。只有一种情况下 94%<code class="docutils literal notranslate"><span class="pre">HPD</span></code> 没有包含 0（我们的参考值），即星期四与星期天的对比。对于所有其他情况，我们没法得出两者的区别为 0 的结论（根据 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 区间与参考值的重叠性准则）。但是即便如此，平均下来 0.5 美元的小费差别是否足够大了呢？该差别是否大到让人们牺牲星期日陪家人或者朋友的时间去工作呢？是否大到就应该这 4 天都给相同的小费而且男服务员和女服务员的小费一模一样呢？诸如此类的问题很难用统计学来回答，只能从统计学中找到些启发。</p>
</div>
</div>
<div class="section" id="id20">
<h2>2.5 分层模型<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id21">
<h3>2.5.1 什么是分层模型？<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>假设想要分析一个城市的水质，然后将城市分成了多个相邻（或者水文学上）的区域。可以自然想到用如下两种方法进行分析：</p>
<ul class="simple">
<li><p>分别对每个区域单独进行估计；</p></li>
<li><p>将所有数据都混合在一起，把整个城市看做一个整体进行估计。</p></li>
</ul>
<p>两种方式都合理，具体使用哪种取决于想知道什么。如果想了解具体细节，那么可以采用第 1 种方式，因为假如对数据进一步做平均处理，那么一些细节就不容易看出来了。采用第 2 种方式则可以将数据都聚在一起，得到一个更大的样本集，从而得出更准确的估计。两种方式都有合理性，不过还可以找到些中间方案。</p>
<p>我们可以在对相邻区域的水质进行评估同时，对整个城市的水质进行评估。这类模型被称为 <code class="docutils literal notranslate"><span class="pre">层次模型（hierarchical</span> <span class="pre">model）</span></code> 或者
<code class="docutils literal notranslate"><span class="pre">分层模型(multilevel</span> <span class="pre">model)</span></code>，名称来自于对数据采用了一种层次化（或者是分层）的建模方式。</p>
<p>那么如何构建分层模型呢？简单说，就是在先验之上使用一个共享先验。也就是说，我们不再固定先验的参数，而是直接从数据中将其估计出来。这类更高层的先验通常被称为 <code class="docutils literal notranslate"><span class="pre">超先验（hyper-prior）</span></code> ，其参数称为 <code class="docutils literal notranslate"><span class="pre">超参数</span></code>。 “超”在希腊语中是”在某某之上”的意思。当然，还可以在超先验之上再增加先验，做到尽可能分层。问题是这么做会使模型变得相当复杂而且难以理解。 原则上，除非问题确实需要更复杂的结构，增加分层对于做推断并没有更大帮助，相反，会使分析人员陷入 <code class="docutils literal notranslate"><span class="pre">超参数</span></code> 和 <code class="docutils literal notranslate"><span class="pre">超先验</span></code> 的混乱中而无法做出有意义的解释，并降低模型的可解释性。</p>
<p>为了更好地解释分层模型中的主要概念，以本节开头提到的水质模型为例，使用一些人工数据来讲解。假设我们从同一个城市的 3 个不同水域得到了含铅量的采样值：其中高于世界卫生组织标准的值标记为 0；低于标准的值标记为 1。（注：此处做了简化，实际中会使用铅含量的连续值，并分成更多组）。</p>
<p>我们通过以下代码合成数据：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">G_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">18</span><span class="p">]</span>
<span class="n">group_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">N_samples</span><span class="p">)),</span> <span class="n">N_samples</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_samples</span><span class="p">)):</span>
 <span class="n">data</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">G_samples</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">N_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">G_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]]))</span>
</pre></div>
</div>
</div>
</div>
<p>上述代码模拟了一个实验，其中测量了三组数据，每组包含一定数量样本。我们将每组的样本总数存储在 <code class="docutils literal notranslate"><span class="pre">N_samples</span></code> 中，将其中水质好的样本数量存储在 <code class="docutils literal notranslate"><span class="pre">G_samples</span></code> 中。代码的其余部分用来生成了对应的数据集，其中填满了 0 和 1 。</p>
<p>该模型基本与解决抛硬币问题的模型相同，只是有两个重要特征：</p>
<ul class="simple">
<li><p>该模型定义了两个影响贝塔先验的超先验。</p></li>
<li><p>模型没有把超先验定义在贝塔分布的参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 上，而是间接地定义在贝塔分布的均值 <span class="math notranslate nohighlight">\(\mu\)</span> 和 精度（ <code class="docutils literal notranslate"><span class="pre">precision</span></code> ） <span class="math notranslate nohighlight">\(\kappa\)</span> 上（ 精度可以粗略地理解为标准差的倒数）， <span class="math notranslate nohighlight">\(\kappa\)</span> 值越大，贝塔分布越集中。</p></li>
</ul>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.6} \label{式2.6} 
\mu &amp;\sim \operatorname{Beta}\left(\alpha_{\mu}, \beta_{\mu}\right) \\
\kappa &amp;\sim\left|\operatorname{Normal}\left(0, \sigma_{\kappa}\right)\right| \\
\alpha &amp;=\mu * \kappa \\
\beta &amp;=(1-\mu) * \kappa \\
\theta_{i} &amp; \sim \operatorname{Beta}\left(\alpha_{i}, \beta_{i}\right) \\
y_{i} &amp; \sim \operatorname{Bern}\left(\theta_{i}\right) 
\end{align*}\]</div>
<p>注意，使用子索引 <span class="math notranslate nohighlight">\(i\)</span> 来指示模型中某些组的参数具有不同的值。也就是说，并非所有参数都在组间共享值。使用 Kruschke 图，很明显新模型有一个额外的级别。</p>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504181501_31.webp" style="zoom:67%;" />
<p>图 2.19</p>
</center>
<p>注意上图中，使用符号 <span class="math notranslate nohighlight">\(=\)</span> 而不是 <span class="math notranslate nohighlight">\(∼\)</span> 来定义 <span class="math notranslate nohighlight">\(\alpha_i\)</span> 和 <span class="math notranslate nohighlight">\(\beta_i\)</span> 。这是因为一旦知道 <span class="math notranslate nohighlight">\(\mu\)</span> 和 <span class="math notranslate nohighlight">\(\kappa\)</span> 的值， <span class="math notranslate nohighlight">\(\alpha_i\)</span> 和 <span class="math notranslate nohighlight">\(\beta_i\)</span> 的值确定了。此类变量被称为 <code class="docutils literal notranslate"><span class="pre">确定性变量</span></code> ，与 <code class="docutils literal notranslate"><span class="pre">随机变量</span></code>（如 <span class="math notranslate nohighlight">\(\mu,\kappa,\theta\)</span> 等）相对, 在 PyMC3 中对两者有比较明确的说明。</p>
<p>模型对均值 <span class="math notranslate nohighlight">\(\mu\)</span> 和精度 <span class="math notranslate nohighlight">\(\kappa\)</span> 的参数化，在数学上最终就是对 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 的参数化。那为什么要舍近求远呢？这有两个原因：</p>
<ul class="simple">
<li><p>首先，均值和精度虽然数学上等价，但在数值上更适合采样器。本书将在第 8 章“推断引擎”中对其做解释。</p></li>
<li><p>其次是处于教学目的。这个例子表明模型的表达方式可能不止一种，但在数学上等价时在实现上可能会有差异。采样器的效率是一个方面，而另一个方面可能是模型的可解释性。对于某些特定问题或特定受众，报告贝塔分布的均值和精度比报告 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 参数更好。</p></li>
</ul>
<p>让我们在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中实现并求解该模型，这样我们就可以继续讨论层次模型：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_h</span><span class="p">:</span>
  <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
  <span class="n">κ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;κ&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
  <span class="n">θ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;θ&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">μ</span><span class="o">*</span><span class="n">κ</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">μ</span><span class="p">)</span><span class="o">*</span><span class="n">κ</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">N_samples</span><span class="p">))</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">θ</span><span class="p">[</span><span class="n">group_idx</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
  
  <span class="n">trace_h</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_h</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504181604_78.webp" style="zoom:67%;" />
<p>图 2.20</p>
</center>
</div>
<div class="section" id="id22">
<h3>2.5.2 收缩<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h3>
<p>现在做个简单实验，使用 <code class="docutils literal notranslate"><span class="pre">az.summary(trace_h)</span></code> 打印并保存摘要。然后，希望对合成数据进行微调后再重新运行模型两次，并始终保留汇总记录。也就是总共运行三次：</p>
<ul class="simple">
<li><p>第一次运行将 <code class="docutils literal notranslate"><span class="pre">G_Samples</span></code> 的所有元素值设置为 18</p></li>
<li><p>第二次运行将 <code class="docutils literal notranslate"><span class="pre">G_Samples</span></code> 的所有元素值设置为 3</p></li>
<li><p>第三次运行将 <code class="docutils literal notranslate"><span class="pre">G_Samples</span></code> 的其中一个元素设置为 18，其他元素设置为 3</p></li>
</ul>
<p>继续之前先想想该实验会是什么结果。重点关注每次实验中 <span class="math notranslate nohighlight">\(\theta_i\)</span> 的均值。根据前两次模型的运行结果，能猜出第 3 种情况下的结果吗？如果将结果汇总在表格中，会得到类似如下的值（注意：由于 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 采样方法的随机性，结果可能会有小幅波动）：</p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504181632_cf.webp" /></p>
<p>表中第一行，可以看到对于 30 个样本中有 18 个正样本的情况，估计值 <span class="math notranslate nohighlight">\(\theta\)</span> 的均值为 0.6 ；注意 <span class="math notranslate nohighlight">\(θ\)</span> 是一个向量，因为有 3 组实验，每组都有一个均值。</p>
<p>表中第二行，可以看到对于 30 个样本中有 3 个正样本的情况，估计值 <span class="math notranslate nohighlight">\(\theta\)</span> 的均值为 0.11 。</p>
<p>表中第三行，结果有点意外， <span class="math notranslate nohighlight">\(\theta\)</span> 的均值并非前面两组中均值的组合（比如 <code class="docutils literal notranslate"><span class="pre">0.6,</span> <span class="pre">0.11,</span> <span class="pre">0.11</span></code>），而是（<code class="docutils literal notranslate"><span class="pre">0.53,</span> <span class="pre">0.14,</span> <span class="pre">0.14</span></code>）。</p>
<p>为什么呢？是模型收敛问题还是模型选型出了问题？其实都不是，这是因为估计结果趋向于整体的均值。事实上，这正是模型预期的结果：在设置了超先验后，直接从数据中估计贝塔先验，每个组的估计值会都受到其他组估计值的影响，同时也影响着其他组的估计值。换句话说，所有组都通过超先验共享了部分信息，从而出现一种称为 <code class="docutils literal notranslate"><span class="pre">收缩（shrinkage</span></code>）的现象。 收缩现象的效果相当于对数据做了 <code class="docutils literal notranslate"><span class="pre">部分池化（pooling）</span></code> ，既不是对数据分组的建模，也不是将数据作为一个大组的建模，而是介于二者之间。</p>
<p><code class="docutils literal notranslate"><span class="pre">收缩</span></code> 有利于更稳健的推断。这和前面讨论过的学生 <span class="math notranslate nohighlight">\(t\)</span> 分布与异常点的关系很像，那个例子中，使用重尾分布后的模型对偏离均值的异常点表现得更健壮。引入超先验后，在更高层次上进行推断，从而得到一个更 <code class="docutils literal notranslate"><span class="pre">&quot;保守&quot;</span></code> 的模型，更少地受到组内极限值的影响。举例来说，假设在某个相邻区域得到了一组不同数量的采样值；那么采样数量越小就越容易得到错误结果；极限情况下，假设在该区域只有一个采样值，而你恰好是从该区域的某个铅管中得到的采样值（或相反，恰好从 PVC 管道中得到的采样值），那么可能导致这片区域水质的整体高估或者低估。在分层模型中，估计出错的情况可通过其他组提供的信息进行改善。当然，通过增加采样值能达到类似效果，但考虑到样本采集成本问题，大多数情况下这并不是最佳候选方案。</p>
<p>显然，收缩的程度取决于数据，数量大的组会对数量较小的组造成更大的影响。如果大多数组都比较相似，而其中某组不太一样，相似组之间会共享这种相似性，从而强化共同的估计值，并拉近表现不太一样的那一组的估计值，前面的例子中已经体现了这一点。</p>
<p>此外，超先验对收缩的程度有影响。如果对所有组的整体分布有一些可信的先验信息，那么将其加入到模型中将有助于收缩程度调整到比较合理的值。</p>
<p>理论上完全可以只用两个组来构建分层模型，不过通常更倾向于使用多个组。直观原因是，收缩其实是将每个组看成一个数据点，而我们是在组这个层级上估计标准差，除非我们对估计值有很强的先验，否则通常不会太相信点数较少的估计值，。</p>
<p>你可能对估计到的先验分布比较感兴趣，以下是将其表示出来的一种方式：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trace_h</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
 <span class="n">u</span> <span class="o">=</span> <span class="n">trace_h</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
 <span class="n">k</span> <span class="o">=</span> <span class="n">trace_h</span><span class="p">[</span><span class="s1">&#39;κ&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
 <span class="n">pdf</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">u</span><span class="o">*</span><span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">u</span><span class="p">)</span><span class="o">*</span><span class="n">k</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
 <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">u_mean</span> <span class="o">=</span> <span class="n">trace_h</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">k_mean</span> <span class="o">=</span> <span class="n">trace_h</span><span class="p">[</span><span class="s1">&#39;κ&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">u_mean</span><span class="o">*</span><span class="n">k_mean</span><span class="p">,</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">u_mean</span><span class="p">)</span><span class="o">*</span><span class="n">k_mean</span><span class="p">)</span>
<span class="n">pdf</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">mode</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pdf</span><span class="p">)]</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">moment</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;mode = </span><span class="si">{</span><span class="n">mode</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="se">\n</span><span class="s1">mean = </span><span class="si">{</span><span class="n">mean</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39; $ θ_</span><span class="si">{prior}</span><span class="s1"> $ &#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504181857_6e.webp" style="zoom:67%;" />
<p>图2.21</p>
</center>
</div>
<div class="section" id="id23">
<h3>2.5.3 另一个例子<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h3>
<p>我们再一次以化学漂移数据为例。这些数据来自一组蛋白质分子。准确地说，该化学漂移数据来自蛋白质的 <span class="math notranslate nohighlight">\(^{13}C_\alpha\)</span> 原子核，因为这是我们能够观测的有限类型原子核。蛋白质是由若干基础类型的 <code class="docutils literal notranslate"><span class="pre">氨基酸</span></code>（总共存在20种基础类型） 序列组合而成。每种氨基酸在序列中出现零次或多次，序列可由几个、数百个、数千个氨基酸组成。每种氨基酸都有且只有一种 <span class="math notranslate nohighlight">\(^{13}C_\alpha\)</span> ，所以可以很有把握地将每一种化学漂移与蛋白质中特定氨基酸联系在一起。此外，这 20 种氨基酸中的每一种都有不同化学性质，对蛋白质的生物学特性有贡献。有些带净电荷，有些是中性的；有些喜欢被水分子包围，而另一些喜欢与同类型氨基酸作伴等。关键点在于：这些氨基酸相似但不相等，因此，根据氨基酸类型的定义，将任何与化学漂移相关的推论建立在 20 个基团上可能是合理甚至自然的。你可以通过这个精彩的视频了解更多关于蛋白质的知识：<a class="reference external" href="https://www.youtube.com/watch?v=wvTv8TqWC48">https://www.youtube.com/watch?v=wvTv8TqWC48</a> 。</p>
<p>在下面的代码块中，我们将数据加载到 <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> 的 <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> 中。可以看到四列：第一列是蛋白质的 ID ；第二列包括氨基酸的名称，使用标准的三字母代码；而其余列对应于理论计算的化学漂移和实验测量的化学漂移。这个例子的目的是比较理论计算值与实验测量值间的差异以了解其吻合程度即差异原因。出于这个原因，我们计算了系列差异 <code class="docutils literal notranslate"><span class="pre">diff</span></code>：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cs_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/chemical_shifts_theo_exp.csv&#39;</span><span class="p">)</span>
<span class="n">diff</span> <span class="o">=</span> <span class="n">cs_data</span><span class="o">.</span><span class="n">theo</span><span class="o">.</span><span class="n">values</span> <span class="o">-</span> <span class="n">cs_data</span><span class="o">.</span><span class="n">exp</span><span class="o">.</span><span class="n">values</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">cs_data</span><span class="p">[</span><span class="s1">&#39;aa&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">codes</span>
<span class="n">groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>为了解分层模型和非分层模型间的区别，我们构建两个模型。第一个与之前 <code class="docutils literal notranslate"><span class="pre">comparing_groups</span></code> 模型基本相同：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">cs_nh</span><span class="p">:</span>
 <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">diff</span><span class="p">)</span>
 <span class="n">trace_cs_nh</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>现在，构建模型的分层版本。我们添加两个超先验：一个用于 <span class="math notranslate nohighlight">\(\mu\)</span> 的均值，另一个用于 <span class="math notranslate nohighlight">\(\mu\)</span> 的标准差（处于教学目的，此处未对 <span class="math notranslate nohighlight">\(\sigma\)</span> 设置超先验）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">cs_h</span><span class="p">:</span>
 <span class="c1"># hyper_priors</span>
 <span class="n">μ_μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;μ_μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
 <span class="n">σ_μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ_μ&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
 <span class="c1"># priors</span>
 <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ_μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ_μ</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">groups</span><span class="p">)</span>
 <span class="n">y</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">sd</span><span class="o">=</span><span class="n">σ</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">observed</span><span class="o">=</span><span class="n">diff</span><span class="p">)</span>
 <span class="n">trace_cs_h</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>我们使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的 <code class="docutils literal notranslate"><span class="pre">plot_forest</span></code> 函数比较结果。当想要比较不同模型（如本例）的参数值时，该函数很有用。注意，此处将几个参数传递给 <code class="docutils literal notranslate"><span class="pre">plot_forest</span></code> 以获得想要的图，例如：设置 <code class="docutils literal notranslate"><span class="pre">combined=True</span></code> 以合并所有链的结果。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">([</span><span class="n">trace_cs_nh</span><span class="p">,</span> <span class="n">trace_cs_h</span><span class="p">],</span>
       <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_h&#39;</span><span class="p">,</span> <span class="s1">&#39;h&#39;</span><span class="p">],</span>
       <span class="n">var_names</span><span class="o">=</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">combined</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;cycle&#39;</span><span class="p">)</span>
<span class="n">y_lims</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_ylim</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">trace_cs_h</span><span class="p">[</span><span class="s1">&#39;μ_μ&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="o">*</span><span class="n">y_lims</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="image-20210504224607251" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210504224610_c3.webp" /></p>
<p>图 2.22</p>
</center>
<p>OK，在图 2.22 中能看到什么呢？ 我们有一个 40 个估计平均值的曲线图（共 20 个氨基酸 ，2 种模型），也有 94% HDP可信区间和二分位数范围（分布中心周边 50% )。垂直的黑色线是根据分层模型得到的全局平均值。该值接近于零，表明理论值能够如预期的一样复现实验值。</p>
<p>此图最相关的部分是，分层模型的估计值被拉向 <code class="docutils literal notranslate"><span class="pre">部分池化</span></code> 的均值，或者说，相对于 <code class="docutils literal notranslate"><span class="pre">未池化的估计</span></code>，分层模型的估计值被收缩了。您还会注意到，这种影响对于远离均值的组（如 13) 来说更明显，并且其不确定性比非分层模型更小。这些估计是部分池化的，因为我们对每组都有一个估计，但单个组的估计通过超先验相互制约。因此，我们得到了一种中间情况，一种是只有一个基团，所有的化学漂移都在一起，另一个是 20 个独立基团，每个氨基酸一个。这就是，层次分明的模型之美。</p>
<p>可以肯定地说，分层模型是一个非常棒的想法。在接下来的章节中，我们将继续构建分层模型，并学习如何使用它构建更好的模型。在第 5 章“模型比较”中，我们还将讨论分层模型与统计学和机器学习中普遍存在的 <code class="docutils literal notranslate"><span class="pre">过拟合/欠拟合</span></code> 问题之间的相关性。在第 8 章“推断引擎”中，我们将讨论从分层模型中采样时可能会出现的一些技术问题，以及如何诊断和修复这些问题。</p>
</div>
</div>
<div class="section" id="id24">
<h2>2.6 总结<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<p>虽然贝叶斯统计概念上很简单，但全概率公式经常无法获得解析解。多年来，这个问题严重阻碍了贝叶斯方法的广泛应用。幸运的是，数学、统计学、物理学和计算机科学以数值方法的方式拯救了人类，这些方法至少在原理上能够解决任何推断问题。自动化推断过程的这种可能性导致了概率编程语言的发展，允许模型定义和推断过程之间的明确分离。</p>
<p><code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，用于概率编程，具有非常简单、直观和易于阅读的语法，也接近于描述概率模型的统计语法。本章回顾第 1 章“概率思维”中的抛硬币模型，此次没有解析地推导后验，而是采用了 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 构建模型。在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中，只需编写一行代码即可将概率分布添加到模型中。概率分布可以组合，可用于先验（未观测变量）或似然（观测变量）。如果将数据传递给一个分布，那它就成为一种似然。<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 允许我们从后验分布中获得样本， 而且可以用一行代码就能实现。如果一切正常，这些样本将代表正确的后验分布，从而代表模型和数据的逻辑结果。</p>
<p>可以使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 探索 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 生成的后验分布，<code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 是一个 <code class="docutils literal notranslate"><span class="pre">Python</span></code> 库，它与 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 协同工作，可以用来帮助我们解释和可视化后验分布。一种使用后验来帮助我们做出推断性决策的方法是将 <code class="docutils literal notranslate"><span class="pre">ROPE</span></code> 与 <code class="docutils literal notranslate"><span class="pre">HPD</span></code> 间隔进行比较。我们还简要提到了 <code class="docutils literal notranslate"><span class="pre">损失函数</span></code> 的概念，这是一种在存在不确定性的情况下，量化决策权衡和成本的形式化方法。我们也了解到 <code class="docutils literal notranslate"><span class="pre">损失函数</span></code> 和 <code class="docutils literal notranslate"><span class="pre">点估计</span></code> 是密切相关的。</p>
<p>到目前为止，讨论仅限于简单的单参数模型。在 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中，将参数推广到任意数量是非常简单的，我们举例说明了如何使用高斯模型和学生 <span class="math notranslate nohighlight">\(t\)</span> 模型来实现这一点。高斯分布是学生 <span class="math notranslate nohighlight">\(t\)</span> 分布的特例，我们展示了在存在异常值的情况下，如何使用后者进行更为稳健的推断。在下一章中，我们将研究如何将这些模型用作线性回归模型的一部分。</p>
<p>我们使用高斯模型来比较组间常见的数据分析任务。虽然人们经常被假设检验背景限制，但贝叶斯方法采取了另一种路线，将组间比较任务转换为推断效应大小的问题，这是一种更丰富、更有成效的方法。我们还探索了解释和报告效应大小的不同方式。</p>
<p>我们把从本书中最重要的概念之一 – <strong>层次模型</strong> – 留到了最后。我们可以在每次识别数据中的子组时建立分层模型。在这种情况下，我们可以构建一个模型在组间做部分池化，而不是将子组作为独立对象对待，或者忽略子组将整体作为一个对象来对待。这种部分池化的主要影响是，每个子组的估计值将被其余子组估计值拉偏，这种效果被称为 <code class="docutils literal notranslate"><span class="pre">收缩</span></code>。 收缩是一个非常有用的技巧，可以通过使推断更保守和通过更多信息来帮助改进推断。在接下来的章节中，我们将看到更多分层模型的示例。每个例子都有助于从不同角度更好地理解它们。</p>
</div>
<div class="section" id="id25">
<h2>2.7 练习<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h2>
<p>（1）对于本章的第一个模型，将高斯分布的先验均值修改为一个经验性均值，用几个对应的标准差多跑几遍，观察推断过程对这些变化的鲁棒性/敏感性如何。你觉得用一个没有限制上下界的高斯分布对有上下界的数据建模的效果怎样？记住我们说过数据不可能大于 100 或者小于 0。</p>
<p>（2）利用第一个例子中的数据，分别在包含和不包含异常值情况下，计算出经验均值和标准差。将结果与使用高斯分布和 <span class="math notranslate nohighlight">\(t\)</span> 分布的贝叶斯估计进行比较，增加更多异常值并重复该过程。</p>
<p>（3）修改小费例子中的模型，使其对于异常点更鲁棒。分别尝 试对所有组使用一个共享的 <span class="math notranslate nohighlight">\(\nu\)</span> 和单独为每个组设置一个 <span class="math notranslate nohighlight">\(\nu\)</span> ，最后对这 3 个模型进行后验预测检查。</p>
<p>（4）直接从后验中计算出优势概率（先不要计算 <code class="docutils literal notranslate"><span class="pre">Cohen's</span> <span class="pre">d</span></code>），你可以用 <code class="docutils literal notranslate"><span class="pre">sample_ppc()</span></code> 函数从每个组中获取一个采样值。对比这样做与基于正态假设的计算是否不同？并对结果做出解释。</p>
<p>（5）重复水质对比的例子，不过不用多层模型，而是使用一个均匀分布（比如 ）。比较两种模型的结果。</p>
<p>（6）在小费的例子中，对一个星期中的不同天使用部分池化操作，构建一个多层模型，将结果与不使用多层模型的结果进行对比。</p>
<p>（7）重复本章中的所有例子，用 <code class="docutils literal notranslate"><span class="pre">findMAP()</span></code> 函数的返回值来初始化采样。看是否能得到相同的推断结果。同时看一下 <code class="docutils literal notranslate"><span class="pre">find_MAP</span> <span class="pre">()</span></code> 函数对退化过程的数量以及推断的速度有什么影响。
（8）对所有模型进行诊断测试并采取相应措施，比如，如果有 必要，增加采样次数。</p>
<p>（9）对本章中的至少一个模型使用你自己的数据并运行。牢记第 1 章中提到的构建模型的 3 个步骤。</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.7} \label{式2.7} 
\alpha &amp;\sim \mathcal{N}(\mu_{\alpha},\sigma_{\alpha})\\
\beta &amp;\sim \mathcal{N}(\mu_{\beta},\sigma_{\beta})\\
\epsilon &amp;\sim |\mathcal{N}(0,\sigma_{\epsilon})|\\
\nu &amp;\sim \text{Exp}(\lambda)\\\\
y &amp;\sim \mathcal{T}(\alpha + x \beta, \epsilon,\nu)
\end{align}


\begin{align*} \tag{式2.8} \label{式2.8} 
\beta_0 &amp;\sim \mathcal{N}(\mu_{\beta_0},\sigma_{\beta_0})\\
\beta_1 &amp;\sim \mathcal{N}(\mu_{\beta_1},\sigma_{\beta_1})\\
&amp;\text{...}\\
\beta_n &amp;\sim \mathcal{N}(\mu_{\beta_n},\sigma_{\beta_n})\\
\epsilon &amp;\sim |\mathcal{N}(0,\sigma_{\epsilon})|\\\\
y &amp;\sim \mathcal{N}(\beta_0 + \beta_1x^1 + \beta_2x^2 + ...  + \beta_nx^n,\epsilon)
\end{align*}\]</div>
<hr class="docutils" />
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.9} \label{式2.9} 
\beta_0 &amp;\sim \mathcal{N}(\mu_{\beta_0},\sigma_{\beta_0})\\
\beta_1 &amp;\sim \mathcal{N}(\mu_{\beta_1},\sigma_{\beta_1})\\
&amp;\text{...}\\
\beta_n &amp;\sim \mathcal{N}(\mu_{\beta_n},\sigma_{\beta_n})\\
\epsilon &amp;\sim |\mathcal{N}(0,\sigma_{\epsilon})|\\\\
y &amp;\sim \mathcal{N}(\beta_0 + \beta_1x_1 + \beta_2x_2 + ...  + \beta_nx_n,\epsilon)
\end{align*}\]</div>
<hr class="docutils" />
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.10} \label{式2.10} 
\mu_{\alpha} &amp;\sim \mathcal{N}(\mu_{\mu_{\alpha}},\sigma_{\mu_{\alpha}})\\
\sigma_{\alpha} &amp;\sim |\mathcal{N}(0,\sigma_{\sigma_{\alpha}})|\\
\end{align*}\]</div>
<hr class="docutils" />
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} \tag{式2.11} \label{式2.11} 
\mu_{\beta} &amp;\sim \mathcal{N}(\mu_{\mu_{\beta}},\sigma_{\mu_{\beta}})\\
\sigma_{\beta} &amp;\sim |\mathcal{N}(0,\sigma_{\sigma_{\beta}})|\\
\alpha &amp;\sim \mathcal{N}(\mu_{\alpha},\sigma_{\alpha})\\
\beta &amp;\sim \mathcal{N}(\mu_{\beta},\sigma_{\beta})\\
\epsilon &amp;\sim |\mathcal{N}(0,\sigma_{\epsilon})|\\
\nu &amp;\sim \text{Exp}(\lambda)\\
y &amp;\sim \mathcal{T}(\alpha + x \beta,\epsilon,\nu)
\end{align*}\]</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="chapter01-ThinkingProbabilistically.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">第 1 章 概率思维</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="chapter03-ModellingwithLinearRegression.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">第 3 章 线性回归模型的贝叶斯视角</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>