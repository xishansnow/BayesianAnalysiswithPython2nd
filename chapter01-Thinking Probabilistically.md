# 第**1**章　概率思维

> 归根到底，概率论不过是把常识化作计算而已。
>    ------皮埃尔---西蒙•拉普拉斯

本章我们将学习贝叶斯统计中的核心概念以及一些用于贝叶斯分析的基本工具。大部分内容都是一些理论介绍，其中会涉及一些Python代码，绝大多数概念会在本书其余章节中反复提到。尽管本章内容有点偏理论，可能会让习惯代码的你感到有点不安，不过这会让你在后面应用贝叶斯统计方法解决问题时容易一些。

本章包含以下主题：

- 统计模型；
- 概率及不确定性；
- 贝叶斯理论及统计推断；
- 单参数推断以及经典的抛硬币问题；
- 如何选择先验以及人们为什么不喜欢它；
- 如何报告贝叶斯分析结果。



## **1.1**　统计、模型与本书途径

统计学主要是收集、组织、分析并解释数据，因此，统计学的基础知识对数据分析来说至关重要。数据分析主要使用两种统计方法：

- **探索性数据分析(ExploratoryDataAnalysis，EDA)**：这是关于数字汇总，例如平均值、模式、标准偏差和四分位数范围(EDA的这一部分也称为描述性统计)。EDA还使用您可能已经熟悉的工具(如直方图和散点图)直观地检查数据。

>假设我们已经有了数据集，通常的做法是先对其探索并可视化，这样我们就能对手头的数据有个直观的认识。可以通过如下两步完成所谓的探索式数据分析过程：描述性统计、数据可视化。其中：描述性统计是指如何用一些指标或统计值来定量地总结或刻画数据，例如你已经知道了如何用均值、众数、标准差、四分位差等指标来描述数据。数据可视化是指用生动形象的方式表述数据，你大概对直方图、散点图等表现形式比较熟悉。乍看起来，探索式数据分析似乎是在复杂分析之前的一些准备工作，或者是作为一些复杂分析方法的替代品，不过探索式数据分析在理解、解释、检查、总结及交流贝叶斯分析结果等过程中依然有用。

- **推断统计（Inferentialstatistics）**：这是关于在当前数据之外做出陈述。我们可能想要了解一些特定的现象，或者我们可能想要对未来(尚未观测到的)数据点做出预测，或者我们需要在几种相互矛盾的解释中对相同的观测做出选择。推理统计学是一套方法和工具，将帮助我们回答这些类型的问题。

>有时候，画画图、对数据做些简单的计算（比如求均值）就够了。另外一些时候，我们希望从数据中挖掘出一些更一般性的结论。我们可能希望了解数据是怎么生成的，也可能是想对未来还未观测到的数据做出预测，又或者是希望从多个对观测值的解释中找出最合理的一个，这些正是统计推断所做的事情。模型分为许多种，统计推断依赖的是概率模型，许多科学研究也都是基于模型的，大脑不过是对现实进行建模的一台机器。

- **本书重点**：如何执行贝叶斯推断统计，然后使用EDA来总结、解释、检查和沟通贝叶斯推断结果。

大多数统计学入门课程，至少对非统计学家来说，都是作为“食谱的集合”来教授的。大致是这样的：去“统计”食品室，拿一个罐头并打开它，加些数据来品尝，搅拌直到你获得一致的$p$值，最好在$0.05$以下。此类课程的主要目标是教你如何挑选合适的罐头。我不喜欢这种方法，主要因为常常让读者更困扰了。即使在概念层面上，也很难掌握统一的学习方法。我们采取了一种不同方法：我们还将学习一些食谱，但这将是自制的，而不是罐头食品；我们将学习如何混合适合不同美食场景的新鲜食材，更重要的是，这可以让你应用远超出本书示例的那些概念。

采取这种方法是可能的，有两个原因：

- **本体论层面**：统计学是在概率论的数学框架下统一的一种建模形式。使用概率方法提供了一个可能看起来非常不同的方法的统一视图；统计方法和机器学习(ML)方法在概率镜头下看起来更相似。
- **技术层面**：像PyMC3这样的现代软件允许实践者，就像你和我一样，以相对简单的方式定义和求解模型。就在几年前，这些模型中的许多还无法解决，或者需要高度的数学和技术复杂性。

### （1）与数据共舞

数据是统计学和数据科学的重要组成部分。数据来自几个来源，如实验、计算机模拟、调查和实地观察。如果我们是负责产生或收集数据的人，首先仔细考虑我们想要回答的问题和我们将使用的方法，然后才着手获取数据，这总是一个好主意。事实上，有一个完整的统计学分支来处理数据收集，也就是所谓的实验设计。在数据泛滥的时代，我们有时会忘记，收集数据并不总是便宜的。例如，虽然大型强子对撞机(LHC)确实每天产生数百太字节，但它的建造需要多年的体力和脑力劳动。

一般来说，我们可以认为生成数据的过程是随机的，因为存在本体论、技术和/或认知上的不确定性，即系统本质上是随机的，存在增加噪声或限制我们以任意精度进行测量的技术问题，和/或存在对我们隐藏细节的概念限制。由于所有这些原因，我们总是需要在模型的上下文中解释数据，包括心理模型和形式模型。数据不会说话，而是通过模型说话。

在这本书中，我们将假设我们已经收集了数据。我们的数据也将是干净整洁的，这在现实世界中很少发生。我们将做出这些假设，以便集中在本书的主题上。我只想强调，特别是对于数据分析的新手来说，即使本书没有介绍这些技能，您也应该学习和练习这些重要技能，以便成功地使用数据。

分析数据时的一项非常有用的技能是知道如何用编程语言(如Python)编写代码。考虑到我们生活在一个数据更加混乱的世界，操作数据通常是必要的，而编码有助于完成任务。即使您很幸运，并且您的数据非常干净整洁，编码仍然非常有用，因为现代贝叶斯统计主要是通过Python或R等编程语言完成的。

如果您想了解如何使用Python清理和操作数据，我推荐您阅读杰克·范德普拉斯的优秀著作《Python数据科学手册》

### （2）贝叶斯建模

模型是对给定系统或流程的简化描述，出于某种原因，我们对此很感兴趣。这些描述被故意设计成只捕捉系统中最相关的方面，而不是解释每一个次要的细节。这就是为什么更复杂的模型并不总是更好的原因之一。有许多不同类型的模型；在本书中，我们将仅介绍贝叶斯模型。我们可以使用三个步骤总结贝叶斯建模过程：

（1）给定一些数据以及关于这些数据是如何生成的一些假设，通过组合**概率分布**的构建块来设计一个模型。这些模型都是粗略近似的，但大多数情况下满足需要。

（2）利用贝叶斯理论将数据和模型结合起来，根据数据和假设推导出逻辑结论，我们称之为经数据拟合后的模型。

（3）根据多种标准（包括真实数据和在研究主题上的专业知识），判断模型拟合得是否合理。

通常，我们会发现实际的建模过程并非严格按照该顺序进行的，有时候我们有可能跳到其中任何一步，原因可能是编写的程序出错了，也可能是找到了某种改进模型的方式，又或者是我们需要增加更多的数据。

贝叶斯模型是基于概率构建的，因此也称作**概率模型**。为什么基于概率呢？因为概率能够很好地描述数据中的不确定性，并让我们在满是岔路的花园里面轻松散步。

## **1.2**　概率与不确定性

这一节的标题可能有点自命不凡，因为我们不会在短短几页内学习概率论，但这不是我的本意。我只想介绍几个一般性和重要的概念。这些概念对于更好地理解贝叶斯方法是必要的，应该也足以帮助理解本书其余部分。如有必要，我们将根据需要扩展或引入与概率相关的新概念。要详细学习概率论，我强烈推荐约瑟夫·K·布利茨坦（Joseph K Blitzstein）和杰西卡·黄 （Jessica Hwang） 写的《Introduction to Probability》。另一本有用的书可能是渡部住夫的《Mathematical Theory of Bayesian Statistics》，该书比第一本更注重贝叶斯，在数学方面也更重。

### （1）解释概率

虽然概率论是一个成熟而久负盛名的数学分支，但对概率的解释不止一种。从贝叶斯角度来看，概率是一种量化命题不确定性水平的度量。根据这个概率定义，询问火星上有生命的概率、电子质量为 $9.1 \times 10^{-31}$ 千克的概率或 布宜诺斯艾利斯1816 年 7 月 9 日为晴天的概率是完全有效和自然的。注意，火星上存在或不存在生命，结果是二元的，是一个 “ 是 ” 与 “ 否 ” 的问题。但考虑到我们不能确定这一事实，明智的做法是找出火星上有生命的可能性有多大。

由于概率的这个定义与我们的认知心理状态有关，所以通常也被称为概率的主观定义。但请注意，任何有科学头脑的人都不会用自己的信仰，也不会用天使提供的信息来回答这样的问题，而是会使用所有有关火星的地球物理数据，以及所有有关生命必备条件的生化知识等等。因此，贝叶斯统计和我们拥有的任何其他成熟科学方法一样都是主观（或客观）的。

如果我们没有关于一个问题的信息，那么每个可能的事件都有相同的可能性，从形式上讲，这等同于为每个可能的事件分配相同的概率。在没有信息的情况下，我们的不确定性是最大的。相反，如果我们知道某些事件更有可能发生，那么可以通过给其分配更高的概率或给其他时间更少的概率来形式化表示。此外，用统计语言谈论事件时，通常并不局限于可能发生的事情，例如：小行星撞向地球或我姑姑60岁的生日派对。事件是一个变量可以接受的任何可能值(或值的集合)，例如：30岁以上的事件，或去年在世界各地售出的自行车数量。

概率的概念与逻辑学学科也有关。在亚里士多德或古典逻辑中，只能有取值为真或假的语句。在概率的贝叶斯定义下，确定性只是一个特例：真陈述的概率为 1，假陈述的概率为 0。只有在有确凿数据表明某些东西正在生长、繁殖和进行其他与生物相关的活动后，才会将火星生命概率定为 1。然而，将概率指定为0更难，因为几乎总是可以认为：火星上有一些尚未探索的地点，或在某些实验中犯了错误等原因，导致得出火星上没有生命这个可能错误的结论。与这一点相关的是克伦威尔规则，它指出，我们应该保留使用先验概率 0 或 1 来处理逻辑上正确或错误的陈述。有趣的是，理查德·考克斯(Richard Cox)在数学上证明，如果我们想要将逻辑扩展到包含不确定性，我们必须使用概率和概率理论。贝叶斯定理只是概率规则的一个逻辑推论。因此，贝叶斯统计的另一种思维方式是在处理不确定性时将其作为逻辑的延伸，这显然与贬义意义上的 “主观推理” 无关。

综上所述，用概率来模拟不确定性并不一定与自然界是确定性还是随机性的争论有关，也不一定与主观个人信念有关。相反，这是一种纯粹用来建模不确定性的方法论。我们认识到大多数现象很难理解，因为通常不得不处理不完整和（或）有噪声的数据，而本质上人类会受到大脑的限制。因此，我们使用了一种明确考虑不确定性的建模方法。

### （2）定义概率

概率值介于\[0,1\]之间（包括0和1），其计算遵循一些法则，其中之一是乘法法则：
$$
p(A, B)=p(A \mid B) p(B) \tag{1.1}
$$
上式的读法是：$A$ 和 $B$ 同时发生的概率等于 $B$ 发生的概率乘以在 $B$ 发生条件下 $A$ 也发生的概率。其中，$p(A,B)$ 表示 $A$ 和 $B$ 的**联合概率**，指 $A$ 和 $B$ 同时发生的概率； $p(A|B)$ 表示**条件概率** ，指在知识（或证据、事件） $B$ 支持下，$A$ 发生的概率。二者的现实意义不同，例如：“路面是湿的” 概率跟 “（给定条件）下雨时路面是湿的” 概率截然不同。

条件概率 $p(A|B)$ 可能比原概率 $p(A)$ 高，也可能低或者相等。

- 如果 $B$ 并不能提供任何关于 $A$ 的信息，那么 $p(A|B)=p(A)$ ，也暗示 $A$ 和 $B$ 是相互独立的。

- 如果事件 $B$ 能够给出关于事件 $A$ 的一些信息，那么根据事件 $B$ 提供的信息不同，事件 $A$ 可能发生的概率会变得更高或是更低。

让我们看一个使用公平的六边形骰子的简单例子。如果我们掷骰子，得到数字3的可能性有多大？是六分之一，因为六个数字中的每一个都有相同机会。假设我们得到了一个奇数，得到数字 3 的概率是多少？是三分之一，因为如果知道出现了奇数，唯一可能的数字是 $\{1,3,5\}$ ，而且每个数字都有相同几率。最后，如果知道出现的是偶数，得到数字 3 的可能性有多大？这是 0，因为如果我们知道这个数字是偶数，那么唯一可能的数字就是 $\{2,4,6\}$ ，因此得到 3 是不可能的。

正如这个简单例子所述，通过观测数据的条件作用，我们有效地改变了事件概率，以及事件的不确定性。条件概率是统计学的核心，不管你的问题是掷骰子还是制造自动驾驶汽车。

### （3）概率分布

概率分布是一个数学对象，用来描述不同事件发生的可能性有多大。通常这些事件以某种方式被限制为一组可能的事件中，例如：骰子的 $\{1,2,3,4,5\}$ 。统计学中一个常见且有用的概念是：**数据是从某个具有未知参数的真实概率分布中生成的**。而<u>推断是从符合真实概率分布的样本（也称为数据集）中找出这些参数值的过程</u>。一般来说，我们无法获得真实的概率分布，因此我们必须想办法以某种方式创建一个具有近似分布的模型。概率模型是通过合理组合概率分布来建立的。

>请注意，一般来说不能确定我们的模型是否正确，因此需要评估和批判这些模型，以便获得信心并说服他人相信模型适用于想要探索或解决的问题。

如果一个变量 $X$ 可以用概率分布来描述，即可以称之为随机变量 $X$ 。一般来说，使用大写字母（例如 $X$） 来表示一个随机变量，并用小写 $x$ 表示该随机变量的一个实例。$x$ 可以是包含许多元素或单个值的向量 $x=\{x_1,x_2,...,x_n\}$ 。

让我们看一个使用 Python 的示例：真实概率分布是均值 $\mu=0$ 和方差 $\sigma=1$ 的正态（或高斯）分布；这两个参数完全明确地定义了正态分布。使用 SciPy，可以通过编写 `stats.Norm(μ，σ)` 来定义随机变量，并且使用 `rvs` （random variates的缩写）方法获得一个实例 $x$ 。而下面示例中，代码要求提供三个值：

```python
μ = 0.
σ = 1.
X = stats.norm(μ, σ)
x = X.rvs(3)
```

您会注意到，每次执行此代码（统计术语为：每次试验）时，您将获得不同随机结果。请注意，一旦知道概率分布参数的值，则该分布中每个值的概率就是已知的，随机的是在每次试验中获得的精确值。

关于随机的含义，**一个常见误解是：你可以从随机变量中得到任何可能的值，或者认为所有值都是等可能的。**

随机变量的可能值及其概率是由概率分布严格控制的，随机性只是因为我们不能预测在每次试验中将要得到的精确值。每次执行前面的代码时，我们都会得到三个不同数字，但如果我们重复代码数千次，将能够经验性地检查采样值的平均值是否在零附近，以及 95% 的样本值是否在 [-1.96，+1.96] 范围内。请不要相信我，用你的 Python 力量自己去验证吧。如果我们研究正态分布的数学性质，我们可以得出同样的结论。

统计学中表示变量随参数 $\mu,\sigma$ 呈正态分布的形式为：
$$
x \sim \mathcal{N}(\mu,\sigma) \tag{1.2}
$$
在本书中，当您找到（波浪号）$\sim$ 符号时，读为：$x$ 服从...分布。

> 在许多文本中，常用方差而不是标准差来表示正态分布，记作 $\mathcal{N}(\mu,\sigma^2)$ 。本书中，我们将使用标准差来做正态分布的参数，首先是因为它更容易解释，其次是因为 PyMC3 是这样工作的。

在本书后面将遇到几个概率分布；每次出现一个概率分布，都会花一点时间来描述它。首先从正态分布开始，因为它类似于概率分布的宙斯。如果变量的值由以下表达式规定，则变量服从高斯分布：
$$
p(x \mid \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}}\tag{1.3}
$$




这是正态分布的概率密度函数。不需要记住公式 1.3，此处只想展示给大家看，这样就能知道数字是从哪里来的。正如已经提到的，$\mu$ 和 $\sigma$ 是该分布的参数，通过指定这些参数值，我们完全可以定义分布；可以从表达式 1.3 中看到这一点，因为其他项都是常量。$\mu$ 可以取任何实值，即 $\mu \in \mathbf{R}$ ，并指定分布的平均值 （以及中位数和模式，它们都是相等的）。$\sigma$ 是标准差，它只能是正数，表示概率分布的散布情况，值越大分布越分散。因为 $\mu$ 和 $\sigma$ 有无限多个可能组合，所以有无限多个高斯分布的实例，并且所有这些实例都属于相同的高斯族。

数学公式简明扼要而且不存在二义性，有人甚至说很漂亮。但必须承认，第一次遇到它可能会让人害怕，特别是那些对数学不太感兴趣的人；打破僵局的一个好方法是使用 Python 来探索它们：

```python
mu_params = [-1, 0, 1]
sd_params = [0.5, 1, 1.5]
x = np.linspace(-7, 7, 200)
_, ax = plt.subplots(len(mu_params), len(sd_params), sharex=True,
                     sharey=True,
                     figsize=(9, 7), constrained_layout=True)
for i in range(3):
    for j in range(3):
        mu = mu_params[i]
        sd = sd_params[j]
        y = stats.norm(mu, sd).pdf(x)
        ax[i,j].plot(x, y)
        ax[i,j].plot([], label="μ = {:3.2f}\nσ = {:3.2f}".format(mu,
                     sd), alpha=0)
        ax[i,j].legend(loc=1)
ax[2,1].set_xlabel('x')
ax[1,0].set_ylabel('p(x)', rotation=0, labelpad=20)
ax[1,0].set_yticks([])
```

前面的大部分代码用于绘图，概率部分由 `y=stats.norm(u，sd).pdf(X)` 行执行。在给定一组 $x$ 值的 $µ$ 和 $sd$ 参数的情况下，通过这条线，我们可以评估正态分布的概率密度函数。前面的代码生成图1.1。在每个子图中，我们有一条蓝色(深灰色)曲线，表示具有特定参数的高斯分布，并且包含在每个子图的图例中：

> 本书中大多数数字都是直接从它们前面的代码生成的，很多时候甚至没有将代码与数字联系起来的前导短语。使用 Jupyter 笔记本或 Jupyter Lab 的人应该熟悉这种模式。

<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210430230432_cf.webp" style="zoom:67%;" />

随机变量有两种类型：连续型和离散型。连续变量可以取某个区间中的任何值(我们可以使用 Python 浮点数来表示它们)，而离散变量只能取某些值（我们可以使用 Python 整数来表示它们）。正态分布是一种连续分布。

请注意，前图中 `ytick` 被省略了；这是一个特性，而不是一个 `bug`。省略它们的原因是，这些值不会添加太多相关信息，但可能会让人感到困惑。解释一下：$y$ 轴上的实际数字其实并不重要，重要的是它们之间的相对值。如果从中取两个值，比方说和，你会发现(在曲线图中高出两倍)，你可以有把握地说，的值的概率是的概率的两倍。这是大多数人会凭直觉理解的，幸运的是这是正确的解释。在处理连续分布时，唯一棘手的部分是在y轴上绘制的值不是概率，而是概率密度。为了得到一个合适的概率，你必须在给定的区间内积分，也就是说，你必须计算曲线下方的面积(对于该区间)。虽然概率不能大于1，但概率密度可以，并且是概率密度曲线下的总面积限制为1。从数学角度理解概率和概率密度之间的差异是至关重要的。对于本书中使用的实用方法，我们可以稍微草率一点，因为只要你对如何用相对值来解释前面的情节有正确的直觉，这种差别就不那么重要了。

概率分布是数学中的一个概念，用来描述不同事件发生的可能\
性，通常这些事件限定在一个集合内，代表了所有可能发生的事件。

在统计学里可以这么理解：数据是从某种参数未知的概率分布中生成的。由于并不知道具体的参数，我们只能借用贝叶斯定理从仅有的数据中反推参数。概率分布是构建贝叶斯模型的基础，不同分布组合在一起之后可以得到一些很有用的复杂模型。

本书会介绍一些概率分布，在第一次介绍某个概率分布时，我们会先花点时间理解它。最常见的一种概率分布是高斯分布，又叫正态分布，其数学公式描述如下：

![](C:/ProgramFiles/Typora/media/image255.png){width="2.373818897637795in"height="0.4373118985126859in"}

![](C:/ProgramFiles/Typora/media/image256.png){width="0.47892825896762903in"height="0.1770067804024497in"}上式中，*μ*和*σ*是高斯分布的两个参数。第1个参数*μ*是该分布的均值（同时也是中位数和众数），其取值范围是任意实数，即；第2个参数*σ*是标准差，用来衡量分布的离散程度，其取值只能为正。由于*μ*和*σ*的取值范围无穷大，因此高斯分布的实例也有无穷多。虽然数学公式这一表达形式简洁明了，也有人称之有美感，不过得承认公式还是有些不够直观，我们可以尝试用Python代码将公式的含义重新表示出来。首先看看高斯分布都长什么样：

![](C:/ProgramFiles/Typora/media/image257.png){width="3.818897637795276e-2in"height="3.495042650918635in"}importmatplotlib.pyplotaspltimportnumpyasnp

fromscipyimportstats

importseabornassns

mu_params=\[-1,0,1\]

sd_params=\[0.5,1,1.5\]

x=np.linspace(-7,7,100)

f,ax=plt.subplots(len(mu_params),len(sd_params),sharex=True,sharey=True)

foriinrange(3):

forjinrange(3):

mu=mu_params\[i\]

sd=sd_params\[j\]

y=stats.norm(mu,sd).pdf(x)

ax\[i,j\].plot(x,y)

ax\[i,j\].plot(0,0,

label=\"\$\\\\mu\$={:3.2f}\\n\$\\\\sigma\$={:3.2f}\".format(mu,sd),

32

![](C:/ProgramFiles/Typora/media/image264.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}alpha=0)\
ax\[i,j\].legend(fontsize=12)\
ax\[2,1\].set_xlabel(\'\$x\$\',fontsize=16)\
ax\[1,0\].set_ylabel(\'\$pdf(x)\$\',fontsize=16)plt.tight_layout()

上面代码的输出结果如下：

![](C:/ProgramFiles/Typora/media/image268.png){width="5.643024934383202in"height="3.8004560367454068in"}

由概率分布生成的变量（例如*x*）称作随机变量，当然这并不是说该变量可以取任意值，相反，我们观测到该变量的数值受到概率分

布的约束，而其随机性源于我们只知道变量的分布却无法准确预测该变量的值。通常，如果一个随机变量服从在参数*μ*和*σ*下的高斯分布，我们可以这样表示该变量：

![](C:/ProgramFiles/Typora/media/image276.png){width="1.0099136045494312in"height="0.187419072615923in"}

其中，符号～读作服从于某种分布。

随机变量分为两种：连续变量和离散变量。连续随机变量可以从某个区间内取任意值（我们可以用Python中的浮点型数据来表

33

示），而离散随机变量只能取某些特定的值（我们可以用Python中的整型数据来表示）。

![](C:/ProgramFiles/Typora/media/image281.png){width="1.457607174103237in"height="0.187419072615923in"}许多模型都假设，如果对服从于同一个分布的多个随机变量进行连续采样，那么各个变量的采样值之间相互独立，我们称这些随机变量是独立同分布的。用数学语言描述就是，如果两个随机变量*x*和*y*对于所有可能的取值都满足，那么称这两个变量相互

独立。

时间序列是不满足独立同分布的一个典型例子。在时间序列中，需要对时间维度的变量多加留心。下面的例子是从\
http://cdiac.esd.ornl.gov中获取的数据。这份数据记录了从1959年到1997年大气中二氧化碳的含量。我们用以下代码将它写出来：

data=np.genfromtxt(\'mauna_loa_CO2.csv\',delimiter=\',\')plt.plot(data\[:,0\],data\[:,1\])

plt.xlabel(\'\$year\$\',fontsize=16)

plt.ylabel(\'\$CO_2(ppmv)\$\',fontsize=16)

![](C:/ProgramFiles/Typora/media/image286.png){width="5.01833552055993in"height="3.4047911198600174in"}

图中每个点表示每个月空气中二氧化碳含量的测量值，可以看到

34

测量值是与时间相关的。我们可以观察到两个趋势：一个是季节性的波动趋势（这与植物周期性生长和衰败有关）；另一个是二氧化碳含量整体性的上升趋势。

**1.2.2**　贝叶斯定理与统计推断

到目前为止，我们已经学习了一些统计学中的基本概念和词汇，接下来让我们首先看看神奇的贝叶斯定理：

![](C:/ProgramFiles/Typora/media/image290.png){width="2.2697036307961507in"height="0.4477241907261592in"}

看起来稀松平常，似乎跟小学课本里的公式差不多，不过这就是关于贝叶斯统计你所需要掌握的全部。首先看看贝叶斯定理是怎么来的，这对我们理解它会很有帮助。事实上，我们已经掌握了如何推导它所需要的全部概率论知识。

根据前面提到的概率论中的乘法准则，我们有以下式子：

![](C:/ProgramFiles/Typora/media/image292.png){width="2.144765966754156in"height="0.19783136482939634in"}

上式还可以写成如下形式：

![](C:/ProgramFiles/Typora/media/image294.png){width="2.155177165354331in"height="0.19783136482939634in"}

由于以上式子的左边相等，于是可以得到：

![](C:/ProgramFiles/Typora/media/image296.png){width="2.6965748031496064in"height="0.19783136482939634in"}

对上式调整下顺序，便得到了贝叶斯定理：

![](C:/ProgramFiles/Typora/media/image298.png){width="2.2697036307961507in"height="0.4477241907261592in"}

现在，让我们看看这个式子的含义及其重要性。首先，上式表明

35

![](C:/ProgramFiles/Typora/media/image302.png){width="0.7600382764654419in"height="0.19783136482939634in"}和并不一定相等，这一点非常重要，日常分析中即\
使系统学习过统计学和概率论的人也很容易忽略这点。我们举个简单

例子来说明为什么二者不一定相等：有两条腿的动物就是人的概率和人有两条腿的概率显然是不同的。几乎所有人都有两条腿（除了某些人因为先天性原因或者意外导致没有两条腿），但是有两条腿的动物中很多都不是人类，比如鸟类。

在前面的式子中，如果我们将*H*理解为假设，*D*理解为数据，那\
么贝叶斯定理告诉我们的就是，在给定数据的条件下如何计算假设成

立的概率。不过，如何把假设融入贝叶斯定理中去呢？答案是概率分布。换句话说，*H*是一种狭义上的假设，我们所做的实际上是寻找模型的参数（更准确地说是参数的分布）。因此，与其称*H*为假设，不如称之为模型，这样能避免歧义。

贝叶斯定理非常重要，后面会反复用到，这里我们先熟悉下其各个部分的名称：

*p*(*H*)：先验；

*p*(*D*\|*H*)：似然；

*p*(*H*\|*D*)：后验；

*p*(*D*)：证据。

![](C:/ProgramFiles/Typora/media/image323.png){width="0.6246916010498688in"height="3.4706911636045494e-2in"}先验分布反映的是在观测到数据之前我们对参数的了解，如果我们对参数一无所知（就跟《权力的游戏》中的雪诺一样），那么可以用一个不包含太多信息的均匀分布来表示。由于引入了先验，有些人会认为贝叶斯统计是偏主观的，然而，这些先验不过是构建模型时的一些假设罢了，其主观性跟似然差不多。

36

![](C:/ProgramFiles/Typora/media/image331.png){width="5.838564085739282in"height="3.4706911636045494e-2in"}似然是指如何在实验分析中引入观测数据，反映的是在给定参数下得到某组观测数据的可信度。

![](C:/ProgramFiles/Typora/media/image333.png){width="2.498755468066492in"height="3.4706911636045494e-2in"}后验分布是贝叶斯分析的结果，反映的是在给定数据和模型的条件下我们对问题的全部认知。需要注意，后验指的是我们模型中参数的概率分布而不是某个值，该分布正比于先验乘以似然。有这么个笑话：贝叶斯学派就像是这样一类人，心里隐约期待着一匹马，偶然间瞥见了一头驴，结果坚信他看到的是一头骡子。当然了，如果要刻意纠正这个笑话的话，在先验和似然都比较含糊的情况下，我们会得到一个（模糊的）"骡子"后验。不过，这个笑话也讲出了这样一个道

![](C:/ProgramFiles/Typora/media/image335.png){width="3.3316765091863516in"height="3.4706911636045494e-2in"}理，后验其实是对先验和似然的某种折中。从概念上讲，后验可以看做是在观测到数据之后对先验的更新。事实上，一次分析中的后验，在收集到新的数据之后，也可以看做是下一次分析中的先验。这使得贝叶斯分析特别适合于序列化的数据分析，比如通过实时处理来自气象站和卫星的数据从而提前预警灾害，更详细的内容可以阅读在线机器学习方面的算法。

最后一个概念是证据，也称作边缘似然。正式地讲，证据是在模型的参数取遍所有可能值的条件下得到指定观测值的概率的平均。不过，本书的大部分内容并不关心这个概念，我们可以简单地把它当作归一化系数。我们只关心参数的相对值而非绝对值。把证据这一项忽略掉之后，贝叶斯定理可以表示成如下正比例形式：

![](C:/ProgramFiles/Typora/media/image348.png){width="2.2384689413823273in"height="0.19783136482939634in"}

理解其中的每个概念可能需要时间和更多的例子，本书也将围绕这些内容展开。

37

**1.3**　单参数推断

![](C:/ProgramFiles/Typora/media/image355.png){width="2.2905260279965005in"height="3.4706911636045494e-2in"}前面，我们学习了几个重要概念，其中有两个是贝叶斯统计的核心概念，这里我们用一句话再重新强调下：概率是用来衡量参数不确定性的，贝叶斯定理就是用来在观测到新的数据时正确更新这些概率以期降低我们的不确定性。

现在我们已经知道什么是贝叶斯统计了，接下来就从一个简单的例子入手，通过推断单个未知参数来学习如何进行贝叶斯统计。

**1.3.1**　抛硬币问题

抛硬币是统计学中的一个经典问题，其描述如下：我们随机抛一枚硬币，重复一定次数，记录正面朝上和反面朝上的次数，根据这些数据，我们需要回答诸如这枚硬币是否公平，以及更进一步这枚硬币有多不公平等问题。抛硬币是一个学习贝叶斯统计非常好的例子，一方面是因为几乎人人都熟悉抛硬币这一过程，另一方面是因为这个模型很简单，我们可以很容易计算并解决这个问题。此外，许多真实问题都包含两个互斥的结果，例如0或者1、正或者负、奇数或者偶数、垃圾邮件或者正常邮件、安全或者不安全、健康或者不健康等。因

此，即便我们讨论的是硬币，该模型也同样适用于前面这些问题。

为了估计硬币的偏差，或者更广泛地说，想要用贝叶斯学派理论解决问题，我们需要数据和一个概率模型。对于抛硬币这个问题，假设我们已试验了一定次数并且记录了正面朝上的次数，也就是说数据部分已经准备好了，剩下的就是模型部分了。考虑到这是第一个模

型，我们会列出所有必要的数学公式，并且一步一步推导。下一章\
中，我们会重新回顾这个问题，并借用PyMC3从数值上解决它（也

38

就是说那部分不需要手动推导，而是利用PyMC3和计算机来完成）。

通用模型

首先，我们要抽象出偏差的概念。我们称，如果一枚硬币总是正面朝上，那么它的偏差就是1，反之，如果总是反面朝上，那么它的偏差就是0，如果正面朝上和反面朝上的次数各占一半，那么它的偏差就是0.5。这里用参数*θ*来表示偏差，用*y*表示*N*次抛硬币实验中正面朝上的次数。根据贝叶斯定理，我们有如下公式：

![](C:/ProgramFiles/Typora/media/image360.png){width="1.884478346456693in"height="0.19783136482939634in"}

![](C:/ProgramFiles/Typora/media/image361.png){width="0.6246883202099738in"height="0.19783136482939634in"}这里需要指定我们将要使用的先验和似然分别是什么。让我们首先从似然开始。

选择似然

假设多次抛硬币的结果相互之间没有影响，也就是说每次抛硬币都是相互独立的，同时还假设结果只有两种可能：正面朝上或者反面朝上。但愿你能认同我们对这个问题做出的合理假设。基于这些假

设，一个不错的似然候选是二项分布：

![](C:/ProgramFiles/Typora/media/image365.png){width="2.9152154418197727in"height="0.4268996062992126in"}

这是一个离散分布，表示*N*次抛硬币实验中*y*次正面朝上的概率（或者更通俗地描述是，*N*次实验中，*y*次成功的概率）。下面的代码生成了9个二项分布，每个子图中的标签显示了对应的参数：

![](C:/ProgramFiles/Typora/media/image366.png){width="3.818897637795276e-2in"height="1.079410542432196in"}n_params=\[1,2,4\]

p_params=\[0.25,0.5,0.75\]

x=np.arange(0,max(n_params)+1)

f,ax=plt.subplots(len(n_params),len(p_params),sharex=True,sharey=True)

39

![](C:/ProgramFiles/Typora/media/image372.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}foriinrange(3):

forjinrange(3):

n=n_params\[i\]

p=p_params\[j\]

y=stats.binom(n=n,p=p).pmf(x)\
ax\[i,j\].vlines(x,0,y,colors=\'b\',lw=5)\
ax\[i,j\].set_ylim(0,1)\
ax\[i,j\].plot(0,0,label=\"n={:3.2f}\\np={:3.2f}\".format(n,p),alpha=0)\
ax\[i,j\].legend(fontsize=12)\
ax\[2,1\].set_xlabel(\'\$\\\\theta\$\',fontsize=14)\
ax\[1,0\].set_ylabel(\'\$p(y\|\\\\theta)\$\',fontsize=14)\
ax\[0,0\].set_xticks(x)

![](C:/ProgramFiles/Typora/media/image376.png){width="5.01833552055993in"height="3.425615704286964in"}

二项分布是似然的一个合理选择，直观上讲，*θ*可以看作抛一次硬币时正面朝上的可能性，并且该过程发生了*y*次。类似地，我们可以把"1−*θ*"看作抛一次硬币时反面朝上的概率，并且该过程发生了"*N*−*y*"次。

假如我们知道了*θ*，那么就可以从二项分布得出硬币正面朝上的分布。如果我们不知道*θ*，也别灰心，在贝叶斯统计中，当我们不知道某个参数的时候，就对其赋予一个先验。接下来继续选择先验。

选择先验

40

这里我们选用贝叶斯统计中最常见的**beta**分布，作为先验，其数学形式如下：

![](C:/ProgramFiles/Typora/media/image388.png){width="2.675751312335958in"height="0.4477241907261592in"}

![](C:/ProgramFiles/Typora/media/image389.png){width="0.11452537182852143in"height="0.16659448818897638in"}仔细观察上面的式子可以看出，除了*Γ*部分之外，beta分布和二\
项分布看起来很像。*Γ*是希腊字母中大写的伽马，用来表示伽马函数。现在我们只需要知道，用分数表示的第一项是一个正则化常量，用来保证该分布的积分为1，此外，和两个参数用来控制具体的分布形态。beta分布是我们到目前为止见到的第3个分布，利用下面的代码，我们可以深入了解其形态：

params=\[0.5,1,2,3\]

x=np.linspace(0,1,100)

f,ax=plt.subplots(len(params),len(params),sharex=True,sharey=True

)

foriinrange(4):

forjinrange(4):

a=params\[i\]

b=params\[j\]

y=stats.beta(a,b).pdf(x)

ax\[i,j\].plot(x,y)

ax\[i,j\].plot(0,0,label=\"\$\\\\alpha\$={:3.2f}\\n\$\\\\beta\$={:3.2f}\".format(a,b),alpha=0)

ax\[i,j\].legend(fontsize=12)

ax\[3,0\].set_xlabel(\'\$\\\\theta\$\',fontsize=14)\
ax\[0,0\].set_ylabel(\'\$p(\\\\theta)\$\',fontsize=14)\
plt.savefig(\'B04958_01_04.png\',dpi=300,figsize=(5.5,5.5))

41

![](C:/ProgramFiles/Typora/media/image398.png){width="5.01833552055993in"height="3.6026235783027123in"}

![](C:/ProgramFiles/Typora/media/image400.png){width="1.8740660542432197in"height="3.730971128608924e-2in"}为什么要在模型中使用beta分布呢？在抛硬币以及一些其他问题中使用beta分布的原因之一是：beta分布的范围限制在0到1之间，这跟我们的参数一样；另一个原因是其通用性，从前面的图可以看出，该分布可以有多种形状，包括均匀分布、类高斯分布、U型分布等。第3个原因是：beta分布是二项分布（前面我们使用了该分布描述似然）的共轭先验。似然的共轭先验是指，将该先验分布与似然组合在一起之后，得到的后验分布与先验分布的表达式形式仍然是一样的。简单说，就是每次用beta分布作为先验、二项分布作为似然时，我们会得到一个beta分布的后验。除beta分布之外还有许多其他共轭先验，例如高斯分布，其共轭先验就是自己。关于共轭先验更详细的内容可以查看[https://en.wikipedia.org/wiki/Conjugate_prior。许多年](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)[来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)[验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)[验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)[验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)[现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。](https://en.wikipedia.org/wiki/Conjugate_prior。许多年来，贝叶斯分析都限制在共轭先验范围内，这主要是因为共轭能让后验在数学上变得更容易处理，要知道贝叶斯统计中一个常见问题的后验都很难从分析的角度去解决。在建立合适的计算方法来解决任意后验之前，这只是个折中的办法。从下一章开始，我们将学习如何使用现代的计算方法来解决贝叶斯问题而不必考虑是否使用共轭先验。)

42

计算后验

首先回忆一下贝叶斯定理：后验正比于似然乘以先验。

![](C:/ProgramFiles/Typora/media/image416.png){width="1.884478346456693in"height="0.19783136482939634in"}

对于我们的问题而言，需要将二项分布乘以beta分布：

![](C:/ProgramFiles/Typora/media/image417.png){width="5.039159011373578in"height="0.4477241907261592in"}

现在，对上式进行简化。针对我们的实际问题，可以先把与*θ*不相关的项去掉而不影响结果，于是得到下式：

![](C:/ProgramFiles/Typora/media/image418.png){width="3.1859142607174102in"height="0.22906824146981627in"}

重新整理之后得到：

![](C:/ProgramFiles/Typora/media/image419.png){width="2.665340113735783in"height="0.22906824146981627in"}

![](C:/ProgramFiles/Typora/media/image420.png){width="1.5825448381452318in"height="0.1770067804024497in"}可以看出，上式和beta分布的形式很像（除了归一化部分），其对应的参数分别为、。也就是

说，在抛硬币这个问题中，后验分布是如下beta分布：

![](C:/ProgramFiles/Typora/media/image422.png){width="3.3941437007874016in"height="0.20824365704286965in"}

计算后验并画图现在已经有了后验的表达式，我们可以用Python对其计算并画出结果。下面的代码中，其实只有一行是用来计算后验结果的，其余的代码都是用来画图的：

![](C:/ProgramFiles/Typora/media/image423.png){width="3.8190069991251095e-2in"height="1.7770275590551181in"}theta_real=0.35

trials=\[0,1,2,3,4,8,16,32,50,150\]data=\[0,1,1,1,1,4,6,9,13,48\]

beta_params=\[(1,1),(0.5,0.5),(20,20)\]dist=stats.beta

x=np.linspace(0,1,100)

foridx,Ninenumerate(trials):

43

![](C:/ProgramFiles/Typora/media/image428.png){width="2.7777777777777776e-2in"height="2.7777777777777776e-2in"}ifidx==0:

plt.subplot(4,3,2)

else:

plt.subplot(4,3,idx+3)

y=data\[idx\]

for(a_prior,b_prior),cinzip(beta_params,(\'b\',\'r\',\'g\')):p_theta_given_y=dist.pdf(x,a_prior+y,b_prior+N-y)plt.plot(x,p_theta_given_y,c)

plt.fill_between(x,0,p_theta_given_y,color=c,alpha=0.6)

plt.axvline(theta_real,ymax=0.3,color=\'k\')

plt.plot(0,0,label=\"{:d}experiments\\n{:d}heads\".format(N,y),alpha=0)

plt.xlim(0,1)

plt.ylim(0,12)

plt.xlabel(r\"\$\\theta\$\")

plt.legend()

plt.gca().axes.get_yaxis().set_visible(False)

plt.tight_layout()

plt.savefig(\'B04958_01_05.png\',dpi=300,figsize=(5.5,5.5))

![](C:/ProgramFiles/Typora/media/image432.png){width="5.643024934383202in"height="3.77963145231846in"}

在上图的第一行中，实验的次数为0，因此第一个图中的曲线描绘的是先验分布，其中有3条曲线，每条曲线分别表示一种先验。

蓝色的线是一个均匀分布先验，其含义是：偏差的所有可能取值都是等概率的。

44

红色的线与均匀分布有点类似，对抛硬币这个例子而言可以理解为：偏差等于0或者1的概率要比其他值更大一些。\
最后一条绿色的线集中在中间值0.5附近，该分布反映了通常硬\
币正面朝上和反面朝上的概率大致是差不多的。我们也可以称，该先验与大多数硬币都是公平的这一信念是兼容的。"兼容"这个词在贝叶斯相关的讨论中会经常用到，特别是在提及受到数据启发的模型时。

![](C:/ProgramFiles/Typora/media/image438.png){width="0.5934547244094488in"height="0.19783136482939634in"}剩余的子图描绘了后续实验的后验分布，回想一下，后验可以看做是在给定数据之后更新了的先验。实验（抛硬币）的次数和正面朝上的次数分别标注在每个子图中。此外每个子图中在横轴0.35附近还有一个黑色的竖线，表示的是真实的*θ*，显然，在真实情况

下，我们并不知道该值，在这里标识出来只是为了方便理解。从这幅图中可以学到很多贝叶斯分析方面的知识。

贝叶斯分析的结果是后验分布而不是某个值，该分布描述了根据给定数据和模型得到的不同数值的可能性。\
后验最可能的值是根据后验分布的形态决定的（也就是后验分布的峰值）。\
后验分布的离散程度与我们对参数的不确定性相关；分布越离\
散，不确定性越大。\
尽管1/2=4/8=0.5，但从图中可以看出，前者的不确定性要比后者大。这是因为我们有了更多的数据来支撑我们的推断，该直觉也同时反映在了后验分布上。\
在给定足够多的数据时，两个或多个不同先验的贝叶斯模型会趋近于收敛到相同的结果。在极限情况下，如果有无限多的数据，不论我们使用的是怎样的先验，最终都会得到相同的后验。注意这里说的无限多是指某种程度而非某个具体的数量，也就是说，

45

从实际的角度来讲，某些情况下无限多的数据可以通过比较少量的数据近似。\
不同后验收敛到相同分布的速度取决于数据和模型。从前面的图中可以看出，蓝色和红色的后验在经过8次实验之后就很难看出区别了，而红色的曲线则一直到150次实验之后才与另外两个后验看起来比较接近。\
有一点从前面的图中不太容易看出来，如果我们一步一步地更新后验，最后得到的结果跟一次性计算得到的结果是一样的。换句话说，我们可以对后验分150次计算，每次增加一个新的观测数据并将得到的后验作为下一次计算的先验，也可以在得到150次抛硬币的结果之后一次性计算出后验，而这两种计算方式得到的结果是完全一样的。这个特点非常有意义，在许多数据分析的问题中，每当我们得到新的数据时可以更新估计值。

先验的影响以及如何选择合适的先验

从前面的例子可以看出，先验对分析的结果会有影响。一些贝叶斯分析的新手（以及一些诋毁该方法的人）会对如何选择先验感到茫然，因为他们不希望先验起到决定性作用，而是更希望数据本身替自己说话！有这样的想法很正常，不过我们得牢记，数据并不会真

的"说话"，只有在模型中才会有意义，包括数学上的和脑海中的模\
型。面对同一主题下的同一份数据，不同人会有不同的看法，这类例子在科学史上有许多，查看以下链接可以了解《纽约时报》最近一次[实验的例子：http://www.nytimes.com/interactive/2016/09/20/upshot/the-](http://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html?_r=0)[error-the-polling-world-rarely-talks-about.html?\_r=0。](http://www.nytimes.com/interactive/2016/09/20/upshot/the-error-the-polling-world-rarely-talks-about.html?_r=0)

![](C:/ProgramFiles/Typora/media/image458.png){width="5.83042760279965in"height="3.4706911636045494e-2in"}有些人青睐于使用没有信息量的先验（也称作均匀的、含糊的或者发散的先验），这类先验对分析过程的影响最小。本书将遵循

46

![](C:/ProgramFiles/Typora/media/image463.png){width="6.212886045494313in"height="3.76826334208224e-2in"}Gelman、McElreath和Kruschke3人的建议^\[1\]^，更倾向于使用带有较弱信息量的先验。在许多问题中，我们对参数可以取的值一般都会有些了解，比如，参数只能是正数，或者知道参数近似的取值范围，又或者是希望该值接近0或大于/小于某值。这种情况下，我们可以给模型加入一些微弱的先验信息而不必担心该先验会掩盖数据本身的信息。由于这类先验会让后验近似位于某一合理的边界内，因此也被称作正则化先验。

![](C:/ProgramFiles/Typora/media/image465.png){width="1.4576060804899387in"height="3.4706911636045494e-2in"}当然，使用带有较多信息量的强先验也是可行的。视具体的问题不同，有可能很容易或者很难找到这类先验，例如在我工作的领域（结构生物信息学），人们会尽可能地利用先验信息，通过贝叶斯或者非贝叶斯的方式来了解和预测蛋白质的结构。这样做是合理的，原因是我们在数十年间已经从上千次精心设计的实验中收集了数据，因而有大量可信的先验信息可供使用。如果你有可信的先验信息，完全没有理由不去使用。试想一下，如果一个汽车工程师每次设计新车的时候，他都要重新发明内燃机、轮子乃至整个汽车，这显然不是正确的方式。

现在我们知道了先验有许多种，不过这并不能缓解我们选择先验时的焦虑。或许，最好是没有先验，这样事情就简单了。不过，不论是否基于贝叶斯，模型都在某种程度上拥有先验，即使这里的先验并没有明确表示出来。事实上，许多频率统计学方面的结果可以看做是贝叶斯模型在一定条件下的特例，比如均匀先验。让我们再仔细看看前面那幅图，可以看到蓝色后验分布的峰值与频率学分析中*θ*的期望

值是一致的：

![](C:/ProgramFiles/Typora/media/image470.png){width="0.6871576990376203in"height="0.22906824146981627in"}

![](C:/ProgramFiles/Typora/media/image471.png){width="9.370297462817148e-2in"height="0.1770067804024497in"}注意，这里是点估计而不是后验分布（或者其他类型的分

47

![](C:/ProgramFiles/Typora/media/image473.png){width="2.2905271216097987in"height="3.4706911636045494e-2in"}布）。由此看出，你没办法完全避免先验，不过如果你在分析中引入先验，得到的会是概率分布分布而不只是最可能的一个值。明确引入先验的另一个好处是，我们会得到更透明的模型，这意味着更容易评判、（广义上的）调试以及优化。构建模型是一个循序渐进的过程，有时候可能只需要几分钟，有时候则可能需要数年；有时候整个过程可能只有你自己，有时候则可能包含你不认识的人。而且，模型复现很重要，而模型中透明的假设能有助于复现。

![](C:/ProgramFiles/Typora/media/image479.png){width="2.706990376202975in"height="3.4706911636045494e-2in"}在特定分析任务中，如果我们对某个先验或者似然不确定，可以自由使用多个先验或者似然进行尝试。模型构建过程中的一个环节就是质疑假设，而先验就是质疑的对象之一。不同的假设会得到不同的模型，根据数据和与问题相关的领域知识，我们可以对这些模型进行比较，本书第6章模型比较部分会深入讨论该内容。

由于先验是贝叶斯统计中的一个核心内容，在接下来遇到新的问题时我们还会反复讨论它，因此，如果你对前面的讨论内容感到有些疑惑，别太担心，要知道人们在这个问题上已经困惑了数十年并且相关的讨论一直在继续。

**1.3.2**　报告贝叶斯分析结果

现在我们已经有了后验，相关的分析也就结束了。下面我们可能还需要对分析结果进行总结，将分析结果与别人分享，或者记录下来以备日后使用。

**1.3.3**　模型注释和可视化

根据受众不同，你可能在交流分析结果的同时还需要交流模型。以下是一种简单表示概率模型的常见方式：

48

![](C:/ProgramFiles/Typora/media/image483.png){width="1.2389665354330708in"height="0.187419072615923in"}

![](C:/ProgramFiles/Typora/media/image485.png){width="1.8220089676290463in"height="0.187419072615923in"}

这是我们抛硬币例子中用到的模型。符号～表示左边随机变量的分布服从右边的分布形式，也就是说，这里*θ*服从于参数为*α*和*β*的Beta分布，而*y*服从于参数为*n*=1和*p*=*θ*的二项分布。该模型还可以用类似Kruschke书中的图表示成如下形式：

![](C:/ProgramFiles/Typora/media/image487.png){width="1.249377734033246in"height="2.81129593175853in"}

在第一层，根据先验生成了*θ*，然后通过似然生成最下面的数据。图中的箭头表示变量之间的依赖关系，符号～表示变量的随机

性。

本书中用到的类似Kruschke中的图都是由Rasmus\
[Bååth（http://www.sumsar.net/blog/2013/10/diy-kruschke-style-](http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/)

[diagrams/）提供的模板生成的。](http://www.sumsar.net/blog/2013/10/diy-kruschke-style-diagrams/)

**1.3.4**　总结后验

贝叶斯分析的结果是后验分布，该分布包含了有关参数在给定数\
据和模型下的所有信息。如果可能的话，我们只需要将后验分布展示

49

![](C:/ProgramFiles/Typora/media/image495.png){width="1.8740693350831146in"height="3.4706911636045494e-2in"}给观众即可。通常，一个不错的做法是：同时给出后验分布的均值\
（或者众数、中位数），这样能让我们了解该分布的中心，此外还可以给出一些描述该分布的衡量指标，如标准差，这样人们能对我们估计的离散程度和不确定性有一个大致的了解。拿标准差衡量类似正态分布的后验分布很合适，不过对于一些其他类型的分布（如偏态分\
布）却可能得出误导性结论，因此，我们还可以采用下面的方式衡\
量。

最大后验密度

![](C:/ProgramFiles/Typora/media/image500.png){width="1.2697112860892388in"height="3.4706911636045494e-2in"}一个经常用来描述后验分布分散程度的概念是最大后验密度（\
HighestPosteriorDensity，HPD）区间。一个HPD区间是指包含一定

比例概率密度的最小区间，最常见的比例是95%HPD或98%HPD，通常还伴随着一个50%HPD。如果我们说某个分析的HPD区间是\[2,5\]，其含义是指：根据我们的模型和数据，参数位于2～5的概率是0.95。这是一个非常直观的解释，以至于人们经常会将频率学中的置信区间

与贝叶斯方法中的可信区间弄混淆。如果你对频率学的范式比较熟\
悉，请注意这两种区间的区别。贝叶斯学派的分析告诉我们的是参数取值的概率，这在频率学的框架中是不可能的，因为频率学中的参数是固定值，频率学中的置信区间只能包含或不包含参数的真实值。在继续深入之前，有一点需要注意：选择95%还是50%或者其他什么值作为HPD区间的概率密度比例并没有什么特殊的地方，这些不过是经常使用的值罢了。比如，我们完全可以选用比例为91.37%的HPD区\
间。如果你选的是95%，这完全没问题，只是要记住这只是个默认\
值，究竟选择多大比例仍然需要具体问题具体分析。

对单峰分布计算95%HPD很简单，只需要计算出2.5%和97.5%处的值即可：

50

defnaive_hpd(post):

sns.kdeplot(post)

HPD=np.percentile(post,\[2.5,97.5\])

plt.plot(HPD,\[0,0\],label=\'HPD{:.2f}{:.2f}\'.format(\*HPD),linewidth=8,color=\'k\')

plt.legend(fontsize=16);

plt.xlabel(r\'\$\\theta\$\',fontsize=14)\
plt.gca().axes.get_yaxis().set_ticks(\[\])

np.random.seed(1)

post=stats.beta.rvs(5,11,size=1000)naive_hpd(post)

plt.xlim(0,1)

![](C:/ProgramFiles/Typora/media/image507.png){width="4.393646106736658in"height="3.0195395888013996in"}

对于多峰分布而言，计算HPD要稍微复杂些。如果把对HPD的原始定义应用到混合高斯分布上，我们可以得到：

np.random.seed(1)

gauss_a=stats.norm.rvs(loc=4,scale=0.9,size=3000)gauss_b=stats.norm.rvs(loc=-2,scale=1,size=2000)mix_norm=np.concatenate((gauss_a,gauss_b))

naive_hpd(mix_norm)

plt.savefig(\'B04958_01_08.png\',dpi=300,figsize=(5.5,5.5))

51

![](C:/ProgramFiles/Typora/media/image513.png){width="4.393646106736658in"height="3.206959755030621in"}

从上图可以看出，通过原始HPD定义计算出的可信区间包含了一部分概率较低的区间，位于\[0,2\]。为了正确计算出HPD，这里我们使用了plot_post函数，你可以从本书附带的代码中下载对应的源码：

fromplot_postimportplot_post\
plot_post(mix_norm,roundto=2,alpha=0.05)plt.legend(loc=0,fontsize=16)\
plt.xlabel(r\"\$\\theta\$\",fontsize=14)

![](C:/ProgramFiles/Typora/media/image518.png){width="4.393646106736658in"height="3.2173720472440945in"}

从上图可以看出，95%HPD包含两个区间，同时plot_post函数

52

也返回了两个众数。

53

**1.4**　后验预测检查

![](C:/ProgramFiles/Typora/media/image522.png){width="5.830437445319335in"height="3.4706911636045494e-2in"}贝叶斯方法的一个优势是：一旦得到了后验分布，我们可以根据该后验生成未来的数据*y*，即用来做预测。后验预测检查主要是对观测数据和预测数据进行比较从而发现这两个集合的不同之处，其目的是进行一致性检查。生成的数据和观测的数据应该看起来差不多，否则有可能是建模出现了问题或者输入数据到模型时出了问题，不过就算我们没有出错，两个集合仍然有可能出现不同。尝试去理解其中的偏差有助于我们改进模型，或者至少能知道我们模型的极限。即使我们并不知道如何去改进模型，但是理解模型捕捉到了问题或数据的哪些方面以及没能捕捉到哪些方面也是非常有用的信息。也许模型能够很好地捕捉到数据中的均值但却没法预测出罕见值，这可能是个问题，不过如果我们只关心均值，这个模型对我们而言也还是可用的。通常我们的目的不是去声称一个模型是错误的，我们更愿意遵循GeorgeBox的建议，即所有模型都是错的，但某些是有用的。我们只想知道模型的哪个部分是值得信任的，并测试该模型是否在特定方面符合我们的预期。不同学科对模型的信任程度显然是不同的，物理学中研究的系统是在高可控条件下依据高深理论运行的，因而模型可以看做是对现实的不错描述，而在一些其他学科如社会学和生物学中，研究的是错综复杂的孤立系统，因而模型对系统的认知较弱。尽管如此，不论你研究的是哪一门学科，都需要对模型进行检查，利用后验预测和本章学到的探索式数据分析中的方法去检查模型。

54

**1.5**　安装必要的**Python**库

本书用到的代码是用Python3.5写的，建议使用Python3的最新版本运行，尽管大多数代码也能在更老的Python版本（包括Python2.7）上运行，不过可能会需要做些微调。

本书建议使用Anaconda安装Python及相关库，Anaconda是一个用于科学计算的软件分发，你可以从以下链接下载并了解更\
多：<https://www.continuum.io/downloads[。在系统上装好Anaconda之](https://www.continuum.io/downloads。在系统上装好Anaconda之后，就可以通过以下方式安装Python库了：)[后，就可以通过以下方式安装Python库了：](https://www.continuum.io/downloads。在系统上装好Anaconda之后，就可以通过以下方式安装Python库了：)

**condainstallNamePackage**

我们会用到以下Python库：

Ipython5.0；\
NumPy1.11.1；\
SciPy0.18.1；\
Pandas0.18.1；\
Matplotlib1.5.3；Seaborn0.7.1；\
PyMC33.0。

在命令行中执行以下命令即可安装最新稳定版的PyMC3：

pipinstallpymc3

55

**1.6**　总结

我们的贝叶斯之旅首先围绕统计建模、概率论和贝叶斯定理做了一些简短讨论，然后用抛硬币的例子介绍了贝叶斯建模和数据分析，借用这个经典例子传达了贝叶斯统计中的一些最重要的思想，比如用概率分布构建模型并用概率分布来表示不确定性。此外我们尝试揭示了如何选择先验，并将其与数据分析中的一些其他问题置于同等地位（怎么选择似然，为什么要解决该问题等）。本章的最后讨论了如何解释和报告贝叶斯分析的结果。本章我们对贝叶斯分析的一些主要方面做了简要总结，后面还会重新回顾这些内容，从而充分理解和吸

收，并为后面理解更高级的内容打下基础。下一章我们会重点关注一些构建和分析更复杂模型的技巧，此外，还会介绍PyMC3并将其用\
于实现和分析贝叶斯模型。

56

**1.7**　练习

我们尚不清楚大脑是如何运作的，是按照贝叶斯方式？还是类似贝叶斯的某种方式？又或许是进化过程中形成的某种启发式的方式？不管如何，我们至少知道自己是通过数据、例子和练习来学习的，尽管你可能对此有不同的意见，不过我仍然强烈建议你完成以下练习。

（1）修改生成本章的第3个图的代码，在图中增加一条竖线用来表示观测到的正面朝上的比例（正面朝上的次数/抛硬币的次数），将该竖线的位置与每个子图中后验的众数进行比较。

（2）尝试用不同的先验参数（beta值）和不同的实验数据（正面朝上的次数和实验次数）重新绘制本章的第3个图。

（3）阅读维基百科上有关Cromwell准则的内容：[https://en.wikipedia.org/wiki/Cromwell%27s_rule。](https://en.wikipedia.org/wiki/Cromwell%27s_rule。)

（4）探索不同参数下高斯分布、二项分布和beta分布的图像，你可以为每个分布单独画一个图而不是全都画在一个网格中。

\[1\]　该3人分别是《BayesianDataAnalysis》《StatisticalRethinking:ABayesianCoursewithExamplesinRandStan》和《DoingBayesianDataAnalysis》的主要作者。------译者注

57