> 第**3**章　多参和分层模型
>
> 前面两章中，我们学习了贝叶斯方法的核心思想以及如何用\
> PyMC3进行贝叶斯推断。如果我们想要构建任意复杂的模型（肯定
>
> 会的），就必须学会构建多参模型。几乎所有我们可能感兴趣去建模 的问题都需要不止一个参数，而且，在许多真实世界的问题中，某些 参数可能会依赖于其他参数，这类关系可以通过分层贝叶斯模型优雅 地建模。这些概念都非常重要，本书剩余部分将会反复进行回顾。
>
> 本章，我们会讨论以下主题：
>
> 冗余参数和边缘概率分布；\
> 高斯模型；\
> 存在异常值时的鲁棒估计；\
> 比较不同的组以及效应值；\
> 分层模型和收缩（shrinkage）。
>
> 94
>
> **3.1**　冗余参数和边缘概率分布
>
> 尽管大多数有意思的模型都是多参的，但事实上，并非构建模型 的所有参数都是我们直接感兴趣的。有时候，增加一个参数只是出于 构建模型的完整性，并非因为我们真的关心这个参数。有时候我们需 要估计出一个高斯分布的均值来回答某个重要问题，对于这样一个模 型，除非我们知道该分布的标准差，否则在预测该分布均值的同时还 需要将标准差预测出来，尽管我们对标准差并不感兴趣。我们把构建 模型中并不感兴趣但却必须有的参数称为冗余参数。在贝叶斯框架
>
> 下，所有未知量都是同等对待的，因而一个参数是否是冗余参数与实 际的问题相关，而不是与参数本身、模型或者是推断过程相关。
>
> 此刻你可能在想，构建模型的过程中居然需要用到并不感兴趣的 参数，这简直就是个负担。恰恰相反，模型中包含这些不感兴趣的参 数之后，我们可以利用这类参数包含的不确定性自动传播到最后目标 参数估计的结果中。在许多问题中，我们需要将一些测量值转化成感 兴趣的量；例如在磁共振成像（Magnetic Resonance Imaging，MRI） 中，我们将被特定原子核（主要是氢原子）发散和吸收的无线电频率 转化成一个人内部的影像。这类转换通常需要用到冗余参数，大多数 情况下，人们会将其设为某些预先校准的值，或者是某些经验值，又 或许是根据某个勉强适用的经验性准则得到的值，不过贝叶斯统计可 以估计出这些冗余参数（及其不确定性）。
>
> 对于两个参数的模型，我们可以把贝叶斯模型写成如下形式：

![](C:/Program Files/Typora/media/image961.png){width="2.831923665791776in" height="0.19783136482939634in"}

> ![](C:/Program Files/Typora/media/image962.png){width="8.32917760279965e-2in" height="0.11453412073490814in"}只需要继续增加，我们就可以把上式扩展到超过两个参数的情
>
> 95
>
> ![](C:/Program Files/Typora/media/image964.png){width="0.1457600612423447in" height="0.16659448818897638in"}况。我们假设和是标量（数字）而不是向量。上面的式子与前面 章节中看到的式子的一个不同点是：现在我们得到的是一个用和\
> 两个参数的联合分布表示的二维后验分布。我们假设是我们问题中 的一个冗余参数，我们如何只用来表示后验呢？只需要计算后验分 布对的边缘分布即可：

![](C:/Program Files/Typora/media/image971.png){width="2.311349518810149in" height="0.4268996062992126in"}

> ![](C:/Program Files/Typora/media/image964.png){width="0.1457600612423447in" height="0.16659448818897638in"}也就是说，我们将后验对求积分，从而将后验表示成只包含\
> 的项，同时隐式地考虑了的不确定性。对离散变量而言，积分就变
>
> ![](C:/Program Files/Typora/media/image964.png){width="0.1457600612423447in" height="0.16659448818897638in"}成了求和。下图中，中央的点表示和的联合分布，上侧和右侧分 别表示和的边缘分布。
>
> 因此，每当我们听到参数*x*的边缘分布时，我们就要联想到*x*在其 他参数取遍所有可能分布后得到的平均分布。
>
> 边缘化不仅仅是从多峰分布中得到较低维度的一个切片的方法， 而且还有利于简化数学分析和计算分析。有时候，我们可以在计算后 验之前先对冗余参数从理论上边缘化，在第7章中会见到相关的例
>
> 子。
>
> 通过仿真得到后验（例如用PyMC3）的一个好处是，我们会对\
> 模型中的每个参数得到一个单独的向量，也就是说，参数已经边缘化
>
> 了。
>
> 96

![](C:/Program Files/Typora/media/image980.png){width="5.643024934383202in" height="5.705890201224847in"}

> 97
>
> **3.2**　随处可见的高斯分布
>
> 前面我们用beta-二项分布模型介绍了贝叶斯的思想，该模型很简 单。另外一个非常简单的模型是高斯分布或者叫正态分布。从数学的 角度来看，高斯分布非常受欢迎的原因是它处理起来非常简单，例
>
> 如，高斯分布的平均值的共轭先验还是高斯分布。此外，许多现象都 可以用高斯分布来近似；本质上来说，每当我们测量某种均值时，只 要采样的样本量足够大，观测值的分布就会呈现高斯分布。至于这种 近似什么时候是对的，什么时候是错的，可以了解下中心极限定理
>
> （Central Limit Theorem， CLT），去搜索下这个统计学的核心概\
> 念。这里举一个例子，身高（以及其他描述人的特征）是受到基因和 许多环境因素影响的，因而我们观测到的成年人的身高符合高斯分\
> 布。不过事实上，我们得到的其实是一个双峰分布，男人和女人的身 高分布重叠在了一起。总的来说，高斯分布用起来很简单，而且自然 界中随处可见，这也是为什么你了解或者听说过的许多统计方法都基 于高斯分布。学习如何构建这类模型非常重要，此外，学会如何放宽 正态分布的假设也同等重要，这一点在贝叶斯框架中利用PyMC3之\
> 类的现代计算工具很容易处理。
>
> **3.2.1**　高斯推断
>
> 下面的例子与核磁共振中的实验有关，核磁共振是一种研究分子 和生物（毕竟生物也是由分子构成的）的技术。下面这组数据，可能 来自一群人身高的测量值、回家的平均时间、从超市买回来橙子的重 量、大壁虎的伴侣个数或者任何可以用高斯分布近似的测量值。在这 个例子中，我们有48个测量值：
>
> ![](C:/Program Files/Typora/media/image983.png){width="3.818897637795276e-2in" height="0.35055555555555556in"}data = np.array(\[51.06, 55.12, 53.73, 50.24, 52.05, 56.40, 48.45, 52.34
>
> 98 ![](C:/Program Files/Typora/media/image986.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}
>
> ![](C:/Program Files/Typora/media/image988.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}, 55.65, 51.49, 51.86, 63.43, 53.00, 56.09, 51.93, 52.31, 52.33, 57.48, 57.44, 55.14, 53.93, 54.62, 56.09, 68.58, 51.36, 55.47, 50.73, 51.94, 54.95, 50.39, 52.91, 51.5, 52.68, 47.72, 49.73, 51.82, 54.99, 52.84, 53 .19, 54.52, 51.46, 53.73, 51.61, 49.81, 52.42, 54.3, 53.84, 53.16\])
>
> 下图显示了上面的数据集，看起来有点像高斯分布，除了有两个 点偏离了均值。

![](C:/Program Files/Typora/media/image992.png){width="5.643024934383202in" height="3.914990157480315in"}

> 暂且先不考虑偏离均值的那两个点，假设以上分布就是高斯分\
> 布。由于我们不知道均值和方差，需要先对这两个变量设置先验。然
>
> 后，顺理成章地得到如下模型：

![](C:/Program Files/Typora/media/image993.png){width="1.5200765529308837in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image994.png){width="1.8011865704286965in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image995.png){width="1.4680194663167103in" height="0.187419072615923in"}

> ![](C:/Program Files/Typora/media/image996.png){width="0.11452537182852143in" height="0.12494641294838145in"}其中，来自上下界分别为*l*和*h*的均匀分布，来自标准差为 的 半正态分布。半正态分布和普通正态分布很像，不过只包含正数，看 起来就好像将普通的正态分布沿着均值对折了。最后，在我们的模型
>
> 99
>
> ![](C:/Program Files/Typora/media/image996.png){width="0.11452537182852143in" height="0.12494641294838145in"}中，数据*y*来自参数分别为和的正态分布，我们可以用Kruschke风 格的图将其画出来：

![](C:/Program Files/Typora/media/image1002.png){width="2.49875656167979in" height="2.7488221784776905in"}

> ![](C:/Program Files/Typora/media/image996.png){width="0.11452537182852143in" height="0.12494641294838145in"}如果不知道和的值，可以通过先验来表示该未知信息。例如， 可以将均匀分布的上下界分别设为（*l* = 40, *h* = 75），这个范围要比 数据本身的范围稍大一些。或者，可以根据我们的先验知识设得更广 一些，比如我们知道这类观测值不可能小于0或者大于100，因而可以 将均匀先验的参数设为（*l* = 0, *h* = 100）。对于半正态分布而言，我 们可以把 的值设为10，该值相对于数据的分布而言算是较大的。 利用PyMC3，我们可以将模型表示如下：
>
> with pm.Model() as model_g:
>
> mu = pm.Uniform(\'mu\', 40, 75)
>
> sigma = pm.HalfNormal(\'sigma\', sd=10)
>
> y = pm.Normal(\'y\', mu=mu, sd=sigma, observed=data)
>
> trace_g = pm.sample(1100)
>
> traceplot看起来很正常，我们可以接着继续分析，当然你也可 以抱着怀疑的心态跑一遍前面第2章提到的诊断测试。可以看\
> 到traceplot返回的图有两行，每行表示一个参数。这些都是边缘分
>
> 布，要记住后验是二维的。

![](C:/Program Files/Typora/media/image1010.png){width="3.818897637795276e-2in" height="6.94258530183727e-2in"}

> ![](C:/Program Files/Typora/media/image1013.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}100
>
> ![](C:/Program Files/Typora/media/image1015.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}chain_g = trace_g\[100:\] pm.traceplot(chain_g)

![](C:/Program Files/Typora/media/image1019.png){width="5.643024934383202in" height="1.728426290463692in"}

> 这里将参数的总结打印出来，后面会用到。
>
> pm.df_summary(chain_g)

+---------+--------+------+----------+---------+----------+
|         | > mean | sd   | mc_error | hpd_2.5 | hpd_97.5 |
+=========+========+======+==========+=========+==========+
| > mu    | 53.51  | 0.53 | 0.02     | 52.56   | 54.54    |
+---------+--------+------+----------+---------+----------+
| > sigma | 3.55   | 0.38 | 0.01     | 2.86    | 4.32     |
+---------+--------+------+----------+---------+----------+

> 现在我们得到了后验，可以将其用于模拟数据，然后就可以检查 模拟数据与观测数据是否一致了。在第1章中，我们将这种检查称作 后验预测检查，因为我们先通过后验做出预测，然后用这些预测来检 查模型。利用PyMC3中的sample_ppc()函数可以很容易地从后验中 得到预测值。下面的代码中我们从后验中生成了100组预测值，每组 预测值的大小与观测数据的维度一致。注意我们需要将迹和模型传给 sample_ppc()，其他参数是可选的。
>
> ![](C:/Program Files/Typora/media/image1024.png){width="3.818897637795276e-2in" height="1.0273490813648294in"}y_pred = pm.sample_ppc(chain_g, 100, model_g, size=len(data)) sns.kdeplot(data, c=\'b\')
>
> for i in y_pred\[\'y\'\]:
>
> sns.kdeplot(i, c=\'r\', alpha=0.1)
>
> plt.xlim(35, 75)
>
> ![](C:/Program Files/Typora/media/image1027.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}101
>
> ![](C:/Program Files/Typora/media/image1029.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}plt.title(\'Gaussian model\', fontsize=16) plt.xlabel(\'\$x\$\', fontsize=16)

![](C:/Program Files/Typora/media/image1033.png){width="5.643024934383202in" height="4.102409230096238in"}

> 上图中，蓝色的线是观测数据的KDE，半透明的红色的线是100 组从后验中采样出来的预测值的KDE。可以看出，采样值的均值要稍
>
> 稍偏右一些，而且采样值的变化相比原始的观测值也更大一些。接下 来的内容中，我们会逐步优化模型，最终得到一个与观测数据更吻合 的后验分布。
>
> **3.2.2**　鲁棒推断
>
> 对于前面的模型，你可能有点疑惑，我们假设数据的分布是高斯 分布，但是在数据的末端却有两个数据点，这看起来不太像高斯分 布。高斯分布的两端随着距离均值越远，值会迅速下降。对于我们这 里的数据而言，模型中的高斯分布看到右端的那两个点时会感到很惊 讶，于是会向右侧靠近，从而使得其标准差也上升了。可以看出，这 两个点对于高斯分布的参数有着举足轻重的作用。那么可以采取什么
>
> 102
>
> 措施改进呢？一个做法是将这两个点看做是异常点并将其从观测值中 剔除，因为这两个值有可能是因为仪器异常或者人为疏忽导致的。有 时候我们也许能够直接矫正这些点，因为有可能只是我们处理数据时 的代码出了些问题，但更多时候，我们希望能够根据某种异常值的处 理规则自动消除这些异常点，其中的两个规则如下：
>
> 所有超出1.5倍4分位范围的数据都是异常值； 所有超出观测数据两倍标准差的都是异常值。
>
> **t** 分布
>
> 除了利用以上规则改变原始数据之外，我们还可以修改模型。通 常，按照贝叶斯的思想，我们更倾向于通过使用不同的先验或者似然 将假设编码到模型中，而不是直接使用一些先验准则（例如前面这些 剔除异常值的准则）。
>
> 一个用来解决异常值的非常有用的方法是：将高斯分布替换成t\
> 分布。t分布有3个参数：均值、尺度（与标准差类似）和自由度（通
>
> ![](C:/Program Files/Typora/media/image1037.png){width="0.4372823709536308in" height="0.15618219597550306in"}常用*v*表示，取值范围为\[0,¥\]。根据Kruschke的命名方式，我们将*v*称 为正态参数，这是因为该参数决定了t分布与正态分布的相似程度。\
> 对于*v*=1的情况，t分布的尾部要比高斯分布更重，在不同的领域也称 柯西分布或者洛伦兹分布，这里尾部更重的意思是：相比高斯分布， 我们更有可能观测到偏离均值的点，换句话说，该分布并不像高斯分 布那样聚集在均值附近。举例来说，柯西分布95%的点都分布在\
> −12.7～12.7，而对于（标准差为1的）高斯分布，对应的区间为−1.96 ～1.96。此外，当正态参数*v*趋近于无穷大时，我们就会得到高斯分\
> 布（你不可能比正态分布还正态对吧？）。t分布一个有意思的特性\
> 是：当时，该分布没有准确定义的均值。当然，实际中从t分布\
> 得到的采样不过是一些数字，因而总是可以算出经验性的均值来，不
>
> 103
>
> 过理论上还没有一个准确定义的均值。直观上可以这么理解：t分布\
> 的尾部很重，因而我们得到的采样值很可能是实轴上的任意一点，所 以只要不停地采样，我们永远也无法得到一个固定值。你可以尝试多 次运行下面的代码（或者将参数df换成一个更大的值，比如100）：
>
> np.mean(stats.t(loc=0, scale=1, df=1).rvs(100))
>
> ![](C:/Program Files/Typora/media/image1043.png){width="0.3123436132983377in" height="0.12494641294838145in"}类似地，只有当时，分布的方差才有明确定义，因此，需要 注意t分布的尺度与标准差不是同一个概念。对于的分布，方差 并没有明确定义，因而也没有明确定义的标准差。当v趋向于无穷大 时，尺度趋近于标准差。
>
> x_values = np.linspace(-10, 10, 200)
>
> for df in \[1, 2, 5, 30\]:
>
> distri = stats.t(df)
>
> x_pdf = distri.pdf(x_values)
>
> plt.plot(x_values, x_pdf, label=r\'\$\\nu\$ = {}\'.format(df))
>
> x_pdf = stats.norm.pdf(x_values)\
> plt.plot(x_values, x_pdf, label=r\'\$\\nu = \\infty\$\') plt.xlabel(\'x\')
>
> plt.ylabel(\'p(x)\', rotation=0)
>
> plt.legend(loc=0, fontsize=14)
>
> plt.xlim(-7, 7)
>
> 104

![](C:/Program Files/Typora/media/image1050.png){width="5.01833552055993in" height="3.3631430446194224in"}

> 利用t分布将模型表示成如下形式：

![](C:/Program Files/Typora/media/image1051.png){width="1.5200765529308837in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image1052.png){width="1.8011865704286965in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image1053.png){width="1.62419072615923in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image1054.png){width="1.62419072615923in" height="0.187419072615923in"}

> 上面这个模型与前面的高斯模型的主要区别是：现在似然是t分\
> 布，由于t分布多了一个新的参数，我们需要为其增加一个先验。这 里用了一个均值为30的指数分布。上图可以看出，t分布看起来很像 高斯分布（尽管其实并不一样）。*v*值较小的分布更分散，因而，均 值为30的指数分布是一个很弱的先验，认为正态参数*v*在30附近，不 过也可以很容易地将其调大或调小。从图像上看，我们的模型表示如
>
> 下：
>
> 105

![](C:/Program Files/Typora/media/image1056.png){width="3.768956692913386in" height="2.957066929133858in"}

> 同样，PyMC3让我们只需要几行代码便可修改模型。唯一需要 注意的是，PyMC3中指数分布的参数用的是分布均值的倒数。
>
> with pm.Model() as model_t:
>
> mu = pm.Uniform(\'mu\', 40, 75)
>
> sigma = pm.HalfNormal(\'sigma\', sd=10)
>
> nu = pm.Exponential(\'nu\', 1/30)
>
> y = pm.StudentT(\'y\', mu=mu, sd=sigma, nu=nu, observed=data) trace_t = pm.sample(1100)
>
> chain_t = trace_t\[100:\]
>
> pm.trace_plot(chain_t)

![](C:/Program Files/Typora/media/image1061.png){width="5.643024934383202in" height="3.248607830271216in"}

> 106
>
> 现在用summary函数将迹的总结打印出来并与前面的结果对比。
>
> 继续深入阅读之前，花点时间对比分析下两组不同的结果，你能发现 什么有趣的地方吗？
>
> pm.df_summary(chain_t)

+---------+--------+------+----------+---------+----------+
|         | > mean | sd   | mc_error | hpd_2.5 | hpd_97.5 |
+=========+========+======+==========+=========+==========+
| > mu    | 52.99  | 0.38 | 0.01     | 52.28   | 53.81    |
+---------+--------+------+----------+---------+----------+
| > sigma | 2.15   | 0.39 | 0.02     | 1.42    | 2.97     |
+---------+--------+------+----------+---------+----------+
| > nu    | 4.13   | 2.78 | 0.19     | 1.19    | 8.54     |
+---------+--------+------+----------+---------+----------+

> 可以看到，两个模型对*µ*的估计比较接近，只相差0.5左右，而*σ*\
> 的估计则从3.5变成了2.1，这正是因为t分布对于偏离均值的点所赋予
>
> 的权重较小所致。此外还可以看到，*µ*的值接近4，也就是说，该分布 并不太像高斯分布，而是更接近重尾分布。
>
> 接下来我们对t分布模型做后验检查，并将其与高斯分布对比：
>
> y_pred = pm.sample_ppc(chain_t, 100, model_t, size=len(data)) sns.kdeplot(data, c=\'b\')
>
> for i in y_pred\[\'y\'\]:
>
> sns.kdeplot(i, c=\'r\', alpha=0.1)
>
> plt.xlim(35, 75)
>
> plt.title(\"Student\'s t model\", fontsize=16)
>
> plt.xlabel(\'\$x\$\', fontsize=16)
>
> 107

![](C:/Program Files/Typora/media/image1072.png){width="5.01833552055993in" height="3.706745406824147in"}

> 可以看到，使用t分布之后，从分布的峰值和形状来看，模型的\
> 预测值与观测数据更吻合了（留意预测值远离观测值中心的部分）。
>
> 这是因为t分布希望看到在偏离数据中心的两个方向上都有数据。在\
> 我们的模型中，t分布的估计值更鲁棒，因为异常点降低了正态参数*v* 的值，从而均值和尺度更多地是从观测数据的中心估计出来的，而不 是像前面高斯分布的例子中那样，均值和标准差都偏向了异常值。再 强调一次，这里的尺度并不是标准差。不过，尺度这个参数确实与数 据的分散程度有关，尺度越小，数据分布得越集中。此外，对应正态 参数*v*大于2的情况，尺度的值倾向于接近去掉异常值之后的标准差。 因此，粗略地讲，对于不是特别小的*v*值，我们可以将t分布的尺度大 致看做是去掉异常值之后的数据的标准差（理论上这么说可能不太\
> 对）。
>
> 108
>
> **3.3**　组间比较
>
> 统计分析中一个常见的任务是对不同的组进行比较，例如我们可 能想知道病人对某种药的反应如何、引入某种交通法规后车祸数量是 否会降低、学生对不同教学方式的表现如何等。有时候，这类问题统 一归到了假设检验的框架下，其目的是得到统计学意义上的显著性。 仅仅依赖于统计显著性可能会带来很多问题：一方面，统计显著性并 非实际显著性；另一方面，即使是很小的作用，只要收集尽可能多的 数据，都会被看做具有显著性。而且，统计显著性的核心思想往往需 要计算*p*值。已经有很多文章和研究记录表明，通常，*p*值会被错误地 使用和解释，即使那些每天跟统计打交道的科学家也会犯错。不过在 贝叶斯框架下，我们不需要计算*p*值，所以这里暂且将其放一边。毕
>
> 竟，在实践中我们最想知道的是效应值，也就是量化估计出某种现象 的强弱。
>
> 在比较不同组的数据时，人们往往会将其分为一个实验组和一个 对照组（也可能超过一个实验组和对照组），例如当我们测试一个新 药时，由于安慰剂效应或者某些其他原因，我们希望将使用新药的组 （实验组）和不使用新药的组（对照组）进行对比。在这个例子中， 我们想知道对于治疗某种疾病，使用药物对比不用药物（或者是使用 安慰剂）的作用有多大。另一个有趣的问题是：与治疗某种疾病最常 用的（已经被审批的）药相比，我们的药效果如何？此时，对照组不 再是使用安慰剂的组，而是使用其他药物的组。从统计学上讲，使用 假的对照组是一种不错的撒谎方式，例如，假设某家邪恶的乳制品公 司想要卖某种糖过量的酸奶给小朋友，同时告诉他们的家长乳酸有利 于免疫系统。一种支撑该说法的做法是：使用牛奶或者水作为对照
>
> 组，而不是用更便宜、糖更少、市场更小的酸奶。这么做听起来很
>
> 109
>
> 笨，不过下次再听到有人说某种东西更坚固、更好、更快、更强时， 记得问一下他对比的基准线是什么。
>
> **3.3.1**　**"**小费**"**数据集
>
> 接下来，我们将使用seaborn中的tips数据集来讨论前面提到的
>
> 那些思想。我们希望知道星期几对于餐馆小费数量的影响。这个例子 中，实际上并没有明确的实验组和对照组之分，这只是观察性的实\
> 验，并非像前面药物测试的例子一样。如果愿意的话，我们可以任选 一天（例如星期四）作为实验组，或者对照组，尽管我们并没有控制 某个具体的东西。需要注意的一点是：对于观察性实验，我们没法得 出某种因果关系，能得到的只是相关性。事实上，如何从数据中得出 因果关系是一个非常热门的研究问题，我们会在第4章重新讨论这个\
> 问题。现在，我们首先用一行代码将数据导入成Pandas中的数据结\
> 构，如果你对Pandas不太熟悉，这里需要说明下，tail函数返回数据 中的最后一部分（当然你也可以用head函数返回前面一部分数
>
> 据）。
>
> tips = sns.load_dataset(\'tips\') tips.tail()

+-------+--------------+------+--------+--------+-----+--------+------+
|       | > total_bill | tip  | sex    | smoker | day | time   | size |
+=======+==============+======+========+========+=====+========+======+
| > 239 | 29.03        | 5.92 | Male   | No     | Sat | Dinner | 3    |
+-------+--------------+------+--------+--------+-----+--------+------+
| > 240 | 27.18        | 2.00 | Female | Yes    | Sat | Dinner | 2    |
+-------+--------------+------+--------+--------+-----+--------+------+
| > 241 | 22.67        | 2.00 | Male   | Yes    | Sat | Dinner | 2    |
+-------+--------------+------+--------+--------+-----+--------+------+

![](C:/Program Files/Typora/media/image1080.png){width="3.818897637795276e-2in" height="0.3713801399825022in"}

> ![](C:/Program Files/Typora/media/image1096.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}110
>
> ![](C:/Program Files/Typora/media/image1105.png){width="2.7777777777777776e-2in" height="2.7777777777777776e-2in"}242 17.82 1.75Male No Sat Dinner 2

+-------+-------+------+--------+----+------+--------+---+
| > 243 | 18.78 | 3.00 | Female | No | Thur | Dinner | 2 |
+-------+-------+------+--------+----+------+--------+---+

> 对于这个数据集，我们只关心其中的day和tip列，利 用seaborn中的violinplot函数可以将其画出来：
>
> sns.violinplot(x=\'day\', y=\'tip\', data=tips)
>
> 把问题简化下，我们创建两个变量：变量y表示tips；变量idx 表示分类变量的编码。也就是说，我们用数字0、1、2、3表示星期 四、星期五、星期六和星期天。
>
> y = tips\[\'tip\'\].values
>
> idx = pd.Categorical(tips\[\'day\'\]).codes

![](C:/Program Files/Typora/media/image1137.png){width="5.01833552055993in" height="3.6130358705161854in"}

> ![](C:/Program Files/Typora/media/image1138.png){width="0.11452537182852143in" height="0.12494641294838145in"}这个问题中的模型与之前的模型几乎一样，唯一的区别是和现\
> 在是一组随机向量而不再是一个标量。换句话说，每次从先验中采样
>
> 111
>
> ![](C:/Program Files/Typora/media/image1138.png){width="0.11452537182852143in" height="0.12494641294838145in"}的时候，我们会得到4个和4个。PyMC3的语法能够很好地适应这\
> 个场景，我们可以直接用向量的方式表示模型，而不用使用for循
>
> ![](C:/Program Files/Typora/media/image1138.png){width="0.11452537182852143in" height="0.12494641294838145in"}环，代码的变化相比前面的模型很小。对应先验，我们需要传一个维 度变量shape，对于似然，我们需要对和正确地进行编码，这也是 为什么创建了idx变量。
>
> with pm.Model() as comparing_groups:　　　　
>
> means = pm.Normal(\'means\', mu=0, sd=10, shape=len(set(x))) sds = pm.HalfNormal(\'sds\', sd=10, shape=len(set(x)))
>
> y = pm.Normal(\'y\', mu=means\[idx\], sd=sds\[idx\], observed=y)
>
> trace_cg = pm.sample(5000) chain_cg = trace_cg\[100::\]\
> pm.traceplot(chain_cg)

![](C:/Program Files/Typora/media/image1149.png){width="5.643024934383202in" height="1.728426290463692in"}

> 这里照常使用df_summary函数来描述估计点，同样你还可以进
>
> 行诊断测试。切记贝叶斯分析返回的是（在给定数据和模型条件下） 参数的完整分布，因而我们可以对后验进行进一步处理，并从中提出 一些合理的问题。比如，我们可能想知道组与组之间均值差别的分布 情况，下面，我们就来分析看看。
>
> 这里我们使用PyMC3中的plot_posterior函数画出后验分布， 其中选取参考值（ref_val）为0，因为我们希望将后验与0进行比
>
> 较。下面的代码将两个变量的差画了出来，没有进行重复比较。注意 这里并没有一对一的对比矩阵，只是画出了上三角部分。代码和图中
>
> 112
>
> 最陌生的部分是**Cohen's d**和概率优势，后面会详细解释，其实它们 都是对效应值的不同表示方式而已。
>
> dist = dist = stats.norm()
>
> \_, ax = plt.subplots(3, 2, figsize=(16, 12))
>
> comparisons = \[(i,j) for i in range(4) for j in range(i+1, 4)\] pos = \[(k,l) for k in range(3) for l in (0, 1)\]
>
> for (i, j), (k,l) in zip(comparisons, pos):
>
> means_diff = chain_cg\[\'means\'\]\[:,i\]-chain_cg\[\'means\'\]\[:,j\]\
> d_cohen = (means_diff / np.sqrt((chain_cg\[\'sds\'\]\[:,i\]\*\*2 + chain_cg \[\'sds\'\]\[:,j\]\*\*2) / 2)).mean()
>
> ps = dist.cdf(d_cohen/(2\*\*0.5))
>
> 
>
> pm.plot_posterior(means_diff, ref_val=0, ax=ax\[k, l\], color=\'skyblu e\')
>
> ax\[k, l\].plot(0, label=\"Cohen\'s d = {:.2f}\\nProb sup = {:.2f}\".form at(d_cohen, ps) ,alpha=0)
>
> ax\[k, l\].set_xlabel(\'\$\\mu\_{}-\\mu\_{}\$\'.format(i, j), fontsize=18)\
> ax\[k,l \].legend(loc=0, fontsize=14)
>
> 前面的例子中，一种解释结果的方式是将参考值与HPD区间进行 比较。只有一种情况下95%HPD没有包含0（我们的参考值），即星 期四与星期天的对比。对于所有其他情况，我们没法得出两者的区别 为0的结论（根据HPD区间与参考值的重叠性准则）。但是即便如 此，平均下来0.5美元的小费差别是否足够大了呢？这个差别是否大 到让人们牺牲星期日陪家人或者朋友的时间去工作呢？是否大到就应 该这4天都给相同的小费而且男服务员和女服务员的小费一模一样 呢？诸如此类的问题很难用统计学来回答，只能从统计学中找到些启 发。 描述效应值的方式有好几种，我们接下来将学习其中的两个： Cohen's d 和概率优势。
>
> 113

![](C:/Program Files/Typora/media/image1156.png){width="5.643024934383202in" height="4.164882983377078in"}

> **3.3.2**　**Cohen's d**
>
> Cohen's d 是一种用来描述效应值的常见方式：

![](C:/Program Files/Typora/media/image1157.png){width="0.6351006124234471in" height="0.551846019247594in"}

> 也就是说，效应值是在考虑不同组的标准差的情况下，均值的差 异。在前面的代码中，我们根据估计值的均值和标准差算出了\
> Cohen's d的值，因而我们可以添加对Cohen's d的描述而不仅仅是均 值。
>
> 比较各组数据的时候，很重要的一点是要考虑组内的波动性（比 如标准差）。一组数据相比另一组数据变化了*x*个单位，可能是每个 点都整体变化了*x*个单位，也可能是其中一半的数据没有变化而另外 一半数据变化了2*x*，还可能是其他组合。根据Cohen's d得到的效应值 可以看做是Z-score，因而Cohen's d为0.5可以解释为一组数据相比另
>
> 114
>
> 一组数据点的差别是0.5倍的标准差。使用Cohen's d的一个问题是不\
> 太好解释，我们需要根据具体的问题来说明该值是太大、太小或者是 适中。当然，我们可以从实践中得到些经验，不过更多地还是依赖于 具体问题。假如说我们对同一类问题做了一些分析，然后得到\
> Cohen's d的值约为1，这时如果得到另外一个Cohen's d的值（比如说 2），那么我们很可能有了重要发现（也可能是某个地方弄错了）。\
> 在[http://rpsychologist.com/d3/cohend这个网页中，你可以探索一下不](http://rpsychologist.com/d3/cohend这个网页中，你可以探索一下不同Cohen)\
> [同Cohen](http://rpsychologist.com/d3/cohend这个网页中，你可以探索一下不同Cohen)'s d的值都长什么样，此外，在这个网页中还可以看到一些描 述效应值的其他方式，其中某些方式可能更直观（比如概率优势）。
>
> **3.3.3**　概率优势
>
> 概率优势是表示效应值的另一种方式，描述的是从一组数据中取 出的一个点大于从另外一组中取出的点的概率。假设两个组中数据的 分布都是正态分布，我们可以通过以下表达式从Cohen's d中得到概率 优势：

![](C:/Program Files/Typora/media/image1160.png){width="1.1244400699912511in" height="0.46854877515310583in"}

> ![](C:/Program Files/Typora/media/image1161.png){width="0.11452537182852143in" height="0.16659448818897638in"}其中，是累计正态分布，是Cohen's d。我们可以算出概率优势 的点估计（通常列出的是该值），也可以计算出概率优势的分布。注 意到，我们可以用该式根据Cohen's d来计算概率优势，或者，我们可 以直接将其从后验中计算出来（查看练习部分）。这正是使用
>
> MCMC方法的一个很大好处。一旦我们从后验中得到了采样，我们\
> 就可以算出某些值（比如概率优势等）而不必依赖于具体的分布假\
> 设。
>
> 115
>
> **3.4**　分层模型
>
> 假设我们想要分析一个城市的水质，然后将城市分成了多个相邻 （或者水文学上）的区域。我们可以用如下两种方法进行分析：
>
> 分别对每个区域单独进行估计；\
> 将所有数据都混合在一起，把整个城市看做一个整体进行估计。
>
> 两种方式都是合理的，具体使用哪种取决于我们想知道什么。如 果我们想了解具体的细节，那么可以采用第1种方式，因为假如对数 据进一步做了一些平均处理，那么一些细节就不太容易看出来了。采 用第2种方式则可以将数据都聚在一起，得到一个更大的样本集，从 而得出更准确的估计。两种方式都有其合理性，不过我们还可以找到 些中间方案。我们可以在对相邻区域的水质进行评估的同时对整个城 市的水质进行评估，这类模型称为层次化模型或者分层模型，这么称 呼的原因是我们对数据采用了一种层次化（或者是分层）的建模方 式。
>
> 那么如何构建分层模型呢？简单说，就是在先验之上使用一个共 享先验。也就是说，我们不再固定先验参数，而是直接从数据中将其 估计出来。这类更高层的先验通常称为超先验（hyper-prior），它们
>
> 的参数称为超参数，这里"超"在希腊语中是"在某某之上"的意思。当 然，还可以在超先验之上再增加先验，做到尽可能分层。问题是这么 做会使得模型变得相当复杂而难以理解，而且除非问题确实需要更复 杂的结构，增加分层对于做推断并没有更大帮助，相反，我们会陷入 超参和超先验的混乱中而无法对其做出任何有意义的解释，从而降低 模型的可解释性。毕竟，我们建模的首要目的是理解数据。
>
> 116
>
> 为了更好地解释分层模型中的主要概念，我们以本节开头提到的 水质模型作为例子，使用一些构造的数据来讲解。假设我们从同一个 城市的3个不同水域得到了含铅量的采样值：其中高于世界卫生组织
>
> （World Health Organization,WHO）标准的值标记为0；低于标准的值 标记为1。这个例子只是用来教学，实际中，我们会使用铅含量的连\
> 续值，并且可能会分成更多组。不过，对我们来说，这个例子足够用 来揭示多层模型的细节了。
>
> 我们通过以下代码合成数据：
>
> N_samples =　\[30, 30, 30\]\
> G_samples =　\[18, 18, 18\]
>
> group_idx = np.repeat(np.arange(len(N_samples)), N_samples)
>
> data = \[\]　
>
> for i in range(0, len(N_samples)):
>
> data.extend(np.repeat(\[1, 0\], \[G_samples\[i\], N_samples\[i\]-G_samples \[i\]\]))
>
> 这里进行了一个仿真实验，分别对3个组进行了一定次数的采\
> 样。我们将每组的采样总数放在列表N_samples中，用列\
> 表G_samples记录每组中合格的采样值。剩下的代码用于生成0、1数
>
> 据。
>
> 模型本质上还是抛硬币问题中的那个模型，不同之处在于需要指 定影响beta先验的超先验：

![](C:/Program Files/Typora/media/image1172.png){width="1.8115977690288714in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image1173.png){width="1.8115977690288714in" height="0.20824365704286965in"}

![](C:/Program Files/Typora/media/image1174.png){width="1.2389665354330708in" height="0.187419072615923in"}

![](C:/Program Files/Typora/media/image1175.png){width="1.0515594925634295in" height="0.187419072615923in"}

> 使用Kruschke图，可以清楚地看到新的模型相比原来的模型多了
>
> 117
>
> 一层。

![](C:/Program Files/Typora/media/image1177.png){width="3.768956692913386in" height="3.9462259405074365in"}

> with pm.Model() as model_h:
>
> alpha = pm.HalfCauchy(\'alpha\', beta=10) beta = pm.HalfCauchy(\'beta\', beta=10)
>
> theta = pm.Beta(\'theta\', alpha, beta, shape=len(N_samples))
>
> y = pm.Bernoulli(\'y\', p=theta\[group_idx\], observed=data)
>
> trace_j = pm.sample(2000) chain_h = trace_h\[200:\]\
> pm.traceplot(chain_h)
>
> 118

![](C:/Program Files/Typora/media/image1183.png){width="5.643024934383202in" height="2.7279975940507435in"}

> **3.4.1**　收缩
>
> 现在和我一起做个简单的实验。我需要你输出模型总结并且将结 果保存下来待会用，然后再分别重新运行模型两次，其中一次将所有 的G_samples都设为3，另外一次将G_samples设为\[18,3,3\]，并且每
>
> ![](C:/Program Files/Typora/media/image1184.png){width="9.370297462817148e-2in" height="0.12494641294838145in"}次都记录下模型的总结。继续阅读之前，先想想这个实验的结果会是 什么。重点关注每次实验中的均值。根据前两次模型的运行结果，\
> 你能猜出第3种情况下的结果吗？
>
> 如果将结果汇总在表格中，会得到类似如下的值（注意由于 NUTS采样方法的随机性，结果可能会有小幅波动）：

+-------------+----------------+
| > G_samples | Theta(mean)    |
+=============+================+
| > 18,18,18  | 0.6,0.6,0.6    |
+-------------+----------------+
| > 3,3,3     | 0.1,0.1,0.1    |
+-------------+----------------+
| > 18,3,3    | 0.53,0.14,0.14 |
+-------------+----------------+

> 119
>
> ![](C:/Program Files/Typora/media/image1184.png){width="9.370297462817148e-2in" height="0.12494641294838145in"}表中第一行，可以看到对于30个样本中有18个正样本的情况，\
> 估计值的均值为0.6；注意现在***θ*** 是一个向量，因为现在我们有3个 组，每个组都有一个均值。第2行中，30个样本中有3个是正样本，得 到的的均值为0.1。最后一行中的结果有点意外，的均值并非是前 面两组中均值的组合（比如0.6,0.1,0.1），而是0.53,0.14,0.14。为什么 呢？是模型收敛的问题还是模型选型出了问题？都不是，是我们的估 计结果趋向了整体的均值。事实上，这正是我们模型预期的结果，在 设置了超先验后，我们直接从数据中估计（beta）先验，每个组的估 计都受到了其他组的估计值的影响，同时也影响着其他组的估计值。 换句话说，所有组都通过超先验共享了部分信息，从而看到一种称为 收缩的现象，其效果相当于对数据做了部分"池化"（pooling），我们 既不是在对数据分组建模，也不是将数据看做一个大组在建模，而是 介于二者之间，其结果之一就是收缩效应。
>
> 收缩有利于更稳定的推断。这一点和前面讨论过的t分布与异常\
> 点的关系很像。使用重尾分布之后的模型对于偏离均值的异常点表现
>
> 得更鲁棒（更不受其影响）。引入超先验后，我们在更高的层次上进 行推断，从而得到一个更"保守"的模型（这可能是我第一次将"保\
> 守"这个词当做褒义词），更少地受到每个组中极限值的影响。举例\
> 来说，假设我们在某个相邻区域得到了一组不同数量的采样值；采样 数量越小就越容易得到错误的结果。极限情况下，假设在这片区域只 有一个采样值，你可能恰好是从这片区域的某个铅管中得到的采样\
> 值，或者，有可能恰好是从PVC管道中得到的采样值，从而可能导致 你对这片区域的水质高估或者低估。在多层模型中，估计出错的情况 可以通过其他组提供的信息进行改善。当然，更大的采样值同样能达 到类似的效果，不过大多数情况下这并不是个候选方案。
>
> 显然，收缩的程度取决于数据，数量更大的组会对其他数量较小
>
> 120
>
> 的组造成更大的影响。如果大多数组都比较相似，而其中某组不太一 样，相似的组之间会共享这种相似性，从而强化共同的估计值，并拉 近表现不太一样的那一组的估计值，前面的例子中也已经体现了这一 点。此外，超先验也对收缩的程度有影响。如果我们对所有组的整体 分布有一些可以信赖的先验信息，那么可以将其加入到模型中并将收 缩程度调整到一个合理的值。我们完全可以只用两个组来构建层级化 模型，不过通常我们更倾向于使用多个组。直观上的原因是，收缩其 实是将每个组看成了一个数据点，然后我们在组这一层估计标准差。 通常我们不会太相信点数较少的估计值，除非对估计值有很强的先
>
> 验，这一点对层次化模型也适用。
>
> 你可能对估计到的先验分布比较感兴趣，以下是将其表示出来的 一种方式：
>
> x = np.linspace(0, 1, 100)
>
> for i in np.random.randint(0, len(chain_h), size=100):
>
> pdf = stats.beta(chain_h\[\'alpha\'\]\[i\], chain_h\[\'beta\'\]\[i\]).pdf(x)\
> plt.plot(x, pdf,　\'g\', alpha=0.05)
>
> dist = stats.beta(chain_h\[\'alpha\'\].mean(), chain_h\[\'beta\'\].mean())
>
> pdf = dist.pdf(x)
>
> mode = x\[np.argmax(pdf)\]
>
> mean = dist.moment(1)
>
> plt.plot(x, pdf, label=\'mode = {:.2f}\\nmean = {:.2f}\'.format(mode, mean ))
>
> plt.legend(fontsize=14)\
> plt.xlabel(r\'\$\\theta\_{prior}\$\', fontsize=16)
>
> 121

![](C:/Program Files/Typora/media/image1195.png){width="5.643024934383202in" height="3.8316918197725283in"}

> 套用Python之禅的说法，我们可以说，分层模型是一种绝妙的理 念，我们应当多加利用！^\[1\]^在接下来的章节中，我们会继续构建分层 模型并学习如何构建更好的模型。在第6章模型比较部分，我们还会 详细讨论构建模型过程中的过拟合和欠拟合问题。
>
> 122
>
> **3.5**　总结
>
> 这章我们使用多个参数扩展了构建模型的能力，在PyMC3的帮\
> 助下这非常容易实现。例如，从后验中计算边缘分布只需要从迹中选
>
> 出相应的部分即可。此外，我们用几个例子学习了如何从后验分布中 提取我们感兴趣的量，比如合成数据，或者是提取能够更好地解释数 据的量。起初我们使用的是高斯模型，这主要是因为高斯模型是数据 分析的支柱之一，不过在包含异常值的数据上应用高斯分布时遇到了 一些问题，然后我们学习了使用t分布对数据的正态性假设做一些放
>
> 松，从而了解了鲁棒模型的概念以及如何改进一个模型使其适用于具 体的问题。对不同数据组进行比较是数据分析中的一个常见任务，对 此我们使用了高斯模型，并且讨论了一些量化指标来衡量不同组之间 数据的区别。最后，我们学到的核心概念之一是：分层模型，或者说 是如何结构化地解决问题从而更好地做推断，并且通过部分池化不同 组的信息收缩估计值。
>
> 下一章我们将学习线性模型以及如何利用线性模型解释数据。
>
> 123
>
> **3.6**　深入阅读
>
> 《Doing Bayesian Data Analysis, Second Edition》中的第9章\
> 《Statistical Rethinking》中的第12章
>
> 《Bayesian Data Analysis, Third Edition》中的第5章\
> 阅读完本书第4章后，记得读一下PyMC3的文档中有关GLM的多 层模型以及Rugby的例子
>
> 124
>
> **3.7**　练习
>
> （1）对于本章的第一个模型，将高斯分布的先验均值修改为一 个经验性均值，用几个对应的标准差多跑几遍，观察推断过程对这些
>
> 变化的鲁棒性/敏感性如何。你觉得用一个没有限制上下界的高斯分\
> 布对有上下界的数据建模的效果怎样？记住我们说过数据不可能大于 100或者小于0。
>
> （2）利用第一个例子中的数据，分别在包含和不包含异常值情 况下，计算出经验均值和标准差。将结果与使用高斯分布和t分布的 贝叶斯估计进行比较，增加更多异常值并重复该过程。
>
> （3）修改小费例子中的模型，使其对于异常点更鲁棒。分别尝 试对所有组使用一个共享的*v*和单独为每个组设置一个*v*，最后对这3 个模型进行后验预测检查。
>
> （4）直接从后验中计算出概率优势（先不要计算Cohen's d），\
> 你可以用sample_ppc()函数从每个组中获取一个采样值。对比这样
>
> 做与基于正态假设的计算是否不同？并对结果做出解释。
>
> ![](C:/Program Files/Typora/media/image1206.png){width="1.5408989501312336in" height="0.187419072615923in"}（5）重复水质对比的例子，不过不用多层模型，而是使用一个 均匀分布（比如 ）。比较两种模型的结果。
>
> （6）在小费的例子中，对一个星期中的不同天使用部分池化操 作，构建一个多层模型，将结果与不使用多层模型的结果进行对比。
>
> （7）重复本章中的所有例子，用findMAP()函数的返回值来初\
> 始化采样。看是否能得到相同的推断结果。同时看一下find_MAP()
>
> 函数对退化过程的数量以及推断的速度有什么影响。
>
> 125
>
> （8）对所有模型进行诊断测试并采取相应措施，比如，如果有 必要，增加采样次数。
>
> （9）对本章中的至少一个模型使用你自己的数据并运行。牢记 第1章中提到的构建模型的3个步骤。
>
> \[1\]　Python之禅的最后一句话是："命名空间是一种绝妙的理念，我 们应当多加利用！"。------译者注
>
> 126