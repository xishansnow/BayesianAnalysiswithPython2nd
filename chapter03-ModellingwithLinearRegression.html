
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>第 3 章 线性回归模型 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第 4 章 广义线性回归模型" href="chapter04-GeneralizedLinearRegression.html" />
    <link rel="prev" title="第 2 章 概率编程" href="chapter02-ProgrammingProbabilistically.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  书籍正文
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   第 3 章 线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较与模型平均
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter08-InterefenceEngine.html">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  文献阅读
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Append-01-MCMC_Tutorial.html">
   附录 A： MCMC 推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-02-VariationalInference_Tutorial.html">
   附录 B： 变分法推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-03-GaussianProcessTutorial_01.html">
   附录 C： 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-04-BayesianNN_Tutorial.html">
   附录 D：贝叶斯神经网络
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-05-BayesianDeepLearning_Tutorial.html">
   附录 E：贝叶斯深度学习
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-06-BayesianDeepLearningPymc3.html">
   附录 F：贝叶斯深度学习编程初步
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-07-ModelAveraging.html">
   附录 G：模型平均
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-08-ModelEnsembling.html">
   附录 H：模型集成
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-09-BayesianOptimization.html">
   附录 J：贝叶斯优化
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Append-10-WorkFlow.html">
   附录 K：贝叶斯工作流程
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/chapter03-ModellingwithLinearRegression.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter03-ModellingwithLinearRegression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd/issues/new?title=Issue%20on%20page%20%2Fchapter03-ModellingwithLinearRegression.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xishansnow/BayesianAnalysiswithPython2nd/master?urlpath=lab/tree/chapter03-ModellingwithLinearRegression.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/xishansnow/BayesianAnalysiswithPython2nd&urlpath=lab/tree/BayesianAnalysiswithPython2nd/chapter03-ModellingwithLinearRegression.md&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   3.1 高斯线性回归
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     3.1.1 与机器学习的联系
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     3.1.2 线性回归模型的核心
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     3.1.3 线性模型与高自相关性问题
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       （1）解决方法 1：运行之前做中心化或归一化处理
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       （2）解决办法 2：更换采样方法
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     3.1.4 对后验进行解释和可视化
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     3.1.5 皮尔逊相关系数
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     3.1.6 多元高斯分布的皮尔逊相关系数
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   3.2 更稳健的线性回归
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   3.3 分层线性回归
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id13">
     3.3.1 关于相关性与因果性
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   3.4 多项式回归
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id15">
     3.4.1 多项式回归系数的可解释性困局
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id16">
     3.4.2 多项式回归不应成为代替其他模型的“终极模型”
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id17">
   3.5 多元线性回归
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id18">
     3.5.1 多元线性回归中的混淆变量和冗余变量
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id19">
     3.5.2 多重共线性或相关性太高有影响吗？
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id20">
     3.5.3 通过多元线性回归防止掩蔽效应
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id21">
     3.5.4 在多元线性回归模型中增加变量间的交互作用
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id22">
   3.6 变方差的线性回归模型
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id23">
   3.7 总结
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id24">
   3.8 练习
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>第 3 章 线性回归模型<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<style>p{text-indent:2em;2}</style>
<p>本章将介绍最流行、最有用的一种模型–线性模型。其本身就是非常有用的模型，也是许多其他模型的基础。如果你学过统计学课程，你可能听说过简单线性回归、多元线性回归、逻辑回归、方差分析、方差分析等。所有这些方法都是同一基本主题–线性回归模型的变体。在本章中，我们将介绍以下主题：</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">一元线性回归</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">稳健的线性回归</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">分层线性回归</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">多项式线性回归</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">多元线性回归</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">交互作用</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">变方差的线性回归</span></code></p></li>
</ul>
<hr class="docutils" />
<div class="section" id="id2">
<h2>3.1 高斯线性回归<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>实际应用中经常会遇到下面这类问题：我们有一个连续变量 <span class="math notranslate nohighlight">\(x\)</span> ，希望对另外一个变量 <span class="math notranslate nohighlight">\(y\)</span> 建模并进行预测。这些变量通常以 <span class="math notranslate nohighlight">\(\{(x_1,y_1),(x_2,y_2),...,(x_n,y_n)\}\)</span> 成对方式出现。此类问题一般可通过线性回归建模，当只有一个自变量时，被称为一元线性回归模型。</p>
<p>在上述描述中，通常 <span class="math notranslate nohighlight">\(x\)</span> 被称为自变量、预测变量或输入变量，而 <span class="math notranslate nohighlight">\(y\)</span> 被称为因变量、结果变量或输出变量。在 <code class="docutils literal notranslate"><span class="pre">Numpy</span></code> 中，一元线性回归模型中的输入 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和 输出 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 为一维数组。当存在多个自变量时，输入 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 为矩阵，此时的模型被称为多元线性回归模型。</p>
<p>使用线性模型的一些典型场景包括：</p>
<ul class="simple">
<li><p>对多个因素之间的关系建模，如雨量、土壤盐度与农作物是否施肥等，然后回答：它们之间的关系是否线性？关系有多强？哪个因素影响最强？</p></li>
<li><p>找出全国平均巧克力摄入量与诺贝尔奖得主数量之间的关系。理解为什么这二者之间的关系可能是假的。</p></li>
<li><p>根据当地天气预报中的太阳辐射，预测家里的燃气账单。该预测的准确性如何？</p></li>
</ul>
<div class="section" id="id3">
<h3>3.1.1 与机器学习的联系<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>（1）机器学习与统计学</p>
<p>按照 <code class="docutils literal notranslate"><span class="pre">Kevin</span> <span class="pre">P.</span> <span class="pre">Murphy</span></code> 的说法，机器学习指一系列从数据中自动学习隐藏的规律、并用于预测未知数据，或在不确定状态中做出决策的方法的总称。机器学习与统计学相互交织，不过正如 <code class="docutils literal notranslate"><span class="pre">Kevin</span> <span class="pre">P.</span> <span class="pre">Murphy</span></code> 所说：“如果从概率视角来看，二者间的关系就比较清晰了”。尽管两个领域在概念和数学上紧密联系，但二者间不同的术语让这种联系显得不那么清晰了。因此，本文会介绍一些机器学习中的术语。</p>
<p>（2）回归是一种监督学习方法</p>
<p>用机器学习的术语来说，回归属于典型的<code class="docutils literal notranslate"><span class="pre">监督学习</span></code>。在机器学习框架中，学习从 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 到 <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> 的一个映射就是<code class="docutils literal notranslate"><span class="pre">回归</span></code>问题（ <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> 是连续变量）。不过，机器学习术语中通常用 <code class="docutils literal notranslate"><span class="pre">特征</span></code> 取代统计学中的 <code class="docutils literal notranslate"><span class="pre">变量</span></code>。而 <code class="docutils literal notranslate"><span class="pre">监督</span></code> 则指，已经知道 <span class="math notranslate nohighlight">\(\mathbf{X}-\mathbf{Y}\)</span> 变量对的观测值，如何从中抽象出一种 <code class="docutils literal notranslate"><span class="pre">映射关系</span></code> 来处理未来的观测（即只知道 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 而不知道 <span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> 的情形）。</p>
</div>
<div class="section" id="id4">
<h3>3.1.2 线性回归模型的核心<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>让我们开始学习如何构建线性模型。看下面该公式：</p>
<div class="math notranslate nohighlight">
\[
y_i= \alpha + x_i \beta \tag{式3.1}
\]</div>
<p>该等式描述了变量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 之间的线性关系。 <span class="math notranslate nohighlight">\(\beta\)</span> 参数控制着线性关系的斜率，可被解释为变量 <span class="math notranslate nohighlight">\(y\)</span> 随一个单位 <span class="math notranslate nohighlight">\(x\)</span> 的变化而产生的变化量。另外一个参数 <span class="math notranslate nohighlight">\(α\)</span> 为截距，可以解释为当 <span class="math notranslate nohighlight">\(x_i=0\)</span> 时, <span class="math notranslate nohighlight">\(y_i\)</span> 的值，在图形上表示， <span class="math notranslate nohighlight">\(α\)</span> 就是直线与 <span class="math notranslate nohighlight">\(y\)</span> 轴交点的坐标。</p>
<p>计算线性模型参数的方法很多，频率主义的最小二乘法就是其中之一。每次使用软件去拟合直线时，底层可能用的就是最小二乘法。最小二乘法返回的 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 能够让实际观测的 <span class="math notranslate nohighlight">\(y\)</span> 与预测的 <span class="math notranslate nohighlight">\(\hat y\)</span> 之间均方误差最小。估计 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 的本质是求解一个最优化问题，其目标是寻找使目标函数达到最值（最小值或最大值）时的参数解。</p>
<p>最优化并非求解线性模型的唯一方法，同样的问题可以从贝叶斯角度描述。用概率方式思考的优势是：<strong>在得到最优参数解 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 的同时，还能够知道其不确定性程度。</strong> 而最优化方法则需要一些其他工作来提供不确定性信息。此外，贝叶斯方法还具备很大灵活性，尤其在使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 等工具时，可将模型应用到本章后面所介绍的各种特定问题中。</p>
<p>从概率角度，线性回归模型可以表示成如下形式：</p>
<div class="math notranslate nohighlight">
\[
\mathbb{y} \sim \mathcal{N} ( \mu = \alpha + \mathbf{X} \beta , \epsilon ) \tag{式3.2}
\]</div>
<p>也就是说，假设随机变量 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 服从均值为 <span class="math notranslate nohighlight">\(α + \mathbf{X} β\)</span> 、标准差为 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的正态分布。其中 <span class="math notranslate nohighlight">\(α\)</span> 、 <span class="math notranslate nohighlight">\(β\)</span> 、 <span class="math notranslate nohighlight">\(\epsilon\)</span> 为未知的模型参数（ 在贝叶斯方法中视其为随机变量，具有自身的概率分布），需要设置先验。</p>
<p>先验的设置根据问题上下文和数据分析师的经验给出，例如，下面是假设参数服从正态分布的一组先验设置：</p>
<div class="math notranslate nohighlight">
\[
\alpha \sim \mathcal{N}\left(\mu_{\alpha}, \sigma_{\alpha}\right) \tag{式3.3}
\]</div>
<div class="math notranslate nohighlight">
\[
\beta \sim \mathcal{N}\left(\mu_{\beta}, \sigma_{\beta}\right)
\]</div>
<div class="math notranslate nohighlight">
\[
\epsilon \sim\left|N\left(0, \sigma_{\epsilon}\right)\right|
\]</div>
<p>其中：</p>
<p>（1）截距参数 <span class="math notranslate nohighlight">\(α\)</span> 的先验，根据问题不同会有较大变化，可使用一个平坦的高斯分布,其标注差 <span class="math notranslate nohighlight">\(\sigma_\alpha\)</span> 相对于数据的值域较大。</p>
<p>（2）斜率参数 <span class="math notranslate nohighlight">\(\beta\)</span> 可能比截距更容易获得先验，因为许多问题中至少可以预先知道斜率的正负符号；例如，预期权重值 <span class="math notranslate nohighlight">\(\beta\)</span> 平均会随着高度变化而增加。</p>
<p>（3）误差参数 <span class="math notranslate nohighlight">\(\epsilon\)</span> 应大于 0，采用半高斯分布是一个选择。当对误差范围不可预期时，可以将 <span class="math notranslate nohighlight">\(\sigma_\epsilon\)</span> 设置为相对 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的方差而言较大的值，如设置为 <span class="math notranslate nohighlight">\(\sigma_{\mathbb{y}}\)</span> 的 10 倍，以保留足够空间通过数据似然来驱动不确定性的收缩。</p>
<p>上述较为模糊的先验设置可保证先验对后验影响不至于过大，并较容易被数据克服，使最终结果更倾向于数据证据。</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>（1） 原理上，随着数据证据的逐步增加，先验终被数据似然所克服，或者说，无论先验如何设置，理论上在经过充分的数据证据后，后验将收缩至相同的结果。但现实中可能无法得到如此丰富的观测数据。</p>
<p>（2）使用最大似然法（最小二乘）得到的参数解与采用平坦高斯先验的贝叶斯最大后验估计（MAP）得到的解都是对参数的点估计，两者的结果一致。</p>
</div>
<p>上述误差参数 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的半高斯先验，也可以改为均匀分布或半柯西分布。半柯西分布是一个很好的正则化先验，而均匀分布由于存在硬边界的限制，可能不是一个好的选择。如果想对 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的标准差施加某个特定值附近的强先验，也可以为 <span class="math notranslate nohighlight">\(\epsilon\)</span> 设置伽马先验。不同软件包中伽马分布的默认参数化方法可能有点不一样，不过<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>允许使用<code class="docutils literal notranslate"><span class="pre">形状（</span> <span class="pre">shape</span> <span class="pre">）</span></code>和<code class="docutils literal notranslate"><span class="pre">速率（</span> <span class="pre">rate</span> <span class="pre">）</span></code>参数组合、或者<code class="docutils literal notranslate"><span class="pre">平均值（</span> <span class="pre">mean</span> <span class="pre">）</span></code>和<code class="docutils literal notranslate"><span class="pre">标准差（</span> <span class="pre">$\sigma$</span> <span class="pre">）</span></code>参数组合来定义它。</p>
<p>要查看伽马和其他分布的形状，可以查看 <a class="reference external" href="https://docs.pymc.io/api/distributions/continuous.html">PyMC3 文档</a> 。</p>
<p>回过头再看线性回归模型，借助 Kruschke 图有图 3.1 。在上一章的  Kruschke 图中，我们曾规定用符号 <code class="docutils literal notranslate"><span class="pre">=</span></code> 来定义确定性变量（如图中的 <span class="math notranslate nohighlight">\(\mu\)</span> ），用 <code class="docutils literal notranslate"><span class="pre">∼</span></code> 来定义随机变量，如图中的 <span class="math notranslate nohighlight">\(\alpha\)</span> 、 <span class="math notranslate nohighlight">\(\beta\)</span> 和 <span class="math notranslate nohighlight">\(\epsilon\)</span> ：</p>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505092353_aa.webp" style="zoom:50%;" />
<blockquote>
<div><p><strong>图 3.1 线性模型的 Kruschke 图</strong></p>
</div></blockquote>
</center>
<p>定义好模型后，需要为其提供数据。这里采用了人工合成的数据集（合成数据集的优点是：可事前知道参数的真值，进而方便检查是否能够使用模型恢复它们）：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">arviz</span> <span class="k">as</span> <span class="nn">az</span>

<span class="n">az</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;arviz-darkgrid&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 生成实验数据</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">N</span><span class="o">=</span><span class="mi">100</span>
<span class="n">alpha_real</span><span class="o">=</span><span class="mf">2.5</span>
<span class="n">beta_real</span><span class="o">=</span><span class="mf">0.9</span>
<span class="n">eps_real</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">N</span><span class="p">)</span>
<span class="n">y_real</span><span class="o">=</span><span class="n">alpha_real</span><span class="o">+</span><span class="n">beta_real</span><span class="o">*</span><span class="n">x</span>
<span class="n">y</span><span class="o">=</span><span class="n">y_real</span><span class="o">+</span><span class="n">eps_real</span>

<span class="n">_</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="s1">&#39;C0.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y_real</span><span class="p">,</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_kde</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2621/3927609152.py:18: UserWarning: This figure was using constrained_layout, but that is incompatible with subplots_adjust and/or tight_layout; disabling constrained_layout.
  plt.tight_layout()
</pre></div>
</div>
<img alt="_images/chapter03-ModellingwithLinearRegression_2_1.png" src="_images/chapter03-ModellingwithLinearRegression_2_1.png" />
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505092831_15.webp" style="zoom:67%;"/>
<blockquote>
<div><p><strong>图 3.2 回归模型样本集的散点图以及 <span class="math notranslate nohighlight">\(y\)</span> 的边缘分布</strong></p>
</div></blockquote>
</center>
<p>现在使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 来构建和拟合模型。注意这里 <span class="math notranslate nohighlight">\(\mu\)</span> 在模型中通过 <code class="docutils literal notranslate"><span class="pre">pm.deterministic</span></code> 来定义，表示它是<code class="docutils literal notranslate"><span class="pre">确定性变量</span></code>，反映了数学表达式和 Kruschke 图的内容。在<code class="docutils literal notranslate"><span class="pre">PyMC3</span></code>中，如果显式定义了一个确定性变量，则会计算该变量并保存其轨迹：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_g</span><span class="p">:</span>
    <span class="c1"># 定义模型参数的先验</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="c1"># 定义映射 (y = α + β * x) 和似然 P(y|α,β,ε）</span>
    <span class="n">μ</span><span class="o">=</span><span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">y_pred</span><span class="o">=</span><span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span><span class="n">mu</span> <span class="o">=</span> <span class="n">μ</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># 近似推断：随机采样生成模型中所有随机变量（模型参数或隐变量等）和显式确定性变量的迹</span>
    <span class="n">trace_g</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">,</span> <span class="n">tune</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2621/2262848942.py:12: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.
  trace_g = pm.sample(2000, tune = 1000)
Auto-assigning NUTS sampler...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initializing NUTS using jitter+adapt_diag...
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span>---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
/tmp/ipykernel_2621/2262848942.py in &lt;module&gt;
     10 
     11     # 近似推断：随机采样生成模型中所有随机变量（模型参数或隐变量等）和显式确定性变量的迹
---&gt; 12     trace_g = pm.sample(2000, tune = 1000)

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/sampling.py in sample(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, jitter_max_retries, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)
    494             # By default, try to use NUTS
    495             _log.info(&quot;Auto-assigning NUTS sampler...&quot;)
--&gt; 496             start_, step = init_nuts(
    497                 init=init,
    498                 chains=chains,

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/sampling.py in init_nuts(init, chains, n_init, model, random_seed, progressbar, jitter_max_retries, **kwargs)
   2185         raise ValueError(f&quot;Unknown initializer: {init}.&quot;)
   2186 
-&gt; 2187     step = pm.NUTS(potential=potential, model=model, **kwargs)
   2188 
   2189     return start, step

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/step_methods/hmc/nuts.py in __init__(self, vars, max_treedepth, early_max_treedepth, **kwargs)
    166         `pm.sample` to the desired number of tuning steps.
    167         &quot;&quot;&quot;
--&gt; 168         super().__init__(vars, **kwargs)
    169 
    170         self.max_treedepth = max_treedepth

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/step_methods/hmc/base_hmc.py in __init__(self, vars, scaling, step_scale, is_cov, model, blocked, potential, dtype, Emax, target_accept, gamma, k, t0, adapt_step_size, step_rand, **theano_kwargs)
     86         vars = inputvars(vars)
     87 
---&gt; 88         super().__init__(vars, blocked=blocked, model=model, dtype=dtype, **theano_kwargs)
     89 
     90         self.adapt_step_size = adapt_step_size

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/step_methods/arraystep.py in __init__(self, vars, model, blocked, dtype, logp_dlogp_func, **theano_kwargs)
    252 
    253         if logp_dlogp_func is None:
--&gt; 254             func = model.logp_dlogp_function(vars, dtype=dtype, **theano_kwargs)
    255         else:
    256             func = logp_dlogp_func

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/model.py in logp_dlogp_function(self, grad_vars, tempered, **kwargs)
   1002         varnames = [var.name for var in grad_vars]
   1003         extra_vars = [var for var in self.free_RVs if var.name not in varnames]
-&gt; 1004         return ValueGradFunction(costs, grad_vars, extra_vars, **kwargs)
   1005 
   1006     @property

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/pymc3/model.py in __init__(self, costs, grad_vars, extra_vars, dtype, casting, compute_grads, **kwargs)
    689 
    690         if compute_grads:
--&gt; 691             grad = tt.grad(self._cost_joined, self._vars_joined)
    692             grad.name = &quot;__grad&quot;
    693             outputs = [self._cost_joined, grad]

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in grad(cost, wrt, consider_constant, disconnected_inputs, add_names, known_grads, return_disconnected, null_gradients)
    637             assert g.type.dtype in theano.tensor.float_dtypes
    638 
--&gt; 639     rval = _populate_grad_dict(var_to_app_to_idx, grad_dict, wrt, cost_name)
    640 
    641     for i in range(len(rval)):

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in _populate_grad_dict(var_to_app_to_idx, grad_dict, wrt, cost_name)
   1438         return grad_dict[var]
   1439 
-&gt; 1440     rval = [access_grad_cache(elem) for elem in wrt]
   1441 
   1442     return rval

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in &lt;listcomp&gt;(.0)
   1438         return grad_dict[var]
   1439 
-&gt; 1440     rval = [access_grad_cache(elem) for elem in wrt]
   1441 
   1442     return rval

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_grad_cache(var)
   1391                     for idx in node_to_idx[node]:
   1392 
-&gt; 1393                         term = access_term_cache(node)[idx]
   1394 
   1395                         if not isinstance(term, Variable):

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_term_cache(node)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in &lt;listcomp&gt;(.0)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_grad_cache(var)
   1391                     for idx in node_to_idx[node]:
   1392 
-&gt; 1393                         term = access_term_cache(node)[idx]
   1394 
   1395                         if not isinstance(term, Variable):

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_term_cache(node)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in &lt;listcomp&gt;(.0)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_grad_cache(var)
   1391                     for idx in node_to_idx[node]:
   1392 
-&gt; 1393                         term = access_term_cache(node)[idx]
   1394 
   1395                         if not isinstance(term, Variable):

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_term_cache(node)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in &lt;listcomp&gt;(.0)
   1059             inputs = node.inputs
   1060 
-&gt; 1061             output_grads = [access_grad_cache(var) for var in node.outputs]
   1062 
   1063             # list of bools indicating if each output is connected to the cost

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_grad_cache(var)
   1391                     for idx in node_to_idx[node]:
   1392 
-&gt; 1393                         term = access_term_cache(node)[idx]
   1394 
   1395                         if not isinstance(term, Variable):

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/gradient.py in access_term_cache(node)
   1218                             )
   1219 
-&gt; 1220                 input_grads = node.op.L_op(inputs, node.outputs, new_output_grads)
   1221 
   1222                 if input_grads is None:

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in L_op(self, inputs, outs, ograds)
    562 
    563         # compute grad with respect to broadcasted input
--&gt; 564         rval = self._bgrad(inputs, outs, ograds)
    565 
    566         # TODO: make sure that zeros are clearly identifiable

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in _bgrad(self, inputs, outputs, ograds)
    666                 ret.append(None)
    667                 continue
--&gt; 668             ret.append(transform(scalar_igrad))
    669 
    670         return ret

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in transform(r)
    657                 return DimShuffle((), [&quot;x&quot;] * nd)(res)
    658 
--&gt; 659             new_r = Elemwise(node.op, {})(*[transform(ipt) for ipt in node.inputs])
    660             return new_r
    661 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in &lt;listcomp&gt;(.0)
    657                 return DimShuffle((), [&quot;x&quot;] * nd)(res)
    658 
--&gt; 659             new_r = Elemwise(node.op, {})(*[transform(ipt) for ipt in node.inputs])
    660             return new_r
    661 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in transform(r)
    657                 return DimShuffle((), [&quot;x&quot;] * nd)(res)
    658 
--&gt; 659             new_r = Elemwise(node.op, {})(*[transform(ipt) for ipt in node.inputs])
    660             return new_r
    661 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in &lt;listcomp&gt;(.0)
    657                 return DimShuffle((), [&quot;x&quot;] * nd)(res)
    658 
--&gt; 659             new_r = Elemwise(node.op, {})(*[transform(ipt) for ipt in node.inputs])
    660             return new_r
    661 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/tensor/elemwise.py in transform(r)
    657                 return DimShuffle((), [&quot;x&quot;] * nd)(res)
    658 
--&gt; 659             new_r = Elemwise(node.op, {})(*[transform(ipt) for ipt in node.inputs])
    660             return new_r
    661 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py in __call__(self, *inputs, **kwargs)
    251 
    252         if config.compute_test_value != &quot;off&quot;:
--&gt; 253             compute_test_value(node)
    254 
    255         if self.default_output is not None:

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py in compute_test_value(node)
    124 
    125     # Create a thunk that performs the computation
--&gt; 126     thunk = node.op.make_thunk(node, storage_map, compute_map, no_recycling=[])
    127     thunk.inputs = [storage_map[v] for v in node.inputs]
    128     thunk.outputs = [storage_map[v] for v in node.outputs]

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py in make_thunk(self, node, storage_map, compute_map, no_recycling, impl)
    632             )
    633             try:
--&gt; 634                 return self.make_c_thunk(node, storage_map, compute_map, no_recycling)
    635             except (NotImplementedError, MethodNotDefined):
    636                 # We requested the c code, so don&#39;t catch the error.

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/graph/op.py in make_c_thunk(self, node, storage_map, compute_map, no_recycling)
    598                 print(f&quot;Disabling C code for {self} due to unsupported float16&quot;)
    599                 raise NotImplementedError(&quot;float16&quot;)
--&gt; 600         outputs = cl.make_thunk(
    601             input_storage=node_input_storage, output_storage=node_output_storage
    602         )

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py in make_thunk(self, input_storage, output_storage, storage_map)
   1201         &quot;&quot;&quot;
   1202         init_tasks, tasks = self.get_init_tasks()
-&gt; 1203         cthunk, module, in_storage, out_storage, error_storage = self.__compile__(
   1204             input_storage, output_storage, storage_map
   1205         )

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py in __compile__(self, input_storage, output_storage, storage_map)
   1136         input_storage = tuple(input_storage)
   1137         output_storage = tuple(output_storage)
-&gt; 1138         thunk, module = self.cthunk_factory(
   1139             error_storage,
   1140             input_storage,

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py in cthunk_factory(self, error_storage, in_storage, out_storage, storage_map)
   1632             for node in self.node_order:
   1633                 node.op.prepare_node(node, storage_map, None, &quot;c&quot;)
-&gt; 1634             module = get_module_cache().module_from_key(key=key, lnk=self)
   1635 
   1636         vars = self.inputs + self.outputs + self.orphans

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py in module_from_key(self, key, lnk)
   1189             try:
   1190                 location = dlimport_workdir(self.dirname)
-&gt; 1191                 module = lnk.compile_cmodule(location)
   1192                 name = module.__file__
   1193                 assert name.startswith(location)

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/basic.py in compile_cmodule(self, location)
   1541             try:
   1542                 _logger.debug(f&quot;LOCATION {location}&quot;)
-&gt; 1543                 module = c_compiler.compile_str(
   1544                     module_name=mod.code_hash,
   1545                     src_code=src_code,

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/link/c/cmodule.py in compile_str(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)
   2494 
   2495         try:
-&gt; 2496             p_out = output_subprocess_Popen(cmd)
   2497             compile_stderr = p_out[1].decode()
   2498         except Exception:

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/site-packages/theano/utils.py in output_subprocess_Popen(command, **params)
    252     # we need to use communicate to make sure we don&#39;t deadlock around
    253     # the stdout/stderr pipe.
--&gt; 254     out = p.communicate()
    255     return out + (p.returncode,)
    256 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/subprocess.py in communicate(self, input, timeout)
   1026 
   1027             try:
-&gt; 1028                 stdout, stderr = self._communicate(input, endtime, timeout)
   1029             except KeyboardInterrupt:
   1030                 # https://bugs.python.org/issue25942

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/subprocess.py in _communicate(self, input, endtime, orig_timeout)
   1866                             &#39;failed to raise TimeoutExpired.&#39;)
   1867 
-&gt; 1868                     ready = selector.select(timeout)
   1869                     self._check_timeout(endtime, orig_timeout, stdout, stderr)
   1870 

/opt/hostedtoolcache/Python/3.8.12/x64/lib/python3.8/selectors.py in select(self, timeout)
    413         ready = []
    414         try:
--&gt; 415             fd_event_list = self._selector.poll(timeout)
    416         except InterruptedError:
    417             return ready

KeyboardInterrupt: 
</pre></div>
</div>
</div>
</div>
<p>如果不在模型中显式地定义确定性变量。则 <code class="docutils literal notranslate"><span class="pre">PCMC3</span></code> 仍会计算该变量，但不会保存其轨迹。例如，可编写以下代码：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model_g</span><span class="p">:</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>为探索推断结果，可以绘制未知随机变量的轨迹图（ 图 3.3 ），此处省略了确定性变量 <span class="math notranslate nohighlight">\(\mu\)</span> 。你可以通过将变量名称（随机变量或显式确定性变量）以列表形式传递给参数 <code class="docutils literal notranslate"><span class="pre">var_names</span></code> 的方式，来实现多变量轨迹图的绘制。许多 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 函数都有一个 <code class="docutils literal notranslate"><span class="pre">var_names</span></code> 参数，你可以尝试其他 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的绘图函数来探索后验。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model_g</span><span class="p">:</span>
    <span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_g</span><span class="p">,</span> <span class="n">var_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">,</span><span class="s1">&#39;β&#39;</span><span class="p">,</span><span class="s1">&#39;ϵ&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210505093554_e3.webp" /></p>
<p>图3.3</p>
</center>
<p>下一节将讨论线性模型的性质，以及其如何影响采样过程和模型的解释，并介绍几种解释和可视化后验的方法。</p>
</div>
<div class="section" id="id5">
<h3>3.1.3 线性模型与高自相关性问题<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>前面模型中，随机变量 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 之间实际上存在比较严重的相关性。这意味着采样结果会很差，有效采样很少。</p>
<p>为什么呢？ 因为我们被自己的假设误导了。</p>
<p>事实上，上述模型中，不论用哪条直线去拟合数据，该直线都会穿过 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的均值点。拟合直线的过程相当于将直线固定在均值点上做旋转，其结果是呈现出<code class="docutils literal notranslate"><span class="pre">斜率越大截距越小</span></code>的相关性。如果将后验画出来的话可以很清楚地看到这点（见图 3.4 , 暂时忽略 <span class="math notranslate nohighlight">\(ε\)</span> ）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model_g</span><span class="p">:</span>
    <span class="n">az</span><span class="o">.</span><span class="n">plot_pair</span><span class="p">(</span><span class="n">trace_g</span><span class="p">,</span> <span class="n">var_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="s1">&#39;β&#39;</span><span class="p">],</span> <span class="n">plot_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510120946ab.webp" /></p>
<p>图 3.4</p>
</center>
<p>可以看到，后验呈斜对角形状，这对于类似 <code class="docutils literal notranslate"><span class="pre">Metropolis-Hastings</span></code> 的采样器会产生问题（详细解释见<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">8</span> <span class="pre">章</span></code>），而且参数维度越高，这种情况越严重。</p>
<p>在继续深入前，需澄清一点：前面提到的<code class="docutils literal notranslate"><span class="pre">拟合直线穿过均值点的现象</span></code>只在最小二乘法假设下成立。使用贝叶斯方法后，这个限制会稍微被放松。后面的例子中可以看到，贝叶斯方法中，拟合直线会在均值点附近而不是正好穿过均值。但总体上，随机变量之间的自相关性与直线固定在某一点附近的假设仍然成立。</p>
<p>接下来从两个方面理解和解决高自相关性问题：</p>
<div class="section" id="id6">
<h4>（1）解决方法 1：运行之前做中心化或归一化处理<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<p>解决问题的一个简单办法是先将 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 中心化，也就是说，对于每个点 <span class="math notranslate nohighlight">\(x_i\)</span> ，减去 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 的均值。这样做的结果是 <span class="math notranslate nohighlight">\(x'\)</span> 的中心在 0 附近，从而在修改斜率时，旋转点与截距点重合，参数空间也会变得不那么自相关。该方法在机器学习以及深度学习中经常被使用。</p>
<div class="math notranslate nohighlight">
\[
x'=x-\bar x \tag{式3.4}
\]</div>
<p>中心化不仅是一种计算技巧，同时有利于解释数据。截距是指当 <span class="math notranslate nohighlight">\(x_i=0\)</span> 时 <span class="math notranslate nohighlight">\(y_i\)</span> 的值，对许多问题而言，截距并没有什么实际意义。例如，对于身高或者体重的关系模型，当值为 0 时没有实际意义，因而截距对理解数据就没有帮助；对于另外一些问题，估计出截距可能很有用，因为在实验中可能无法测量出 <span class="math notranslate nohighlight">\(x_i=0\)</span> 的情况，此时截距的估计值能够提供有价值的信息。但不管怎么说，外推都有局限性，应当谨慎使用！</p>
<p>根据问题和受众不同，可能需要报告中心化之前和之后的参数估计值。如果需要报告的是中心化之前的参数，那么可以像下面这样将参数转换成原来的尺度：</p>
<div class="math notranslate nohighlight">
\[
\alpha=\alpha^{\prime}-\beta^{\prime} \bar{x} \tag{式3.5}
\]</div>
<p>上面的公式可以通过以下公式推导出来：</p>
<div class="math notranslate nohighlight">
\[
y = \alpha^{\prime}+\beta^{\prime} x^{\prime}+\epsilon 
\]</div>
<div class="math notranslate nohighlight">
\[
y = \alpha^{\prime}+\beta^{\prime}(x-\bar{x})+\epsilon 
\]</div>
<div class="math notranslate nohighlight">
\[
y = \alpha^{\prime}-\beta^{\prime} \bar{x}+\beta^{\prime} x+\epsilon   \tag{式3.6}
\]</div>
<p>然后可以得出：</p>
<div class="math notranslate nohighlight">
\[
\beta = \beta' \tag{式3.7} 
\]</div>
<p>进一步，在运行模型之前可以对数据进行<code class="docutils literal notranslate"><span class="pre">归一化处理</span></code>。归一化在统计学和机器学习中是常见的数据处理手段，许多算法对归一化后的数据效果更好。归一化过程在中心化基础上再除以标准差，其数学形式如下：</p>
<div class="math notranslate nohighlight">
\[
x^{\prime} = \frac{x-\bar{x}}{x_{s d}} 
\]</div>
<div class="math notranslate nohighlight">
\[
y^{\prime} = \frac{y-\bar{y}}{y_{s d}} \tag{式3.8}
\]</div>
<p>归一化的好处是能够对数据使用相同的弱先验，而不必关心数据值域大小（因为已经对数据做了尺度变换）。归一化后的数据，截距通常在 0 附近，斜率在 <span class="math notranslate nohighlight">\(-1～1\)</span> 附近。</p>
<p>归一化后的数据可以使用 <code class="docutils literal notranslate"><span class="pre">标准分（z-score）</span></code> 来描述参数。如果某人称一个参数的 <code class="docutils literal notranslate"><span class="pre">z-score</span></code> 为 1.3，那么我们就知道该值在归一化前位于均值附近 1.3 倍标准差处。<code class="docutils literal notranslate"><span class="pre">z-score</span></code> 每变化一个单位，对应原始数据中变化 1 倍标准差。这点在分析多变量时很有用，因为所有参数都在同一个尺度上，进而可以简化对数据的解释。</p>
</div>
<div class="section" id="id7">
<h4>（2）解决办法 2：更换采样方法<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<p>另外一种解决高自相关性的办法是使用不同采样方法。<code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 算法与 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 算法相比，在类似受限的对角空间中遇到的困难小一些。原因是 <code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 是根据后验曲率来移动的，因而更容易沿着对角空间移动。<code class="docutils literal notranslate"><span class="pre">NUTS</span></code> 算法每走一步都要比 <code class="docutils literal notranslate"><span class="pre">Metropolis</span></code> 算法更慢，但得到一个合理后验近似值所需步数更少（相关解释见<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">8</span> <span class="pre">章</span></code>）。</p>
</div>
</div>
<div class="section" id="id8">
<h3>3.1.4 对后验进行解释和可视化<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>正如已经看到的，可以使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 函数（如 <code class="docutils literal notranslate"><span class="pre">plot_trace</span></code> 和 <code class="docutils literal notranslate"><span class="pre">summary</span></code> ）探索后验，也可以使用自己的函数。对于线性回归，绘制出符合数据均值的直线，并标示参数 <span class="math notranslate nohighlight">\(\alpha\)</span> 和 <span class="math notranslate nohighlight">\(\beta\)</span> 的均值可能很有用。对于感兴趣的不确定性程度，则可以从后验中采样并以半透明线条形式绘制在均值直线周边（图 3.5）。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;C0.&#39;</span><span class="p">)</span>
<span class="n">alpha_m</span> <span class="o">=</span> <span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">beta_m</span> <span class="o">=</span> <span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">draws</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]),</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># 绘制不确定性集合</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">][</span><span class="n">draws</span><span class="p">]</span> <span class="o">+</span> <span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">][</span><span class="n">draws</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># 绘制均值直线</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha_m</span> <span class="o">+</span> <span class="n">beta_m</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;y = </span><span class="si">{</span><span class="n">alpha_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> + </span><span class="si">{</span><span class="n">beta_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> * x&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051012370861.webp" />
<blockquote>
<div><p><strong>图 3.5 拟合后的回归曲线，黑色为均值曲线，灰色为不确定性边界</strong></p>
</div></blockquote>
</center>
<p>可以看到，上图中间部分比较确定（即不确定性程度低），不过直线并没有都相交于一点（贝叶斯方法并不强制所有直线都穿过均值点）。</p>
<p>半透明直线是一种比较直观的表示方法，不过还可以给该图增加更酷的东西：用半透明区间来描述 <span class="math notranslate nohighlight">\(μ\)</span> 的最大后验密度 <code class="docutils literal notranslate"><span class="pre">HPDI</span></code> 区间（ 图 3.6 ）。注意这也是在模型中将变量 <span class="math notranslate nohighlight">\(μ\)</span> 显式定义为确定性变量的主要原因，简化以下代码：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 绘制均值直线</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha_m</span> <span class="o">+</span> <span class="n">beta_m</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> 
        <span class="n">label</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;y = </span><span class="si">{</span><span class="n">alpha_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> + </span><span class="si">{</span><span class="n">beta_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> * x&#39;</span><span class="p">)</span>

<span class="c1"># 绘制参数的不确定性程度区间（0.98）</span>
<span class="n">sig</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">trace_g</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">],</span> <span class="n">credible_interval</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051012334888.webp" />
<blockquote>
<div><p><strong>图3.6 用不同颜色表示的 94% 和 50% 最高后验密度区间</strong></p>
</div></blockquote>
</center>
<p>另外一种方式是绘制因变量值 <span class="math notranslate nohighlight">\(\hat y\)</span> 的 <code class="docutils literal notranslate"><span class="pre">HPDI</span></code> 区间（ 见图 3.7 ），用于显示模型预测中 94% 和 50%的数据分布范围。在图中将 <code class="docutils literal notranslate"><span class="pre">50%</span> <span class="pre">HPDI</span> <span class="pre">区间</span></code> 用深灰色区域表示，将 <code class="docutils literal notranslate"><span class="pre">94%</span> <span class="pre">HPDI区间</span></code> 用浅灰色表示。</p>
<p>利用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中的 <code class="docutils literal notranslate"><span class="pre">sample_posterior_predictive</span></code> 函数可以很容易得到预测值的采样。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_g</span><span class="p">,</span> <span class="n">samples</span> <span class="o">=</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_g</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>然后我们可以画出结果：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b.&#39;</span><span class="p">)</span>

<span class="c1"># 绘制均值直线</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">alpha_m</span> <span class="o">+</span> <span class="n">beta_m</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;y = </span><span class="si">{</span><span class="n">alpha_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> + </span><span class="si">{</span><span class="n">beta_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> * x&#39;</span><span class="p">)</span>

<span class="c1"># 绘制因变量的不确定性区间（指定的 0.5 和默认的 0.94）         </span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">],</span> <span class="n">credible_interval</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_hpd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;lightgray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051012410596.webp" style="zoom:67%;" />
<blockquote>
<div><p><strong>图 3.7 后验预测分布的 <code class="docutils literal notranslate"><span class="pre">HPDI</span></code> 区间</strong></p>
</div></blockquote>
</center>
<p>函数 <code class="docutils literal notranslate"><span class="pre">az.plot_hpd</span></code> 是一个辅助函数，可以使用它来绘制线性回归的 HPD 间隔。默认情况下，此功能会平滑间隔，可尝试传递参数 <code class="docutils literal notranslate"><span class="pre">smooth=false</span></code> 取消默认值。</p>
</div>
<div class="section" id="id9">
<h3>3.1.5 皮尔逊相关系数<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>有时我们希望衡量两个变量之间的（线性）依赖关系。度量两个变量间线性相关性最常见的指标是<code class="docutils literal notranslate"><span class="pre">皮尔逊相关系数（Pearson</span> <span class="pre">correlation</span> <span class="pre">coefficient）</span></code> ，通常用小写的 <span class="math notranslate nohighlight">\(r\)</span> 表示。如果 <span class="math notranslate nohighlight">\(r\)</span> 值为 <span class="math notranslate nohighlight">\(+1\)</span> ，我们称两个变量完全正相关，即一个变量随另一个变量的增加而增加；如果 <span class="math notranslate nohighlight">\(r\)</span> 值为 <span class="math notranslate nohighlight">\(-1\)</span> ，则称完全负相关，即一个变量随另一变量的增加而减少；当 <span class="math notranslate nohighlight">\(r\)</span> 为 0 时，称两个变量间没有线性相关性。</p>
<p>皮尔逊相关系数并不涉及非线性相关性。人们很容易将皮尔逊相关系数与线性回归中的斜率弄混淆，但查看 <a class="reference external" href="https://en.wikipedia.org/wiki/Correlation_and_dependence#/media/File:Correlation_examples2.svg">此链接</a> 就可以明白，二者本质上是两个完全不同的量。</p>
<p>下面的公式可以在某种程度上减轻你的疑惑：</p>
<div class="math notranslate nohighlight">
\[
r=\beta \frac{\sigma_{x}}{\sigma_{y}} \tag{式3.9} 
\]</div>
<p>只有在 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的标准差相等时，皮尔逊相关系数才与斜率相等。也就是说，皮尔逊相关系数和斜率的主要区别在于是否受数据尺度影响。在对数据做归一化处理消除尺度影响后，两者之间确实等价，但在未做归一化处理前，两者并不等价。需要注意：</p>
<ul class="simple">
<li><p>皮尔逊相关系数衡量的是两个变量之间的相关性程度，其值位于 [-1,1] 区间内，<code class="docutils literal notranslate"><span class="pre">皮尔逊相关系数与数据尺度无关</span></code>；</p></li>
<li><p>斜率 <span class="math notranslate nohighlight">\(\beta\)</span> 表示 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 变化一个单位时 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的变化量，可以取任意实数。</p></li>
</ul>
<p>根据统计学知识，皮尔逊相关系数与一个被称为 <code class="docutils literal notranslate"><span class="pre">决定系数（或可决系数）</span></code> 的量有关。决定系数记为 <span class="math notranslate nohighlight">\(r^2\)</span> 或 <span class="math notranslate nohighlight">\(R^2\)</span> ，发音为 “ <span class="math notranslate nohighlight">\(r\)</span> 平方”。决定系数反映了<code class="docutils literal notranslate"><span class="pre">因变量的全部变异中，能够通过回归关系被自变量解释的那部分比例（即认为测量值反映的变异中，有一部分可以用模型来解释，而剩下的部分模型无法解释）</span></code>，数学上被定义为因变量 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的预测值方差除以测量值方差。该系数越大，表明 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 与  <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 间的回归关系确定性越高。如果回归关系被建模为线性回归关系，则该系数越大，就表明 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 与  <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 间存在强线性相关性。</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>注： 皮尔逊相关系数反映了两个变量之间的线性相关程度，而决定系数则反映了模型的确定性程度或可解释程度。因此，如果一个线性回归模型的决定系数非常高，则表明因变量和自变量之间的线性关系能够比较好地解释数据，两者之间的皮尔逊相关系数也应该越大。但对于非线性回归模型，决定系数和皮尔逊相关系数之间不一定存在这种映射关系。</p>
</div>
<p>需要注意的是：在贝叶斯线性回归模型中，预测值方差可能大于测量值方差，进而导致 <span class="math notranslate nohighlight">\(R^2\)</span> 大于 1，不利于解释。因此，通常对 <span class="math notranslate nohighlight">\(R^2\)</span> 做如下定义：</p>
<div class="math notranslate nohighlight">
\[
R^{2} = \frac{\mathbf{V}_{n=1}^{N} \mathbf{E}\left[\hat{y}^{s}\right]}{\mathbf{V}_{n=1}^{N} \mathbf{E}\left[\hat{y}^{s}\right]+\mathbf{V}_{n=1}^{S}\left(\hat{y}^{s}-y\right)} \tag{式3.10} 
\]</div>
<p>上式中，<span class="math notranslate nohighlight">\(E[\hat y^S]\)</span> 是后验预测样本 <span class="math notranslate nohighlight">\(S\)</span> 上预测值 <span class="math notranslate nohighlight">\(\hat y\)</span> 的平均值。</p>
<p>上式用 “预测值方差” 除以 “预测值方差 + 残差方差” 来确保 <span class="math notranslate nohighlight">\(R^2\)</span> 被限制在区间 [0，1] 内。其中残差方差指预测值与真实值之差的方差。</p>
<p>在 <code class="docutils literal notranslate"><span class="pre">PYMC3</span></code> 中计算 <span class="math notranslate nohighlight">\(R^2\)</span> 最简单的方法是调用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的 <code class="docutils literal notranslate"><span class="pre">r2_core()</span></code> 函数。其输入为观测值 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 和预测值 <span class="math notranslate nohighlight">\(\hat y\)</span> 。其中， <span class="math notranslate nohighlight">\(\hat y\)</span> 可利用 <code class="docutils literal notranslate"><span class="pre">sample_posterior_predictive</span></code> 函数轻松获得：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>默认情况下，此函数将返回 <span class="math notranslate nohighlight">\(R^2\)</span> （本例为 0.8） 和标准差 （0.03）。</p>
</div>
<div class="section" id="id10">
<h3>3.1.6 多元高斯分布的皮尔逊相关系数<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>计算皮尔逊相关系数的另一种方法是估计多变量高斯分布的协方差矩阵。多元高斯分布是高斯分布在一维以上的推广。以二维为例，要完全描述一个二元高斯分布，需要两个均值（或一个具有两个元素的向量），每个高斯分布对应一个，还需要一个 <span class="math notranslate nohighlight">\(2 \times 2\)</span> 的协方差矩阵，如下所示：</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\Sigma=\left[\begin{array}{cc}\sigma_{\mathbf{X}_{1}}^{2} &amp; \rho \sigma_{\mathbf{X}_{1}} \sigma_{\mathbf{X}_{2}} \\ \rho \sigma_{\mathbf{X}_{1}} \sigma_{\mathbf{X}_{2}} &amp; \sigma_{\mathbf{X}_{2}}^{2}\end{array}\right]    \tag{式3.11}  
\end{equation*}\]</div>
<p>这里 <span class="math notranslate nohighlight">\(\Sigma\)</span> 为希腊大写的希格玛字母，表示协方差矩阵。主对角线上为每个变量的自方差，用该变量的标准差的平方 <span class="math notranslate nohighlight">\(\sigma_{\mathbf{X}_1}、\sigma_{\mathbf{X}_2}\)</span> 来表示。矩阵中其余元素是变量之间的协方差，用单个标准差和变量间的皮尔逊相关系数 <span class="math notranslate nohighlight">\(\rho\)</span> 的乘积表示。请注意，这里只有一个 <span class="math notranslate nohighlight">\(\rho\)</span> ，因为只有两个维度。对于三个变量，则应有三个皮尔逊相关系数。</p>
<p>下面的代码为双变量高斯分布生成等值线图，均值固定在 <span class="math notranslate nohighlight">\((0，0)\)</span> 点。其中一个标准差是固定的，另一个标准差采用值 1 或 2 以及皮尔逊相关系数 <span class="math notranslate nohighlight">\(\rho\)</span> 的不同值：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma_x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sigmas_x2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">rhos</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.90</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">]</span>
<span class="n">k</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mf">.1</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">:</span><span class="mi">5</span><span class="p">:</span><span class="mf">.1</span><span class="p">]</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
<span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span>
<span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">l</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sigmas_x2</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">rhos</span><span class="p">),</span>
                     <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
                     <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">sigma_x2</span> <span class="o">=</span> <span class="n">sigmas_x2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">rho</span> <span class="o">=</span> <span class="n">rhos</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="n">sigma_x1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">sigma_x1</span><span class="o">*</span><span class="n">sigma_x2</span><span class="o">*</span><span class="n">rho</span><span class="p">],</span>
               <span class="p">[</span><span class="n">sigma_x1</span><span class="o">*</span><span class="n">sigma_x2</span><span class="o">*</span><span class="n">rho</span><span class="p">,</span> <span class="n">sigma_x2</span><span class="o">**</span><span class="mi">2</span><span class="p">]]</span>
        <span class="n">rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cov</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">pos</span><span class="p">))</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;$</span><span class="se">\\</span><span class="s1">sigma_</span><span class="se">{{</span><span class="s1">x2</span><span class="se">}}</span><span class="s1">$ = </span><span class="si">{</span><span class="n">sigma_x2</span><span class="si">:</span><span class="s1">3.2f</span><span class="si">}</span><span class="se">\n</span><span class="s1">$</span><span class="se">\\</span><span class="s1">rho$ = </span><span class="si">{</span><span class="n">rho</span><span class="si">:</span><span class="s1">3.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">f</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;x_1&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;x_2&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510131210a9.webp" /></p>
<blockquote>
<div><p><strong>图 3.8 二维高斯分布中不同皮尔逊系数的图示。</strong> 上面一行 <span class="math notranslate nohighlight">\(\sigma_{x1}=1.00, \sigma_{x2}=1.00\)</span> ； 下面一行 <span class="math notranslate nohighlight">\(\sigma_{x1}=1.00, \sigma_{x2}=2.00\)</span></p>
</div></blockquote>
</center>
<p>现在我们了解了多元高斯分布，可以用它来进一步估计 <code class="docutils literal notranslate"><span class="pre">Pearson</span> <span class="pre">相关系数</span></code>。 由于我们并不知道协方差矩阵的值，因此只能考虑在其上放置先验，并通过贝叶斯分析得到相应后验。贝叶斯统计方法中常用三种协方差矩阵的先验设置方法：</p>
<ul class="simple">
<li><p>一是使用 <code class="docutils literal notranslate"><span class="pre">Wishart</span> <span class="pre">分布</span></code>直接为<code class="docutils literal notranslate"><span class="pre">协方差矩阵</span></code>设置先验， <code class="docutils literal notranslate"><span class="pre">Wishart</span> <span class="pre">分布</span></code> 是多元高斯分布的逆协方差矩阵的共轭先验，可被视为伽马分布或者 <span class="math notranslate nohighlight">\(\chi^2\)</span> 分布的高维推广。</p></li>
<li><p>二是使用 <a class="reference external" href="https://docs.pymc.io/notebooks/LKJ.html"><code class="docutils literal notranslate"><span class="pre">LKJ</span></code></a> 为<code class="docutils literal notranslate"><span class="pre">相关矩阵</span></code>（注意不是协方差矩阵）设置先验。</p></li>
<li><p>三是为协方差矩阵中的模型参数 <span class="math notranslate nohighlight">\(\sigma_{\mathbf{X}_1}\)</span> 、<span class="math notranslate nohighlight">\(\sigma_{\mathbf{X}_2}\)</span> 和 <span class="math notranslate nohighlight">\(\rho\)</span> 分别设置先验。</p></li>
</ul>
<p>此处探索第三种方法，然后使用这些参数手动构建协方差矩阵：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">pearson_model</span><span class="p">:</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">σ_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ_1&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">σ_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;σ_2&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ρ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s1">&#39;ρ&#39;</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;r2&#39;</span><span class="p">,</span> <span class="n">ρ</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">stack</span><span class="p">(([</span><span class="n">σ_1</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">σ_1</span><span class="o">*</span><span class="n">σ_2</span><span class="o">*</span><span class="n">ρ</span><span class="p">],</span>
				    <span class="p">[</span><span class="n">σ_1</span><span class="o">*</span><span class="n">σ_2</span><span class="o">*</span><span class="n">ρ</span><span class="p">,</span> <span class="n">σ_2</span><span class="o">**</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">MvNormal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">,</span> 
    				<span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="n">trace_p</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>此处仅绘制 <code class="docutils literal notranslate"><span class="pre">r2</span></code> 的轨迹图：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_trace</span><span class="p">(</span><span class="n">trace_p</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;r2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051013133311.webp" /></p>
<blockquote>
<div><p><strong>图 3.9 <span class="math notranslate nohighlight">\(R^2\)</span> 的轨迹图</strong></p>
</div></blockquote>
</center>
<p>可以看到，<span class="math notranslate nohighlight">\(r^2\)</span> 值的分布与上一个示例中使用 <code class="docutils literal notranslate"><span class="pre">ArviZ</span></code> 的 <code class="docutils literal notranslate"><span class="pre">r2_core</span></code> 函数获得的值基本相同。通过摘要可以更简单地进行比较。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_p</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;r2&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510131427f7.webp" /></p>
</center>
</div>
</div>
<div class="section" id="id11">
<h2>3.2 更稳健的线性回归<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>在许多情况下，假设数据服从高斯分布是合理的。但需要注意的是：假设数据符合高斯特性，并不是说数据真的就符合高斯分布，而是说高斯分布对于问题而言是一个合理的、可接受的近似。</p>
<p>有时高斯假设并不成立，例如当数据中存在异常值时，利用学生 <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> 分布可以更有效地解决该问题，从而得到更稳健的推断。类似思想同样可以用于线性回归问题。</p>
<p>为了验证学生 <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> 分布确实能增加线性回归的稳健性，这里使用<a class="reference external" href="https://en.wikipedia.org/wiki/Anscombe%27s_quartet"><code class="docutils literal notranslate"><span class="pre">Anscombe</span> <span class="pre">quartet</span></code></a>数据集中的第 3 组数据。下面代码用 <code class="docutils literal notranslate"><span class="pre">Pandas</span></code> 读取数据，并对数据做中心化处理，以使采样器更容易收敛。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/anscombe.csv&#39;</span><span class="p">)</span>
<span class="n">x_3</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[</span><span class="n">ans</span><span class="o">.</span><span class="n">group</span> <span class="o">==</span> <span class="s1">&#39;III&#39;</span><span class="p">][</span><span class="s1">&#39;x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_3</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[</span><span class="n">ans</span><span class="o">.</span><span class="n">group</span> <span class="o">==</span> <span class="s1">&#39;III&#39;</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">x_3</span> <span class="o">=</span> <span class="n">x_3</span> <span class="o">-</span> <span class="n">x_3</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>先来看看该数据集长什么样：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">beta_c</span><span class="p">,</span> <span class="n">alpha_c</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="n">y_3</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="p">(</span><span class="n">alpha_c</span> <span class="o">+</span> <span class="n">beta_c</span> <span class="o">*</span> <span class="n">x_3</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span>
           <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;y =</span><span class="si">{</span><span class="n">alpha_c</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> + </span><span class="si">{</span><span class="n">beta_c</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> * x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="n">y_3</span><span class="p">,</span> <span class="s1">&#39;C0o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">az</span><span class="o">.</span><span class="n">plot_kde</span><span class="p">(</span><span class="n">y_3</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">rug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510133712af.webp" /></p>
<p>图3.10</p>
</center>
<p>现在用 <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> 分布替换模型中的高斯分布，该改变需要引入正态参数 <span class="math notranslate nohighlight">\(\nu\)</span> ，有关该参数的含义，可参照第 2 章的相关内容。</p>
<p>在下面的模型中，使用平移的指数分布来避免接近零的 <span class="math notranslate nohighlight">\(\nu\)</span> 值。非平移的指数分布给接近零的值赋予过高权重。这对没有异常值的数据来说很好，但对有极端异常值的数据（比如 <code class="docutils literal notranslate"><span class="pre">Anscombe</span></code> 的第三个数据集）最好避免这么低的值。当然，默认设置是很好的起点，但没必要拘泥于它。其他常见的先验还包括 <span class="math notranslate nohighlight">\(\Gamma(2，0.1)\)</span> 或 <span class="math notranslate nohighlight">\(\Gamma(\mu=20，SD=15)\)</span> 等。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_t</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">y_3</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">ν_</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;ν_&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">29</span><span class="p">)</span>
    <span class="n">ν</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;ν&#39;</span><span class="p">,</span> <span class="n">ν_</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">α</span> <span class="o">+</span> <span class="n">β</span> <span class="o">*</span> <span class="n">x_3</span><span class="p">,</span>
                         <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">ν</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_3</span><span class="p">)</span>
    <span class="n">trace_t</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>在下图中，可以看到根据 <code class="docutils literal notranslate"><span class="pre">model_t</span></code> 的稳健拟合和根据 <code class="docutils literal notranslate"><span class="pre">SciPy</span></code> 线性回归的非稳健拟合（采用最小二乘回归）。作为额外练习，你可以尝试添加使用 <code class="docutils literal notranslate"><span class="pre">model_g</span></code> 获得的最佳直线：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">beta_c</span><span class="p">,</span> <span class="n">alpha_c</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="n">y_3</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="p">(</span><span class="n">alpha_c</span> <span class="o">+</span> <span class="n">beta_c</span> <span class="o">*</span> <span class="n">x_3</span><span class="p">),</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;non-robust&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="n">y_3</span><span class="p">,</span> <span class="s1">&#39;C0o&#39;</span><span class="p">)</span>
<span class="n">alpha_m</span> <span class="o">=</span> <span class="n">trace_t</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">beta_m</span> <span class="o">=</span> <span class="n">trace_t</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_3</span><span class="p">,</span> <span class="n">alpha_m</span> <span class="o">+</span> <span class="n">beta_m</span> <span class="o">*</span> <span class="n">x_3</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;robust&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510134431b0.webp" /></p>
<blockquote>
<div><p><strong>图 3.11 稳健和非稳健的拟合结果</strong></p>
</div></blockquote>
</center>
<p>当非稳健拟合试图折衷并包含所有点时，稳健的贝叶斯模型 <code class="docutils literal notranslate"><span class="pre">model_t</span></code> 会自动丢弃一个点，并拟合一条恰好通过所有剩余点的直线。这是一个非常奇特的数据集，但该信息仍然适用于更真实、更复杂的其他数据集。由于学生 <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> 分布是重尾分布，所以可以给异常数据点以较小权重。</p>
<p>在继续前，花一点时间来考虑模型参数的值：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="n">varnames</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051013485414.webp" /></p>
</center>
<p>如表所示，<span class="math notranslate nohighlight">\(\alpha\)</span> 、 <span class="math notranslate nohighlight">\(\beta\)</span> 和 <span class="math notranslate nohighlight">\(\epsilon\)</span> 的值定义非常狭窄，其中对于基本上为 <span class="math notranslate nohighlight">\(0\)</span> 的 <span class="math notranslate nohighlight">\(\epsilon\)</span> 值更是如此。这是完全合理的，因为我们正在将一条线拟合到一组完全对齐的点上（如果忽略异常值）。</p>
<p>运行后验预测检查，以探索模型捕获数据的能力：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_t</span><span class="p">,</span><span class="n">random_seed</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data_ppc</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">from_PyMC3</span><span class="p">(</span><span class="n">trace</span><span class="o">=</span><span class="n">trace_t</span><span class="p">,</span> <span class="n">posterior_predictive</span><span class="o">=</span><span class="n">ppc</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">plot_ppc</span><span class="p">(</span><span class="n">data_ppc</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051013515477.webp" /></p>
<blockquote>
<div><p><strong>图 3.12 后验预测检查示意图</strong></p>
</div></blockquote>
</center>
<p>如图所示，大部分数据得到了非常好的匹配。需要注意的是：此模型的预测值不仅大于整体值，而且位于其两边。就当前目的而言，此模型运行良好，不需要进一步更改。不过对于其他问题，可能希望预测值大于整体值，此时应返回并更改模型。</p>
</div>
<div class="section" id="id12">
<h2>3.3 分层线性回归<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>上一章学习了分层模型的基础知识，现在可以将其应用到线性回归，在分组层次和高于分组的层次建模并估计。与之前相同，这里引入 <code class="docutils literal notranslate"><span class="pre">超先验</span></code>。</p>
<p>首先创建 8 个相关的数据组，其中有一组仅包含一个数据点。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">N</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>
<span class="n">alpha_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
<span class="n">beta_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
<span class="n">eps_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
<span class="n">y_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
<span class="n">x_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
<span class="n">y_m</span> <span class="o">=</span> <span class="n">alpha_real</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_real</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_m</span> <span class="o">+</span> <span class="n">eps_real</span>
<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">N</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_m</span><span class="p">[</span><span class="n">j</span><span class="p">:</span><span class="n">k</span><span class="p">],</span> <span class="n">y_m</span><span class="p">[</span><span class="n">j</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;x_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;y_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">17</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">+=</span> <span class="n">N</span>
    <span class="n">k</span> <span class="o">+=</span> <span class="n">N</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051014002833.webp" /></p>
<p>图3.13</p>
</center>
<p>在将数据提供给模型前先对其做中心化处理：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_centered</span> <span class="o">=</span> <span class="n">x_m</span> <span class="o">-</span> <span class="n">x_m</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>首先，和前面做法一样，先用非多层的模型拟合，唯一区别是需要增加部分代码将 <span class="math notranslate nohighlight">\(α\)</span> 转换到原始尺度。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">unpooled_model</span><span class="p">:</span>
    <span class="n">α_tmp</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α_tmp&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">ν</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;ν&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">α_tmp</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">β</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_centered</span><span class="p">,</span>
                         <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">ν</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_m</span><span class="p">)</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">α_tmp</span> <span class="o">-</span> <span class="n">β</span> <span class="o">*</span> <span class="n">x_m</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">trace_up</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>从结果中可以看到，除了其中一组参数（ <span class="math notranslate nohighlight">\(α7\)</span> 和 <span class="math notranslate nohighlight">\(β7\)</span> ），大多数情况下结果都很正常。根据它们的迹来看，似乎这一组参数一直在自由移动而没有收敛。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">trace_up</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="s1">&#39;β&#39;</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="image-20210510140311255" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202105101641358f.webp" /></p>
<p>图3.14</p>
</center>
<p>显然，用一条唯一的直线去拟合一个点是不合适的，至少需要两个点或者限制参数 <span class="math notranslate nohighlight">\(α\)</span> 和 <span class="math notranslate nohighlight">\(β\)</span> 的范围。此时，如果能提供一些额外的信息，例如给 <span class="math notranslate nohighlight">\(α\)</span> 加入一个很强的先验，则即使数据中只有一个点，也能够收敛。</p>
<p>另一种方式是构建多层模型，为每个分组引入其他分组的信息（<code class="docutils literal notranslate"><span class="pre">分层模型的本质是组与组之间的信息共享</span></code>），这对于已经有不同分组的稀疏数据非常有用。本例将数据稀疏性推向了极致（即其中一组只有一个数据），目的是将问题描述得更清楚一些。</p>
<p>现在实现一个与前面线性回归模型相同的多层模型，不过这次使用超先验（见如下 Kruschke 图 ）</p>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510141026c7.webp" /></p>
<blockquote>
<div><p><strong>图 3.15 稳健线性回归模型的 Kruschke 图</strong></p>
</div></blockquote>
</center>
<p>用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 代码实现的模型与之前模型的主要区别如下：</p>
<ul class="simple">
<li><p>增加了超先验。</p></li>
<li><p>增加了几行代码将参数转换到中心化前的尺度。记住这并非强制的，我们完全可以将参数保留在转换后的尺度上，只是对结果进行解释的时候需要小心。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">hierarchical_model</span><span class="p">:</span>
    <span class="c1"># hyper-priors</span>
    <span class="n">α_μ_tmp</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α_μ_tmp&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">α_σ_tmp</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;α_σ_tmp&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">β_μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β_μ&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β_σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;β_σ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># priors</span>
    <span class="n">α_tmp</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α_tmp&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">α_μ_tmp</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">α_σ_tmp</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">β_μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">β_σ</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">M</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">ν</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Exponential</span><span class="p">(</span><span class="s1">&#39;ν&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">StudentT</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span>
                         <span class="n">mu</span><span class="o">=</span><span class="n">α_tmp</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">β</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_centered</span><span class="p">,</span>
                         <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">ν</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_m</span><span class="p">)</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">α_tmp</span> <span class="o">-</span> <span class="n">β</span> <span class="o">*</span> <span class="n">x_m</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">α_μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;α_μ&#39;</span><span class="p">,</span> <span class="n">α_μ_tmp</span> <span class="o">-</span> <span class="n">β_μ</span> <span class="o">*</span> <span class="n">x_m</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">α_σ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;α_sd&#39;</span><span class="p">,</span> <span class="n">α_σ_tmp</span> <span class="o">-</span> <span class="n">β_μ</span> <span class="o">*</span> <span class="n">x_m</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">trace_hm</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>为了比较 <code class="docutils literal notranslate"><span class="pre">unpooled_model</span></code> 和 <code class="docutils literal notranslate"><span class="pre">hierarhical_model</span></code> 的结果，我们将再做一个森林图：</p>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510141313e8.webp" /></p>
<blockquote>
<div><p><strong>图 3.16 各参数的 94% 可信区间</strong></p>
</div></blockquote>
</center>
<p>使用 <code class="docutils literal notranslate"><span class="pre">az.plot_forest()</span></code> 比较模型的一个好方法是在同一绘图中同时显示两个模型 ( <code class="docutils literal notranslate"><span class="pre">unpooled_model</span></code>、<code class="docutils literal notranslate"><span class="pre">hierarhical_model</span></code>) 的参数。要做到这一点，您只需传递一个迹的列表。为了更好地理解模型捕获的有关数据的内容，为八组中的每一组绘制拟合线：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">j</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">N</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_m</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_m</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_m</span><span class="p">[</span><span class="n">j</span><span class="p">:</span><span class="n">k</span><span class="p">],</span> <span class="n">y_m</span><span class="p">[</span><span class="n">j</span><span class="p">:</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;x_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;y_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">17</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">alpha_m</span> <span class="o">=</span> <span class="n">trace_hm</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">][:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">beta_m</span> <span class="o">=</span> <span class="n">trace_hm</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">][:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">alpha_m</span> <span class="o">+</span> <span class="n">beta_m</span> <span class="o">*</span> <span class="n">x_range</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;y = </span><span class="si">{</span><span class="n">alpha_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> + </span><span class="si">{</span><span class="n">beta_m</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1"> * x&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_m</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">y_m</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">y_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">+=</span> <span class="n">N</span>
    <span class="n">k</span> <span class="o">+=</span> <span class="n">N</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051014144830.webp" /></p>
<blockquote>
<div><p><strong>图 3.17 七个分组的不同拟合结果</strong></p>
</div></blockquote>
</center>
<p>使用分层模型，能够将一条线拟合于单个数据点，如上图所示。乍一看，这可能听起来很奇怪，甚至有点可疑，但这只是分层模型的结果。每一条线都由其他组的线提供通报，因此并不是真正地将一条线拟合为一个点。取而代之的是，将一条线调整为由其他组中的点通报的单个点。</p>
<div class="section" id="id13">
<h3>3.3.1 关于相关性与因果性<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<p>现在假设已经知道了当地的太阳辐射量，想要预测冬天家里的燃气费。在该问题中，太阳的辐射量是自变量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> ，燃气费是因变量 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 。当然，我们完全可以将问题反过来，根据燃气费推算太阳辐射量，一旦建立了一种线性关系（或者其他什么关系），就可以根据 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 得出 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> ，或者反过来这么做。我们称一个变量为自变量是因为它的值不是从模型中预测出来的，而是作为模型的输入，相应的因变量作为模型的输出。当我们说一个变量依赖于另一个变量的时候，这其中的依赖关系是由模型决定的。</p>
<p>我们建立的并不是变量之间的因果关系，即并不是说 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 导致了 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 。永远要记住这句话：相关性并不意味着因果关系。就该话题多说一点，我们可能根据家中的燃气费预测出太阳辐射量或者反过来根据太阳辐射量预测出家中的燃气费。但是显然并不能通过调节燃气阀门来控制太阳的辐射量。不过，太阳辐射量的高低是与燃气费的高低相关的。</p>
<p>因此，需要强调一点，我们构建的统计模型是一回事，变量之间的物理机制又是另外一回事。想要将相关性解释为因果关系，我们还需要给问题的描述增加一些可信的物理机制，仅仅相关性还不够。有一个网页，描述了一些有相关性但并没有因果关系的变量：<a class="reference external" href="http://www.tylervigen.com/spurious-correlations">http://www.tylervigen.com/spurious-correlations</a></p>
<p>那么，相关性是否在确定因果关系时一点用都没有呢？不是。事实上如果能够进行一些精心设计的实验，那么相关性是能够用于支撑因果关系的。举例来说：</p>
<p>我们知道全球变暖与大气中二氧化碳的含量是高度相关的。仅仅根据该观测，我们无法得出结论是温度升高导致的二氧化碳含量上升，还是二氧化碳含量的上升导致了温度升高。更进一步，可能存在某种我们没考虑到的第 3 个变量，导致二氧化碳含量和温度同时上升了。不过，我们可以设计一个实验，将玻璃箱子中充满不同比例的二氧化碳含量，其中一个是正常空气中的含量（约 0.04%），其余箱子中二氧化碳含量逐渐增加，然后让这些箱子接受一定时间的阳光照射（比如 3 个小时）。如果这么做之后能证实二氧化碳含量较高的箱子温度也更高，那么就能得出二氧化碳的含量导致温室效应的结论。同样的实验，我们可以反过来让相同二氧化碳含量的箱子接受不同温度的照射，然后可以看到二氧化碳含量并不会上升（至少空气中的二氧化碳含量不会上升）。事实上，更高的温度会导致二氧化碳含量的上升，因为海洋中蕴含着二氧化碳，随着温度上升，水中蕴含的二氧化碳含量会降低。简言之，全球正在变暖而我们没有采取足够措施解决该问题。</p>
<p>该例子中还有一点需要说明下，尽管太阳辐射量与燃气费相关，根据太阳辐射量可能预测出燃气费，不过如果考虑到一些其他变量，这中间的关系就变得复杂了。我们一起来看一下，更高的太阳辐射量意味着更多的能量传递到家里，部分能量被反射掉了，还有部分转化成了热能，其中部分热量被房子吸收，还有部分散失到环境中了。热能消失多少取决于许多因素，比如室外的温度、风力等。此外，我们还知道，燃气费也受到很多因素影响，比如国际上石油和燃气的价格，燃气公司的成本/利润（及其贪婪程度），国家对燃气公司的管控等。而我们在尝试用两个变量和一条直线对所有这一切建模。因此，充分考虑问题的上下文是有必要的，而且有利于得出更合理的解释，降低得出荒谬结论的风险，从而得到更好的预测，此外还有可能为我们提供线索改进模型。</p>
<p>总而言之，生活是杂乱无章的，问题通常不容易理解，上下文总是很重要的。统计模型可以帮助我们实现更好的解释，降低做出无稽之谈的风险，并获得更好的预测，但这些都不是自动的。</p>
</div>
</div>
<div class="section" id="id14">
<h2>3.4 多项式回归<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>接下来，将学习如何用线性回归拟合曲线。使用线性回归模型去拟合曲线的一种做法是构建如下多项式：</p>
<div class="math notranslate nohighlight">
\[
\mu=\beta_{0} x^{0}+\beta_{1} x^{1} \cdots+\beta_{m} x^{m} \tag{式3.12}
\]</div>
<p>可以看到多项式中其实包含了一元线性回归模型，只需将上式中 <span class="math notranslate nohighlight">\( n&gt;1\)</span> 的系数 <span class="math notranslate nohighlight">\(β_n\)</span> 设为 <span class="math notranslate nohighlight">\(0\)</span> 即可得到下式：</p>
<div class="math notranslate nohighlight">
\[
\mu=\beta_{0}+\beta_{1} x^{1} \tag{式3.13}
\]</div>
<p>多项式回归仍然是线性回归，此处“线性”的意思是<code class="docutils literal notranslate"><span class="pre">指模型中的参数是线性组合的，而不是指变量是线性变化的</span></code>。现从一个简单的抛物线开始构建多项式回归模型：</p>
<div class="math notranslate nohighlight">
\[
\mu=\beta_{0}+\beta_{1} x^{1}+\beta_{2} x^{2}  \tag{式3.14}
\]</div>
<p>其中第 3 项控制曲率。数据选用 <code class="docutils literal notranslate"><span class="pre">Anscombe</span> <span class="pre">quartet</span></code> 的第 2 组数据集</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_2</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[</span><span class="n">ans</span><span class="o">.</span><span class="n">group</span> <span class="o">==</span> <span class="s1">&#39;II&#39;</span><span class="p">][</span><span class="s1">&#39;x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_2</span> <span class="o">=</span> <span class="n">ans</span><span class="p">[</span><span class="n">ans</span><span class="o">.</span><span class="n">group</span> <span class="o">==</span> <span class="s1">&#39;II&#39;</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">x_2</span> <span class="o">-</span> <span class="n">x_2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_2</span><span class="p">,</span> <span class="n">y_2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051014252547.webp" /></p>
<blockquote>
<div><p><strong>图 3.18  <code class="docutils literal notranslate"><span class="pre">Anscombe</span> <span class="pre">quartet</span></code> 数据集的散点图</strong></p>
</div></blockquote>
</center>
<p>现在建立 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 模型如下：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_poly</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">y_2</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">β1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">β2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β1</span> <span class="o">*</span> <span class="n">x_2</span> <span class="o">+</span> <span class="n">β2</span> <span class="o">*</span> <span class="n">x_2</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y_2</span><span class="p">)</span>
    <span class="n">trace_poly</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>此处省略一些检查和摘要工作，直接绘制结果，这将是一条很好的曲线，几乎没有错误地拟合了数据。考虑到数据集的极简主义性质：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">y_p</span> <span class="o">=</span> <span class="n">trace_poly</span><span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">+</span> <span class="n">trace_poly</span><span class="p">[</span><span class="s1">&#39;β1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> \
    <span class="n">x_p</span> <span class="o">+</span> <span class="n">trace_poly</span><span class="p">[</span><span class="s1">&#39;β2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="n">x_p</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_2</span><span class="p">,</span> <span class="n">y_2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_p</span><span class="p">,</span> <span class="n">y_p</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id15">
<h3>3.4.1 多项式回归系数的可解释性困局<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>多项式回归的问题之一在于参数的可解释性。如果想知道 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 相对于 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 的变化量，不能只看 <span class="math notranslate nohighlight">\(β_1\)</span> ，因为 <span class="math notranslate nohighlight">\(β_2\)</span> 和更高项的系数对其也有影响。因此，系数 <span class="math notranslate nohighlight">\(β\)</span> 的值不再表示斜率。前面的例子中 <span class="math notranslate nohighlight">\(β_1\)</span> 是正数，因而曲线是以一个大于 0 的斜率开始的，但由于 <span class="math notranslate nohighlight">\(β_2\)</span> 是负数，因而随后曲线的斜率开始下降。这看起来就好像有两股力量，一个使直线向上，另一个使直线向下，二者相互作用的结果取决于 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> ，当 <span class="math notranslate nohighlight">\(x_i&lt;11\)</span> 时（在原始尺度上，如果是在中心尺度上则为 2）， <span class="math notranslate nohighlight">\(β_1\)</span> 起决定作用，而当 <span class="math notranslate nohighlight">\(x_i&gt;11\)</span> 时， <span class="math notranslate nohighlight">\(β_2\)</span> 起决定作用。</p>
<p>如何解释参数不仅是个数学问题，因为需要通过仔细检查和理解模型来解决问题。不过许多情况下，参数并不能根据我们的领域知识转换为有意义的量，例如：我们无法将其与细胞的新陈代谢速率、或者恒星释放的能量、或者房间里的卧室数联系起来。它们只是些没有物理意义的参数。这样的模型或许对于预测有用，但对于理解数据在底层是如何生成的并没有多大帮助。而且在实际中，超过 2 阶或者 3 阶的多项式模型并没有多大用途，我们更倾向于使用一些其他模型。</p>
</div>
<div class="section" id="id16">
<h3>3.4.2 多项式回归不应成为代替其他模型的“终极模型”<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<p>我们知道，直线可以看作是当 <span class="math notranslate nohighlight">\(β_2\)</span> 为 0 时抛物线的子模型，还可以看作是 <span class="math notranslate nohighlight">\(β_2\)</span> 和 <span class="math notranslate nohighlight">\(β_3\)</span> 都为 0 时的 3 次方模型的子模型。显然，抛物线模型也可以看作是当 <span class="math notranslate nohighlight">\(β_3\)</span> 为 0 时 3 次方模型的子模型。….</p>
<p>这似乎意味着存在一种算法可以使用线性回归模型去拟合任意复杂的模型。我们先构建一个无限高阶的多项式，然后将其中的大部分参数置零，直到得到对数据的完美拟合。为验证该想法，可以从简单例子开始，用刚刚构建的 2 次模型去拟合 <code class="docutils literal notranslate"><span class="pre">Anscombe</span> <span class="pre">quartet</span></code> 的第 3 个数据集。</p>
<p>完成练习之后，你会发现用 2 次模型去拟合直线是可能的。该例子看起来似乎验证了可以使用无限高阶多项式去拟合数据这一思想，但是通常用多项式去拟合数据并不是最好的办法。为什么呢？</p>
<p>因为该方法并不关心数据是怎么来的，从原理上讲，我们始终能够找到一个多项式去完美拟合数据。如果一个模型完美拟合了当前数据，那么通常对于没有观测到的数据会表现得很糟糕，原因是现实中的任意数据集都同时包含一些噪声和一些感兴趣的模式。一个过于复杂的模型会同时拟合噪声，从而使得预测结果变差，这称作过拟合，一个在统计学和机器学习中常见的现象。越复杂的模型越容易导致过拟合，因而分析数据时，需要确保模型没有产生过拟合，我们将在<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">5</span> <span class="pre">章</span> <span class="pre">模型比较</span></code> 中详细讨论。</p>
<p>除了过拟合问题，我们通常倾向于更容易理解的模型。从物理意义上讲，线性模型的参数要比 3 次模型的参数更容易解释，即便 3 次模型对数据拟合得更好。</p>
</div>
</div>
<div class="section" id="id17">
<h2>3.5 多元线性回归<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h2>
<p>前面的所有例子中，我们讨论的都是一个因变量和一个自变量的情况，不过在许多例子中，模型可能包含多个自变量。例如：</p>
<ul class="simple">
<li><p>红酒的口感（因变量）与酒的酸度、比重、酒精含量、甜度以及硫酸盐含量（自变量）的关系；</p></li>
<li><p>学生的平均成绩（因变量）与家庭收入、家到学校的距离、母亲的受教育程度（自变量）的关系。</p></li>
</ul>
<p>这种情况下，因变量可以这样建模：</p>
<div class="math notranslate nohighlight">
\[
\mu=\alpha+\beta_{1} x_{1}+\beta_{2} x_{2} \cdots+\beta_{m} x_{m} \tag{式3.15}   
\]</div>
<p>注意该式与多项式回归的式子不一样，现在有了多个变量而不再是一个变量的多次方。用线性代数方法可以表示为更简洁的形式：</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\mu}=\boldsymbol{\alpha}+ \mathbf{X} \boldsymbol{\beta} \tag{式3.16} 
\]</div>
<p>其中， <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> 是一个长度为 <span class="math notranslate nohighlight">\(m\)</span> 的系数向量，也就是说，自变量的个数为 <span class="math notranslate nohighlight">\(m\)</span> 。变量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 是一个维度为 <span class="math notranslate nohighlight">\(n×m\)</span> 的矩阵，其中， <span class="math notranslate nohighlight">\(n\)</span> 为观测的样本数， <span class="math notranslate nohighlight">\(m\)</span> 表示自变量个数。有关线性代数，可参阅相关书籍。本书中，您需要知道的只是使用了一种更短、更方便的方式来编写我们的模型：</p>
<div class="math notranslate nohighlight">
\[
\mathbf{X} \boldsymbol{\beta}=\sum_{i=1}^{n} \beta_{i} x_{i}=\beta_{1} x_{1}+\beta_{2} x_{2} \cdots+\beta_{m} x_{m} \tag{式3.17}
\]</div>
<p>在一元线性回归模型中，我们希望找到一条直线来解释数据，而在多元线性回归模型中，我们希望找到一个维度为 <span class="math notranslate nohighlight">\(m\)</span> 的超平面来解释数据。因此，多元线性回归模型本质上与一元线性回归模型是一样的，唯一区别是：现在 <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> 是一个向量而 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 是一个矩阵。</p>
<p>现在定义如下数据：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">314</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">alpha_real</span> <span class="o">=</span> <span class="mf">2.5</span>
<span class="n">beta_real</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>
<span class="n">eps_real</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span>
<span class="mf">1.5</span><span class="p">])])</span><span class="o">.</span><span class="n">T</span>
<span class="n">X_mean</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_centered</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X_mean</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">alpha_real</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta_real</span><span class="p">)</span> <span class="o">+</span> <span class="n">eps_real</span>
</pre></div>
</div>
</div>
</div>
<p>然后定义一个函数去画 3 个散点图，前两个表示的是自变量与因变量的关系，最后一个表示的是两个自变量之间的关系。这种散点图使用很频繁，而且只需要调用一个简单的绘图函数，本章后面将会反复用到。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">scatter_plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">x_i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;x_</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;x_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;x_</span><span class="si">{</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>用前面刚刚定义的 scatter_plot 可以将我们的合成数据可视化地表示出来。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scatter_plot</span><span class="p">(</span><span class="n">X_centered</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510144455e0.webp" /></p>
<blockquote>
<div><p><strong>图 3.19 多元线性回归数据集的散点图</strong></p>
</div></blockquote>
</center>
<p>现在用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 针对多变量线性回归问题定义出一个合适的模型，代码部分与单变量线性回归的代码基本一致，唯一的区别是：</p>
<ul class="simple">
<li><p>参数 <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> 是高斯分布的向量，<code class="docutils literal notranslate"><span class="pre">shape</span></code> 为 2，即每个独立参数都对应有一个斜率；</p></li>
<li><p>使用 <code class="docutils literal notranslate"><span class="pre">pm.math.dot()</span></code> 来定义均值变量 <span class="math notranslate nohighlight">\(\mu\)</span> ，也就是前面提到的线性代数中的点乘（或者矩阵相乘），根据公式，<span class="math notranslate nohighlight">\(\mu\)</span> 应当为确定性变量；</p></li>
</ul>
<p>如果你对 <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> 比较熟悉，那么应该知道 <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> 包含一个面向数组的点乘函数，并且 <code class="docutils literal notranslate"><span class="pre">Python</span> <span class="pre">3.5</span></code>（以及 <code class="docutils literal notranslate"><span class="pre">NumPy1.10</span></code>）之后增加了一个新的操作符 <code class="docutils literal notranslate"><span class="pre">&#64;</span></code>。不过这里我们使用的是 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 中的点乘函数 <code class="docutils literal notranslate"><span class="pre">dot()</span></code> （该函数是对底层  <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 函数的一个封装） ，因为变量 <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> 定义为一个 <code class="docutils literal notranslate"><span class="pre">Theano</span></code> 张量而非 <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> 数组。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_mlr</span><span class="p">:</span>
    <span class="n">α_tmp</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α_tmp&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">α_tmp</span> <span class="o">+</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_centered</span><span class="p">,</span> <span class="n">β</span><span class="p">)</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">α_tmp</span> <span class="o">-</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_mean</span><span class="p">,</span> <span class="n">β</span><span class="p">))</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">trace_mlr</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>现在看一下推断出来的参数的总结，这样分析结果会更容易一些。我们的模型表现如何呢？</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">varnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="s1">&#39;ϵ&#39;</span><span class="p">]</span>
<span class="n">az</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">trace_mlr</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="n">varnames</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510144845f1.webp" /></p>
</center>
<p>可以看到，模型能够重现正确的值（对比生成数据用的值）。</p>
<p>接下来，将重点关注在分析多变量线性回归模型中需要注意的点，特别是对斜率的解释。这里需要特别提醒的是：<code class="docutils literal notranslate"><span class="pre">每个参数只有在整体考虑了其他参数的情况下才有意义</span></code>。</p>
<div class="section" id="id18">
<h3>3.5.1 多元线性回归中的混淆变量和冗余变量<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h3>
<p>设想这样一种情况：有一个变量 <span class="math notranslate nohighlight">\(z\)</span> 与自变量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 相关，同时还与因变量 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 相关。假设 <span class="math notranslate nohighlight">\(z\)</span> 对 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 和 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 都有影响，例如， <span class="math notranslate nohighlight">\(z\)</span> 是工业革命（一个相当复杂的变量）， <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 是海盗的数量， <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 是二氧化碳浓度。如果在分析中将 <span class="math notranslate nohighlight">\(z\)</span> 去掉，我们会得出结论： <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 与 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 之间有完美的线性相关性，甚至可以通过 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 来预测 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 。但如果我们关注的重点是如何缓解全球变暖问题，那么可能完全没搞清到底发生了什么以及其内在机制是什么。</p>
<blockquote>
<div><p>注：这里隐含表达了因果推断的问题，通过数据的相关性是一个事情，而其内部因果机制则可能是另外一个事情。</p>
</div></blockquote>
<p>前面已经讨论了相关性并不意味着因果关系，原因可能是在分析过程中忽略了变量 <span class="math notranslate nohighlight">\(z\)</span> 。在这种情况下， <span class="math notranslate nohighlight">\(z\)</span> 称作混淆变量（或混淆因素）。<strong>现实中最大的问题是混淆变量 <span class="math notranslate nohighlight">\(z\)</span> 很容易被忽视</strong>。可能的原因包括：</p>
<ul class="simple">
<li><p>确实压根儿没有测量 <span class="math notranslate nohighlight">\(z\)</span></p></li>
<li><p>拿到手的数据集中，缺失了 <span class="math notranslate nohighlight">\(z\)</span></p></li>
<li><p>实验时考虑不周全，没想到 <span class="math notranslate nohighlight">\(z\)</span> 可能与关心的问题有联系</p></li>
</ul>
<p>没有考虑到混淆变量可能会导致分析得出无法解释的相关性，这在解释数据和做预测时是一个问题。</p>
<p>理解底层数据的生成机制有利于将学到的东西迁移到新场景中，相反，盲目的预测很难迁移。例如，帆布鞋产量可以作为一个反映国家经济实力的易测指标，但是对那些 <em>生产链不同</em> 或者 <em>文化背景不同</em> 的国家而言，用帆布鞋产量作为指标可能导致错误的结果。</p>
<p>下面使用人工合成数据来探讨混淆变量的问题。下面的代码中模拟了一个混淆变量 <span class="math notranslate nohighlight">\(x_1\)</span>，注意该变量是如何影响 <span class="math notranslate nohighlight">\(x_2\)</span>和 <span class="math notranslate nohighlight">\(y\)</span> 的。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1">#x_2 = x_1 + np.random.normal(size=N, scale=0.01)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<p>根据生成数据的方式，可以看出变量已经中心化了。因此，不需要再对数据进行中心化处理了，事实上该例中的数据已经同时做了归一化。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scatter_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510145615c1.webp" /></p>
<blockquote>
<div><p><strong>图 3.20 存在混淆变量时的多元线性回归数据集对应的散点图</strong></p>
</div></blockquote>
</center>
<p>现在建立三个相关模型：</p>
<ul class="simple">
<li><p>第一个模型 <code class="docutils literal notranslate"><span class="pre">m_x1x2</span></code>，是有两个自变量的线性回归模型，<span class="math notranslate nohighlight">\(x_1\)</span> 和 <span class="math notranslate nohighlight">\(x_2\)</span> （在变量 X 中堆叠在一起）。</p></li>
<li><p>第二个模型 <code class="docutils literal notranslate"><span class="pre">m_x1</span></code>， 是 <span class="math notranslate nohighlight">\(x_1\)</span> 的简单线性回归模型。</p></li>
<li><p>第三个模型 <code class="docutils literal notranslate"><span class="pre">m_x2</span></code>， 是 <span class="math notranslate nohighlight">\(x_2\)</span> 的简单线性回归模型。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">m_x1x2</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β1</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">β2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">trace_x1x2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">m_x1</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β1&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β1</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">trace_x1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">m_x2</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β2&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β2</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">trace_x2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>使用森林图，可以在一个图中对这些模型的参数 <span class="math notranslate nohighlight">\(\beta\)</span>进行比较：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">([</span><span class="n">trace_x1x2</span><span class="p">,</span> <span class="n">trace_x1</span><span class="p">,</span> <span class="n">trace_x2</span><span class="p">],</span>
               <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;m_x1x2&#39;</span><span class="p">,</span> <span class="s1">&#39;m_x1&#39;</span><span class="p">,</span> <span class="s1">&#39;m_x2&#39;</span><span class="p">],</span>
               <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;β1&#39;</span><span class="p">,</span> <span class="s1">&#39;β2&#39;</span><span class="p">],</span>
               <span class="n">combined</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;cycle&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202105101500367e.webp" /></p>
<p>图3.21</p>
</center>
<p>正如所看到的，对于模型 <code class="docutils literal notranslate"><span class="pre">m_x1x2</span></code>，<span class="math notranslate nohighlight">\(\beta_2\)</span> 值大约为零，表明对于解释 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 变量， <span class="math notranslate nohighlight">\(x_2\)</span> 的贡献几乎为零。这非常有趣，因为在人工合成数据时，我们已经知道真正重要的变量是 <span class="math notranslate nohighlight">\(x_1\)</span> 。还要注意：模型 <code class="docutils literal notranslate"><span class="pre">m_x2</span></code> 的 <span class="math notranslate nohighlight">\(\beta_2\)</span> 值约为 0.55。这比模型 <code class="docutils literal notranslate"><span class="pre">m_x1x2</span></code> 的大。即当考虑 <span class="math notranslate nohighlight">\(x_1\)</span> 时，<span class="math notranslate nohighlight">\(x_2\)</span> 的预测能力就会降低；也就是说，当给定 <span class="math notranslate nohighlight">\(x_1\)</span> 时， <span class="math notranslate nohighlight">\(x_2\)</span> 给出的信息是冗余的。</p>
</div>
<div class="section" id="id19">
<h3>3.5.2 多重共线性或相关性太高有影响吗？<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h3>
<p>前面的例子中，可以看到多元线性回归模型中的冗余变量问题，同时还了解了混淆变量的重要性。</p>
<p>接下来沿着前面例子继续深入学习：当两个预测（自）变量高度相关时会发生什么。为了研究该问题以及其对推断的影响，我们使用和前面一样的合成数据和模型，不过采用 <em>减小根据 <span class="math notranslate nohighlight">\(x_1\)</span> 生成 <span class="math notranslate nohighlight">\(x_2\)</span> 时的随机噪声</em> 的方式，增加了  <span class="math notranslate nohighlight">\(x_1\)</span> 和  <span class="math notranslate nohighlight">\(x_2\)</span> 之间的相关性：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x_1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<p>数据生成代码中的这种变化实际上等同于将零加到 <span class="math notranslate nohighlight">\(x_1\)</span> ，因此，在所有实际目的中，这两个变量都是相等的。然后，您可以尝试改变尺度值并使用不太极端的值，但现在我们想让事情简单些。生成新数据后，检查散点图的外观：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scatter_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051015131081.webp" /></p>
<blockquote>
<div><p><strong>图 3.22 当两个预测（自）变量高度线性相关时的数据集，以及其对应的散点图</strong></p>
</div></blockquote>
</center>
<p>您应该看到上图中，<span class="math notranslate nohighlight">\(x_1\)</span> 和 <span class="math notranslate nohighlight">\(x_2\)</span> 的散点图实际上是一条斜率约为 1 的直线。然后，运行多元线性回归：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_red</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfCauchy</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">α</span> <span class="o">+</span> <span class="n">pm</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">β</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">trace_red</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>用森林图检查参数 <span class="math notranslate nohighlight">\(\beta\)</span> 的结果：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">(</span><span class="n">trace_red</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">],</span> <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510151553cf.webp" /></p>
<p>图3.23</p>
</center>
<p><span class="math notranslate nohighlight">\(\beta\)</span> 参数的 <code class="docutils literal notranslate"><span class="pre">HPD</span> <span class="pre">区间</span></code> 相当广，与先验几乎一样。可以从系数的散点图中得到一些线索：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_pair</span><span class="p">(</span><span class="n">trace_red</span><span class="p">,</span> <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;β&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510151732e5.webp" /></p>
<p>图3.24</p>
</center>
<p>哇！参数 <span class="math notranslate nohighlight">\(\beta\)</span> 的后验是一条非常窄的对角线。当一个系数上升时，另一个系数必然下降。两者实际上是相关的。这只是模型和数据的结果。根据模型，平均值 <span class="math notranslate nohighlight">\(\mu\)</span> 是：</p>
<div class="math notranslate nohighlight">
\[
\mu=\alpha+\beta_{1} x_{1}+\beta_{2} x_{2} \tag{式3.19}  
\]</div>
<p>假设  <span class="math notranslate nohighlight">\(x_1\)</span> 和  <span class="math notranslate nohighlight">\(x_2\)</span> 不只是近似相同，而是完全一样的，那么可以将模型改写成如下形式：</p>
<div class="math notranslate nohighlight">
\[
\mu=\alpha+（\beta_{1} +\beta_{2}） x \tag{式3.20}  
\]</div>
<p>可以看到，对 <span class="math notranslate nohighlight">\(μ\)</span> 有影响的是  <span class="math notranslate nohighlight">\(\beta_1\)</span> 与 <span class="math notranslate nohighlight">\(\beta_2\)</span> 的和而不是二者单独的值。因此，此时模型是不确定的（或者说，数据并不能决定  <span class="math notranslate nohighlight">\(\beta_1\)</span> 和 <span class="math notranslate nohighlight">\(\beta_2\)</span> 的值）。在本示例中，<span class="math notranslate nohighlight">\(\beta\)</span> 并不能在区间 [-∞,∞] 内自由移动，原因有两个：其一，两个变量几乎相同，不过并非完全一样；其二，更重要的是 <span class="math notranslate nohighlight">\(\beta\)</span> 系数的可能取值受到了先验约束。</p>
<p>该例子中有几点需要注意。</p>
<ul class="simple">
<li><p>第 1 点，后验只是根据模型和数据得出的逻辑上的结果，因而得出一个分布很广的 <span class="math notranslate nohighlight">\(\beta\)</span> 分布并没有错，事实就是这样子；</p></li>
<li><p>第 2 点是，可以依据该模型做预测，并尝试做后验预测检查，该模型预测得到的值与数据分布是一致的，也就是说模型对数据拟合得很好；</p></li>
<li><p>第 3 点是，对于理解问题而言这可能不是一个很好的模型，更好的做法是从模型中去掉一个参数，这样模型的预测能力与以前一样，但更容易解释。</p></li>
</ul>
<p><strong>在任何真实的数据集中，相关性是普遍存在的。那么两个或多个变量之间相关性多高时会导致问题呢？事实上并没有确切的数值。</strong></p>
<p>可以在运行贝叶斯模型之前，通过构建相关矩阵来了解变量之间的相关性，对其中相关性较高（比如说高于 0.9）的变量进行检查。但仅根据相关矩阵来观察和分析相关性有时并不太重要，因为还要结合具体模型，才能反映出变量相关性对模型的实质性影响。</p>
<p>前面示例也表明，不同变量在单独情况下的表现与放一起时的表现是不同的。在多元回归模型中，两个或多个变量之间的相关性可能会受其他变量影响，从而使得其相关性降低或者升高。建议在迭代式构建模型的同时，加入一些诊断环节（比如检查自相关性和后验），这有利于发现问题和理解模型与数据。</p>
<p>以下是发现高相关性变量后，应对的一些经验性做法：</p>
<ul class="simple">
<li><p><strong>（1）剔除一个变量</strong>。如果相关性非常高，可以从分析中将其中一个变量去掉。如果两个变量的信息都差不多，具体去掉哪个并不重要，可以视方便程度（比如去掉最不常见的或者最难解释或测量的变量）。</p></li>
<li><p><strong>（2）对变量做<code class="docutils literal notranslate"><span class="pre">平均</span></code>或 <code class="docutils literal notranslate"><span class="pre">PCA</span></code> 等变换</strong>。另外一种可行做法是构建一个新变量对冗余变量求均值。更高级的做法是使用一些降维算法，如<code class="docutils literal notranslate"><span class="pre">主成分分析法（PCA）</span></code>。不过 <code class="docutils literal notranslate"><span class="pre">PCA</span></code> 的问题是其结果变量是原始变量的线性组合，缺乏可解释性。</p></li>
<li><p><strong>（3）给变量设置强信息先验</strong>。第三种办法是给变量可能的取值设置一个较强的先验。在<code class="docutils literal notranslate"><span class="pre">第</span> <span class="pre">6</span> <span class="pre">章</span> <span class="pre">模型比较</span></code> 中会简要讨论如何选择此类正则先验。</p></li>
</ul>
</div>
<div class="section" id="id20">
<h3>3.5.3 通过多元线性回归防止掩蔽效应<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h3>
<p>有一种情况与前面见过的类似，其中某个变量与因变量正相关而另外一个与因变量负相关，此时单独使用其中某一个变量构造的模型都会有问题，必须通过多元回归来消除这种效应。这里人工合成一些数据来说明。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">126</span>
<span class="n">r</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">r</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">x_1</span> <span class="o">-</span> <span class="n">x_2</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">scatter_plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<img src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510155007ff.webp" style="zoom: 50%;" />
<p>图3.25</p>
</center>
<p>正如之前所做的那样，我们将构建三个相关的模型：</p>
<ul class="simple">
<li><p>第一个是 <code class="docutils literal notranslate"><span class="pre">m_x1x2</span></code>，它是一个有两个自变量的线性回归模型，并且（在变量 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 中堆叠在一起）。</p></li>
<li><p>第二个模型 <code class="docutils literal notranslate"><span class="pre">m_x1</span></code>，它是一个对 <span class="math notranslate nohighlight">\(x_1\)</span> 的简单线性回归。</p></li>
<li><p>第三个模型 <code class="docutils literal notranslate"><span class="pre">m_x2</span></code>，它是一个对 <span class="math notranslate nohighlight">\(x_2\)</span> 的简单线性回归。</p></li>
</ul>
<p>从这些模型采样后，使用森林图查看参数进行比较：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">az</span><span class="o">.</span><span class="n">plot_forest</span><span class="p">([</span><span class="n">trace_x1x2</span><span class="p">,</span> <span class="n">trace_x1</span><span class="p">,</span> <span class="n">trace_x2</span><span class="p">],</span>
               <span class="n">model_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;m_x1x2&#39;</span><span class="p">,</span> <span class="s1">&#39;m_x1&#39;</span><span class="p">,</span> <span class="s1">&#39;m_x2&#39;</span><span class="p">],</span>
               <span class="n">var_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;β1&#39;</span><span class="p">,</span> <span class="s1">&#39;β2&#39;</span><span class="p">],</span>
               <span class="n">combined</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;cycle&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510155120c2.webp" /></p>
<p>图3.26</p>
</center>
<p>从后验可以看出，模型 <code class="docutils literal notranslate"><span class="pre">m_x1x2</span></code>的 <span class="math notranslate nohighlight">\(\beta\)</span> 值接近 1 和 -1。也就是说，<span class="math notranslate nohighlight">\(x_1\)</span> 与 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 正相关， <span class="math notranslate nohighlight">\(x_2\)</span> 与 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 负相关。而对于单变量的简单线性回归模型， <span class="math notranslate nohighlight">\(β\)</span> 接近 0。也就是说：每个变量单独都不足以预测 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> ，而其组合在一起后就可以预测 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 。</p>
<p>注意 <span class="math notranslate nohighlight">\(x_1\)</span> 和 <span class="math notranslate nohighlight">\(x_2\)</span> 是相关的，事实上当  <span class="math notranslate nohighlight">\(x_1\)</span> 增加时  <span class="math notranslate nohighlight">\(x_2\)</span> 也增加。 同时应注意当 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 增加时， <span class="math notranslate nohighlight">\(x_1\)</span> 在增加，但 <span class="math notranslate nohighlight">\(x_2\)</span> 在降低。作为特殊安排的结果，除非将两个变量包含在同一线性回归模型中，否则会得到部分抵消的效应。</p>
</div>
<div class="section" id="id21">
<h3>3.5.4 在多元线性回归模型中增加变量间的交互作用<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h3>
<p>目前为止，所有多元回归模型的定义中，在其他自变量固定的条件下，  <span class="math notranslate nohighlight">\(x_1\)</span> 的变化都会隐式地带来 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 的稳定变化。不过这显然并非一定的，有可能改变  <span class="math notranslate nohighlight">\(x_2\)</span> 之后，原来 <span class="math notranslate nohighlight">\(\mathbb{y}\)</span> 与 <span class="math notranslate nohighlight">\(x_1\)</span> 之间的关系发生了改变。一个经典例子是药物之间的相互作用，例如，在没有使用药物 B 时，增加药物 A 的剂量有正向影响，而当增加药物 B 的剂量时，药物 A 反而有负向影响。</p>
<p>目前见过的所有例子中，因变量对于自变量的作用都是加性的。我们只是增加变量并乘以一个系）。如果希望捕捉到前述药物变量间的交互效应，需要给模型增加一项非加性的量，例如：变量间的乘积：</p>
<div class="math notranslate nohighlight">
\[
\mu=\alpha+\beta_{1} x_{1}+\beta_{2} x_{2}+\beta_{3} x_{1} x_{2} \tag{式3.21} 
\]</div>
<p>注意这里系数 <span class="math notranslate nohighlight">\( β_3\)</span>  乘的是  <span class="math notranslate nohighlight">\(x_1\)</span> 和  <span class="math notranslate nohighlight">\(x_2\)</span> 的乘积，该非加性项只是用来说明统计学中的变量间相互作用的一个例子，因为它衡量了变量之间的相关性。事实上对相关性建模的表达式有很多种，相乘只是其中一个比较常用的。</p>
<p>解释有交互作用的线性模型并不像解释没有交互作用的线性模型那么容易。让我们重写表达式 3.21：</p>
<div class="math notranslate nohighlight">
\[
\mu =\alpha+\underbrace{\left(\beta_{1}+\beta_{3} x_{2}\right)}_{\text {slope of } x_{1}} x_{1}+\beta_{2} x_{2} 
\]</div>
<div class="math notranslate nohighlight">
\[
\mu =\alpha+\beta_{1} x_{1}+\underbrace{\left(\beta_{2}+\beta_{3} x_{1}\right)}_{\text {slope of } x_{2}} x_{2}  \tag{式3.22}
\]</div>
<p>上式表明以下内容：</p>
<ul class="simple">
<li><p><strong>（1）交互作用项可以理解为线性模型</strong>。因此，平均值 <span class="math notranslate nohighlight">\(\mu\)</span> 的表达式是一个线性模型，其中包含另一个线性模型！</p></li>
<li><p><strong>（2）交互作用是对称的</strong>。可以把 <span class="math notranslate nohighlight">\(\beta_3 x_1 x_2\)</span> 理解为： <span class="math notranslate nohighlight">\(x_1\)</span> 的斜率是 <span class="math notranslate nohighlight">\(x_2\)</span> 的函数，也可以看作 <span class="math notranslate nohighlight">\(x_2\)</span> 的斜率是 <span class="math notranslate nohighlight">\(x_1\)</span> 的函数。</p></li>
<li><p><strong>（3）在多元线性回归模型中，如果没有变量之间的交互作用项，将得到一个超平面，但在加入交互作用项后，会有超平面变为超曲面。</strong></p></li>
<li><p><strong>（4） 可以将非交互作用项的系数 <span class="math notranslate nohighlight">\(\beta_1\)</span> 视为仅描述了当 <span class="math notranslate nohighlight">\(x_2=0\)</span> 时 <span class="math notranslate nohighlight">\(x_1\)</span> 对因变量的影响</strong>。同样的推断也可适用于 <span class="math notranslate nohighlight">\(\beta_2\)</span> 。</p></li>
</ul>
</div>
</div>
<div class="section" id="id22">
<h2>3.6 变方差的线性回归模型<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h2>
<p>前述章节一直使用线性模型来建模概率分布的平均值 <span class="math notranslate nohighlight">\(\mu\)</span> ，上一节甚至使用它来建模了交互作用。但是，上述模型均建立在同方差假设（即假设变量的方差相等）基础之上，当同方差假设不成立（或没意义）时，一样可以用线性模型对方差（或标准差）建模，此时可能希望将方差视为自变量的函数。当该函数是线性函数时，被称为变方差的线性回归模型。</p>
<p>世界卫生组织和世界各地其他卫生机构收集新生儿和学步儿童的数据，并设计了标准的生长图表。这些图表是儿童工具包的重要组成部分，也是衡量人口总体幸福感的指标（ <a class="reference external" href="http://www.Who.int/ChildGrowth/en/">链接</a>）。这些数据的一个例子是新生女孩的身高随年龄（以月为单位）的变化：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;../data/babies.csv&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="s1">&#39;Month&#39;</span><span class="p">,</span> <span class="s1">&#39;Lenght&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510153936bd.webp" />
图 3.27</p>
</center>
<p>为对此数据建模，我们引入三个新元素，与之前模型的区别在于：</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\epsilon\)</span> 现在是 <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> 的线性函数。为此，我们添加了两个新参数，<span class="math notranslate nohighlight">\(\gamma\)</span> 和 <span class="math notranslate nohighlight">\(\delta\)</span> 。这是和 <span class="math notranslate nohighlight">\(\alpha、\beta\)</span>的直接类比。</p></li>
<li><p>均值 <span class="math notranslate nohighlight">\(\mu\)</span> 的线性模型是 <span class="math notranslate nohighlight">\(\sqrt{x}\)</span> 的函数，将线性模型拟合到曲线上，仅用于说明案例，无物理解释。</p></li>
<li><p>定义了一个共享变量 <code class="docutils literal notranslate"><span class="pre">x_shared</span></code> 。在模型拟合之后，用它来更改变量（在本例中为 Month) 的值，而无需重新调整模型。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model_vv</span><span class="p">:</span>
    <span class="n">α</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;α&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">β</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;β&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">γ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;γ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">δ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">HalfNormal</span><span class="p">(</span><span class="s1">&#39;δ&#39;</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">x_shared</span> <span class="o">=</span> <span class="n">shared</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Month</span><span class="o">.</span><span class="n">values</span> <span class="o">*</span> <span class="mf">1.</span><span class="p">)</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;μ&#39;</span><span class="p">,</span> <span class="n">α</span> <span class="o">+</span> <span class="n">β</span> <span class="o">*</span> <span class="n">x_shared</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ϵ</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s1">&#39;ϵ&#39;</span><span class="p">,</span> <span class="n">γ</span> <span class="o">+</span> <span class="n">δ</span> <span class="o">*</span> <span class="n">x_shared</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;y_pred&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="o">=</span><span class="n">μ</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="n">ϵ</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">Lenght</span><span class="p">)</span>
    
    <span class="n">trace_vv</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">tune</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>下图显示了我们模型的结果。均值用一条黑色曲线表示，两个半透明的橙色带分别表示 1 个和 2 个标准差：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Month</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">Lenght</span><span class="p">,</span> <span class="s1">&#39;C0.&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">μ_m</span> <span class="o">=</span> <span class="n">trace_vv</span><span class="p">[</span><span class="s1">&#39;μ&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ϵ_m</span> <span class="o">=</span> <span class="n">trace_vv</span><span class="p">[</span><span class="s1">&#39;ϵ&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Month</span><span class="p">,</span> <span class="n">μ_m</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Month</span><span class="p">,</span> <span class="n">μ_m</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">ϵ_m</span><span class="p">,</span> <span class="n">μ_m</span> <span class="o">-</span>
                 <span class="mi">1</span> <span class="o">*</span> <span class="n">ϵ_m</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Month</span><span class="p">,</span> <span class="n">μ_m</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">ϵ_m</span><span class="p">,</span> <span class="n">μ_m</span> <span class="o">-</span>
                 <span class="mi">2</span> <span class="o">*</span> <span class="n">ϵ_m</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051015443536.webp" /></p>
<p>图3.28</p>
</center>
<p>在写此书时，我女儿只有两周大，所以我想知道她的身高与刚绘制的生长图表相比如何。回答此问题的方法是询问半个月大婴儿身高的分布模型。使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> ，可以通过 <code class="docutils literal notranslate"><span class="pre">sample_posterior_predictive</span></code> 函数回答这个问题。</p>
<p>该函数的输出基于观测数据和所估计参数分布（包括不确定性）的样本。唯一问题是：根据定义，此函数返回对观测值的预测，但数据集中所有度量都是以整月报告的，没有 0.5 个月的情况（我关心的值）。要获得非观测值的预测，更简单的方法是定义一个共享变量（作为模型的一部分），然后在对后验预测分布采样之前更新共享变量的值：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_shared</span><span class="o">.</span><span class="n">set_value</span><span class="p">([</span><span class="mf">0.5</span><span class="p">])</span>
<span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_posterior_predictive</span><span class="p">(</span><span class="n">trace_vv</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model_vv</span><span class="p">)</span>
<span class="n">y_ppc</span> <span class="o">=</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;y_pred&#39;</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>现在，可以画出两周大婴儿的预期身高分布，并计算额外数据。例如，给定孩子的身高，她所处的百分位数。在下面的代码块和图中查看该示例。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ref</span> <span class="o">=</span> <span class="mf">47.5</span>
<span class="n">density</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">az</span><span class="o">.</span><span class="n">_fast_kde</span><span class="p">(</span><span class="n">y_ppc</span><span class="p">)</span>
<span class="n">x_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">density</span><span class="p">)</span>
<span class="n">percentile</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_ppc</span> <span class="o">&lt;=</span> <span class="n">ref</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_ppc</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_</span><span class="p">[</span><span class="n">x_</span> <span class="o">&lt;</span> <span class="n">ref</span><span class="p">],</span> <span class="n">density</span><span class="p">[</span><span class="n">x_</span> <span class="o">&lt;</span> <span class="n">ref</span><span class="p">],</span>
                 <span class="n">label</span><span class="o">=</span><span class="s1">&#39;percentile = </span><span class="si">{:2d}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">percentile</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;length&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<center>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_202105101546025a.webp" /></p>
<p>图3.29</p>
</center>
</div>
<div class="section" id="id23">
<h2>3.7 总结<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h2>
<p>一元线性回归是一种可以用来预测和/或解释一个预测（自）变量与另一个因变量间映射关系的模型。从机器学习语言表述，这是一个有监督学习的案例。从概率角度来看，线性回归模型是高斯模型的扩展，其中均值不是直接估计的，而是作为自变量和一些附加参数的线性函数来计算的。虽然高斯分布是因变量最常见的选择，但我们也可以选择其他分布。一种在处理潜在异常值时特别有用的替代方法就是学生 <span class="math notranslate nohighlight">\(\boldsymbol{t}\)</span> 分布。在后面章节中，我们还将探索其他替代方案。</p>
<p>本章还讨论了皮尔逊相关系数，这是两个变量间<code class="docutils literal notranslate"><span class="pre">线性相关性</span></code>的最常见度量，我们学习了如何使用多元高斯分布从数据和后验预测样本中计算出它的贝叶斯版本。</p>
<p>扩展线性回归模型的一种有用方法是建立其分层版本，进而具备收缩的优势。使用 <code class="docutils literal notranslate"><span class="pre">PyMC3</span></code> 可以非常简单地实现这一点。</p>
<p>本章还简要讨论了不将相关性解释为因果关系的重要性，至少在缺乏物理模型的情况下是这样。</p>
<p>听起来可能令人惊讶，但我们可以使用线性模型来拟合曲线。本章用两个例子来说明这一点：一是多项式回归，另外一个是自变量的平方根。</p>
<p>简单线性回归的另一个扩展是用多元线性回归来处理多个自变量。为避免解释此类型的模型时出现错误和问题，有必要采取一些预防措施，我们使用了几个示例来说明了这一点。</p>
<p>使用线性模型的其他方法包括对交互作用建模、对变方差建模等，本章均做了阐述。</p>
</div>
<div class="section" id="id24">
<h2>3.8 练习<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h2>
<center>
<p><img alt="image-20210510161310448" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510161347fd.webp" /></p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051016133031.webp" /></p>
<p><img alt="" src="https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210510161419e6.webp" /></p>
</center></div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="chapter02-ProgrammingProbabilistically.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">第 2 章 概率编程</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="chapter04-GeneralizedLinearRegression.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">第 4 章 广义线性回归模型</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>