
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>自动微分变分推断 &#8212; Python贝叶斯分析(中文)</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.e8f53015daec13862f6db5e763c41738.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="MCMC采样的傻瓜书" href="Ref-chapter08-MC-MCMCforDummies.html" />
    <link rel="prev" title="变分推断傻瓜书" href="Ref-chapter08-VI-VIforDummies.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Python贝叶斯分析(中文)</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   封面
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第 1 章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第 2 章 概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第 3 章 线性回归模型的贝叶斯视角
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第 4 章 广义线性回归模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter05-ModelComparison.html">
   第 5 章 模型比较
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第 6 章 混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第 7 章 高斯过程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter08-InterefenceEngine.html">
   第 8 章 推断引擎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter09-WheretoGoNext.html">
   第 9 章 下一步去哪儿？
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-VI-VIforDummies.html">
   变分推断傻瓜书
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   自动微分变分推断
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Ref-chapter08-MC-MCMCforDummies.html">
   MCMC采样的傻瓜书
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="_sources/Ref-chapter08-VI-ADVI.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Ref-chapter08-VI-ADVI.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/xishansnow/BayesianAnalysiswithPython2nd/issues/new?title=Issue%20on%20page%20%2FRef-chapter08-VI-ADVI.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/xishansnow/BayesianAnalysiswithPython2nd/master?urlpath=lab/tree/Ref-chapter08-VI-ADVI.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/xishansnow/BayesianAnalysiswithPython2nd&urlpath=lab/tree/BayesianAnalysiswithPython2nd/Ref-chapter08-VI-ADVI.md&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   目前机器学习的发展趋势
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     大规模概率编程
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     深度学习
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     桥接深度学习和概率编程
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#pymc3">
   PyMC3中的贝叶斯神经网络
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     生成数据
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     模型规格
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id8">
     变分推理：扩展模型复杂性
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     来看看分类器学到了什么
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id10">
     概率面
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     预测值中的不确定性
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#advi">
   小批次ADVI：扩展数据大小
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   总结
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   下一步
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id14">
   致谢
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>自动微分变分推断<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<blockquote>
<div><p>原文链接：<a class="reference external" href="http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/">Bayesian Deep Learning</a><br />
作者：<a class="reference external" href="https://disqus.com/by/twiecki/">Thomas Wiecki</a>，关注贝叶斯模型与Python<br />
译者：刘翔宇 校对：赵屹华<br />
责编：周建丁（zhoujd&#64;csdn.net）</p>
</div></blockquote>
<div class="section" id="id2">
<h2>目前机器学习的发展趋势<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>目前机器学习有三大趋势：<strong>概率编程</strong>、<strong>深度学习</strong>和“<strong>大数据</strong>”。在概率编程（PP）方面，有许多创新，它们大规模使用<strong>变分推理</strong>。在这篇博客中，我将展示如何使用<a class="reference external" href="http://pymc-devs.github.io/pymc3/">PyMC3</a>中的变分推理来拟合一个简单的贝叶斯神经网络。我还将讨论桥接概率编程与深度学习能够为将来研究开创怎样的有趣途径。</p>
<div class="section" id="id3">
<h3>大规模概率编程<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>概率编程可以灵活创建自定义概率模型，主要关注从数据中洞悉和学习。这种方法本质上是贝叶斯方法，所以我们可以指定先验来告知和约束我们的模型，并得到后验分布形式的不确定性估计。使用MCMC采样算法，我们可以从后验中抽样灵活地估计这些模型。<a class="reference external" href="http://pymc-devs.github.io/pymc3/">PyMC3</a>和Stan是目前用来构建并估计这些模型最先进的工具。但是，采样的一个主要缺点就是它往往非常耗时，特别是对于高维度模型。这就是为什么最近变分推理算法得到发展，它几乎与MCMC同样灵活，但是更快。这些算法拟合后验的分布（比如正态分布），将采样问题转换为优化问题，而不是从后验中采样。<a class="reference external" href="http://arxiv.org/abs/1506.03431">ADVI</a>——自动微分变分推理（Automatic Differentation Variational Inference）——在PyMC3和<a class="reference external" href="http://mc-stan.org/">Stan</a>中已经实现，一个新的包<a class="reference external" href="https://github.com/blei-lab/edward/">Edward</a>同样得到了实现，它主要与变分推理有关。</p>
<p>不幸的是，当面临传统的机器学习问题时，比如分类或（非线性）回归，与集成学习（比如随机森林或梯度提升回归树）这样的算法相比，概率编程不能胜任（精度和可扩展性方面）。</p>
</div>
<div class="section" id="id4">
<h3>深度学习<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>现在深度学习第三次复兴，它已经成为头条新闻，支配了几乎所有的物体识别基准，在Atari游戏中获胜，并且战胜了世界围棋冠军李世石。从统计学角度看，神经网络非常擅长非线性函数逼近和表示法学习。大多数为人所知的是分类任务，它们已经通过AutoEncoders和其他各种有趣的方法（比如循环网络，或使用MDN来估计多模态分布）扩展到了非监督学习。它们的效果为何如此好？没有人真正知道原因，因为这些统计特性仍不为人完全理解。</p>
<p>深度学习很大一部分创新是可以训练极其复杂的模型。这依赖于几个支柱：</p>
<ul class="simple">
<li><p>速度：提高GPU性能获得更快的处理。</p></li>
<li><p>软件：像<a class="reference external" href="http://deeplearning.net/software/theano/">Theano</a>和<a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a>这样的框架允许灵活创建抽象模型，然后可以对其优化并编译到CPU或GPU上。</p></li>
<li><p>学习算法：在数据子集上训练——随机梯度下降——可以让我们在海量数据上训练这些模型。使用drop-out这样的技术可以避免过拟合。</p></li>
<li><p>架构：大量的创新都是改变输入层，比如卷积神经网络，或改变输出层，比如<a class="reference external" href="http://cbonnett.github.io/MDN_EDWARD_KERAS_TF.html">MDN</a>。</p></li>
</ul>
</div>
<div class="section" id="id5">
<h3>桥接深度学习和概率编程<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>一方面，概率编程可以让我们以原则化和易于理解的方式构建比较小的，集中的模型来深入了解数据；在另一方面，使用深度学习的启发式方法来训练大量和高度复杂的模型，这些模型的预测效果惊人。最近变分推理中的创新能够使概率编程扩大模型的复杂性和数据大小。所以，我们处于结合这两种方法的风口浪尖，希望能在机器学习方面解锁新的创新。想了解更多，也可以看看<a class="reference external" href="https://twitter.com/dustinvtran">Dustin Tran</a>最近的<a class="reference external" href="http://dustintran.com/blog/a-quick-update-edward-and-some-motivations/">博客文章</a>。</p>
<p>这种桥接可以让概率编程被运用于一系列更广泛的有趣问题中，我相信它同样能在深度学习方面有所创新。比如：</p>
<ul class="simple">
<li><p><strong>预测中的不确定性</strong>：我们下面将会看到，贝叶斯神经网络告诉我们它的预测中的不确定性。我认为不确定性是机器学习中被低估的概念，因为它对现实世界的应用来说显然是重要的。它在训练中也非常有用。比如，我们可以在模型最不确定的样本中来训练模型。</p></li>
<li><p><strong>表示中的不确定性</strong>：我们同样会得到权重的不确定估计，它可以告诉我们网络中学习到的表示的稳定性。</p></li>
<li><p><strong>先验正则</strong>：权重往往通过L2正则化来避免过拟合，这很自然地在权重系数上使用高斯先验。我们可以想象其他各种先验，比如spike-and-slab 来加强稀疏程度（使用L1范数更合适）。</p></li>
<li><p><strong>知情先验的迁移学习</strong>：如果我们想在一个新的物体识别数据集上训练网络，我们可以使用其他预训练的网络生成的权值作为知情先验来引导学习，比如<a class="reference external" href="https://arxiv.org/abs/1409.4842">GoogLeNet</a>。</p></li>
<li><p><strong>分层神经网络</strong>：概率编程中一种强大的方法是分层建模，可以将在子组中学习到的东西池化运用于全局（见<a class="reference external" href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/">PyMC3分层线性回归</a>教程）。在分层数据集中运用神经网络，我们可以对子组训练单个神经网络，而同时还能获得全局的表示。比如，假设一个网络被训练用来从汽车图片中分类车型。我们可以训练一个分层神经网络，其中一个子网络仅用来分辨某个制造商生产的车型。直觉告诉我们，某个制造商的所有车辆都有相似之处，所以针对特定品牌来训练单个网络完全说的通。然而，由于各个单个网络都与上一层相连，它们仍然可以与其他特定的子网络共享特征信息，这些特征对于所有品牌都有用。有趣的是，网络的不同层可以从分层不同的级别中获得信息——例如，提取视觉线条的初层在所有子网络中都是同一的，而高阶表示则不同。分层模型可以从数据中学习到所有东西。</p></li>
<li><p><strong>其他混合架构</strong>：我们可以自由地构建各种神经网络。例如，贝叶斯非参数化可以用来灵活调整隐藏层的大小和形状，根据在训练过程中碰到的问题最佳地扩展网络架构。目前，这需要昂贵的超参数优化和大量的系统知识。</p></li>
</ul>
</div>
</div>
<div class="section" id="pymc3">
<h2>PyMC3中的贝叶斯神经网络<a class="headerlink" href="#pymc3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id6">
<h3>生成数据<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>首先，我们生成一些小型数据——一个简单的二元分类问题，非线性可分。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_1904</span><span class="o">/</span><span class="mf">4158819057.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">run_line_magic</span><span class="p">(</span><span class="s1">&#39;matplotlib&#39;</span><span class="p">,</span> <span class="s1">&#39;inline&#39;</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="kn">import</span> <span class="nn">pymc3</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="kn">import</span> <span class="nn">theano</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="kn">import</span> <span class="nn">sklearn</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;pymc3&#39;
</pre></div>
</div>
</div>
</div>
<p>In [2]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">noise</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In [3]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 0&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">Y</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Class 1&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">();</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Toy binary classification data set&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612091911193" /></p>
</div>
<div class="section" id="id7">
<h3>模型规格<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>神经网络很简单。最基本的单元是一个感知器，它只不过是一个逻辑回归实现。我们并行使用许多这样的单元，然后堆叠起来组成隐藏层。在这里，我们将使用2个隐藏层，每层5个神经元，处理这个简单的问题足够了。</p>
<p>In [17]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Trick: Turn inputs and outputs into shared variables. </span>
<span class="c1"># It&#39;s still the same thing, but we can later change the values of the shared variable </span>
<span class="c1"># (to switch in the test-data later) and pymc3 will just use the new data. </span>
<span class="c1"># Kind-of like a pointer we can redirect.</span>
<span class="c1"># For more info, see: http://deeplearning.net/software/theano/library/compile/shared.html</span>
<span class="n">ann_input</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">ann_output</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>

<span class="n">n_hidden</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Initialize random weights between each layer</span>
<span class="n">init_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_hidden</span><span class="p">)</span>
<span class="n">init_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
<span class="n">init_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">neural_network</span><span class="p">:</span>
    <span class="c1"># Weights from input to hidden layer</span>
    <span class="n">weights_in_1</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;w_in_1&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                             <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">n_hidden</span><span class="p">),</span> 
                             <span class="n">testval</span><span class="o">=</span><span class="n">init_1</span><span class="p">)</span>

    <span class="c1"># Weights from 1st to 2nd layer</span>
    <span class="n">weights_1_2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;w_1_2&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">),</span> 
                            <span class="n">testval</span><span class="o">=</span><span class="n">init_2</span><span class="p">)</span>

    <span class="c1"># Weights from hidden layer to output</span>
    <span class="n">weights_2_out</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="s1">&#39;w_2_out&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                              <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,),</span> 
                              <span class="n">testval</span><span class="o">=</span><span class="n">init_out</span><span class="p">)</span>

    <span class="c1"># Build neural-network using tanh activation function</span>
    <span class="n">act_1</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">ann_input</span><span class="p">,</span> 
                         <span class="n">weights_in_1</span><span class="p">))</span>
    <span class="n">act_2</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">act_1</span><span class="p">,</span> 
                         <span class="n">weights_1_2</span><span class="p">))</span>
    <span class="n">act_out</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">act_2</span><span class="p">,</span> 
                                   <span class="n">weights_2_out</span><span class="p">))</span>

    <span class="c1"># Binary classification -&gt; Bernoulli likelihood</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s1">&#39;out&#39;</span><span class="p">,</span> 
                       <span class="n">act_out</span><span class="p">,</span>
                       <span class="n">observed</span><span class="o">=</span><span class="n">ann_output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>还不错。Normal先验用来正则化权值。通常我们会在输入中加入一个常数b，但为代码简洁起见，我在这里省略了。</p>
</div>
<div class="section" id="id8">
<h3>变分推理：扩展模型复杂性<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<p>现在我们已经可以运行一个MCMC采样器了，比如NUTS，在这里效果非常不错，但是正如我前面提到的，当我们扩展模型到更深的架构，更多层时，处理起来会非常缓慢。</p>
<p>不过我们将使用最近加入到PyMC3全新的ADVI变分推理算法。这种算法更快而且能够更好地扩展。注意，这是平均场近似，所以我们忽略后验相关性。</p>
<p>In [34]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="k">with</span> <span class="n">neural_network</span><span class="p">:</span>
    <span class="c1"># Run ADVI which returns posterior means, standard deviations, and the evidence lower bound (ELBO)</span>
    <span class="n">v_params</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">variational</span><span class="o">.</span><span class="n">advi</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50000</span><span class="p">)</span>

<span class="n">Iteration</span> <span class="mi">0</span> <span class="p">[</span><span class="mi">0</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">368.86</span>
<span class="n">Iteration</span> <span class="mi">5000</span> <span class="p">[</span><span class="mi">10</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">185.65</span>
<span class="n">Iteration</span> <span class="mi">10000</span> <span class="p">[</span><span class="mi">20</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">197.23</span>
<span class="n">Iteration</span> <span class="mi">15000</span> <span class="p">[</span><span class="mi">30</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">203.2</span>
<span class="n">Iteration</span> <span class="mi">20000</span> <span class="p">[</span><span class="mi">40</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">192.46</span>
<span class="n">Iteration</span> <span class="mi">25000</span> <span class="p">[</span><span class="mi">50</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">198.8</span>
<span class="n">Iteration</span> <span class="mi">30000</span> <span class="p">[</span><span class="mi">60</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">183.39</span>
<span class="n">Iteration</span> <span class="mi">35000</span> <span class="p">[</span><span class="mi">70</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">185.04</span>
<span class="n">Iteration</span> <span class="mi">40000</span> <span class="p">[</span><span class="mi">80</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">187.56</span>
<span class="n">Iteration</span> <span class="mi">45000</span> <span class="p">[</span><span class="mi">90</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">192.32</span>
<span class="n">Finished</span> <span class="p">[</span><span class="mi">100</span><span class="o">%</span><span class="p">]:</span> <span class="n">ELBO</span> <span class="o">=</span> <span class="o">-</span><span class="mf">225.56</span>
<span class="n">CPU</span> <span class="n">times</span><span class="p">:</span> <span class="n">user</span> <span class="mf">36.3</span> <span class="n">s</span><span class="p">,</span> <span class="n">sys</span><span class="p">:</span> <span class="mi">60</span> <span class="n">ms</span><span class="p">,</span> <span class="n">total</span><span class="p">:</span> <span class="mf">36.4</span> <span class="n">s</span>
<span class="n">Wall</span> <span class="n">time</span><span class="p">:</span> <span class="mf">37.2</span> <span class="n">s</span>
</pre></div>
</div>
</div>
</div>
<p>在我老旧的笔记本上耗时小于40秒。这相当不错，考虑到NUTS将会花费相当多的时间。在下面，我们又会减少运行时间。想让它有质的飞跃，我们可能要在GPU上训练神经网络。</p>
<p>由于这些样本非常便于处理，我们可以使用sample_vp()（这只是从正态分布中取样，所以与MCMC完全不同）从变分后验中很快地提取样本：</p>
<p>In [35]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">neural_network</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">variational</span><span class="o">.</span><span class="n">sample_vp</span><span class="p">(</span><span class="n">v_params</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>绘制目标函数（ELBO），我们可以看出随着时间推移，拟合效果越来越好。</p>
<p>In [36]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v_params</span><span class="o">.</span><span class="n">elbo_vals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;ELBO&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Out[36]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">Text</span> <span class="n">at</span> <span class="mh">0x7fa5dae039b0</span><span class="o">&gt;</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092107882" /></p>
<p>现在我们已经训练了模型，接下来我们使用后验预测检查（PPC）在测试集上进行预测。我们使用sample_ppc()从后验（从变分估计中采样）中生成新的数据（在此例中是类别预测）。</p>
<p>In [7]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace shared variables with testing set</span>
<span class="n">ann_input</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">ann_output</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>

<span class="c1"># Creater posterior predictive samples</span>
<span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_ppc</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">neural_network</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># Use probability of &gt; 0.5 to assume prediction of class 1</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.5</span> 
</pre></div>
</div>
</div>
</div>
<p>In [8]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Predicted labels in testing set&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092219930" /></p>
<p>In [9]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy = </span><span class="si">{}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">Y_test</span> <span class="o">==</span> <span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Accuracy = 94.19999999999999%</p>
</div></blockquote>
<p>嘿，我们训练的神经网络效果非常好！</p>
</div>
<div class="section" id="id9">
<h3>来看看分类器学到了什么<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>在这里，我们在所有输入空间里评估类别概率预测。</p>
<p>In [10]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="mi">3</span><span class="p">:</span><span class="mi">100</span><span class="n">j</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">:</span><span class="mi">3</span><span class="p">:</span><span class="mi">100</span><span class="n">j</span><span class="p">]</span>
<span class="n">grid_2d</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">dummy_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In [11]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ann_input</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">grid_2d</span><span class="p">)</span>
<span class="n">ann_output</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">dummy_out</span><span class="p">)</span>

<span class="c1"># Creater posterior predictive samples</span>
<span class="n">ppc</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample_ppc</span><span class="p">(</span><span class="n">trace</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">neural_network</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id10">
<h3>概率面<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<p>In [26]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">250</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">85</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="o">*</span><span class="n">grid</span><span class="p">,</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">);</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Posterior predictive mean probability of class label = 0&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092331367" /></p>
</div>
<div class="section" id="id11">
<h3>预测值中的不确定性<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>目前为止，我向大家展示的所有事情都能用非贝叶斯神经网络完成。对于每个类别的后验预测的平均值应该与最大似然预测值相同。然而，我们也可以看看后验预测的标准差来了解预测中的不确定性。就是下面这样子：</p>
<p>In [27]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">cubehelix_palette</span><span class="p">(</span><span class="n">light</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="o">*</span><span class="n">grid</span><span class="p">,</span> <span class="n">ppc</span><span class="p">[</span><span class="s1">&#39;out&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test</span><span class="p">[</span><span class="n">pred</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">ylim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;Y&#39;</span><span class="p">);</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Uncertainty (posterior predictive standard deviation)&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092424242" /></p>
</div>
</div>
<div class="section" id="advi">
<h2>小批次ADVI：扩展数据大小<a class="headerlink" href="#advi" title="Permalink to this headline">¶</a></h2>
<p>目前，我们在所有数据上训练了模型。显然，这不能扩展到ImageNet这样的数据集上。此外，在小批次数据（随机梯度下降）上训练可以避免局部最小，并可能加快收敛。</p>
<p>幸运的是，ADVI可以在小批次数据上运行。它只需要进行一些设置：</p>
<p>In [43]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set back to original data to retrain</span>
<span class="n">ann_input</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">ann_output</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Tensors and RV that will be using mini-batches</span>
<span class="n">minibatch_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">ann_input</span><span class="p">,</span> <span class="n">ann_output</span><span class="p">]</span>
<span class="n">minibatch_RVs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out</span><span class="p">]</span>

<span class="c1"># Generator that returns mini-batches in each iteration</span>
<span class="k">def</span> <span class="nf">create_minibatch</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># Return random data samples of set size 100 each iteration</span>
        <span class="n">ixs</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">data</span><span class="p">[</span><span class="n">ixs</span><span class="p">]</span>

<span class="n">minibatches</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">create_minibatch</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> 
    <span class="n">create_minibatch</span><span class="p">(</span><span class="n">Y_train</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">total_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>上面的代码看起来有点吓人，但我很喜欢这种设计。特别是你定义了一个非常灵活的生成器。原则上，我们可以从数据库中获取数据，而且不需要将所有数据放在RAM中。</p>
<p>我们把它们传给advi_minibatch()：</p>
<p>In [48]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="k">with</span> <span class="n">neural_network</span><span class="p">:</span>
    <span class="c1"># Run advi_minibatch</span>
    <span class="n">v_params</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">variational</span><span class="o">.</span><span class="n">advi_minibatch</span><span class="p">(</span>
        <span class="n">n</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">minibatch_tensors</span><span class="o">=</span><span class="n">minibatch_tensors</span><span class="p">,</span> 
        <span class="n">minibatch_RVs</span><span class="o">=</span><span class="n">minibatch_RVs</span><span class="p">,</span> <span class="n">minibatches</span><span class="o">=</span><span class="n">minibatches</span><span class="p">,</span> 
        <span class="n">total_size</span><span class="o">=</span><span class="n">total_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1.0</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p>Iteration 0 [0%]: ELBO = -311.63<br />
Iteration 5000 [10%]: ELBO = -162.34<br />
Iteration 10000 [20%]: ELBO = -70.49<br />
Iteration 15000 [30%]: ELBO = -153.64<br />
Iteration 20000 [40%]: ELBO = -164.07<br />
Iteration 25000 [50%]: ELBO = -135.05<br />
Iteration 30000 [60%]: ELBO = -240.99<br />
Iteration 35000 [70%]: ELBO = -111.71<br />
Iteration 40000 [80%]: ELBO = -87.55<br />
Iteration 45000 [90%]: ELBO = -97.5<br />
Finished [100%]: ELBO = -75.31<br />
CPU times: user 17.4 s, sys: 56 ms, total: 17.5 s<br />
Wall time: 17.5 s</p>
</div></blockquote>
<p>In [49]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">neural_network</span><span class="p">:</span>    
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">variational</span><span class="o">.</span><span class="n">sample_vp</span><span class="p">(</span><span class="n">v_params</span><span class="p">,</span> <span class="n">draws</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In [50]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">v_params</span><span class="o">.</span><span class="n">elbo_vals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;ELBO&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092606061" /><br />
正如你所看到的，小批次ADVI的运行时间要少的多。它似乎也收敛的更快。</p>
<p>为了好玩，我们也可以看看轨迹。我们在神经网络权值中同样会有不确定性。</p>
<p>In [51]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pm</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p><img alt="图片描述" src="https://img-blog.csdn.net/20160612092648899" /></p>
</div>
<div class="section" id="id12">
<h2>总结<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>希望这篇博客很好地讲述了PyMC3中一种强大的新型推理算法：ADVI。我同样认为桥接概率编程和深度学习能够为此领域开辟许多新渠道的创新，上面已经讨论。特别地，分层神经网络听起来相当牛逼。这真是激动人心的时刻。</p>
</div>
<div class="section" id="id13">
<h2>下一步<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>使用PyMC3作为计算后端的Theano，主要用于估计神经网络，而且有许多类似于Lasagne的非常棒的库，来使简化最常见的神经网络架构的构建，这些库构建于Theano之上。理想情况下，我们不需要像上面那样手动构建模型，而是使用Lasagne方便的语法来构建网络体系结构，定义先验，并运行ADVI。虽然我们还没有成功地在GPU上运行PyMC3，但是这应该没什么难度（因为Theano能够在GPU上运行），并且能够进一步大幅减少运行时间。如果你了解Theano，这将会是你发挥作用的领域！</p>
<p>你可能会说，上面的网络不是很深，但请注意，我们可以很容易地扩展到更多层，包括卷积层，用来在更具挑战的数据集上进行训练。</p>
<p>我也提供了一些我在PyData London的一些工作资料，见下面的视频：</p>
<p><a class="reference external" href="https://www.youtube.com/embed/LlzVlqVzeD8">https://www.youtube.com/embed/LlzVlqVzeD8</a></p>
<p>最后，你可以在<a class="reference external" href="https://github.com/twiecki/WhileMyMCMCGentlySamples/blob/master/content/downloads/notebooks/bayesian_neural_network.ipynb">这里</a>下载NB。在下面的评论区留言，并关注<a class="reference external" href="https://twitter.com/twiecki">我的Twitter</a>。</p>
</div>
<div class="section" id="id14">
<h2>致谢<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/taku-y">Taku Yoshioka</a>为PyMC3的ADVI做了很多工作，包括小批次实现和从变分后验采样。我同样要感谢Stan的开发者（特别是Alp Kucukelbir和Daniel Lee）派生ADVI并且指导我们。感谢Chris Fonnesbeck、Andrew Campbell、Taku Yoshioka和Peadar Coyle为早期版本提供有用的意见。</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="Ref-chapter08-VI-VIforDummies.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">变分推断傻瓜书</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="Ref-chapter08-MC-MCMCforDummies.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">MCMC采样的傻瓜书</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Osvaldo Martin<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>