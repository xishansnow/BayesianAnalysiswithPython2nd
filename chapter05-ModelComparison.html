
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>第5章 模型比较 &#8212; 用Python做贝叶斯分析</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="第6章 混合模型" href="chapter06-MixtureModels.html" />
    <link rel="prev" title="第4章 利用Logistic 回归 对结果进行分类" href="chapter04-GeneralizedLinearRegression.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">用Python做贝叶斯分析</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="preface.html">
   前言
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="chapter01-ThinkingProbabilistically.html">
   第1章 概率思维
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter02-ProgrammingProbabilistically.html">
   第2章　概率编程
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter03-ModellingwithLinearRegression.html">
   第3章　利用线性回归模型理解并预测数据
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter04-GeneralizedLinearRegression.html">
   第4章 利用Logistic 回归 对结果进行分类
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   第
   <strong>
    5
   </strong>
   章　模型比较
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter06-MixtureModels.html">
   第6章　混合模型
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chapter07-GaussianProcesses.html">
   第7章　高斯过程
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/chapter05-ModelComparison.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>第<strong>5</strong>章　模型比较<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>所有模型都是错的，但某些是有用的。</p>
<p>——George Box</p>
<p>我们已经讨论过”所有模型都是错的”这一思想，原因是模型只是 通过数据理解问题的一个近似工具，并非对真实世界的完整刻画。尽 管每个模型都是错误的，但是并非每个模型都错得一样。某些模型在 描述同一份数据时会错得更离谱。前一章中，我们重点关注了推断的 问题，也就是根据数据推断参数的值。这一章，我们将关注另外一个 问题：如何比较两个或多个模型。这个问题并不简单，而且目前也是 数据分析中的一个核心问题。</p>
<p>本章将讨论以下内容：</p>
<p>奥卡姆剃刀、简洁性与准确率、过拟合与欠拟合； 正则先验；</p>
<p>信息量准则；</p>
<p>贝叶斯因子。</p>
<p>220</p>
<p><strong>6.1</strong>　奥卡姆剃刀**——**简约性与准确性</p>
<p>假设对于同一个问题/数据有两个模型，二者对数据解释得同样<br />
好，应该选哪个模型呢？有一个准则叫做奥卡姆剃刀，描述的是如果</p>
<p>对于同一现象有两种不同的假说，我们应该采取比较简单的那一种。 关于奥卡姆剃刀的论证有很多，其中之一与波普尔的可证伪性标准有 关，还有一种说法是从实用的角度提出的，因为更简单的模型相比复 杂的模型更容易理解，另外还有一种论证是基于贝叶斯统计。这里暂 且不深入这些论证的细节，只是将该准则当做一个有用而合理的常</p>
<p>识。</p>
<p>在比较模型时，通常还需要考虑模型的准确性，即模型对数据拟 合得怎么样。我们已经见过了一些衡量准确性的标准，如测定<em>R</em>^2^的系 数，可以将其理解为线性回归中可解释方差的比例。如果我们有两个 模型，其中一个模型对数据的解释比另一个更好，我们是否更倾向于 该模型呢？换句话说，我们是否应该选准确率更高的模型呢？我们更 倾向于更简单的模型。</p>
<p>直观上讲，在比较模型时，我们似乎更倾向于准确率较高，同时 比较简单的模型。本章剩余部分将讨论如何平衡这两者。</p>
<p>这一章要比前面几章更偏理论一些（尽管我们还只是在讨论这个 主题中很浅显的部分）。为了简化问题，这里引入一个例子来帮助理 解如何平衡准确性与复杂性，实现从感性认识到理论证明的跨越。</p>
<p>在这个例子中，我们将使用一系列逐渐复杂的多项式来拟合一个 非常简单的数据集，这里我们没有采用贝叶斯方法，而是采用最小二 乘方近似来拟合线性模型。后者其实可以转化成一个带均匀先验的贝</p>
<p>221</p>
<p>叶斯模型，因此，这里可以理解为还是用的贝叶斯模型，只不过我们 走了个捷径。</p>
<p>x = np.array([4.,5.,6.,9.,12, 14.])</p>
<p>y = np.array([4.2, 6., 6., 9., 10, 10.])</p>
<p>order = [0, 1, 2, 5]</p>
<p>plt.plot(x, y, ‘o’)</p>
<p>for i in order:</p>
<p>x_n = np.linspace(x.min(), x.max(), 100)</p>
<p>coeffs = np.polyfit(x, y, deg=i)</p>
<p>ffit = np.polyval(coeffs, x_n)</p>
<p>p = np.poly1d(coeffs)</p>
<p>yhat = p(x)</p>
<p>ybar = np.mean(y)</p>
<p>ssreg = np.sum((yhat-ybar)**2)</p>
<p>sstot = np.sum((y - ybar)**2)</p>
<p>r2 = ssreg / sstot</p>
<p>plt.plot(x_n, ffit, label=’order {}, $R^2$= {:.2f}’.format(i,r2)) plt.legend(loc=2, fontsize=14)</p>
<p>plt.xlabel(‘$x$’, fontsize=16)</p>
<p>plt.ylabel(‘$y$’, fontsize=16, rotation=0)</p>
<p>![](C:/Program Files/Typora/media/image1836.png){width=”5.643024934383202in” height=”3.98787510936133in”}</p>
<p><strong>6.1.1</strong>　参数太多导致过拟合</p>
<p>222</p>
<p>从前面的图中可以看出，当模型的复杂度增加，对应的决定系<br />
数<em>R</em>^2^也在上升。当多项式为5阶时，模型完美拟合了数据。前面章节</p>
<p>中我们讨论过，通常，用多项式去解决实际问题并不是一个特别好的 办法。</p>
<p>为什么5阶的多项式能够完美地拟合所有数据呢？原因是模型中 参数的个数与样本个数相同，都是6，因此，模型只是用另一种方式 对数据进行了编码，此时模型并没有从数据中学到任何内容，只是记</p>
<p>住了全部的数据。而且该模型对数据的预测看起来非常奇怪。从前面 的图中可以看到，5阶多项式对应的那条最佳拟合曲线一会儿高一会 儿低，对比之下1阶和2阶的模型分别是直线和抛物线。直观上讲，直 线或者抛物线要比一条弯弯曲曲的完美拟合所有数据的曲线要更简单 而且更可信。从这个例子可以看出，准确率更高的模型可能并不是我 们想要的。</p>
<p>下面的例子从另外一个重要的角度做出了解释。假设我们在原来 数据集的基础上收集了更多的数据。比如，我们又收集到了2个点 [(10, 9), (7,7)]（如下面的图所示），此时5阶模型对比1阶或者2阶模 型的效果如何呢？并不好。5阶模型并没有从数据中学到任何有意义 的模式，只是记住了所有见过的数据，因而对于潜在的未观测到的数 据表现很差。</p>
<p>223</p>
<p>![](C:/Program Files/Typora/media/image1839.png){width=”5.643024934383202in” height=”3.98787510936133in”}</p>
<p>之所以泛化能力差是因为模型太灵活了，参数太多导致了过拟<br />
合。在统计学和机器学习中，过拟合是一个很常见的问题，一旦模型</p>
<p>开始学习数据中模式之外的噪声时就会出现过拟合的问题，显然这里 我们假设数据中首先是存在有意义的模式的。通常，一个模型的参数 越多，适应数据的方式也就越多，因而更倾向于对数据过拟合。这一 点是在使用复杂模型时的一个现实考虑，同时也是奥卡姆剃刀的一个 现实佐证。</p>
<p>这个例子告诉我们，如果仅仅关注模型对数据的解释能力，很可 能会被误导。原因是，（至少理论上）我们始终可以通过增加模型参 数个数来提高准确率。这里引入一些词汇来让我们的讨论更清晰一</p>
<p>些，我们称根据输入到模型的数据计算出来的准确率为样本内准确<br />
率，另外一种衡量模型有效性的方式是计算模型在没有见过的数据上 的准确率，通常称为样本外准确率。</p>
<p><strong>6.1.2</strong>　参数太少导致欠拟合</p>
<p>224</p>
<p>继续同样的例子，不过这次重点关注的不是非常复杂的模型，而 是0阶的模型。在0阶模型中，所有的beta参数都为0，因而两个变量 之间的线性关系变成了只是描述因变量的一个高斯模型，注意对于0 阶模型来说，自变量对模型不再有任何影响，而且模型只能捕捉到因 变量的均值。换句话说，模型认为数据能够通过因变量的均值以及一 些高斯噪声来解释。我们称这种模型是欠拟合的，因为它实在太简单 了，以至于并不能从数据中获取到有意义的模式。通常，一个参数很 少的模型容易出现欠拟合。</p>
<p><strong>6.1.3</strong>　简洁性与准确性之间的平衡</p>
<p>经常与奥卡姆剃刀准则一起提到的是爱因斯坦的一句名言”事情<br />
应该尽可能简单，但不必过于简单”。这就好像健康饮食，我们在建 模的时候也需要保持某种平衡。理想状态下，我们希望模型既不过拟</p>
<p>合又不欠拟合，因此，通常需要优化或者调整我们的模型来权衡二<br />
者，具体做法有很多种，比如，我们可以将对数据建模的目的看作是 对数据的一种压缩后的表现；我们希望将数据尽可能简化，从而能够 理解数据并做出预测。如果模型对数据表示压缩得非常严重，那么会 丢失一些细节信息，因而可能只得到一些很简单的总结，比如均值； 相反，则会得到太多噪声，极限情况下，我们得到的可能是没有任何 压缩的数据的另一种表示。</p>
<p>过拟合与欠拟合之间的平衡可以从偏差扰动平衡的角度来讨论， 我用一个例子来解释这个概念。假设我们有一个模型能够拟合数据集 中的每个点，就像前面的5阶模型一样。设想一下，如果我们重新取6 个数据点，然后调整模型以适应新的数据点，这样每次都得到一个新 的曲线，如此重复多次。由于模型可以拟合每组数据中的细节，因而 我们的预测结果会有很大的方差，我们称该模型的方差很大，相反，</p>
<p>225</p>
<p>如果有一个受限的模型，比如一条直线，那么，它总是会试图容纳一 条直线。一个高偏差的模型会有很大的偏见（如果用拟人的方式来描 述的话），或者说惯性很大。</p>
<p>前面例子中1阶模型要比2阶模型的偏差更高而方差更低，后者会 得到不同的曲线（直线是其中的一个特例），总结如下。</p>
<p>高偏差是因为模型不能很好地适应数据。高偏差可能使得模型不 能捕捉到数据中一些关键的模式，因而导致欠拟合。<br />
高方差是由于对数据中的细节很敏感。高偏差会导致模型捕捉到 数据中的噪声，因而可能会导致过拟合。</p>
<p>总的来说，如果提升一个方面，就会导致另一方面下降，这也是 为什么人们称之偏差-方差平衡，而我们最希望得到的是二者平衡的 模型。</p>
<p>226</p>
<p><strong>6.2</strong>　正则先验</p>
<p>使用（弱）信息先验是给模型引入偏差的一种方式，如果引入得 合理是一件好事，因为这有利于避免过拟合。</p>
<p>正则化的思想非常强大，在贝叶斯框架之外也有许多应用。在一 些领域中，这种思想称作吉洪诺夫正则化。在非贝叶斯统计中，对 于最小二乘法，正则化的思想有两种形式，分别是：岭回归和Lasso 回归。从贝叶斯的角度来看，岭回归可以解释为对（线性回归中的） beta系数使用了正态分布的先验，而且该正态分布的标准差很小（而 不是习惯上的很大），因而达到把beta系数限制在0附近的目的，而 Lasso回归则可以看作是对beta系数使用了拉普拉斯先验。标准形式的 岭回归和Lasso回归对应的是点估计。如果严格应用贝叶斯分析的话 是没法得到后验分布的。</p>
<p>在继续深入之前，我们先花点时间讨论下拉普拉斯分布。这个分 布与高斯分布很像，不过它的1阶导数在0附近没有定义，因为该分布 在0附近有一个很尖锐的峰值（具体可以看下图）。拉普拉斯分布相</p>
<p>比高斯分布整体更靠近0，因而当我们使用它作为先验的时候，会使 得参数趋近于0。也就是说，Lasso可以用于正则化和变量筛选（将某 些特征或变量从模型中去掉）。</p>
<p>下面的代码生成了4组中心为0的不同尺度的拉普拉斯分布，此外 还有一个均值为零的标准差为1的高斯分布作为比较。</p>
<p>![](C:/Program Files/Typora/media/image1846.png){width=”3.818897637795276e-2in” height=”1.2355938320209974in”}plt.figure(figsize=(8, 6))</p>
<p>x_values = np.linspace(-10, 10, 300)</p>
<p>for df in [1, 2, 5, 15]:</p>
<p>distri = stats.laplace(scale=df)</p>
<p>x_pdf = distri.pdf(x_values)</p>
<p>plt.plot(x_values, x_pdf, label=’$b$ = {}’.format(df))</p>
<p>227</p>
<p>![](C:/Program Files/Typora/media/image1850.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}</p>
<p>x_pdf = stats.norm.pdf(x_values)</p>
<p>plt.plot(x_values, x_pdf, label=’Gaussian’)</p>
<p>plt.xlabel(‘x’)</p>
<p>plt.ylabel(‘p(x)’, rotation=0)</p>
<p>plt.legend(loc=0, fontsize=14)</p>
<p>plt.xlim(-7, 7);</p>
<p>plt.savefig(‘B04958_06_03.png’, dpi=300, figsize=[5.5, 5.5])</p>
<p>![](C:/Program Files/Typora/media/image1854.png){width=”5.643024934383202in” height=”4.248180227471566in”}</p>
<p>非常值得注意的一点是，这种人们广泛接受的正则化的思想非常 自然地融合进了贝叶斯体系中。有人甚至说，既然大家都认同正则化 是一个相当棒的思想，那么可以说每个人都在某种程度上是贝叶斯</p>
<p>的，尽管他们并没有意识到甚至拒绝这个标签。</p>
<p><strong>6.2.1</strong>　正则先验和多层模型</p>
<p>与我们刚才讨论的相一致，多层模型也可以被认为是一种正则化 的方法。 也就是通过引入超先验，将多层模型看作是从数据中学习 先验的一种方法。 所以，从某种意义上说，因为我们正在从数据中</p>
<p>228</p>
<p>学习先验，所以我们正在进行正规化，并且让数据告诉我们正规化的 强度。 这也许是对多层模型和收缩更深刻的理解。 你可以思考一下 在第四章里当我们使用多层模型对单个数据点拟合一条直线时，如何 从正则化概念的角度来解释。</p>
<p>229</p>
<p><strong>6.3</strong>　衡量预测准确性</p>
<p>从前面的例子可以看出，0阶的模型太过简单，而5阶的模型又太 复杂，那剩下两个呢？如何进行区分？我们需要一个准则来同时考虑 准确性和简洁性。有两种方法可以只使用样本内数据来估计样本外数 据的预测准确性。</p>
<p>交叉验证：这是一种经验性的策略，将数据分成多个子集，然后<br />
轮流将其中一个子集作为测试集，将剩余的子集作为训练集进行<br />
评估。</p>
<p>信息准则：一系列概念的总称，可以看作是对交叉检验的一种数<br />
学近似。</p>
<p><strong>6.3.1</strong>　交叉验证</p>
<p>一般来说，模型在样本内的准确率要比样本外高。由于我们同时 需要训练模型并测试模型的性能，一个简单的做法是将数据分成两部 分：</p>
<p>用于训练模型的训练集；<br />
用于测试模型表现的测试集。</p>
<p>如果有许多数据的话，交叉验证是一种很好的方法。比如，晶体 学家已经使用这种方法求解并验证分子结构数十年了。不过如果数据 不多的话，前面这种做法可能不合适，因为这会进一步减少训练模型 和评估模型准确性的有限信息。</p>
<p>为了绕过缺少数据的问题，一个非常简单而且在大多数情况下都 非常有效的做法是进行交叉验证。将数据分成<em>K</em>份，比如说5份，同</p>
<p>230</p>
<p>时尽可能让每份数据相同（数据的个数以及数据的一些其他特征，比 如每个类别的数量），然后使用其中的<em>K</em>−1份数据用于训练模型（在 这个例子中是4份），将剩下的一份数据用于验证模型。重复该过<br />
程<em>K</em>轮，每一轮都使用不同的数据用于验证，最后对每一轮的验证结 果求均值。整个过程称作**K-**折交叉验证，其中<em>K</em>表示数据拆分成的份 数，在这个例子中，我们称为5折交叉验证。当<em>K</em>与数据集中样本的<br />
个数相同时，我们称之为留一交叉验证（Leave-One-Out Cross-<br />
Validation，LOOCV）。有时候在做留一交叉验证时，验证的轮数可 以小于样本总数。</p>
<p>交叉验证是一个非常简单而且强大的思想，不过对于某些模型或 者某些量很大的数据而言，交叉验证的计算量可能超出我们能接受的 范围。许多人尝试提出了一些其他更容易计算的量，来对交叉验证得 到的结果进行近似，或者应用到不能直接使用交叉验证的情况，下一 节将会详细介绍。</p>
<p><strong>6.3.2</strong>　信息量准则</p>
<p>信息量准则是一系列用来比较模型对数据拟合程度的方法，这类 方法引入了一个惩罚项来平衡模型的复杂度。换句话说，信息量准则 形式化地表示了我们在本章开头建立的一些直觉，用一种合适的方式 平衡模型对数据的解释能力和模型的复杂程度。</p>
<p>这些衡量方式的推导过程与信息论相关，不过这超出了本书的范 围，这里我们只从实用的角度去理解这些概念。</p>
<p><strong>log</strong>似然与偏差</p>
<p>一种衡量模型对数据的拟合程度的方法是计算模型预测结果与真 实数据之间的均方差。</p>
<p>231</p>
<p>![](C:/Program Files/Typora/media/image1864.png){width=”1.769951881014873in” height=”0.38525153105861765in”}</p>
<p>![](C:/Program Files/Typora/media/image1865.png){width=”0.655923009623797in” height=”0.187419072615923in”}其中，是根据预估参数值得到的预测值，可以看到基本<br />
上就是观察值和预测值之间的平均差异，求平方是为了保证正负误差</p>
<p>不会相互抵消，此外相比一些其他的衡量指标（比如绝对误差），该 衡量标准更强调较大的误差。</p>
<p>在数据已经是正态分布的情况下，前面的衡量方法计算简单而且 很有用，不过更通用的一种方法是计算log似然：</p>
<p>![](C:/Program Files/Typora/media/image1866.png){width=”0.8537412510936133in” height=”0.19783136482939634in”}</p>
<p>在一元线性回归模型中，log似然与二次均方差是成比例的。</p>
<p>由于历史原因，在实践中人们通常不直接使用log似然，而是使 用一个称作偏差平方和的量：</p>
<p>![](C:/Program Files/Typora/media/image1867.png){width=”1.0827941819772529in” height=”0.19783136482939634in”}</p>
<p>偏差平方和在贝叶斯方法和非贝叶斯方法中类似，区别在于，贝 叶斯框架中<em>θ</em>是从后验中估计出来的（和其他从后验中得到的量一 样），是一个分布。相反，在非贝叶斯方法中，<em>θ</em>是一个点估计。在 使用偏差平方和的时候，需要注意以下两点。</p>
<p>偏差平方和越小，log似然的值越大，模型的预测结果与数据越<br />
吻合。因此我们希望偏差平方和越小越好。<br />
偏差平方和衡量的是样本内的模型准确率，因而复杂的模型通常 会比简单模型的偏差平方和小。因而需要给复杂模型加入惩罚<br />
项。</p>
<p>下面我们将学习几个不同的信息校准方法，它们的共同点是都使</p>
<p>232</p>
<p>用了偏差平方和及正则项，区别在于偏差平方和和惩罚项的计算方式 不同。</p>
<p>赤池信息量准则</p>
<p>赤池信息量准则（Akaike Information Criterion，AIC）是一个广 泛应用的信息量准则，其定义如下：</p>
<p>![](C:/Program Files/Typora/media/image1871.png){width=”2.6341054243219597in” height=”0.35401465441819774in”}</p>
<p>![](C:/Program Files/Typora/media/image1872.png){width=”0.30193241469816273in” height=”0.20824365704286965in”}其中，表示参数的个数，是<em>θ</em>的最大似然估计。最大似然<br />
估计在非贝叶斯方法中经常用到，等价于使用贝叶斯方法中的均匀先</p>
<p>![](C:/Program Files/Typora/media/image1874.png){width=”0.30193241469816273in” height=”0.20824365704286965in”}验的最大后验估计。注意这里是点估计而不是分布。 前面的表达 式可以表示成如下形式：</p>
<p>![](C:/Program Files/Typora/media/image1875.png){width=”2.779866579177603in” height=”0.35401465441819774in”}</p>
<p>同样，这里的−2是出于历史原因。从实用的角度来看，上式中的 第1项考虑的是模型对数据的拟合效果，第2项衡量的是模型复杂度。 因此，如果两个模型对数据的解释能力相同，但是其中一个比另一个 的参数更多的话，AIC会告诉我们应该选择参数更少的那个。</p>
<p>AIC对于非贝叶斯方法来说很有用，但是对于贝叶斯方法可能会 有些问题。原因之一是AIC没有使用后验，因而将估计中的不确定信 息丢失了，此外假设用到的是均匀先验，因而该准则对于使用非均匀 先验的模型来说就不太合适了。在使用非均匀先验的时候，我们不能 简单地计算模型中参数的个数。合理使用非均匀先验相当于对模型使 用了正则，因而会降低过拟合的可能，也就是说带正则模型的有效参</p>
<p>数个数比真实的参数个数要少。类似的情况在多层模型中同样会出<br />
现，毕竟多层模型可以看作是从数据中学习先验的有效方式。</p>
<p>233</p>
<p>偏差信息量准则</p>
<p>一种获取贝叶斯形式的AIC的方法是从后验中获取信息，同时从 模型和数据中估计出参数的个数，这可以用偏差信息量准则<br />
（Deviance Information Criterion，DIC）来衡量：</p>
<p>![](C:/Program Files/Typora/media/image1877.png){width=”2.2488801399825022in” height=”0.35401465441819774in”}</p>
<p>![](C:/Program Files/Typora/media/image1878.png){width=”0.333167104111986in” height=”0.2394805336832896in”}可以看到DIC和AIC非常像，区别在于现在是从计算的偏差， 即<em>θ</em>的后验均值，而且我们现在使用来代表模型的有效参数个数， 用下式来表示：</p>
<p>![](C:/Program Files/Typora/media/image1880.png){width=”1.145262467191601in” height=”0.35401465441819774in”}</p>
<p>![](C:/Program Files/Typora/media/image1881.png){width=”8.32917760279965e-2in” height=”0.1770067804024497in”}上式的含义是偏差的均值减去均值的偏差。如果得到的是一个有 峰值的后验，<em>θ</em>聚集在附近，那么上式中的左右两项会比较相似，因 而会很小，相反，如果后验分布很广，那么会有更多的<em>θ</em>偏离，</p>
<p>![](C:/Program Files/Typora/media/image1884.png){width=”0.3852241907261592in” height=”0.21865594925634296in”}因而会很大，从而也就很大。</p>
<p>可以说，DIC是更偏贝叶斯形式的AIC，不过，DIC没有使用完<br />
整的后验，而且对于弱先验来说，根据DIC计算得到的参数的有效个</p>
<p>数会有些问题，为了解决这个问题，有一些替代方案。不过DIC对于 这里的讨论来说足够了，PyMC3中也已经实现了DIC。</p>
<p>通用信息量准则</p>
<p>通用信息量准则（Widely Available Information Criterion，<br />
WAIC）与DIC类似，不过更偏贝叶斯，因为它使用的是整个后验分</p>
<p>布。和AIC、DIC一样，我们可以看到WAIC同样有两项，一项衡量 模型对数据的拟合效果；另外一项衡量模型的复杂程度。</p>
<p>![](C:/Program Files/Typora/media/image1886.png){width=”1.9677701224846895in” height=”0.1770067804024497in”}</p>
<p>234</p>
<p>这里<em>lppd</em>是点预测的log，可以用下式近似：</p>
<p>![](C:/Program Files/Typora/media/image1888.png){width=”2.654928915135608in” height=”0.46854877515310583in”}</p>
<p>这里首先从后验中采样<em>S</em>个样本并计算似然的均值，然后对于数 据集中的<em>N</em>个数据点都重复该过程并求和。此外得到的有效参数个数 可以用如下形式计算：</p>
<p>![](C:/Program Files/Typora/media/image1889.png){width=”2.4571106736657917in” height=”0.2707163167104112in”}</p>
<p>也就是说，我们根据从后验中得到的<em>S</em>个采样值计算log似然的偏 差，然后对<em>N</em>个数据点都重复该过程并求和。直观上看这似乎与DIC 中计算有效参数个数的方法一样。在前面AIC部分讨论过，模型越灵 活，就越倾向于得到分布更广（更分散）的后验。</p>
<p>帕累托平滑重要性采样与留一交叉验证</p>
<p>该方法用于近似LOOCV的结果，不过不需要真的计算LOOCV。 这里不过多深入其细节，其核心思想是通过对似然重采样去近似 LOOCV，可以通过一种重要性采样的技巧实现。该方法的问题是得 到的结果不稳定，为了解决稳定性的问题，有人提出了一种新的方法 叫做PSIS，可以用于计算更可靠的LOOCV估计，其含义类似，值越 小，模型得到的估计预测准确率越高。</p>
<p>贝叶斯信息准则</p>
<p>与逻辑回归的名字一样，这个名称同样有误导性。贝叶斯信息<br />
准则（Bayesian Information Criterion，BIC）是用来校正AIC的一些问</p>
<p>题的，作者提出了一种贝叶斯校正方法。不过BIC实际上不是贝叶斯 的方法，而是更像AIC，因而假设先验是平坦的并使用最大似然估<br />
计。</p>
<p>235</p>
<p>更重要的是，BIC与我们见过的其他信息准则都不一样，它更像 后面章节中会讨论到的贝叶斯因子。基于这些理由，同时参考了 Andrew Gelman的建议，这里暂不深入讨论或使用BIC。</p>
<p><strong>6.3.3</strong>　用<strong>PyMC3</strong>计算信息量准则</p>
<p>通过PyMC3可以很容易计算出信息准则，只需要调用一个函数<br />
即可。为了简化它们的使用，我们将构建一个简单的模型，首先定义</p>
<p>一些数据并标准化。</p>
<p>real_alpha = 4.25</p>
<p>real_beta = [8.7, -1.2]</p>
<p>data_size = 20</p>
<p>noise = np.random.normal(0, 2, size=data_size)</p>
<p>x_1 = np.linspace(0, 5, data_size)</p>
<p>y_1 = real_alpha + real_beta[0] * x_1 + real_beta[1] * x_1**2 + noise<br />
order = 2</p>
<p>x_1p = np.vstack([x_1**i for i in range(1, order+1)])</p>
<p>x_1s = (x_1p - x_1p.mean(axis=1, keepdims=True))/x_1p.std(axis=1, keepd ims=True)</p>
<p>y_1s = (y_1 - y_1.mean())/y_1.std()</p>
<p>plt.scatter(x_1s[0], y_1s)</p>
<p>plt.xlabel(‘$x$’, fontsize=14)</p>
<p>plt.ylabel(‘$y$’, fontsize=14, rotation=0)</p>
<p>![](C:/Program Files/Typora/media/image1895.png){width=”5.01833552055993in” height=”3.446440288713911in”}</p>
<p>236</p>
<p>从图中可能看得不是特别明显，不过从代码中可以看到，我们得 到的数据可以用二阶多项式去拟合。假设我们有理由认为线性回归是 一个不错的模型，因此我们分别使用两个模型去拟合数据并用信息准 则比较它们，先从线性回归模型开始。</p>
<p>with pm.Model() as model_l:</p>
<p>alpha = pm.Normal(‘alpha’, mu=0, sd=10)</p>
<p>beta = pm.Normal(‘beta’, mu=0, sd=10)</p>
<p>epsilon = pm.HalfCauchy(‘epsilon’, 5)</p>
<p>mu = alpha + beta * x_1s[0]</p>
<p>y_pred = pm.Normal(‘y_pred’, mu=mu, sd=epsilon, observed=y_1s) trace_l = pm.sample(2000)</p>
<p>chain_l = trace_l[100:]</p>
<p>为了节省版面，这里我们省略了traceplot以及一些其他画图测</p>
<p>试的内容，不过你自己实现的时候可别省略了这部分内容，接下来继 续用二阶模型去拟合。</p>
<p>with pm.Model() as model_p:</p>
<p>alpha = pm.Normal(‘alpha’, mu=0, sd=10)</p>
<p>beta = pm.Normal(‘beta’, mu=0, sd=10, shape=x_1s.shape[0])<br />
epsilon = pm.HalfCauchy(‘epsilon’, 5)</p>
<p>mu = alpha + pm.math.dot(beta, x_1s)</p>
<p>y_pred = pm.Normal(‘y_pred’, mu=mu, sd=epsilon, observed=y_1s) trace_p = pm.sample(1000)</p>
<p>chain_p = trace_p[100:]</p>
<p>现在我们将结果和最佳拟合直线画出来。</p>
<p>alpha_l_post = chain_l[‘alpha’].mean()</p>
<p>betas_l_post = chain_l[‘beta’].mean(axis=0)</p>
<p>idx = np.argsort(x_1s[0])</p>
<p>y_l_post = alpha_l_post + betas_l_post * x_1s[0]</p>
<p>plt.plot(x_1s[0][idx], y_l_post[idx], label=’Linear’)</p>
<p>alpha_p_post = chain_p[‘alpha’].mean()</p>
<p>betas_p_post = chain_p[‘beta’].mean(axis=0)</p>
<p>y_p_post = alpha_p_post + np.dot(betas_p_post, x_1s)<br />
plt.plot(x_1s[0][idx], y_p_post[idx], label=’Pol order {}’.format(order ))</p>
<p>plt.scatter(x_1s[0], y_1s)</p>
<p>plt.legend()</p>
<p>237</p>
<p>![](C:/Program Files/Typora/media/image1910.png){width=”5.01833552055993in” height=”3.498501749781277in”}</p>
<p>想要用PyMC3得到DIC，我们需要将迹作为参数传给dic函数， 如果调用的位置发生在with语句内，那么对应的模型参数会自动猜</p>
<p>出来，当然也可以显示指定：</p>
<p>pm.dic(trace=trace_l, model=model_l)</p>
<p>同样，要计算WAIC调用pm.waic()即可，计算LOO则只需调<br />
用pm.loo()。对于WAIC和LOO，PyMC3会返回一个点估计和相应</p>
<p>的标准差，我们可以用标准差来评估WAIC（或LOO）估计的不确定 性。不过需要注意的是，由于标准差的估计值假设是正态的，因此当 样本量很小的时候不是很可靠。</p>
<p>![](C:/Program Files/Typora/media/image1915.png){width=”3.818678915135608e-2in” height=”2.2143405511811025in”}plt.figure(figsize=(8, 4))</p>
<p>plt.subplot(121)</p>
<p>for idx, ic in enumerate((waic_l, waic_p)):<br />
plt.errorbar(ic[0], idx, xerr=ic[1], fmt=’bo’) plt.title(‘WAIC’)</p>
<p>plt.yticks([0, 1], [‘linear’, ‘cuadratic’])<br />
plt.ylim(-1, 2)</p>
<p>plt.subplot(122)</p>
<p>for idx, ic in enumerate((loo_l, loo_p)):<br />
plt.errorbar(ic[0], idx, xerr=ic[1], fmt=’go’)</p>
<p>238 ![](C:/Program Files/Typora/media/image1918.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}</p>
<p>![](C:/Program Files/Typora/media/image1920.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}plt.title(‘LOO’)</p>
<p>plt.yticks([0, 1], [‘linear’, ‘cuadratic’]) plt.ylim(-1, 2)</p>
<p>plt.tight_layout()</p>
<p>![](C:/Program Files/Typora/media/image1924.png){width=”5.643024934383202in” height=”2.738409886264217in”}</p>
<p>下面讨论一下关于WAIC和LOO计算结果的可靠性。</p>
<p>计算WAIC或LOO时，你可能会得到这样一条警告信息：二者的 计算结果可能是不可靠的。该警告会根据一个经验性的值抛出（参考</p>
<p>本章深入阅读部分）。尽管这不是多大的问题，不过它可能意味着计 算过程中存在问题。WAIC和LOO相对较新，我们可能还需要构建一 些合适的方法得到它们的可靠性。不管如何，如果你遇到这种情况， 首先确保你有足够多的样本，同时模型的迹有较好的混合度，然后是 查看是否选用了一个”老化”的值。如果你还是得到警告，LOO的作者 建议使用更鲁棒的模型，比如用t分布替换高斯分布。如果这些建议</p>
<p>都没有效果，那么你可能需要考虑一些其他方法，比如直接使用K-折 交叉验证。</p>
<p><strong>6.3.4</strong>　解释和使用信息校准</p>
<p>信息校准的一个简单应用是进行模型选择，直接选出信息准则值<br />
较小的模型并忽略其他模型即可，因而我们可以根据前面的那些图表</p>
<p>239</p>
<p>得出以下结论：两种衡量标准都认为最好的模型是2阶的模型。</p>
<p>模型选择非常简单，但是这里我们抛掉了不确定性信息，这感觉 就像是我们计算出了完整的后验分布却只保留了后验的均值，其后果 是我们可能对得出的结论过于自信。</p>
<p>另一种做法是进行模型选择的同时，汇报和讨论不同模型的信息 准则值以及后验预测检查的结果。将问题中的背景、数据和检查都分 享出来很关键，因为这样人们才能更好地理解我们方法的极限和不</p>
<p>足。如果你在学术界，你可以在论文、演示等讨论部分按照这种方式 进行。</p>
<p>另外一种方法是进行模型平均，其思想是对每个模型加权之后生 成一个元模型。计算权重的一种方式是：</p>
<p>![](C:/Program Files/Typora/media/image1926.png){width=”2.1343536745406824in” height=”0.5206102362204724in”}</p>
<p>![](C:/Program Files/Typora/media/image1927.png){width=”0.343578302712161in” height=”0.14576990376202975in”}这里，是第<em>i</em>个信息准则的值与最小值之间的差。</p>
<p>我们可以根据任意信息准则计算出一系列权重，不过我们显然不 能将其混合在一起。上面的公式是一种启发式的方法，根据信息准则 的值计算每个模型的相对概率，其中的分母仅仅是一个归一项，使得 所有权重之和为1。</p>
<p>还有一些其他方式对模型求平均，比如显式的构建一个模型将我 们所有的模型包含在一起，然后进行参数推断，在后面贝叶斯因子部 分，我们将讨论其中的一种形式。</p>
<p>除了对离散的模型求平均之外，有时候我们还可以将其看作是连<br />
续的。一个简单的例子就是，假设我们有一个抛硬币问题以及两个不</p>
<p>240</p>
<p>同的模型，其中之一的先验偏向正面朝上，另一个偏向于反面朝上。 我们可以分别用两个模型去拟合并用dIC权重求平均，除此之外还可 以构建一个分层模型估计先验分布，注意这里构建的不再是两个离散 的模型了，而是一个连续的模型，其中包含两个离散的模型作为特<br />
例。哪种方法更好呢？还是要具体问题具体分析，最终使用哪一个取 决于实际问题是更适合用离散模型还是连续模型去描述。</p>
<p><strong>6.3.5</strong>　后验预测检查</p>
<p>前面几章中，我们介绍了后验预测检查的概念，并将其作为评估 模型对数据的解释能力的一种方式，我们称之为完备性检查。进行后 验预测检查的目的并不是为了说模型是错的，我们的目的是想知道哪 部分数据拟合得不够好，从而知道模型的极限在哪或者如何优化模</p>
<p>型。这里我们重新回顾这个话题，以此强调后验预测检查可以用来比 较模型并理解模型之间的不同点。</p>
<p>![](C:/Program Files/Typora/media/image1929.png){width=”3.819444444444445e-2in” height=”4.463378171478565in”}plt.subplot(121)</p>
<p>plt.scatter(x_1s[0], y_1s, c=’r’);</p>
<p>plt.ylim(-3, 3)</p>
<p>plt.xlabel(‘x’)</p>
<p>plt.ylabel(‘y’, rotation=0)</p>
<p>plt.title(‘Linear’)</p>
<p>for i in range(0, len(chain_l[‘alpha’]), 50):</p>
<p>plt.scatter(x_1s[0], chain_l[‘alpha’][i] + chain_l[‘beta’][i]*x_1s[ 0], c=’g’, edgecolors=’g’, alpha=0.05);</p>
<p>plt.plot(x_1s[0], chain_l[‘alpha’].mean() + chain_l[‘beta’].mean()*x_1s [0], c=’g’, alpha=1)</p>
<p>plt.subplot(122)</p>
<p>plt.scatter(x_1s[0], y_1s, c=’r’);</p>
<p>plt.ylim(-3, 3)</p>
<p>plt.xlabel(‘x’)</p>
<p>plt.ylabel(‘y’, rotation=0)</p>
<p>plt.title(‘Order {}’.format(order))</p>
<p>for i in range(0, len(chain_p[‘alpha’]), 50):</p>
<p>plt.scatter(x_1s[0], chain_p[‘alpha’][i] + np.dot(chain_p[‘beta’][i ], x_1s), c=’g’, edgecolors=’g’, alpha=0.1)</p>
<p>idx = np.argsort(x_1)</p>
<p>plt.plot(x_1s[0][idx], alpha_p_post + np.dot(betas_p_post, x_1s)[idx],</p>
<p>![](C:/Program Files/Typora/media/image1932.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}241</p>
<p>![](C:/Program Files/Typora/media/image1934.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}c=’g’, alpha=1)</p>
<p>![](C:/Program Files/Typora/media/image1938.png){width=”5.643024934383202in” height=”2.78005905511811in”}</p>
<p>242</p>
<p><strong>6.4</strong>　贝叶斯因子</p>
<p>在贝叶斯的世界中，评估和比较模型的另一种方式是使用贝叶斯 因子。</p>
<p>使用贝叶斯因子时，在单个模型中可能存在某些先验对后验分布 没有实际影响，但却对贝叶斯因子有较大影响。前面的例子中你可能 注意到了，通常一个标准差为100的正态先验与标准差为1000的正态</p>
<p>先验对后验的效果差不多，而贝叶斯因子则会受到模型中这类变化的 影响。贝叶斯因子的另外一个问题是计算起来可能要比推断过程更复 杂。最后一点是，贝叶斯因子可以用来做假设检验，这本来不是什么 问题，不过许多作者指出，类似本书提到的基于模型和推断的思维， 要比基于假设检验的这类思维在大多数问题上更好。为了更好地理解 什么是贝叶斯因子，这里我们再重新写一遍贝叶斯理论：</p>
<p>![](C:/Program Files/Typora/media/image1941.png){width=”1.9157130358705161in” height=”0.4477241907261592in”}</p>
<p>其中，<em>y</em>表示数据，<em>θ</em>表示参数，你也可以写成如下形式：</p>
<p>![](C:/Program Files/Typora/media/image1942.png){width=”2.842334864391951in” height=”0.45813648293963255in”}</p>
<p>两个式子的唯一区别是：重写后的式子中显式地描述了推断过程 中依赖的模型<em>M</em>。其中分母称为证据或者边缘似然。目前为止，得益 于推断引擎（如Metropolis 和NUTS），我们将这一项省略了。这里</p>
<p>可以将证据表示成如下：</p>
<p>![](C:/Program Files/Typora/media/image1943.png){width=”3.0713877952755904in” height=”0.19783136482939634in”}</p>
<p>![](C:/Program Files/Typora/media/image1944.png){width=”0.666334208223972in” height=”0.187419072615923in”}也就是说，为了计算出证据，我们需要边缘化（通过求</p>
<p>243</p>
<p>![](C:/Program Files/Typora/media/image1946.png){width=”0.666334208223972in” height=”0.187419072615923in”}和或者积分）所有可能的，即根据给定模型边缘化所有<em>θ</em>的先 验。</p>
<p>![](C:/Program Files/Typora/media/image1944.png){width=”0.666334208223972in” height=”0.187419072615923in”}本身没有多少信息量，就像信息准则一样，重要的是其<br />
相对值，因此，当我们希望比较两个不同模型的时候，我们会计算其</p>
<p>证据的比例，从而得到贝叶斯因子：</p>
<p>![](C:/Program Files/Typora/media/image1948.png){width=”1.3639041994750656in” height=”0.45813648293963255in”}</p>
<p>当<em>BF</em> \ 1时，模型0比模型1对数据解释得更好。有人总结出了下 面的列表来表示模型0与模型1的对比。</p>
<p>1-3：微弱<br />
3-10：中等<br />
10-30：强<br />
30-100：很强 \100：非常强</p>
<p>注意，这些准则都是一些经验性的指导，最终结果一定要放在具 体场景中去解释，同时还应该给出足够多的信息方便别人检查，从而 确定是否同意我们的结论。得出结论所需的证据在不同场合下是不一 样的。比如说你是在做粒子物理学，或是在法庭上，又或者是决定是 否要撤离一个城镇以防止数百人死亡。</p>
<p><strong>6.4.1</strong>　类比信息量准则</p>
<p>如果对贝叶斯因子求log，我们可以将两个边缘似然的比值转换<br />
成做差，这样比较边缘似然就与前面比较信息准则类似了。不过，衡</p>
<p>量模型对数据的拟合程度的项以及惩罚项去哪儿了呢？前者包含在了</p>
<p>244</p>
<p>似然的部分，而后者是对先验取平均的部分。参数越多，先验空间相 比似然就越大，因而平均之后似然就会较低，而且参数越多，先验就 会越分散，因而在计算证据的时候惩罚越大。这也是为什么人们说贝 叶斯理论会很自然地惩罚更复杂的模型，或者称贝叶斯理论自带奥卡 姆剃刀。</p>
<p><strong>6.4.2</strong>　计算贝叶斯因子</p>
<p>![](C:/Program Files/Typora/media/image1955.png){width=”0.7392147856517935in” height=”0.187419072615923in”}贝叶斯因子的计算可以视作分层模型的应用，其中高层的参数可 以看作是从一个类别分布中采样后将序号赋给每个模型。换句话说， 我们同时对两个（或多个）模型进行推断，同时用一个离散的变量在 模型之间做选择。对每个模型的采样次数正比于 ，为了计算</p>
<p>贝叶斯因子，我们有下式：</p>
<p>![](C:/Program Files/Typora/media/image1956.png){width=”2.4258759842519684in” height=”0.45813648293963255in”}</p>
<p>等式右边的第一项称作后验相对可能性，第2项称作先验相对可 能性。回忆一下前面我们对相对可能性的定义。如果你好奇等式是怎</p>
<p>![](C:/Program Files/Typora/media/image1957.png){width=”0.7288035870516185in” height=”0.187419072615923in”}么来的，根据贝叶斯理论将 和 展开后相除即可。为了 展示贝叶斯因子的计算过程，这里再次以抛硬币问题为例。</p>
<p>coins = 30</p>
<p>heads = 9</p>
<p>y = np.repeat([0, 1], [coins-heads, heads])</p>
<p>用Kruschke图将我们的模型表示出来，如图所示，这个例子中， 我们选用了两个beta先验：一个趋近于0；另一个趋近于1。</p>
<p>245</p>
<p>![](C:/Program Files/Typora/media/image1964.png){width=”3.768956692913386in” height=”5.268577209098862in”}</p>
<p>注意这里我们计算贝叶斯因子时比较的是模型之间先验的不同， 当然，模型之间的似然或者两者同时都有可能不同，本质上思想是一 致的。接下来用PyMC3构建模型。为了切换先验，我们使用了</p>
<p>pm.switch()函数，如果该函数的第一个参数为0，则返回第2个参<br />
数，否则返回第3个参数。这里我们同样使用pm.math.eq()函数去检 查model_index变量是否为0。</p>
<p>![](C:/Program Files/Typora/media/image1965.png){width=”3.818897637795276e-2in” height=”1.8915616797900263in”}with pm.Model() as model_BF:<br />
p = np.array([0.5, 0.5])<br />
model_index = pm.Categorical(‘model_index’, p=p)</p>
<p>m_0 = (4, 8)<br />
m_1 = (8, 4)<br />
m = pm.switch(pm.math.eq(model_index, 0), m_0, m_1)</p>
<p>theta = pm.Beta(‘theta’, m[0], m[1])</p>
<p>y = pm.Bernoulli(‘y’, theta, observed=y)</p>
<p>246 ![](C:/Program Files/Typora/media/image1968.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”}</p>
<p>![](C:/Program Files/Typora/media/image1970.png){width=”2.7777777777777776e-2in” height=”2.7777777777777776e-2in”} trace_BF = pm.sample(5000) chain_BF = trace_BF[500:]<br />
pm.traceplot(chain_BF)</p>
<p>![](C:/Program Files/Typora/media/image1974.png){width=”5.643024934383202in” height=”1.7596620734908137in”}</p>
<p>现在我们可以通过变量model_index计算贝叶斯因子，注意我们 已经有了每个模型的先验：</p>
<p>pM1 = chain_BF[‘model_index’].mean() pM0 = 1 - pM1</p>
<p>BF = (pM0/pM1)*(p[1]/p[0])</p>
<p>最终得到的贝叶斯因子的值约为11，也就是说，我们更倾向于使 用模型0。这个结论完全合理，因为对于<em>θ</em>=5的情况，正面朝上出现得 更少，两个模型之间的唯一区别是模型0更适用于<em>θ</em>&lt; 0.5（反面朝上多 于正面朝上），而模型1更适用于<em>θ</em> \0.5（正面朝上多于反面朝上）。</p>
<p>下面讲一下计算贝叶斯因子的一些常见问题。</p>
<p>用我们定义的方式计算贝叶斯因子会有一些问题，比如当其中一 个模型比另一个模型更好时，根据定义，我们会对更好的这个模型采 样次数更多，这可能会导致我们对另外一个模型欠采样。另外，第1</p>
<p>个问题是：即使某些参数没有用于拟合数据，也会更新。也就是说， 当模型0被选择时，模型1中的参数也会更新，不过由于这部分参数并 没有用于解释数据，值受限于先验。如果先验太模糊，有可能当我们 选到模型1时，参数值距离上一次被接受的值太远了，因而该步被拒</p>
<p>绝，从而导致采样会出现问题。</p>
<p>247</p>
<p>程。</p>
<p>为了避免遇到这些问题，我们对模型做了两处修改来改进采样过</p>
<p>理想情况下，如果两个模型都访问相同次数，我们会得到一个更 好的采样，因此我们对模型的先验做出调整（前一个模型中的<em>p</em> 值），从而向原来访问频次较低的模型倾斜。这个过程对贝叶斯 因子的计算不会有多大影响，因为我们在计算过程中包含了先<br />
验。<br />
根据Kruschke以及其他人的建议，可以使用伪先验，其思想很简 单：当没被选择的模型的参数出现自由漂移时，可以尝试手动限 制它们，不过是在这个模型没被使用的时候。你可以在Kruschke 的书中找到使用伪先验的例子，我将对应的例子转成了<br />
Python/PyMC3，可以查看这里：<br />
<a class="reference external" href="https://github.com/aloctavodia/Doingbayesian_data">https://github.com/aloctavodia/Doing<em>bayesian_data</em></a> analysis。</p>
<p>248</p>
<p><strong>6.5</strong>　贝叶斯因子与信息量准则</p>
<p>前面我们已经说过，贝叶斯因子对先验过于敏感，做推断时某些 参数对推断结果几乎没有影响，但得到的贝叶斯因子却有很大区别。 这也是许多贝叶斯学派的人不喜欢贝叶斯因子的原因之一。 现在我</p>
<p>们来看一个例子，帮助我们理解什么是贝叶斯因子以及信息准则。回 到抛硬币例子中定义数据的部分，现在我们将硬币数量设为300个， 90个正面朝上。这个比例与之前的类似，不过现在的数据量是之前的 10倍，然后单独运行每个模型。</p>
<p>with pm.Model() as model_BF_0:</p>
<p>theta = pm.Beta(‘theta’, 4, 8)</p>
<p>y = pm.Bernoulli(‘y’, theta, observed=y)</p>
<p>trace_BF_0 = pm.sample(5000) chain_BF_0 = trace_BF_0[500:]<br />
pm.traceplot(trace_BF_0);</p>
<p>![](C:/Program Files/Typora/media/image1989.png){width=”5.643024934383202in” height=”0.791327646544182in”}</p>
<p>with pm.Model() as model_BF_1:</p>
<p>theta = pm.Beta(‘theta’, 8, 4)</p>
<p>y = pm.Bernoulli(‘y’, theta, observed=y) trace_BF_1 = pm.sample(5000)<br />
pm.traceplot(trace_BF_1);</p>
<p>![](C:/Program Files/Typora/media/image1994.png){width=”5.643024934383202in” height=”0.8017399387576553in”}</p>
<p>对后验进行检查，尽管二者的先验不同，可以看到两个模型的预 测结果很相似。原因是我们有足够的数据，从而将先验的效果削弱了 （尽管效果还在）。现在对两个模型计算贝叶斯因子，可以得到结果</p>
<p>249</p>
<p>约为25，这个结果意味着我们更倾向于模型0。可以看出，当我们增 加数据个数的时候，不同模型之间的对比更明显了，这一点完全合<br />
理，因为数据更多的时候，我们更加确定模型1的先验假设与实际的 数据不符。不过需要注意，当我们增加数据的时候，两个模型都倾向 于得出相同的<em>θ</em>值，实际上两个模型得到的值都接近0.3。因此，如果 打算用<em>θ</em>做预测，那么两个模型其实没有特别大的区别。在这个例子 中，贝叶斯因子告诉我们一个模型要比另外一个模型更好，某种程度 上是在帮助我们找到真正的模型，不过如果只是根据两个模型估计出 来的参数做预测，二者的结果差不多。</p>
<p>再比较下WAIC和LOO（如图）；模型0和模型1的WAIC分别约<br />
为368.4和368.6，LOO分别约为366.4和366.7。直观上看区别似乎很 小，不过重要的是在30个硬币中应该有9个正面朝上的情况下，模型0 和模型1的WAIC分别为38.1和39.4，LOO分别为36.6和38.0。也就是 说，相对差别随着数据量的增加而减少了，<em>θ</em>的估计值越相似，根据 信息准则得到的预测准确率的结果也越相似。这个例子应该能澄清贝 叶斯因子与信息准则之间的区别了。</p>
<p>下图显示了WAIC和LOO以及它们的标准差，第1行对应抛硬币 问题中的30个样本中9次正面朝上的情况；第2行对应300个样本中90</p>
<p>个正面朝上的情况。</p>
<p>250</p>
<p>![](C:/Program Files/Typora/media/image1997.png){width=”5.643024934383202in” height=”3.8004560367454068in”}</p>
<p>251</p>
<p><strong>6.6</strong>　总结</p>
<p>本章开始我们先建立了这样一种直观感受：好的模型应该能简单 有效地解释数据。基于该直觉，我们讨论了统计学和机器学习中的过 拟合和欠拟合问题，首先分析了传统的AIC，然后是与之类似的更符 合贝叶斯的DIC，接下来讨论了基于二者的改进版WAIC。同时我们</p>
<p>还简单讨论了经验性的交叉验证方法以及采用LOO对其结果进行近似 的方法。本章还从另外一个角度简要讨论了先验与多层模型。最后， 我们讨论了贝叶斯因子，如何计算贝叶斯因子，以及如何解决一些与 之相关的采样问题。本章的最后还解释了使用贝叶斯因子与信息准则 的不同目的。</p>
<p>252</p>
<p><strong>6.7</strong>　深入阅读</p>
<p>《Statistical Rethinking》中的第6章。</p>
<p>《Doing Bayesian Data Analysis, Second Edition》中的第10章。 《Bayesian Data Analysis, Third Edition》中的第7章。</p>
<p>Jake VanderPlas关于模型选择的一篇博客：</p>
<p>&lt;<a class="reference external" href="http://jakevdp.github.io/blog/2015/">http://jakevdp.github.io/blog/2015/</a> 08/07/frequentism-and-<br />
bayesianism-5-model-selection/。<br />
用LOOCV和WAIC对贝叶斯模型进行评估：<br />
<a class="reference external" href="http://arxiv.org/abs/1507.04544%E3%80%82">http://arxiv.org/abs/1507.04544。</a></p>
<p>253</p>
<p><strong>6.8</strong>　练习</p>
<p>（1）本题与正则先验有关。在生成数据部分的代码中，<br />
将order=2改成其他值，比如order=5，然后拟合model_p并画出结</p>
<p>果的曲线。重复该过程，用st=100的beta分布替换st=1的beta分布并画 出结果曲线。两种情况下的曲线有什么不同？如果换做<br />
sd=np.array([10, 0.1, 0.1, 0.1, 0.1])呢？</p>
<p>（2）重复上面的练习，将数据的个数增加到500。</p>
<p>（3）用3阶的数据去拟合，计算WAIC和LOO，画出结果，将它 们与线性和抛物线模型进行比较。</p>
<p>（4）用pm.sample_ppc()重跑PPC的例子，不过画出<em>y</em>的值而非其 均值。</p>
<p>（5）阅读并运行PyMC3官方文档中后验预测的例子：<br />
<a class="reference external" href="https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html%E3%80%82%E7%89%B9%E5%88%AB%E7%95%99%E6%84%8FTheano%E4%B8%AD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8%E3%80%82">https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html。</a></p>
<p><a class="reference external" href="https://pymc-devs.github.io/pymc3/notebooks/posterior_predictive.html%E3%80%82%E7%89%B9%E5%88%AB%E7%95%99%E6%84%8FTheano%E4%B8%AD%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E7%9A%84%E4%BD%BF%E7%94%A8%E3%80%82">特别留意Theano中共享变量的使用。</a></p>
<p>（6）分别用均匀先验beta(1,1)和其他先验（如beta(0.5,0.5)）比<br />
较抛硬币问题中的贝叶斯因子。将数据个数设为30，其中15次正面朝</p>
<p>上。将推断结果与第1章中得到的结果进行比较。</p>
<p>（7）重复本章最后一个例子，减少样本大小，然后再比较贝叶 斯因子与信息量准则。</p>
<p>254</p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="chapter04-GeneralizedLinearRegression.html" title="previous page">第4章 利用Logistic 回归 对结果进行分类</a>
    <a class='right-next' id="next-link" href="chapter06-MixtureModels.html" title="next page">第6章　混合模型</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Guoliang PU<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>